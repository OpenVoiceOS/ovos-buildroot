[
    {
        "_id": "Kibibyte",
        "clean": "Kibibyte",
        "text": "The kibibyte is a multiple of the unit byte for quantities of digital information. The binary prefix kibi means 210, or 1024; therefore, 1 kibibyte is 1024 bytes.  The unit symbol for the kibibyte is KiB.The unit was established by the International Electrotechnical Commission (IEC) in 1998, has been accepted for use by all major standards organizations, and is part of the International System of Quantities.   The kibibyte was designed to replace the kilobyte in those computer science contexts in which the term kilobyte is used to mean 1024 bytes. The interpretation of kilobyte to denote 1024 bytes, conflicting with the SI definition of the prefix kilo (1000), used to be common.One thousand twenty-four kibibytes (1024 KiB) is equal to one mebibyte (1 MiB).\n\n\n== Definition ==\n1 kibibyte = 210 bytes = 1024 bytes.The prefix kibi is derived as a portmanteau of the words kilo and binary, indicating its origin in the closeness in value to the SI prefix kilo (1000). While the SI prefix is written with lowercase (k), all IEC binary prefixes start with an uppercase letter.One byte is defined by IEC/80000-13 as 8 bits (1 B = 8 bit).  Therefore, 1 KiB = 8192 bit.\n\n\n== History ==\nThe kibibyte is closely related to the kilobyte. The latter term is often used in some contexts as a synonym for kibibyte, but formally refers to 103 bytes = 1000 bytes, as the prefix kilo is defined in the International System of Units.\nThe binary interpretation of the metric prefixes causes relatively small differences with the smallest prefixes in the series, i.e. for kilo and mega, but grows to substantial differences beyond.\nDonald Knuth proposed to call this unit a large kilobyte (KKB).In product advertising and other non-scientific publications, \"kilobyte\" sometimes refers to a power of ten and sometimes a power of two.\n\n\n== See also ==\nIEC 80000-13\nIEEE 1541\nTimeline of binary prefixes\n\n\n== References ==",
        "unit": "kibibyte",
        "url": "https://en.wikipedia.org/wiki/Kibibyte"
    },
    {
        "_id": "Day",
        "clean": "Day",
        "text": "A day, a unit of time, is approximately the period of time during which the Earth completes one rotation with respect to the Sun (solar day). In 1960, the second was redefined in terms of the orbital motion of the Earth in year 1900, and was designated the SI base unit of time. The unit of measurement \"day\", was redefined as 86 400 SI seconds and symbolized d. In 1967, the second and so the day were redefined by atomic electron transition. A civil day is usually 86 400 seconds, plus or minus a possible leap second in Coordinated Universal Time (UTC), and   occasionally plus or minus an hour in those locations that change from or to daylight saving time. \nDay can be defined as each of the twenty-four-hour periods, reckoned from one midnight to the next, into which a week, month, or year is divided, and corresponding to a rotation of the earth on its axis. However its use depends on its context, for example when people say 'day and night', 'day' will have a different meaning. It will mean the interval of light between two successive nights; the time between sunrise and sunset. People tend to sleep during the night and are awake at a day, in this instance 'day' will mean time of light between one night and the next. However, in order to be clear when using 'day' in that sense, \"daytime\" should be used to distinguish it from \"day\" referring to a 24-hour period; this is since daytime typically always means 'the time of the day between sunrise and sunset. The word day may also refer to a day of the week or to a calendar date, as in answer to the question, \"On which day?\" The life patterns (circadian rhythms) of humans and many other species are related to Earth's solar day and the day-night cycle.\n\n\n== Introduction ==\n\n\n=== Apparent and mean solar day ===\nSeveral definitions of this universal human concept are used according to context, need and convenience. Besides the day of 24 hours (86 400 seconds), the word day is used for several different spans of time based on the rotation of the Earth around its axis. An important one is the solar day, defined as the time it takes for the Sun to return to its culmination point (its highest point in the sky). Because celestial orbits are not perfectly circular, and thus objects travel at different speeds at various positions in their orbit, a solar day is not the same length of time throughout the orbital year. Because the Earth orbits the Sun elliptically as the Earth spins on an inclined axis, this period can be up to 7.9 seconds more than (or less than) 24 hours. In recent decades, the average length of a solar day on Earth has been about 86 400.002 seconds (24.000 000 6 hours) and there are about 365.2422 solar days in one mean tropical year. \nAncient custom has a new day start at either the rising or setting of the Sun on the local horizon (Italian reckoning, for example, being 24 hours from sunset, oldstyle). The exact moment of, and the interval between, two sunrises or sunsets depends on the geographical position (longitude as well as latitude), and the time of year (as indicated by ancient hemispherical sundials).\nA more constant day can be defined by the Sun passing through the local meridian, which happens at local noon (upper culmination) or midnight (lower culmination). The exact moment is dependent on the geographical longitude, and to a lesser extent on the time of the year. The length of such a day is nearly constant (24 hours \u00b1 30 seconds). This is the time as indicated by modern sundials.\nA further improvement defines a fictitious mean Sun that moves with constant speed along the celestial equator; the speed is the same as the average speed of the real Sun, but this removes the variation over a year as the Earth moves along its orbit around the Sun (due to both its velocity and its axial tilt).\n\n\n=== Stellar day ===\nA day, understood as the span of time it takes for the Earth to make one entire rotation with respect to the celestial background or a distant star (assumed to be fixed), is called a stellar day. This period of rotation is about 4 minutes less than 24 hours (23 hours 56 minutes and 4.1 seconds) and there are about 366.2422 stellar days in one mean tropical year (one stellar day more than the number of solar days). Other planets and moons have stellar and solar days of different lengths from Earth's.\n\n\n=== Daytime ===\nA day, in the sense of daytime that is distinguished from night-time, is commonly defined as the period during which sunlight directly reaches the ground, assuming that there are no local obstacles. The length of daytime averages slightly more than half of the 24-hour day. Two effects make daytime on average longer than nights. The Sun is not a point, but has an apparent size of about 32 minutes of arc. Additionally, the atmosphere refracts sunlight in such a way that some of it reaches the ground even when the Sun is below the horizon by about 34 minutes of arc. So the first light reaches the ground when the centre of the Sun is still below the horizon by about 50 minutes of arc. Thus, daytime is on average around 7 minutes longer than 12 hours.\n\n\n== Etymology ==\nThe term comes from the Old English d\u00e6g, with its cognates such as dagur in Icelandic, Tag in German, and dag in Norwegian, Danish, Swedish and Dutch. All of them from the Indo-European root dyau which explains the similarity with Latin dies though the word is known to come from the Germanic branch. As of  October 17, 2015, day is the 205th most common word in US English, and the 210th most common in UK English.\n\n\n== International System of Units (SI) ==\nA day, symbol d, defined as 86 400 seconds, is not an SI unit, but is accepted for use with SI. The Second is the base unit of time in SI units.\n\nIn 1967\u201368, during the 13th CGPM (Resolution 1), the International Bureau of Weights and Measures (BIPM) redefined a second as \u2026 the duration of 9 192 631 770 periods of the radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium 133 atom.\nThis makes the SI-based day last exactly 794 243 384 928 000 of those periods.\n\n\n=== Leap seconds ===\nMainly due to tidal effects, the Earth's rotational period is not constant, resulting in minor variations for both solar days and stellar \"days\". The Earth's day has increased in length over time. This phenomenon is due to tides raised by the Moon which slow Earth's rotation. Because of the way the second is defined, the mean length of a day is now about 86 400.002 seconds, and is increasing by about 1.7 milliseconds per century (an average over the last 2 700 years). (See tidal acceleration for details.) The length of a day circa 620 million years ago has been estimated from rhythmites (alternating layers in sandstone) as having been about 21.9 hours. The length of day for the Earth before the moon was created is still unknown.In order to keep the civil day aligned with the apparent movement of the Sun, a day according to Coordinated Universal Time (UTC) can include a negative or positive leap second. Therefore, although typically 86 400 SI seconds in duration, a civil day can be either 86 401 or 86 399 SI seconds long on such a day.\nLeap seconds are announced in advance by the International Earth Rotation and Reference Systems Service (IERS), which measures the Earth's rotation and determines whether a leap second is necessary. Leap seconds occur only at the end of a UTC-calculated month, and have only ever been inserted at the end of June 30 or December 31.\n\n\n=== Civil day ===\nFor civil purposes, a common clock time is typically defined for an entire region based on the local mean solar time at a central meridian. Such time zones began to be adopted about the middle of the 19th century when railroads with regularly occurring schedules came into use, with most major countries having adopted them by 1929. As of 2015, throughout the world, 40 such zones are now in use: the central zone, from which all others are defined as offsets, is known as UTC\u00b100, which uses Coordinated Universal Time (UTC).\nThe most common convention starts the civil day at midnight: this is near the time of the lower culmination of the Sun on the central meridian of the time zone. Such a day may be referred to as a calendar day.\nA day is commonly divided into 24 hours of 60 minutes, with each minute composed of 60 seconds.\n\n\n=== Decimal and metric time ===\n\nIn the 19th century, an idea circulated to make a decimal fraction (\u200b1\u204410 000 or \u200b1\u2044100 000) of an astronomical day the base unit of time. This was an afterglow of the short-lived movement toward a decimalisation of timekeeping and the calendar, which had been given up already due to its difficulty in transitioning from traditional, more familiar units. The most successful alternative is the centiday, equal to 14.4 minutes (864 seconds), being not only a shorter multiple of an hour (0.24 vs 2.4) but also closer to the SI multiple kilosecond (1 000 seconds) and equal to the traditional Chinese unit, k\u00e8.\n\n\n== Colloquial ==\nThe word refers to various similarly defined ideas, such as:\n\nFull day24 hours (exactly)\nThe full day covering both the dark and light periods, beginning from the start of the dark period or from a point near the middle of the dark period\nA full dark and light period, sometimes called a nychthemeron in English, from the Greek for night-day; or more colloquially the term 24 hours. In other languages, 24 hours is also often used. Other languages also have a separate word for a full day.DaytimeThe period of light when the Sun is above the local horizon (that is, the time period from sunrise to sunset)\nThe time period from 06:00\u201318:00 (6:00 am \u2013 6:00 pm) or 21:00 (9:00 pm) or another fixed clock period overlapping or offset from other time periods such as \"morning\", \"evening\", or \"night\".\nThe time period from first-light \"dawn\" to last-light \"twilight\".\n\n\n== Boundaries ==\n\nFor most diurnal animals, the day naturally begins at dawn and ends at sunset. Humans, with their cultural norms and scientific knowledge, have employed several different conceptions of the day's boundaries. Common convention among the ancient Romans, ancient Chinese and in modern times is for the civil day to begin at midnight, i.e. 00:00, and last a full 24 hours until 24:00 (i.e. 00:00 of the next day).  \nIn ancient Egypt, the day was reckoned from sunrise to sunrise.\nThe Jewish day begins at either sunset or nightfall (when three second-magnitude stars appear). The \"Damascus Document\", copies of which were also found among the Dead Sea scrolls, states regarding the observance of the Sabbath that \"No one is to do any work on Friday from the moment that the Sun's disk stands distant from the horizon by the length of its own diameter,\" presumably indicating that the monastic community responsible for producing this work counted the day as ending shortly before the Sun had begun to set.Medieval Europe also followed this tradition, known as Florentine reckoning: in this system, a reference like \"two hours into the day\" meant two hours after sunset and thus times during the evening need to be shifted back one calendar day in modern reckoning. Days such as Christmas Eve, Halloween, and the Eve of Saint Agnes are remnants of the older pattern when holidays began during the prior evening. Prior to 1926, Turkey had two time systems: Turkish (counting the hours from sunset) and French (counting the hours from midnight).\nIn many cultures, nights are named after the previous day. For example,\"Friday night\" usually means the entire night between Friday and Saturday. This difference from the civil day often leads to confusion. Events starting at midnight are often announced as occurring the day before. TV-guides tend to list nightly programs at the previous day, although programming a VCR requires the strict logic of starting the new day at 00:00 (to further confuse the issue, VCRs set to the 12-hour clock notation will label this \"12:00 AM\"). Expressions like \"today\", \"yesterday\" and \"tomorrow\" become ambiguous during the night. Because Jews and Muslims begin their days at nightfall, \"Saturday\" night, for example, is what most people would call Friday night.\nValidity of tickets, passes, etc., for a day or a number of days may end at midnight, or closing time, when that is earlier. However, if a service (e.g., public transport) operates from for example, 6:00 to 1:00 the next day (which may be noted as 25:00), the last hour may well count as being part of the previous day. For services depending on the day (\"closed on Sundays\", \"does not run on Fridays\", and so on) there is a risk of ambiguity. For example, a day ticket on the Nederlandse Spoorwegen (Dutch Railways) is valid for 28 hours, from 0:00 to 28:00 (that is, 4:00 the next day); the validity of a pass on Transport for London (TfL) services is until the end of the \"transport day\"\u2014that is to say, until 4:30 am on the day after the \"expiry\" date stamped on the pass.\n\n\n== Midnight sun ==\nIn places which experience the midnight sun (polar day), daytime may extend beyond one 24 hour period and could even extend to months\n\n\n== See also ==\nCalculating the day of the week\nDaylight\nDaytime\nDay length fluctuations\nHoliday\nISO 8601\nMeteorological day\nNychthemeron\nSeason, for a discussion of daylight and darkness at various latitudes\nSynodic day\nSidereal time\nZmanim\n\n\n== References ==\n\n\n== External links ==\n Media related to Day at Wikimedia Commons\n The dictionary definition of day at Wiktionary\n Quotations related to Day at Wikiquote",
        "unit": "day",
        "url": "https://en.wikipedia.org/wiki/Day"
    },
    {
        "_id": "Coulomb",
        "clean": "Coulomb",
        "text": "The coulomb (symbol: C) is the International System of Units (SI) unit of electric charge. It is the charge (symbol: Q or q) transported by a constant current of one ampere in one second:\n\n  \n    \n      \n        1\n         \n        \n          C\n        \n        =\n        1\n         \n        \n          A\n        \n        \u22c5\n        1\n         \n        \n          s\n        \n      \n    \n    {\\displaystyle 1~{\\text{C}}=1~{\\text{A}}\\cdot 1~{\\text{s}}}\n  Thus, it is also the amount of excess charge on a capacitor of one farad charged to a potential difference of one volt:\n\n  \n    \n      \n        1\n         \n        \n          C\n        \n        =\n        1\n         \n        \n          F\n        \n        \u22c5\n        1\n         \n        \n          V\n        \n      \n    \n    {\\displaystyle 1~{\\text{C}}=1~{\\text{F}}\\cdot 1~{\\text{V}}}\n  It is equivalent to the charge of approximately 6.242\u00d71018 (1.036\u00d710\u22125 mol) protons, and \u22121 C is equivalent to the charge of approximately 6.242\u00d71018 electrons.\n\n\n== Name and notation ==\nThis SI unit is named after Charles-Augustin de Coulomb. As with every International System of Units (SI) unit named for a person, the first letter of its symbol is upper case (C). However, when an SI unit is spelled out in English, it is treated as a common noun and should always begin with a lower case letter (coulomb)\u2014except in a situation where any word in that position would be capitalized, such as at the beginning of a sentence or in material using title case.\n\n\n== Definition ==\nThe SI system defines the coulomb in terms of the ampere and second: 1 C = 1 A \u00d7 1 s. The second is defined in terms of a frequency naturally emitted by caesium atoms. The ampere is defined using Amp\u00e8re's force law; the definition relies in part on the mass of the international prototype kilogram, a metal cylinder housed in France. In practice, the Kibble balance is used to measure amperes with the highest possible accuracy.Since the charge of one electron is known to be about 1.6021766208(98)\u00d710\u221219 C, 1 C can also be considered the charge of roughly 6.241509\u00d710^18 electrons or +1 C the charge of that many positrons or protons, where the number is the reciprocal of 1.602177\u00d710^\u221219.\nBy 1873, the British Association for the Advancement of Science had defined the volt, ohm and farad, but not the coulomb.  In 1881, the International Electrical Congress, now the International Electrotechnical Commission (IEC), approved the volt as the unit for electromotive force, the ampere as the unit for electic current and the coulomb as the unit of electric charge.  \nAt that time, the volt was defined as the potential difference [i.e., what is nowadays called the \"voltage (difference)\"] across a conductor when a current of one ampere dissipates one watt of power.\nThe coulomb (later \"absolute coulomb\" or \"abcoulomb\" for disambiguation) was part of the EMU system of units. The \"international coulomb\" based on laboratory specifications for its measurement was introduced by the IEC in 1908. The entire set of \"reproducible units\" was abandoned in 1948 and the \"international coulomb\" became the modern Coulomb.The proposed redefinition of the ampere and other SI base units would have the effect of fixing the numerical value of the elementary charge to an explicit constant expressed in coulombs, and therefore it would implicitly fix the value of the coulomb when expressed as a multiple of the fundamental charge (the numerical values of those quantities are the multiplicative inverses of each other).\n\n\n== SI prefixes ==\nSee also Metric prefix.\n\n\n== Conversions ==\nOne coulomb is the magnitude (absolute value) of electrical charge in 6.24150934(14)\u00d710^18 protons or electrons.\nThe inverse of this number gives the elementary charge of 1.6021766208(98)\u00d710\u221219 C.\nThe magnitude of the electrical charge of one mole of elementary charges (approximately 6.022\u00d71023, or Avogadro's number) is known as a faraday unit of charge (closely related to the Faraday constant). One faraday equals 96485.3399 coulombs. In terms of Avogadro's number (NA), one coulomb is equal to approximately 1.036 \u00d7 NA\u00d710\u22125 elementary charges.\nOne ampere hour = 3600 C \u2234 1 mA\u22c5h = 3.6 C.\nOne statcoulomb (statC), the obsolete CGS electrostatic unit of charge (esu), is approximately 3.3356\u00d710\u221210 C or about one-third of a nanocoulomb.\n\n\n== Relation to elementary charge ==\nThe elementary charge, the charge of a proton (equivalently, the negative of the charge of an electron), is approximately 1.6021766208(98)\u00d710\u221219 C. In SI, the elementary charge in coulombs is an approximate value: no experiment can be infinitely accurate. However, in other unit systems, the elementary charge has an exact value by definition, and other charges are ultimately measured relative to the elementary charge. For example, in conventional electrical units, the values of the Josephson constant KJ and von Klitzing constant RK are exact defined values (written KJ-90 and RK-90), and it follows that the elementary charge e = 2/(KJRK) is also an exact defined value in this unit system. Specifically, e90 = (2\u00d710\u22129)/(25812.807 \u00d7 483597.9) C exactly. SI itself may someday change its definitions in a similar way. For example, one possible proposed redefinition is \"the ampere...is [defined] such that the value of the elementary charge e (charge on a proton) is exactly 1.602176487\u00d710\u221219 coulombs\", (in which the numeric value is the 2006 CODATA recommended value, since superseded). This proposal is not yet accepted as part of the SI.\n\n\n== In everyday terms ==\nThe charges in static electricity from rubbing materials together are typically a few microcoulombs.\nThe amount of charge that travels through a lightning bolt is typically around 15 C, although large bolts can be up to 350 C.\nThe amount of charge that travels through a typical alkaline AA battery from being fully charged to discharged is about 5 kC = 5000 C \u2248 1400 mA\u22c5h.\nThe hydraulic analogy uses everyday terms to illustrate movement of charge and the transfer of energy. The analogy equates charge to a volume of water, and voltage to pressure. One coulomb equals (the negative of) the charge of 6.24\u00d71018 electrons. The amount of energy transferred by the flow of 1 coulomb can vary; for example, 300 times fewer electrons flow through a lightning bolt than in the discharge of an AA battery, but the total energy transferred by the flow of the lightning's electrons is 300 million times greater.\n\n\n== See also ==\nAbcoulomb, a cgs unit of charge\nAmp\u00e8re's circuital law\nCoulomb's law\nElectrostatics\nElementary charge\nFaraday constant, the number of coulombs per mole\n\n\n== Notes and references ==",
        "unit": "coulomb",
        "url": "https://en.wikipedia.org/wiki/Coulomb"
    },
    {
        "_id": "Megabit",
        "clean": "Megabit",
        "text": "The megabit is a multiple of the unit bit for digital information. The prefix mega (symbol M) is defined in the International System of Units (SI) as a multiplier of 106 (1 million), and therefore\n\n1 megabit = 106bits = 1000000bits = 1000 kilobits.The megabit has the unit symbol Mb or Mbit.\nThe megabit is closely related to the mebibit, a unit multiple derived from the binary prefix mebi (symbol Mi) of the same order of magnitude, which is equal to 220bits = 1048576bits, or approximately 5% larger than the megabit. Despite the definitions of these new prefixes for binary-based quantities of storage by international standards organizations, memory semiconductor chips are still marketed using the metric prefix names to designate binary multiples.\nUsing the common byte size of eight bits and the standardized metric definition of megabit and kilobyte, 1 megabit is equal to 125 kilobytes (kB) or approximately 122 kibibytes (KiB).\nThe megabit is widely used when referring to data transfer rates of computer networks or telecommunications systems. Network transfer rates and download speeds often use the megabit as the amount transferred per time unit, e.g., a 100 Mbit/s (megabit per second) Fast-Ethernet connection, or a 10 Mbit/s Internet access service, whereas the sizes of data units (files) transferred over these networks are often measured in megabytes.  To achieve a transfer rate of one megabyte per second one needs a network connection with a transfer rate of eight megabits per second.\n\n\n== Usage ==\nIn telecommunications, the use of the SI definition of the unit is the standard.\nIn the semiconductor industry, it is still common practice to designate random-access memory (RAM), read-only memory (ROM) in a binary interpretation of the metric prefixes, such as the megabit, so that one megabit represents 220bits=1048576bits. For example, a single discrete DDR3 chip specified at 512 Mb invariably contains 229 bits = 536870912bits = 512 Mibit of storage, or 671088648-bit bytes, variously referred to as either 64 mebibytes or 64 (binary) megabytes.\nDuring the 16-bit game console era, the megabit was a commonly used measure of the size (computer data storage capacity) of game cartridges. This size represented one mebibit (Mibit). The vast majority of SNES and Mega Drive (Genesis) games were produced on 8 megabit cartridges, although other sizes such as 4, 12, 16, 24, 32, and 48 megabit cartridges appeared. This usage continued on the Nintendo 64, with cartridge sizes ranging between 32 and 512 megabits.\n\n\n== References ==",
        "unit": "megabit",
        "url": "https://en.wikipedia.org/wiki/Megabit"
    },
    {
        "_id": "Density",
        "clean": "Density",
        "text": "The density, or more precisely, the volumetric mass density, of a substance is its mass per unit volume. The symbol most often used for density is \u03c1 (the lower case Greek letter rho), although the Latin letter D can also be used. Mathematically, density is defined as mass divided by volume:\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            m\n            V\n          \n        \n      \n    \n    {\\displaystyle \\rho ={\\frac {m}{V}}}\n  where \u03c1 is the density, m is the mass, and V is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume, although this is scientifically inaccurate \u2013 this quantity is more specifically called specific weight.\nFor a pure substance the density has the same numerical value as its mass concentration.\nDifferent materials usually have different densities, and density may be relevant to buoyancy, purity and packaging. Osmium and iridium are the densest known elements at standard conditions for temperature and pressure but certain chemical compounds may be denser.\nTo simplify comparisons of density across different systems of units, it is sometimes replaced by the dimensionless quantity \"relative density\" or \"specific gravity\", i.e. the ratio of the density of the material to that of a standard material, usually water. Thus a relative density less than one means that the substance floats in water.\nThe density of a material varies with temperature and pressure. This variation is typically small for solids and liquids but much greater for gases. Increasing the pressure on an object decreases the volume of the object and thus increases its density. Increasing the temperature of a substance (with a few exceptions) decreases its density by increasing its volume. In most materials, heating the bottom of a fluid results in convection of the heat from the bottom to the top, due to the decrease in the density of the heated fluid. This causes it to rise relative to more dense unheated material.\nThe reciprocal of the density of a substance is occasionally called its specific volume, a term sometimes used in thermodynamics. Density is an intensive property in that increasing the amount of a substance does not increase its density; rather it increases its mass.\n\n\n== History ==\nIn a well-known but probably apocryphal tale, Archimedes was given the task of determining whether King Hiero's goldsmith was embezzling gold during the manufacture of a golden wreath dedicated to the gods and replacing it with another, cheaper alloy. Archimedes knew that the irregularly shaped wreath could be crushed into a cube whose volume could be calculated easily and compared with the mass; but the king did not approve of this. Baffled, Archimedes is said to have taken an immersion bath and observed from the rise of the water upon entering that he could calculate the volume of the gold wreath through the displacement of the water. Upon this discovery, he leapt from his bath and ran naked through the streets shouting, \"Eureka! Eureka!\" (\u0395\u03cd\u03c1\u03b7\u03ba\u03b1! Greek \"I have found it\"). As a result, the term \"eureka\" entered common parlance and is used today to indicate a moment of enlightenment.\nThe story first appeared in written form in Vitruvius' books of architecture, two centuries after it supposedly took place. Some scholars have doubted the accuracy of this tale, saying among other things that the method would have required precise measurements that would have been difficult to make at the time.From the equation for density (\u03c1 = m/V), mass density has units of mass divided by volume. As there are many units of mass and volume covering many different magnitudes there are a large number of units for mass density in use. The SI unit of kilogram per cubic metre (kg/m3) and the cgs unit of gram per cubic centimetre (g/cm3) are probably the most commonly used units for density. One g/cm3 is equal to one thousand kg/m3.  One cubic centimetre (abbreviation cc) is equal to one millilitre. In industry, other larger or smaller units of mass and or volume are often more practical and US customary units may be used. See below for a list of some of the most common units of density.\n\n\n== Measurement of density ==\n\n\n=== Homogeneous materials ===\nThe density at all points of a homogeneous object equals its total mass divided by its total volume. The mass is normally measured with a scale or balance; the volume may be measured directly (from the geometry of the object) or by the displacement of a fluid. To determine the density of a liquid or a gas, a hydrometer, a dasymeter or a Coriolis flow meter may be used, respectively. Similarly, hydrostatic weighing uses the displacement of water due to a submerged object to determine the density of the object.\n\n\n=== Heterogeneous materials ===\nIf the body is not homogeneous, then its density varies between different regions of the object. In that case the density around any given location is determined by calculating the density of a small volume around that location. In the limit of an infinitesimal volume the density of an inhomogeneous object at a point becomes: \n  \n    \n      \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        =\n        d\n        m\n        \n          /\n        \n        d\n        V\n      \n    \n    {\\displaystyle \\rho ({\\vec {r}})=dm/dV}\n  , where \n  \n    \n      \n        d\n        V\n      \n    \n    {\\displaystyle dV}\n   is an elementary volume at position \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  . The mass of the body then can be expressed as\n\n  \n    \n      \n        m\n        =\n        \n          \u222b\n          \n            V\n          \n        \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        \n        d\n        V\n        .\n      \n    \n    {\\displaystyle m=\\int _{V}\\rho ({\\vec {r}})\\,dV.}\n  \n\n\n=== Non-compact materials ===\nIn practice, bulk materials such as sugar, sand, or snow contain voids. Many materials exist in nature as flakes, pellets, or granules.\nVoids are regions which contain something other than the considered material.  Commonly the void is air, but it could also be vacuum,  liquid, solid, or a different gas or gaseous mixture.\nThe bulk volume of a material\u2014inclusive of the void fraction\u2014is often obtained by a simple measurement (e.g. with a calibrated measuring cup) or geometrically from known dimensions.\nMass divided by bulk volume determines bulk density.  This is not the same thing as volumetric mass density.\nTo determine volumetric mass density, one must first discount the volume of the void fraction. Sometimes this can be determined by geometrical reasoning.  For the close-packing of equal spheres the non-void fraction can be at most about 74%.  It can also be determined empirically.  Some bulk materials, however, such as sand, have a variable void fraction which depends on how the material is agitated or poured. It might be loose or compact, with more or less air space depending on handling.\nIn practice, the void fraction is not necessarily air, or even gaseous.  In the case of sand, it could be water, which can be advantageous for measurement as the void fraction for sand saturated in water\u2014once any air bubbles are thoroughly driven out\u2014is potentially more consistent than dry sand measured with an air void.\nIn the case of non-compact materials, one must also take care in determining the mass of the material sample. If the material is under pressure (commonly ambient air pressure at the earth's surface) the determination of mass from a measured sample weight might need to account for buoyancy effects due to the density of the void constituent, depending on how the measurement was conducted. In the case of dry sand, sand is so much denser than air that the buoyancy effect is commonly neglected (less than one part in one thousand).\nMass change upon displacing one void material with another while maintaining constant volume can be used to estimate the void fraction, if the difference in density of the two voids materials is reliably known.\n\n\n== Changes of density ==\n\nIn general, density can be changed by changing either the pressure or the temperature. Increasing the pressure always increases the density of a material. Increasing the temperature generally decreases the density, but there are notable exceptions to this generalization. For example, the density of water increases between its melting point at 0 \u00b0C and 4 \u00b0C; similar behavior is observed in silicon at low temperatures.\nThe effect of pressure and temperature on the densities of liquids and solids is small. The compressibility for a typical liquid or solid is 10\u22126 bar\u22121 (1 bar = 0.1 MPa) and a typical thermal expansivity is 10\u22125 K\u22121. This roughly translates into needing around ten thousand times atmospheric pressure to reduce the volume of a substance by one percent. (Although the pressures needed may be around a thousand times smaller for sandy soil and some clays.) A one percent expansion of volume typically requires a temperature increase on the order of thousands of degrees Celsius.\nIn contrast, the density of gases is strongly affected by pressure. The density of an ideal gas is\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            \n              M\n              P\n            \n            \n              R\n              T\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\rho ={\\frac {MP}{RT}},}\n  where M is the molar mass, P is the pressure, R is the universal gas constant, and T is the absolute temperature. This means that the density of an ideal gas can be doubled by doubling the pressure, or by halving the absolute temperature.\nIn the case of volumic thermal expansion at constant pressure and small intervals of temperature the temperature dependence of density is :\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            \n              \u03c1\n              \n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            \n              1\n              +\n              \u03b1\n              \u22c5\n              \u0394\n              T\n            \n          \n        \n      \n    \n    {\\displaystyle \\rho ={\\frac {\\rho _{T_{0}}}{1+\\alpha \\cdot \\Delta T}}}\n  where \n  \n    \n      \n        \n          \u03c1\n          \n            \n              T\n              \n                0\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho _{T_{0}}}\n   is the density at a reference temperature, \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is the thermal expansion coefficient of the material at temperatures close to \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  .\n\n\n== Density of solutions ==\nThe density of a solution is the sum of mass (massic) concentrations of the components of that solution.\nMass (massic) concentration of each given component \u03c1i in a solution sums to density of the solution.\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03f1\n          \n            i\n          \n        \n        \n      \n    \n    {\\displaystyle \\rho =\\sum _{i}\\varrho _{i}\\,}\n  Expressed as a function of the densities of pure components of the mixture and their volume participation, it allows the determination of excess molar volumes:\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \n            \n              V\n              \n                i\n              \n            \n            V\n          \n        \n        \n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \u03c6\n          \n            i\n          \n        \n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \n            \n              V\n              \n                i\n              \n            \n            \n              \n                \u2211\n                \n                  i\n                \n              \n              \n                V\n                \n                  i\n                \n              \n              +\n              \n                \u2211\n                \n                  i\n                \n              \n              \n                \n                  \n                    V\n                    \n                      E\n                    \n                  \n                \n                \n                  i\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho =\\sum _{i}\\rho _{i}{\\frac {V_{i}}{V}}\\,=\\sum _{i}\\rho _{i}\\varphi _{i}=\\sum _{i}\\rho _{i}{\\frac {V_{i}}{\\sum _{i}V_{i}+\\sum _{i}{V^{E}}_{i}}}}\n  provided that there is no interaction between the components.\nKnowing the relation between excess volumes and activity coefficients of the  components, one can determine the activity coefficients.\n\n  \n    \n      \n        \n          \n            \n              \n                V\n                \n                  E\n                \n              \n              \u00af\n            \n          \n          \n            i\n          \n        \n        =\n        R\n        T\n        \n          \n            \n              \u2202\n              ln\n              \u2061\n              \n                \u03b3\n                \n                  i\n                \n              \n            \n            \n              \u2202\n              P\n            \n          \n        \n      \n    \n    {\\displaystyle {\\overline {V^{E}}}_{i}=RT{\\frac {\\partial \\ln \\gamma _{i}}{\\partial P}}}\n  \n\n\n== Densities ==\n\n\n=== Various materials ===\n\n\n=== Others ===\n\n\n=== Water ===\n\n\n=== Air ===\n\n\n=== Molar volumes of liquid and solid phase of elements ===\n\n\n== Common units ==\nThe SI unit for density is:\n\nkilogram per cubic metre (kg/m3)The litre and metric tons are not part of the SI, but are acceptable for use with it, leading to the following units:\n\nkilogram per litre (kg/L)\ngram per millilitre (g/mL)\nmetric ton per cubic metre (t/m3)Densities using the following metric units all have exactly the same numerical value, one thousandth of the value in (kg/m3). Liquid water has a density of about 1 kg/dm3, making any of these SI units numerically convenient to use as most solids and liquids have densities between 0.1 and 20 kg/dm3.\n\nkilogram per cubic decimetre (kg/dm3)\ngram per cubic centimetre (g/cm3)\n1 g/cm3 = 1000 kg/m3\nmegagram (metric ton) per cubic metre (Mg/m3)In US customary units density can be stated in:\n\nAvoirdupois ounce per cubic inch (1 g/cc \u2248 0.578036672 oz/cu in)\nAvoirdupois ounce per fluid ounce (1 g/cc \u2248 1.04317556 oz/fl. oz = 1.04317556 lbs/pint)\nAvoirdupois pound per cubic inch (1 g/cc \u2248 0.036127292 lb/cu in)\npound per cubic foot (1 g/cc \u2248 62.427961 lb/cu ft)\npound per cubic yard (1 g/cc \u2248 1685.5549 lb/cu yd)\npound per US liquid gallon (1 g/cc \u2248 8.34540445 lb/gal)\npound per US bushel (1 g/cc \u2248 77.6888513 lb/bu)\nslug per cubic footImperial units differing from the above (as the Imperial gallon and bushel differ from the US units) in practice are rarely used, though found in older documents. The Imperial gallon was based on the concept that an Imperial fluid ounce of water would have a mass of one Avoirdupois ounce, and indeed 1 g/cc \u2248 1.00224129 ounces per Imperial fluid ounce = 10.0224129 pounds per Imperial gallon. The density of precious metals could conceivably be based on Troy ounces and pounds, a possible cause of confusion.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n \"Density\". Encyclop\u00e6dia Britannica. 8 (11th ed.). 1911.\n \"Density\". The New Student's Reference Work. 1914.\nVideo: Density Experiment with Oil and Alcohol\nVideo: Density Experiment with Whiskey and Water\nGlass Density Calculation \u2013 Calculation of the density of glass at room temperature and of glass melts at 1000 \u2013 1400\u00b0C\nList of Elements of the Periodic Table \u2013 Sorted by Density\nCalculation of saturated liquid densities for some components\nField density test\nOn-line calculator for densities and partial molar volumes of aqueous solutions of some common electrolytes and their mixtures, at temperatures up to 323.15 K.\nWater \u2013 Density and specific weight\nTemperature dependence of the density of water \u2013 Conversions of density units\nA delicious density experiment\nWater density calculator Water density for a given salinity and temperature.\nLiquid density calculator Select a liquid from the list and calculate density as a function of temperature.\nGas density calculator Calculate density of a gas for as a function of temperature and pressure.\nDensities of various materials.\nDetermination of Density of Solid, instructions for performing classroom experiment.\ndensity prediction\ndensity prediction",
        "unit": "density",
        "url": "https://en.wikipedia.org/wiki/Density"
    },
    {
        "_id": "Petayear",
        "clean": "Petayear",
        "text": "A year is the orbital period of the Earth moving in its orbit around the Sun. Due to the Earth's axial tilt, the course of a year sees the passing of the seasons, marked by change in weather, the hours of daylight, and, consequently, vegetation and soil fertility. The current year is 2018.\nIn temperate and subpolar regions around the planet, four seasons are generally recognized: spring, summer, autumn, and winter. In tropical and subtropical regions, several geographical sectors do not present defined seasons; but in the seasonal tropics, the annual wet and dry seasons are recognized and tracked.\nA calendar year is an approximation of the number of days of the Earth's orbital period as counted in a given calendar. The Gregorian calendar, or modern calendar, presents its calendar year to be either a common year of 365 days or a leap year of 366 days, as do the Julian calendars; see below. For the Gregorian calendar, the average length of the calendar year (the mean year) across the complete leap cycle of 400 years is 365.2425 days. The ISO standard ISO 80000-3, Annex C, supports the symbol a (for Latin annus) to represent a year of either 365 or 366 days. In English, the abbreviations y and yr are commonly used.\nIn astronomy, the Julian year is a unit of time; it is defined as 365.25 days of exactly 86,400 seconds (SI base unit), totalling exactly 31,557,600 seconds in the Julian astronomical year.The word year is also used for periods loosely associated with, but not identical to, the calendar or astronomical year, such as the seasonal year, the fiscal year, the academic year, etc. Similarly, year can mean the orbital period of any planet; for example, a Martian year and a Venusian year are examples of the time  a planet takes to    transit one complete orbit. The term can also be used in reference to any long period or cycle, such as the Great Year.\n\n\n== Etymology ==\nEnglish year (via West Saxon \u0121\u0113ar (/j\u025bar/), Anglian \u0121\u0113r) continues Proto-Germanic *j\u01e3ran (*j\u0113\u2081ran).\nCognates are German Jahr, Old High German j\u0101r, Old Norse \u00e1r and Gothic jer, from the Proto-Indo-European noun *yeh\u2081r-om \"year, season\". Cognates also descended from the same Proto-Indo-European noun (with variation in suffix ablaut) are Avestan y\u0101r\u01dd \"year\", Greek \u1f65\u03c1\u03b1 (h\u1e53ra) \"year, season, period of time\" (whence \"hour\"), Old Church Slavonic jar\u016d, and Latin hornus \"of this year\". \nLatin annus (a 2nd declension masculine noun; annum is the accusative singular; ann\u012b is genitive singular and nominative plural; ann\u014d the dative and ablative singular) is from a PIE noun *h\u2082et-no-, which also yielded Gothic a\u00fen \"year\" (only the dative plural a\u00fenam is attested).\nAlthough most languages treat the word as thematic *yeh\u2081r-o-, there is evidence for an original derivation with an *-r/n suffix, *yeh\u2081-ro-. Both Indo-European words for year, *yeh\u2081-ro- and *h\u2082et-no-, would then be derived from verbal roots meaning \"to go, move\", , *h\u2081ey- and *h\u2082et-, respectively  (compare Vedic Sanskrit \u00e9ti \"goes\", atasi \"thou goest, wanderest\").\nA number of English words are derived from Latin annus, such as annual, annuity, anniversary, etc.; per annum means \"each year\", anno Domini means \"in the year of the Lord\".\nThe Greek word for \"year\", \u1f14\u03c4\u03bf\u03c2, is cognate with Latin vetus \"old\", from the PIE word *wetos- \"year\", also preserved in this meaning in Sanskrit  vat-sa-ras \"year\" and vat-sa- \"yearling (calf)\", the latter also reflected in Latin vitulus \"bull calf\",  English wether \"ram\" (Old English we\u00f0er, Gothic wi\u00ferus \"lamb\").\nIn some languages, it is common to count years by referencing to one season, as in \"summers\", or \"winters\", or \"harvests\". Examples include Chinese \u5e74 \"year\", originally \u79c2, an ideographic compound of a person carrying a bundle of wheat denoting \"harvest\". Slavic besides god\u016d \"time period; year\" uses l\u011bto \"summer; year\".\nIn the International System of Quantities (ISO 80000-3), the year (symbol, a) is defined as either 365 days or 366 days.\n\n\n== Intercalation ==\nNo astronomical year has an integer number of days or lunar months, so any calendar that follows an astronomical year must have a system of intercalation such as leap years.\n\n\n=== Julian calendar ===\nIn the Julian calendar, the average (mean) length of a year is 365.25 days. In a non-leap year, there are 365 days, in a leap year there are 366 days. A leap year occurs every fourth year, or leap year, during which a leap day is intercalated into the month of February. The name \"Leap Day\" is applied to the added day.\nThe Revised Julian calendar, proposed in 1923 and used in some Eastern Orthodox Churches, \nhas 218 leap years every 900 years, for  the average (mean) year length of 365.2422222 days, close to the length of the mean tropical year, 365.24219 days (relative error of 9\u00b710\u22128).\nIn the year 2800 CE, the Gregorian and Revised Julian calendars will begin to differ by one calendar day.\n\n\n=== Gregorian calendar ===\nThe Gregorian calendar attempts to cause the northward equinox to fall on or shortly before March 21 and hence it follows the northward equinox year, or tropical year. Because 97 out of 400 years are leap years,   the mean length of the Gregorian calendar year is 365.2425 days; with a relative error below one ppm (8\u00b710\u22127)  relative to the current length of the mean tropical year (365.24219 days) and even closer to the current March equinox year of 365.242374 days that it aims to match.   It is estimated that by the year 4000 CE, the northward equinox will fall back by one day in the Gregorian calendar, not because of this difference, but due to the slowing of the Earth's rotation and the associated lengthening of the day.\n\n\n=== Other calendars ===\n\nHistorically, lunisolar calendars intercalated entire leap months on an observational basis.\nLunisolar calendars have mostly fallen out of use except for liturgical reasons (Hebrew calendar, various Hindu calendars).\nA modern adaptation of the historical Jalali calendar, known as the Solar Hijri calendar (1925), is a purely solar calendar with an irregular pattern of leap days based on observation (or astronomical computation), aiming to place new year (Nowruz) on the day of vernal equinox (for the time zone of Tehran), as opposed to using an algorithmic system of leap years.\n\n\n== Year numbering ==\nA calendar era assigns a cardinal number to each sequential  year, using a reference point in the past as the beginning of the era.\nThe worldwide standard is the Anno Domini era (but the label Common Era is preferred by some). It was historically introduced in the 6th century and intended as counting years from the birth of Jesus.The Anno Domini era is given the Latin abbreviation AD (for Anno Domini \"in the year of the Lord\"), or alternatively CE for \"Common Era. Years before AD 1 are abbreviated BC for Before Christ or alternatively BCE for Before the Common Era.\nYear numbers are based on inclusive counting, so that there is no \"year zero\".\nIn the modern alternative reckoning of Astronomical year numbering, positive numbers indicate years AD, the number 0 designates 1 BC, \u22121 designates 2 BC, and so on.\n\n\n== Pragmatic divisions ==\nFinancial and scientific calculations often use a 365-day calendar to simplify daily rates.\n\n\n=== Fiscal year ===\nA fiscal year or financial year is a 12-month period used for calculating annual financial statements in businesses and other organizations. In many jurisdictions, regulations regarding accounting require such reports once per twelve months, but do not require that the twelve months constitute a calendar year.\nFor example, in Canada and India the fiscal year runs from April 1; in the United Kingdom it runs from April 1 for purposes of corporation tax and government financial statements, but from April 6 for purposes of personal taxation and payment of state benefits;  in Australia it runs from July 1; while in the United States the fiscal year of the federal government runs from October 1.\n\n\n=== Academic year ===\nAn academic year is the annual period during which a student attends an educational institution. The academic year may be divided into academic terms, such as semesters or quarters. The school year in many countries starts in August or September and ends in May, June or July.  In Israel the academic year begins around October or November, aligned with the second month of the Hebrew Calendar.\nSome schools in the UK and USA divide the academic year into three roughly equal-length terms (called trimesters or quarters in the USA), roughly coinciding with autumn, winter, and spring. At some, a shortened summer session, sometimes considered part of the regular academic year, is attended by students on a voluntary or elective basis.  Other schools break the year into two main semesters, a first (typically August through December) and a second semester (January through May). Each of these main semesters may be split in half by mid-term exams, and each of the halves is referred to as a quarter (or term in some countries). There may also be a voluntary summer session and/or a short January session.\nSome other schools, including some in the United States, have four marking periods.  Some schools in the United States, notably Boston Latin School, may divide the year into five or more marking periods. Some state in defense of this that there is perhaps a positive correlation between report frequency and academic achievement.\nThere are typically 180 days of teaching each year in schools in the USA, excluding weekends and breaks, while there are 190 days for pupils in state schools in Canada, New Zealand and the United Kingdom, and 200 for pupils in Australia.\nIn India the academic year normally starts from June 1 and ends on May 31. Though schools start closing from mid-March, the actual academic closure is on May 31 and in Nepal it starts from July 15.Schools and universities in Australia typically have academic years that roughly align with the calendar year (i.e., starting in February or March and ending in October to December), as the southern hemisphere experiences summer from December to February.\n\n\n== Astronomical years ==\n\n\n=== Julian year ===\n\nThe Julian year, as used in astronomy and other sciences, is a time unit defined as exactly 365.25 days. This is the normal meaning of the unit \"year\" (symbol \"a\" from the Latin annus) used in various scientific contexts. The Julian century of 36525 days and the Julian millennium of 365250 days are used in astronomical calculations. Fundamentally, expressing a time interval in Julian years is a way to precisely specify how many days (not how many \"real\" years), for long time intervals where stating the number of days would be unwieldy and unintuitive. By convention, the Julian year is used in the computation of the distance covered by a light-year.\nIn the Unified Code for Units of Measure, the symbol, a (without subscript), always refers to the Julian year, aj, of exactly 31557600 seconds.\n\n365.25 days of 86400 seconds = 1 a = 1 aj = 31.5576 MsThe SI multiplier prefixes may be applied to it to form ka (kiloannus), Ma (megaannus), etc.\n\n\n=== Sidereal, tropical, and anomalistic years ===\n\nEach of these three years can be loosely called an astronomical year.\nThe sidereal year is the time taken for the Earth to complete one revolution of its orbit, as measured against a fixed frame of reference (such as the fixed stars, Latin sidera, singular sidus).  Its average duration is 365.256363004 days (365 d 6 h 9 min 9.76 s) (at the epoch J2000.0 = January 1, 2000, 12:00:00 TT).Today the mean tropical year is defined as the period of time for the mean ecliptic longitude of the Sun to increase by 360 degrees. Since the Sun's ecliptic longitude is measured with respect to the equinox, the tropical year comprises a complete cycle of the seasons; because of the biological and socio-economic importance of the seasons, the tropical year is the basis of most calendars. The modern definition of mean tropical year differs from the actual time between passages of, e.g., the northward equinox for several reasons explained below. Because of the Earth's axial precession, this year is about 20 minutes shorter than the sidereal year.  The mean tropical year is approximately 365 days, 5 hours, 48 minutes, 45 seconds, using the modern definition. (= 365.24219 days of 86400 SI seconds)\nThe anomalistic year is the time taken for the Earth to complete one revolution with respect to its apsides. The orbit of the Earth is elliptical; the extreme points, called apsides, are the perihelion, where the Earth is closest to the Sun (January 3 in 2011), and the aphelion, where the Earth is farthest from the Sun (July 4 in 2011). The anomalistic year is usually defined as the time between perihelion passages.  Its average duration is 365.259636 days (365 d 6 h 13 min 52.6 s) (at the epoch J2011.0).\n\n\n=== Draconic year ===\nThe draconic year, draconitic year, eclipse year, or ecliptic year is the time taken for the Sun (as seen from the Earth) to complete one revolution with respect to the same lunar node (a point where the Moon's orbit intersects the ecliptic). The year is associated with eclipses: these occur only when both the Sun and the Moon are near these nodes; so eclipses occur within about a month of every half eclipse year. Hence there are two eclipse seasons every eclipse year. The average duration of the eclipse year is\n\n346.620075883 days (346 d 14 h 52 min 54 s) (at the epoch J2000.0).This term is sometimes erroneously used for the draconic or nodal period of lunar precession, that is the period of a complete revolution of the Moon's ascending node around the ecliptic: 18.612815932 Julian years (6798.331019 days; at the epoch J2000.0).\n\n\n=== Full moon cycle ===\nThe full moon cycle is the time for the Sun (as seen from the Earth) to complete one revolution with respect to the perigee of the Moon's orbit. This period is associated with the apparent size of the full moon, and also with the varying duration of the synodic month. The duration of one full moon cycle is:\n\n411.78443029 days (411 days 18 hours 49 minutes 34 seconds) (at the epoch J2000.0).\n\n\n=== Lunar year ===\nThe lunar year comprises twelve full cycles of the phases of the Moon, as seen from Earth. It has a duration of approximately 354.37 days. Muslims use this for celebrating their Eids and for marking the start of the fasting month of Ramadan.\nA Muslim calendar year is based on the lunar cycle.\n\n\n=== Vague year ===\nThe vague year, from annus vagus or wandering year, is an integral approximation to the year equaling 365 days, which wanders in relation to more exact years.  Typically the vague year is divided into 12 schematic months of 30 days each plus 5 epagomenal days.  The vague year was used in the calendars of Ancient Egypt, Iran, Armenia and in Mesoamerica among the Aztecs and Maya.   It is still used by many Zoroastrian communities.\n\n\n=== Heliacal year ===\nA heliacal year is the interval between the heliacal risings of a star. It differs from the sidereal year for stars away from the ecliptic due mainly to the precession of the equinoxes.\n\n\n=== Sothic year ===\nThe Sothic year is the interval between heliacal risings of the star Sirius. It is currently less than the sidereal year and its duration is very close to the Julian year of 365.25 days.\n\n\n=== Gaussian year ===\nThe Gaussian year is the sidereal year for a planet of negligible mass (relative to the Sun) and unperturbed by other planets that is governed by the Gaussian gravitational constant. Such a planet would be slightly closer to the Sun than Earth's mean distance. Its length is:\n\n365.2568983 days (365 d 6 h 9 min 56 s).\n\n\n=== Besselian year ===\nThe Besselian year is a tropical year that starts when the (fictitious) mean Sun reaches an ecliptic longitude of 280\u00b0. This is currently on or close to January 1. It is named after the 19th-century German astronomer and mathematician Friedrich Bessel. The following equation can be used to compute the current Besselian epoch (in years):\nB = 1900.0 + (Julian dateTT \u2212 2415020.31352) / 365.242198781The TT subscript indicates that for this formula, the Julian date should use the Terrestrial Time scale, or its predecessor, ephemeris time.\n\n\n=== Variation in the length of the year and the day ===\nThe exact length of an astronomical year changes over time.\n\nThe positions of the equinox and solstice points with respect to the apsides of Earth's orbit change: the equinoxes and solstices move westward relative to the stars because of precession, and the apsides move in the other direction because of the long-term effects of gravitational pull by the other planets.  Since the speed of the Earth varies according to its position in its orbit as measured from its perihelion, Earth's speed when in a solstice or equinox point changes over time: if such a point moves toward perihelion, the interval between two passages decreases a little from year to year; if the point moves towards aphelion, that period increases a little from year to year.  So a \"tropical year\" measured from one passage of the northward (\"vernal\") equinox to the next, differs from the one measured between passages of the southward (\"autumnal\") equinox.  The average over the full orbit does not change because of this, so the length of the average tropical year does not change because of this second-order effect.\nEach planet's movement is perturbed by the gravity of every other planet.  This leads to short-term fluctuations in its speed, and therefore its period from year to year.  Moreover, it causes long-term changes in its orbit, and therefore also long-term changes in these periods.\nTidal drag between the Earth and the Moon and Sun increases the length of the day and of the month (by transferring angular momentum from the rotation of the Earth to the revolution of the Moon); since the apparent mean solar day is the unit with which we measure the length of the year in civil life, the length of the year appears to decrease.  The rotation rate of the Earth is also changed by factors such as post-glacial rebound and sea level rise.\n\n\n==== Numerical value of year variation ====\nMean year lengths in this section are calculated for 2000, and differences in year lengths, compared to 2000, are given for past and future years. In the tables a day is 86,400 SI seconds long.\n\n\n=== Summary ===\nAn average Gregorian year is 365.2425 days (52.1775 weeks, 8765.82 hours, 525949.2 minutes or 31556952 seconds).  For this calendar, a common year is 365 days (8760 hours, 525600 minutes or 31536000 seconds), and a leap year is 366 days (8784 hours, 527040 minutes or 31622400 seconds).  The 400-year cycle of the Gregorian calendar has 146097 days and hence exactly 20871 weeks.\n\n\n== \"Greater\" astronomical years ==\n\n\n=== Equinoctial cycle ===\nThe Great Year, or equinoctial cycle, corresponds to a complete revolution of the equinoxes around the ecliptic. Its length is about 25,700 years, and cannot be determined precisely enough yet, as the precession speed depends on too many factors, causing not yet predictable variation.\n\n\n=== Galactic year ===\nThe Galactic year is the time it takes Earth's solar system to revolve once around the galactic center. It comprises roughly 230 million Earth years.\n\n\n== Seasonal year ==\n\nA seasonal year is the time between successive recurrences of a seasonal event such as the flooding of a river, the migration of a species of bird, the flowering of a species of plant, the first frost, or the first scheduled game of a certain sport. All of these events can have wide variations of more than a month from year to year.\n\n\n== Symbols ==\nIn the International System of Quantities the symbol for the year as a unit of time is a, taken from the Latin word annus.In English, the abbreviations \"y\" or \"yr\" are more commonly used in non-scientific literature, but also specifically in geology and paleontology, where \"kyr, myr, byr\" (thousands, millions, and billions of years, respectively) and similar abbreviations are used to denote intervals of time remote from the present.\n\n\n=== Symbol ===\nNIST SP811 and ISO 80000-3:2006 support the symbol a as the unit of time for a year. In English, the abbreviations y and yr are also used.The Unified Code for Units of Measure disambiguates the varying symbologies of ISO 1000, ISO 2955 and ANSI X3.50 by using:\n\nat = 365.24219 days for the mean tropical year;\naj = 365.25 days for the mean Julian year;\nag = 365.2425 days for the mean Gregorian year;where:\n\na, without a qualifier = 1 aj;\nand, ar for are, is a unit of area.The International Union of Pure and Applied Chemistry (IUPAC) and the International Union of Geological Sciences have jointly recommended defining the annus, with symbol a, as the length of the tropical year in the year 2000:\n\na = 31556925.445 seconds (approximately 365.24219265 ephemeris days)This differs from the above definition of 365.25 days by about 20 parts per million. The joint document says that definitions such as the Julian year \"bear an inherent, pre-programmed obsolescence because of the variability of Earth\u2019s orbital movement\", but then proposes using the length of the tropical year as of 2000 AD (specified down to the millisecond), which suffers from the same problem. (The tropical year oscillates with time by more than a minute.)\nThe notation has proved controversial as it conflicts with an earlier convention among geoscientists to use a specifically for years ago, and y or yr for a one-year time period.\n\n\n==== SI prefix multipliers ====\nFor the following, there are alternative forms which elide the consecutive vowels, such as kilannus, megannus, etc. The exponents and exponential notations are typically used for calculating and in displaying calculations, and for conserving space, as in tables of data.\n\n ka (for kiloannum) \u2014 a unit of time equal to one thousand, or 103, years, or 1 E3 yr, also known as a millennium in anthropology and calendar uses. The prefix multiplier \"ka\" is typically used in geology, paleontology, and archaeology for the Holocene and Pleistocene periods, where a non\u2212radiocarbon dating technique: e.g. ice core dating, dendrochronology, uranium-thorium dating, or varve analysis; is used as the primary dating method for age determination. If age is primarily determined by radiocarbon dating, then the age should be expressed in either radiocarbon or calendar (calibrated) years Before Present.\n Ma (for megaannum) \u2014 a unit of time equal to one million, or 106, years, or 1 E6 yr. The suffix \"Ma\" is commonly used in scientific disciplines such as geology, paleontology, and celestial mechanics to signify very long time periods into the past or future. For example, the dinosaur species Tyrannosaurus rex was abundant approximately 66 Ma (66 million years) ago. The duration term \"ago\" may not always be indicated: if the quantity of a duration is specified while not explicitly mentioning a duration term, one can assume that \"ago\" is implied; the alternative unit \"mya\" does include \"ago\" explicitly. It also written as \"million years\" (ago) in works for general public use. In astronomical applications, the year used is the Julian year of precisely 365.25 days. In geology and paleontology, the year is not so precise and varies depending on the author.\n Ga (for gigaannum) \u2014 a unit of time equal to 109 years, or one billion years. \"Ga\" is commonly used in scientific disciplines such as cosmology and geology to signify extremely long time periods in the past. For example, the formation of the Earth occurred approximately 4.54 Ga (4.54 billion years) ago.\n Ta (for teraannum) \u2014 a unit of time equal to 1012 years, or one trillion years. \"Ta\" is an extremely long unit of time, about 70 times as long as the age of the universe. It is the same order of magnitude as the expected life span of a small red dwarf.\n Pa (for petaannum) \u2014 a unit of time equal to 1015 years, or one quadrillion years. The half-life of the nuclide cadmium-113 is about 8 Pa.  This symbol coincides with that for the pascal without a multiplier prefix, though both are infrequently used and context will normally be sufficient to distinguish time from pressure values.\n Ea (for exaannum) \u2014 a unit of time equal to 1018 years, or one quintillion years. The half-life of tungsten-180 is 1.8 Ea.\n\n\n=== Abbreviations yr and ya ===\n\nIn astronomy, geology, and paleontology, the abbreviation yr for years and ya for years ago are sometimes used, combined with prefixes for thousand, million, or billion. They are not SI units, using y to abbreviate the English \"year\", but following ambiguous international recommendations, use either the standard English first letters as prefixes (t, m, and b) or metric prefixes (k, M, and G) or variations on metric prefixes (k, m, g). In archaeology, dealing with more recent periods, normally expressed dates, eg \"22,000 years ago\" may be used as a more accessible equivalent of a Before Present (\"BP\") date.\nThese abbreviations include:\n\nUse of mya and bya is deprecated in modern geophysics, the recommended usage being Ma and Ga for dates Before Present, but \"m.y.\" for the duration of epochs. This ad hoc distinction between \"absolute\" time and time intervals is somewhat controversial amongst members of the Geological Society of America.Note that on graphs using ya units on the horizontal axis time flows from right to left, which may seem counter-intuitive. If the ya units are on the vertical axis, time flows from top to bottom which is probably easier to understand than conventional notation.\n\n\n== See also ==\n\n\n== References ==\n\n\n=== Notes ===\n\n\n== Further reading ==\nFraser, Julius Thomas (1987). Time, the Familiar Stranger. Time. The Familiar Stranger.. J. T. Fraser.university of Massachusetts Press (illustrated ed.). Amherst: University of Massachusetts Press. Bibcode:1988tfs..book.....F. ISBN 978-0-87023-576-4. OCLC 15790499.\nWhitrow, Gerald James (2003). What is Time?. Oxford: Oxford University Press. ISBN 978-0-19-860781-6. OCLC 265440481.\n\n\n== External links ==\nImages of years",
        "unit": "petayear",
        "url": "https://en.wikipedia.org/wiki/Petayear"
    },
    {
        "_id": "Nucleotide",
        "clean": "Nucleotide",
        "text": "Nucleotides are organic molecules that serve as the monomer units for forming the nucleic acid polymers deoxyribonucleic acid (DNA) and ribonucleic acid (RNA), both of which are essential biomolecules within all life-forms on Earth. Nucleotides are the building blocks of nucleic acids; they are composed of three subunit molecules: a nitrogenous base, a five-carbon sugar (ribose or deoxyribose), and at least one phosphate group.\nA nucleoside is a nitrogenous base and a 5-carbon sugar. Thus a nucleoside plus a phosphate group yields a nucleotide.\nNucleotides also play a central role in metabolism at a fundamental, cellular level. They carry packets of chemical energy\u2014in the form of the nucleoside triphosphates Adenosine triphosphate (ATP), Guanosine triphosphate (GTP), Cytidine triphosphate (CTP) and Uridine triphosphate (UTP)\u2014throughout the cell to the many cellular functions that demand energy, which include: synthesizing amino acids, proteins and cell membranes and parts, moving the cell and moving cell parts (both internally and intercellularly), dividing the cell, etc. In addition, nucleotides participate in cell signaling (cyclic guanosine monophosphate or cGMP and cyclic adenosine monophosphate or cAMP), and are incorporated into important cofactors of enzymatic reactions (e.g. coenzyme A, FAD, FMN, NAD, and NADP+).\nIn experimental biochemistry, nucleotides can be radiolabeled with radionuclides to yield radionucleotides.\n\n\n== Structure ==\n\nA nucleotide is composed of three distinctive chemical sub-units: a five-carbon sugar molecule, a nitrogenous base\u2014which two together are called a nucleoside\u2014and one phosphate group. With all three joined, a nucleotide is also termed a \"nucleoside monophosphate\". The chemistry sources ACS Style Guide and IUPAC Gold Book prescribe that a nucleotide should contain only one phosphate group, but common usage in molecular biology textbooks often extends the definition to include molecules with two, or with three, phosphates. Thus, the terms \"nucleoside diphosphate\" or \"nucleoside triphosphate\" may also indicate nucleotides.\nNucleotides contain either a purine or a pyrimidine base\u2014i.e., the nitrogenous base molecule, also known as a nucleobase\u2014and are termed ribonucleotides if the sugar is ribose, or deoxyribonucleotides if the sugar is deoxyribose. Individual phosphate molecules repetitively connect the sugar-ring molecules in two adjacent nucleotide monomers, thereby connecting the nucleotide monomers of a nucleic acid end-to-end into a long chain. These chain-joins of sugar and phosphate molecules create a 'backbone' strand for a single- or double helix. In any one strand, the chemical orientation (directionality) of the chain-joins runs from the 5'-end to the 3'-end (read: 5 prime-end to 3 prime-end)\u2014referring to the five carbon sites on sugar molecules in adjacent nucleotides. In a double helix, the two strands are oriented in opposite directions, which permits base pairing and complementarity between the base-pairs, all which is essential for replicating or transcribing the encoded information found in DNA.\nUnlike in nucleic acid nucleotides, singular cyclic nucleotides are formed when the phosphate group is bound twice to the same sugar molecule, i.e., at the corners of the sugar hydroxyl groups. These individual nucleotides function in cell metabolism rather than the nucleic acid structures of long-chain molecules.\nNucleic acids then are polymeric macromolecules assembled from nucleotides, the monomer-units of nucleic acids. The purine bases adenine and guanine and pyrimidine base cytosine occur in both DNA and RNA, while the pyrimidine bases thymine (in DNA) and uracil (in RNA) in just one. Adenine forms a base pair with thymine with two hydrogen bonds, while guanine pairs with cytosine with three hydrogen bonds.\n\n\n== Synthesis ==\nNucleotides can be synthesized by a variety of means both in vitro and in vivo.\nIn vitro, protecting groups may be used during laboratory production of nucleotides. A purified nucleoside is protected to create a phosphoramidite, which can then be used to obtain analogues not found in nature and/or to synthesize an oligonucleotide.\nIn vivo, nucleotides can be synthesized de novo or recycled through salvage pathways. The components used in de novo nucleotide synthesis are derived from biosynthetic precursors of carbohydrate and amino acid metabolism, and from ammonia and carbon dioxide. The liver is the major organ of de novo synthesis of  all four nucleotides. De novo synthesis of pyrimidines and purines follows two different pathways. Pyrimidines are synthesized first from aspartate and carbamoyl-phosphate in the cytoplasm to the common precursor ring structure orotic acid, onto which a phosphorylated ribosyl unit is covalently linked. Purines, however, are first synthesized from the sugar template onto which the ring synthesis occurs. For reference, the syntheses of the purine and pyrimidine nucleotides are carried out by several enzymes in the cytoplasm of the cell, not within a specific organelle. Nucleotides undergo breakdown such that useful parts can be reused in synthesis reactions to create new nucleotides.\n\n\n=== Pyrimidine ribonucleotide synthesis ===\n\nThe synthesis of the pyrimidines CTP and UTP occurs in the cytoplasm and starts with the formation of carbamoyl phosphate from glutamine and CO2. Next, aspartate carbamoyltransferase catalyzes a condensation reaction between aspartate and carbamoyl phosphate to form carbamoyl aspartic acid, which is cyclized into 4,5-dihydroorotic acid by dihydroorotase. The latter is converted to orotate by dihydroorotate oxidase. The net reaction is:\n\n(S)-Dihydroorotate + O2 \u2192 Orotate + H2O2Orotate is covalently linked with a phosphorylated ribosyl unit. The covalent linkage between the ribose and pyrimidine occurs at position C1 of the ribose unit, which contains a pyrophosphate, and N1 of the pyrimidine ring. Orotate phosphoribosyltransferase (PRPP transferase) catalyzes the net reaction yielding orotidine monophosphate (OMP):\n\nOrotate + 5-Phospho-\u03b1-D-ribose 1-diphosphate (PRPP)  \u2192  Orotidine 5'-phosphate + PyrophosphateOrotidine 5'-monophosphate is decarboxylated by orotidine-5'-phosphate decarboxylase to form uridine monophosphate (UMP). PRPP transferase catalyzes both the ribosylation and decarboxylation reactions, forming UMP from orotic acid in the presence of PRPP. It is from UMP that other pyrimidine nucleotides are derived.  UMP is phosphorylated by two kinases to uridine triphosphate (UTP) via two sequential reactions with ATP.  First the diphosphate form UDP is produced, which in turn is phosphorylated to UTP. Both steps are fueled by ATP hydrolysis:\n\nATP + UMP \u2192 ADP + UDPUDP + ATP \u2192 UTP + ADPCTP is subsequently formed by amination of UTP by the catalytic activity of CTP synthetase. Glutamine is the NH3 donor and the reaction is fueled by ATP hydrolysis, too:\n\nUTP + Glutamine + ATP + H2O \u2192 CTP + ADP + PiCytidine monophosphate (CMP) is derived from cytidine triphosphate (CTP) with subsequent loss of two phosphates.\n\n\n=== Purine ribonucleotide synthesis ===\n\nThe atoms that are used to build the purine nucleotides come from a variety of sources: \n\nThe de novo synthesis of purine nucleotides by which these precursors are incorporated into the purine ring proceeds by a 10-step pathway to the branch-point intermediate IMP, the nucleotide of the base hypoxanthine. AMP and GMP are subsequently synthesized from this intermediate via separate, two-step pathways. Thus, purine moieties are initially formed as part of the ribonucleotides rather than as free bases.\nSix enzymes take part in IMP synthesis. Three of them are multifunctional:\n\nGART (reactions 2, 3, and 5)\nPAICS (reactions 6, and 7)\nATIC (reactions 9, and 10)The pathway starts with the formation of PRPP. PRPS1 is the enzyme that activates R5P, which is formed primarily by the pentose phosphate pathway, to PRPP by reacting it with ATP. The reaction is unusual in that a pyrophosphoryl group is directly transferred from ATP to C1 of R5P and that the product has the \u03b1 configuration about C1. This reaction is also shared with the pathways for the synthesis of Trp, His, and the pyrimidine nucleotides. Being on a major metabolic crossroad and requiring much energy, this reaction is highly regulated.\nIn the first reaction unique to purine nucleotide biosynthesis, PPAT catalyzes the displacement of PRPP's pyrophosphate group (PPi) by an amide nitrogen donated from either glutamine (N), glycine (N&C), aspartate (N), folic acid (C1), or CO2. This is the committed step in purine synthesis. The reaction occurs with the inversion of configuration about ribose C1, thereby forming \u03b2-5-phosphorybosylamine (5-PRA) and establishing the anomeric form of the future nucleotide.\nNext, a glycine is incorporated fueled by ATP hydrolysis and the carboxyl group forms an amine bond to the NH2 previously introduced. A one-carbon unit from folic acid coenzyme N10-formyl-THF is then added to the amino group of the substituted glycine followed by the closure of the imidazole ring. Next, a second NH2 group is transferred from a glutamine to the first carbon of the glycine unit. A carboxylation of the second carbon of the glycin unit is concomittantly added. This new carbon is modified by the additional of a third NH2 unit, this time transferred from an aspartate residue. Finally, a second one-carbon unit from formyl-THF is added to the nitrogen group and the ring covalently closed to form the common purine precursor inosine monophosphate (IMP).\nInosine monophosphate is converted to adenosine monophosphate in two steps. First, GTP hydrolysis fuels the addition of aspartate to IMP by adenylosuccinate synthase, substituting the carbonyl oxygen for a nitrogen and forming the intermediate adenylosuccinate. Fumarate is then cleaved off forming adenosine monophosphate. This step is catalyzed by adenylosuccinate lyase.\nInosine monophosphate is converted to guanosine monophosphate by the oxidation of IMP forming xanthylate, followed by the insertion of an amino group at C2.  NAD+ is the electron acceptor in the oxidation reaction. The amide group transfer from glutamine is fueled by ATP hydrolysis.\n\n\n=== Pyrimidine and purine degradation ===\nIn humans, pyrimidine rings (C, T, U) can be degraded completely to CO2 and NH3 (urea excretion). That having been said, purine rings (G, A) cannot. Instead they are degraded to the metabolically inert uric acid which is then excreted from the body. Uric acid is formed when GMP is split into the base guanine and ribose. Guanine is deaminated to xanthine which in turn is oxidized to uric acid. This last reaction is irreversible. Similarly, uric acid can be formed when AMP is deaminated to IMP from which the ribose unit is removed to form hypoxanthine. Hypoxanthine is oxidized to xanthine and finally to uric acid. Instead of uric acid secretion, guanine and IMP can be used for recycling purposes and nucleic acid synthesis in the presence of PRPP and aspartate (NH3 donor).\n\n\n== Unnatural base pair (UBP) ==\n\nAn unnatural base pair (UBP) is a designed subunit (or nucleobase) of DNA which is created in a laboratory and does not occur in nature. In 2012, a group of American scientists led by Floyd Romesberg, a chemical biologist at the Scripps Research Institute in San Diego, California, published that his team designed an unnatural base pair (UBP).  The two new artificial nucleotides or Unnatural Base Pair (UBP) were named d5SICS and dNaM. More technically, these artificial nucleotides bearing hydrophobic nucleobases, feature two fused aromatic rings that form a (d5SICS\u2013dNaM) complex or base pair in DNA. In 2014 the same team from the Scripps Research Institute reported that they synthesized a stretch of circular DNA known as a plasmid containing natural T-A and C-G base pairs along with the best-performing UBP Romesberg's laboratory had designed, and inserted it into cells of the common bacterium E. coli that successfully replicated the unnatural base pairs through multiple generations. This is the first known example of a living organism passing along an expanded genetic code to subsequent generations.  This was in part achieved by the addition of a supportive algal gene that expresses a nucleotide triphosphate transporter which efficiently imports the triphosphates of both d5SICSTP and dNaMTP into E. coli bacteria. Then, the natural bacterial replication pathways use them to accurately replicate the plasmid containing d5SICS\u2013dNaM.\nThe successful incorporation of a third base pair is a significant breakthrough toward the goal of greatly expanding the number of amino acids which can be encoded by DNA, from the existing 21 amino acids to a theoretically possible 172, thereby expanding the potential for living organisms to produce novel proteins. The artificial strings of DNA do not encode for anything yet, but scientists speculate they could be designed to manufacture new proteins which could have industrial or pharmaceutical uses.\n\n\n== Length unit ==\nNucleotide (abbreviated \"nt\") is a common unit of length for single-stranded nucleic acids, similar to how base pair is a unit of length for double-stranded nucleic acids.\n\n\n== Nucleotide supplements ==\nA study done by the Department of Sports Science at the University of Hull in Hull, UK has shown that nucleotides have significant impact on cortisol levels in saliva. Post exercise, the experimental nucleotide group had lower cortisol levels in their blood than the control or the placebo. Additionally, post supplement values of Immunoglobulin A were significantly higher than either the placebo or the control. The study concluded, \"nucleotide supplementation blunts the response of the hormones associated with physiological stress.\"Another study conducted in 2013 looked at the impact nucleotide supplementation had on the immune system in athletes. In the study, all athletes were male and were highly skilled in taekwondo. Out of the twenty athletes tested, half received a placebo and half received 480 mg per day of nucleotide supplement. After thirty days, the study concluded that nucleotide supplementation may counteract the impairment of the body's immune function after heavy exercise.\n\n\n== Abbreviation codes for degenerate bases ==\n\nThe IUPAC has designated the symbols for nucleotides. Apart from the five (A, G, C, T/U) bases, often degenerate bases are used especially for designing PCR primers. These nucleotide codes are listed here.  Some primer sequences may also include the character \"I\", which codes for the non-standard nucleotide inosine.  Inosine occurs in tRNAs, and will pair with adenine, cytosine, or thymine.  This character does not appear in the following table however, because it does not represent a degeneracy.  While inosine can serve a similar function as the degeneracy \"D\", it is an actual nucleotide, rather than a representation of a mix of nucleotides that covers each possible pairing needed.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nSigel, Astrid; Operschall, Bert P.; Sigel, Helmut (2017). \"Chapter 11. Complex Formation of Lead(II) with Nucleotides and Their Constituents\".  In Astrid, S.; Helmut, S.; Sigel, R. K. O. Lead: Its Effects on Environment and Health. Metal Ions in Life Sciences. 17. de Gruyter. pp. 319\u2013402. doi:10.1515/9783110434330-011.\n\n\n== External links ==\nAbbreviations and Symbols for Nucleic Acids, Polynucleotides and their Constituents (IUPAC)\nProvisional Recommendations 2004 (IUPAC)\nChemistry explanation of nucleotide structure",
        "unit": "nucleotide",
        "url": "https://en.wikipedia.org/wiki/Nucleotide"
    },
    {
        "_id": "Radioactive_decay",
        "clean": "Radioactive decay",
        "text": "Radioactive decay (also known as nuclear decay, radioactivity or nuclear radiation) is the process by which an unstable atomic nucleus loses energy (in terms of mass in its rest frame) by emitting radiation, such as an alpha particle, beta particle with neutrino or only a neutrino in the case of electron capture, or a gamma ray or electron in the case of internal conversion. A material containing such unstable nuclei is considered radioactive. Certain highly excited short-lived nuclear states can decay through neutron emission, or more rarely, proton emission.\nRadioactive decay is a stochastic (i.e. random) process at the level of single atoms. According to quantum theory, it is impossible to predict when a particular atom will decay, regardless of how long the atom has existed. However, for a collection of atoms, the collection's expected decay rate is characterized in terms of their measured decay constants or half-lives. This is the basis of radiometric dating. The half-lives of radioactive atoms have no known upper limit, spanning a time range of over 55 orders of magnitude, from nearly instantaneous to far longer than the age of the universe.\nA radioactive nucleus with zero spin can have no defined orientation, and hence emits the total momentum of its decay products isotropically (all directions and without bias). If there are multiple particles produced during a single decay, as in beta decay, their relative angular distribution, or spin directions may not be isotropic. Decay products from a nucleus with spin may be distributed non-isotropically with respect to that spin direction, either because of an external influence such as an electromagnetic field, or because the nucleus was produced in a dynamic process that constrained the direction of its spin. Such a parent process could be a previous decay, or a nuclear reaction.The decaying nucleus is called the parent radionuclide (or parent radioisotope), and the process produces at least one daughter nuclide. Except for gamma decay or internal conversion from a nuclear excited state, the decay is a nuclear transmutation resulting in a daughter containing a different number of protons or neutrons (or both). When the number of protons changes, an atom of a different chemical element is created.\nThe first decay processes to be discovered were alpha decay, beta decay, and gamma decay. Alpha decay occurs when the nucleus ejects an alpha particle (helium nucleus). This is the most common process of emitting nucleons, but highly excited nuclei can eject single nucleons, or in the case of cluster decay, specific light nuclei of other elements. Beta decay occurs in two ways:\n(i) beta-minus decay, when the nucleus emits an electron and an antineutrino in a process that changes a neutron to a proton, or\n(ii) beta-plus decay, when the nucleus emits a positron and a neutrino in a process that changes a proton to a neutron. \nHighly excited neutron-rich nuclei, formed as the product of other types of decay, occasionally lose energy by way of neutron emission, resulting in a change from one isotope to another of the same element. The nucleus may capture an orbiting electron, causing a proton to convert into a neutron in a process called electron capture. All of these processes result in a well-defined nuclear transmutation.\nBy contrast, there are radioactive decay processes that do not result in a nuclear transmutation. The energy of an excited nucleus may be emitted as a gamma ray in a process called gamma decay, or that energy may be lost when the nucleus interacts with an orbital electron causing its ejection from the atom, in a process called internal conversion.\nAnother type of radioactive decay results in products that vary, appearing as two or more \"fragments\" of the original nucleus with a range of possible masses. This decay, called spontaneous fission, happens when a large unstable nucleus spontaneously splits into two (or occasionally three) smaller daughter nuclei, and generally leads to the emission of gamma rays, neutrons, or other particles from those products.\nFor a summary table showing the number of stable and radioactive nuclides in each category, see radionuclide. There are 28 naturally occurring chemical elements on Earth that are radioactive, consisting of 33 radionuclides (5 elements have 2 different radionuclides) that date before the time of formation of the solar system. These 33 are known as primordial nuclides. Well-known examples are uranium and thorium, but also included are naturally occurring long-lived radioisotopes, such as potassium-40. Another 50 or so shorter-lived radionuclides, such as radium and radon, found on Earth, are the products of decay chains that began with the primordial nuclides, or are the product of ongoing cosmogenic processes, such as the production of carbon-14 from nitrogen-14 in the atmosphere by cosmic rays. Radionuclides may also be produced artificially in particle accelerators or nuclear reactors, resulting in 650 of these with half-lives of over an hour, and several thousand more with even shorter half-lives. [See here for a list of these sorted by half life.]\n\n\n== History of discovery ==\n\nRadioactivity was discovered in 1896 by the French scientist Henri Becquerel, while working with phosphorescent materials. These materials glow in the dark after exposure to light, and he suspected that the glow produced in cathode ray tubes by X-rays might be associated with phosphorescence. He wrapped a photographic plate in black paper and placed various phosphorescent salts on it. All results were negative until he used uranium salts. The uranium salts caused a blackening of the plate in spite of the plate being wrapped in black paper. These radiations were given the name \"Becquerel Rays\".\nIt soon became clear that the blackening of the plate had nothing to do with phosphorescence, as the blackening was also produced by non-phosphorescent salts of uranium and metallic uranium. It became clear from these experiments that there was a form of invisible radiation that could pass through paper and was causing the plate to react as if exposed to light.\nAt first, it seemed as though the new radiation was similar to the then recently discovered X-rays. Further research by Becquerel, Ernest Rutherford, Paul Villard, Pierre Curie, Marie Curie, and others showed that this form of radioactivity was significantly more complicated. Rutherford was the first to realize that all such elements decay in accordance with the same mathematical exponential formula. Rutherford and his student Frederick Soddy were the first to realize that many decay processes resulted in the transmutation of one element to another. Subsequently, the radioactive displacement law of Fajans and Soddy was formulated to describe the products of alpha and beta decay.The early researchers also discovered that many other chemical elements, besides uranium, have radioactive isotopes. A systematic search for the total radioactivity in uranium ores also guided Pierre and Marie Curie to isolate two new elements: polonium and radium. Except for the radioactivity of radium, the chemical similarity of radium to barium made these two elements difficult to distinguish.\nMarie and Pierre Curie\u2019s study of radioactivity is an important factor in science and medicine. After their research on Becquerel's rays led them to the discovery of both radium and polonium, they coined the term \"radioactivity\". Their research on the penetrating rays in uranium and the discovery of radium launched an era of using radium for the treatment of cancer. Their exploration of radium could be seen as the first peaceful use of nuclear energy and the start of modern nuclear medicine.\n\n\n== Early health dangers ==\n\nThe dangers of ionizing radiation due to radioactivity and X-rays were not immediately recognized.\n\n\n=== X-rays ===\nThe discovery of x\u2011rays by Wilhelm R\u00f6ntgen in 1895 led to widespread experimentation by scientists, physicians, and inventors. Many people began recounting stories of burns, hair loss and worse in technical journals as early as 1896. In February of that year, Professor Daniel and Dr. Dudley of Vanderbilt University performed an experiment involving X-raying Dudley's head that resulted in his hair loss. A report by Dr. H.D. Hawks, of his suffering severe hand and chest burns in an X-ray demonstration, was the first of many other reports in Electrical Review.Other experimenters, including Elihu Thomson and Nikola Tesla, also reported burns. Thomson deliberately exposed a finger to an X-ray tube over a period of time and suffered pain, swelling, and blistering. Other effects, including ultraviolet rays and ozone, were sometimes blamed for the damage, and many physicians still claimed that there were no effects from X-ray exposure at all.Despite this, there were some early systematic hazard investigations, and as early as 1902 William Herbert Rollins wrote almost despairingly that his warnings about the dangers involved in the careless use of X-rays were not being heeded, either by industry or by his colleagues. By this time, Rollins had proved that X-rays could kill experimental animals, could cause a pregnant guinea pig to abort, and that they could kill a fetus. He also stressed that \"animals vary in susceptibility to the external action of X-light\" and warned that these differences be considered when patients were treated by means of X-rays.\n\n\n=== Radioactive substances ===\n\nHowever, the biological effects of radiation due to radioactive substances were less easy to gauge. This gave the opportunity for many physicians and corporations to market radioactive substances as patent medicines. Examples were radium enema treatments, and radium-containing waters to be drunk as tonics. Marie Curie protested against this sort of treatment, warning that the effects of radiation on the human body were not well understood. Curie later died from aplastic anaemia, likely caused by exposure to ionizing radiation. By the 1930s, after a number of cases of bone necrosis and death of radium treatment enthusiasts, radium-containing medicinal products had been largely removed from the market (radioactive quackery).\n\n\n=== Radiation protection ===\n\nOnly a year after R\u00f6ntgen's discovery of X rays, the American engineer Wolfram Fuchs (1896) gave what is probably the first protection advice, but it was not until 1925 that the first International Congress of Radiology (ICR) was held and considered establishing international protection standards. The effects of radiation on genes, including the effect of cancer risk, were recognized much later. In 1927, Hermann Joseph Muller published research showing genetic effects and, in 1946, was awarded the Nobel Prize in Physiology or Medicine for his findings.\nThe second ICR was held in Stockholm in 1928 and proposed the adoption of the rontgen unit, and the 'International X-ray and Radium Protection Committee' (IXRPC) was formed. Rolf Sievert was named Chairman, but a driving force was George Kaye of the British National Physical Laboratory. The committee met in 1931, 1934 and 1937.\nAfter World War II, the increased range and quantity of radioactive substances being handled as a result of military and civil nuclear programmes led to large groups of occupational workers and the public being potentially exposed to harmful levels of ionising radiation. This was considered at the first post-war ICR convened in London in 1950, when the present International Commission on Radiological Protection (ICRP) was born.\nSince then the ICRP has developed the present international system of radiation protection, covering all aspects of radiation hazard.\n\n\n== Units of radioactivity ==\n\nThe International System of Units (SI) unit of radioactive activity is the becquerel (Bq), named in honor of the scientist Henri Becquerel. One Bq is defined as one transformation (or decay or disintegration) per second.\nAn older unit of radioactivity is the curie, Ci, which was originally defined as \"the quantity or mass of radium emanation in equilibrium with one gram of radium (element)\". Today, the curie is defined as 3.7\u00d71010 disintegrations per second, so that 1 curie (Ci) = 3.7\u00d71010 Bq.\nFor radiological protection purposes, although the United States Nuclear Regulatory Commission permits the use of the unit curie alongside SI units, the European Union European units of measurement directives required that its use for \"public health ... purposes\" be phased out by 31 December 1985.The effects of ionizing radiation are often measured in units of gray for mechanical or sievert for damage to tissue.\n\n\n== Types of decay ==\n\nEarly researchers found that an electric or magnetic field could split radioactive emissions into three types of beams. The rays were given the names alpha, beta, and gamma, in increasing order of their ability to penetrate matter. Alpha decay is observed only in heavier elements of atomic number 52 (tellurium) and greater, with the exception of beryllium-8 which decays to two alpha particles. The other two types of decay are produced by all of the elements. Lead, atomic number 82, is the heaviest element to have any isotopes stable (to the limit of measurement) to radioactive decay. Radioactive decay is seen in all isotopes of all elements of atomic number 83 (bismuth) or greater. Bismuth-209, however, is only very slightly radioactive, with a half-life greater than the age of the universe; radioisotopes with extremely long half-lives are considered effectively stable for practical purposes.\n\nIn analysing the nature of the decay products, it was obvious from the direction of the electromagnetic forces applied to the radiations by external magnetic and electric fields that alpha particles carried a positive charge, beta particles carried a negative charge, and gamma rays were neutral. From the magnitude of deflection, it was clear that alpha particles were much more massive than beta particles. Passing alpha particles through a very thin glass window and trapping them in a discharge tube allowed researchers to study the emission spectrum of the captured particles, and ultimately proved that alpha particles are helium nuclei. Other experiments showed beta radiation, resulting from decay and cathode rays, were high-speed electrons. Likewise, gamma radiation and X-rays were found to be high-energy electromagnetic radiation.\nThe relationship between the types of decays also began to be examined: For example, gamma decay was almost always found to be associated with other types of decay, and occurred at about the same time, or afterwards. Gamma decay as a separate phenomenon, with its own half-life (now termed isomeric transition), was found in natural radioactivity to be a result of the gamma decay of excited metastable nuclear isomers, which were in turn created from other types of decay.\nAlthough alpha, beta, and gamma radiations were most commonly found, other types of emission were eventually discovered. Shortly after the discovery of the positron in cosmic ray products, it was realized that the same process that operates in classical beta decay can also produce positrons (positron emission), along with neutrinos (classical beta decay produces antineutrinos). In a more common analogous process, called electron capture, some proton-rich nuclides were found to capture their own atomic electrons instead of emitting positrons, and subsequently these nuclides emit only a neutrino and a gamma ray from the excited nucleus (and often also Auger electrons and characteristic X-rays, as a result of the re-ordering of electrons to fill the place of the missing captured electron). These types of decay involve the nuclear capture of electrons or emission of electrons or positrons, and thus acts to move a nucleus toward the ratio of neutrons to protons that has the least energy for a given total number of nucleons. This consequently produces a more stable (lower energy) nucleus.\n(A theoretical process of positron capture, analogous to electron capture, is possible in antimatter atoms, but has not been observed, as complex antimatter atoms beyond antihelium are not experimentally available. Such a decay would require antimatter atoms at least as complex as beryllium-7, which is the lightest known isotope of normal matter to undergo decay by electron capture.)\nShortly after the discovery of the neutron in 1932, Enrico Fermi realized that certain rare beta-decay reactions immediately yield neutrons as a decay particle (neutron emission). Isolated proton emission was eventually observed in some elements. It was also found that some heavy elements may undergo spontaneous fission into products that vary in composition. In a phenomenon called cluster decay, specific combinations of neutrons and protons other than alpha particles (helium nuclei) were found to be spontaneously emitted from atoms.\nOther types of radioactive decay were found to emit previously-seen particles, but via different mechanisms. An example is internal conversion, which results in an initial electron emission, and then often further characteristic X-rays and Auger electrons emissions, although the internal conversion process involves neither beta nor gamma decay. A neutrino is not emitted, and none of the electron(s) and photon(s) emitted originate in the nucleus, even though the energy to emit all of them does originate there. Internal conversion decay, like isomeric transition gamma decay and neutron emission, involves the release of energy by an excited nuclide, without the transmutation of one element into another.\nRare events that involve a combination of two beta-decay type events happening simultaneously are known (see below). Any decay process that does not violate the conservation of energy or momentum laws (and perhaps other particle conservation laws) is permitted to happen, although not all have been detected. An interesting example discussed in a final section, is bound state beta decay of rhenium-187. In this process, beta electron-decay of the parent nuclide is not accompanied by beta electron emission, because the beta particle has been captured into the K-shell of the emitting atom. An antineutrino is emitted, as in all negative beta decays.\nRadionuclides can undergo a number of different reactions. These are summarized in the following table. A nucleus with mass number A and atomic number Z is represented as (A, Z). The column \"Daughter nucleus\" indicates the difference between the new nucleus and the original nucleus. Thus, (A \u2212 1, Z) means that the mass number is one less than before, but the atomic number is the same as before.\nIf energy circumstances are favorable, a given radionuclide may undergo many competing types of decay, with some atoms decaying by one route, and others decaying by another. An example is copper-64, which has 29 protons, and 35 neutrons, which decays with a half-life of about 12.7 hours. This isotope has one unpaired proton and one unpaired neutron, so either the proton or the neutron can decay to the opposite particle. This particular nuclide (though not all nuclides in this situation) is almost equally likely to decay through positron emission (18%), or through electron capture (43%), as it does through electron emission (39%). The excited energy states resulting from these decays which fail to end in a ground energy state, also produce later internal conversion and gamma decay in almost 0.5% of the time.\nMore common in heavy nuclides is competition between alpha and beta decay. The daughter nuclides will then normally decay through beta or alpha, respectively, to end up in the same place.\n\nRadioactive decay results in a reduction of summed rest mass, once the released energy (the disintegration energy) has escaped in some way. Although decay energy is sometimes defined as associated with the difference between the mass of the parent nuclide products and the mass of the decay products, this is true only of rest mass measurements, where some energy has been removed from the product system. This is true because the decay energy must always carry mass with it, wherever it appears (see mass in special relativity) according to the formula E = mc2. The decay energy is initially released as the energy of emitted photons plus the kinetic energy of massive emitted particles (that is, particles that have rest mass). If these particles come to thermal equilibrium with their surroundings and photons are absorbed, then the decay energy is transformed to thermal energy, which retains its mass.\nDecay energy therefore remains associated with a certain measure of mass of the decay system, called invariant mass, which does not change during the decay, even though the energy of decay is distributed among decay particles. The energy of photons, the kinetic energy of emitted particles, and, later, the thermal energy of the surrounding matter, all contribute to the invariant mass of the system. Thus, while the sum of the rest masses of the particles is not conserved in radioactive decay, the system mass and system invariant mass (and also the system total energy) is conserved throughout any decay process. This is a restatement of the equivalent laws of conservation of energy and conservation of mass.\n\n\n== Radioactive decay rates ==\nThe decay rate, or activity, of a radioactive substance is characterized by:\nConstant quantities:\n\nThe half-life\u2014t1/2, is the time taken for the activity of a given amount of a radioactive substance to decay to half of its initial value; see List of nuclides.\nThe decay constant\u2014 \u03bb, \"lambda\" the reciprocal of the mean lifetime, sometimes referred to as simply decay rate.\nThe mean lifetime\u2014 \u03c4, \"tau\" the average lifetime (1/e life) of a radioactive particle before decay.Although these are constants, they are associated with the statistical behavior of populations of atoms. In consequence, predictions using these constants are less accurate for minuscule samples of atoms.\nIn principle a half-life, a third-life, or even a (1/\u221a2)-life, can be used in exactly the same way as half-life; but the mean life and half-life t1/2 have been adopted as standard times associated with exponential decay.\nTime-variable quantities:\n\nTotal activity\u2014 A, is the number of decays per unit time of a radioactive sample.\nNumber of particles\u2014N, is the total number of particles in the sample.\nSpecific activity\u2014SA, number of decays per unit time per amount of substance of the sample at time set to zero (t = 0). \"Amount of substance\" can be the mass, volume or moles of the initial sample.These are related as follows:\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              (\n              2\n              )\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        (\n        2\n        )\n      \n    \n    {\\displaystyle t_{1/2}={\\frac {\\ln(2)}{\\lambda }}=\\tau \\ln(2)}\n  \n\n  \n    \n      \n        A\n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u03bb\n        N\n      \n    \n    {\\displaystyle A=-{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}=\\lambda N}\n  \n\n  \n    \n      \n        \n          S\n          \n            A\n          \n        \n        \n          a\n          \n            0\n          \n        \n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \n            \n              |\n            \n          \n          \n            t\n            =\n            0\n          \n        \n        =\n        \u03bb\n        \n          N\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle S_{A}a_{0}=-{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}{\\bigg |}_{t=0}=\\lambda N_{0}}\n  where N0 is the initial amount of active substance \u2014 substance that has the same percentage of unstable particles as when the substance was formed.\n\n\n== Mathematics of radioactive decay ==\n\n\n=== Universal law of radioactive decay ===\nRadioactivity is one very frequently given example of exponential decay. The law describes the statistical behaviour of a large number of nuclides, rather than individual atoms. In the following formalism, the number of nuclides or the nuclide population N, is of course a discrete variable (a natural number)\u2014but for any physical sample N is so large that it can be treated as a continuous variable. Differential calculus is used to model the behaviour of nuclear decay.\nThe mathematics of radioactive decay depend on a key assumption that a nucleus of a radionuclide has no \"memory\" or way of translating its history into its present behavior. A nucleus does not \"age\" with the passage of time. Thus, the probability of its breaking down does not increase with time, but stays constant no matter how long the nucleus has existed. This constant probability may vary greatly between different types of nuclei, leading to the many different observed decay rates. However, whatever the probability is, it does not change. This is in marked contrast to complex objects which do show aging, such as automobiles and humans. These systems do have a chance of breakdown per unit of time, that increases from the moment they begin their existence.\n\n\n==== One-decay process ====\nConsider the case of a nuclide A that decays into another B by some process A \u2192 B (emission of other particles, like electron neutrinos \u03bde and electrons e\u2212 as in beta decay, are irrelevant in what follows). The decay of an unstable nucleus is entirely random in time so it is impossible to predict when a particular atom will decay. However, it is equally likely to decay at any instant in time. Therefore, given a sample of a particular radioisotope, the number of decay events \u2212dN expected to occur in a small interval of time dt is proportional to the number of atoms present N, that is\n\n  \n    \n      \n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \u221d\n        N\n        .\n      \n    \n    {\\displaystyle -{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}\\propto N.}\n  Particular radionuclides decay at different rates, so each has its own decay constant \u03bb. The expected decay \u2212dN/N is proportional to an increment of time, dt:\n\nThe negative sign indicates that N decreases as time increases, as the decay events follow one after another. The solution to this first-order differential equation is the function:\n\n  \n    \n      \n        N\n        (\n        t\n        )\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N(t)=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  where N0 is the value of N at time t = 0, with the decay constant expressed as \u03bb or 1/\u03c4We have for all time t:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        +\n        \n          N\n          \n            B\n          \n        \n        =\n        \n          N\n          \n            \n              t\n              o\n              t\n              a\n              l\n            \n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        ,\n      \n    \n    {\\displaystyle N_{A}+N_{B}=N_{\\mathrm {total} }=N_{A0},}\n  where Ntotal is the constant number of particles throughout the decay process, which is equal to the initial number of A nuclides since this is the initial substance.\nIf the number of non-decayed A nuclei is:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        \n        \n      \n    \n    {\\displaystyle N_{A}=N_{A0}e^{-{\\lambda }t}\\,\\!}\n  then the number of nuclei of B, i.e. the number of decayed A nuclei, is\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \u2212\n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \u2212\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                \n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{B}=N_{A0}-N_{A}=N_{A0}-N_{A0}e^{-{\\lambda }t}=N_{A0}\\left(1-e^{-{\\lambda }t}\\right).}\n  The number of decays observed over a given interval obeys Poisson statistics. If the average number of decays is <N>, the probability of a given number of decays N is\n\n  \n    \n      \n        P\n        (\n        N\n        )\n        =\n        \n          \n            \n              \u27e8\n              N\n              \n                \u27e9\n                \n                  N\n                \n              \n              exp\n              \u2061\n              (\n              \u2212\n              \u27e8\n              N\n              \u27e9\n              )\n            \n            \n              N\n              !\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle P(N)={\\frac {\\langle N\\rangle ^{N}\\exp(-\\langle N\\rangle )}{N!}}.}\n  \n\n\n==== Chain-decay processes ====\nChain of two decays\nNow consider the case of a chain of two decays: one nuclide A decaying into another B by one process, then B decaying into another C by a second process, i.e. A \u2192 B \u2192 C. The previous equation cannot be applied to the decay chain, but can be generalized as follows. Since A decays into B, then B decays into C, the activity of A adds to the total number of B nuclides in the present sample, before those B nuclides decay and reduce the number of nuclides leading to the later sample. In other words, the number of second generation nuclei B increases as a result of the first generation nuclei decay of A, and decreases as a result of its own decay into the third generation nuclei C. The sum of these two terms gives the law for a decay chain for two nuclides:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  B\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u2212\n        \n          \u03bb\n          \n            B\n          \n        \n        \n          N\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            A\n          \n        \n        \n          N\n          \n            A\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}=-\\lambda _{B}N_{B}+\\lambda _{A}N_{A}.}\n  The rate of change of NB, that is dNB/dt, is related to the changes in the amounts of A and B, NB can increase as B is produced from A and decrease as B produces C.\nRe-writing using the previous results:\n\nThe subscripts simply refer to the respective nuclides, i.e. NA is the number of nuclides of type A, NA0 is the initial number of nuclides of type A, \u03bbA is the decay constant for A - and similarly for nuclide B. Solving this equation for NB gives:\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                N\n                \n                  A\n                  0\n                \n              \n              \n                \u03bb\n                \n                  A\n                \n              \n            \n            \n              \n                \u03bb\n                \n                  B\n                \n              \n              \u2212\n              \n                \u03bb\n                \n                  A\n                \n              \n            \n          \n        \n        \n          (\n          \n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    B\n                  \n                \n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{B}={\\frac {N_{A0}\\lambda _{A}}{\\lambda _{B}-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-e^{-\\lambda _{B}t}\\right).}\n  In the case where B is a stable nuclide (\u03bbB = 0), this equation reduces to the previous solution:\n\n  \n    \n      \n        \n          lim\n          \n            \n              \u03bb\n              \n                B\n              \n            \n            \u2192\n            0\n          \n        \n        \n          [\n          \n            \n              \n                \n                  \n                    N\n                    \n                      A\n                      0\n                    \n                  \n                  \n                    \u03bb\n                    \n                      A\n                    \n                  \n                \n                \n                  \n                    \u03bb\n                    \n                      B\n                    \n                  \n                  \u2212\n                  \n                    \u03bb\n                    \n                      A\n                    \n                  \n                \n              \n            \n            \n              (\n              \n                \n                  e\n                  \n                    \u2212\n                    \n                      \u03bb\n                      \n                        A\n                      \n                    \n                    t\n                  \n                \n                \u2212\n                \n                  e\n                  \n                    \u2212\n                    \n                      \u03bb\n                      \n                        B\n                      \n                    \n                    t\n                  \n                \n              \n              )\n            \n          \n          ]\n        \n        =\n        \n          \n            \n              \n                N\n                \n                  A\n                  0\n                \n              \n              \n                \u03bb\n                \n                  A\n                \n              \n            \n            \n              0\n              \u2212\n              \n                \u03bb\n                \n                  A\n                \n              \n            \n          \n        \n        \n          (\n          \n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n            \u2212\n            1\n          \n          )\n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\lim _{\\lambda _{B}\\rightarrow 0}\\left[{\\frac {N_{A0}\\lambda _{A}}{\\lambda _{B}-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-e^{-\\lambda _{B}t}\\right)\\right]={\\frac {N_{A0}\\lambda _{A}}{0-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-1\\right)=N_{A0}\\left(1-e^{-\\lambda _{A}t}\\right),}\n  as shown above for one decay. The solution can be found by the integration factor method, where the integrating factor is e\u03bbBt. This case is perhaps the most useful, since it can derive both the one-decay equation (above) and the equation for multi-decay chains (below) more directly.\nChain of any number of decays\nFor the general case of any number of consecutive decays in a decay chain, i.e. A1 \u2192 A2 \u00b7\u00b7\u00b7 \u2192 Ai \u00b7\u00b7\u00b7 \u2192 AD, where D is the number of decays and i is a dummy index (i = 1, 2, 3, ...D), each nuclide population can be found in terms of the previous population. In this case N2 = 0, N3 = 0,..., ND = 0. Using the above result in a recursive form:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  j\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u2212\n        \n          \u03bb\n          \n            j\n          \n        \n        \n          N\n          \n            j\n          \n        \n        +\n        \n          \u03bb\n          \n            j\n            \u2212\n            1\n          \n        \n        \n          N\n          \n            (\n            j\n            \u2212\n            1\n            )\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n              \n                j\n                \u2212\n                1\n              \n            \n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{j}}{\\mathrm {d} t}}=-\\lambda _{j}N_{j}+\\lambda _{j-1}N_{(j-1)0}e^{-\\lambda _{j-1}t}.}\n  The general solution to the recursive problem is given by Bateman's equations:\n\n\n==== Alternative decay modes ====\nIn all of the above examples, the initial nuclide decays into just one product. Consider the case of one initial nuclide that can decay into either of two products, that is A \u2192 B and A \u2192 C in parallel. For example, in a sample of potassium-40, 89.3% of the nuclei decay to calcium-40 and 10.7% to argon-40. We have for all time t:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            A\n          \n        \n        +\n        \n          N\n          \n            B\n          \n        \n        +\n        \n          N\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle N=N_{A}+N_{B}+N_{C}}\n  which is constant, since the total number of nuclides remains constant. Differentiating with respect to time:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        d\n                      \n                      \n                        N\n                        \n                          A\n                        \n                      \n                    \n                    \n                      \n                        d\n                      \n                      t\n                    \n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  (\n                  \n                    \n                      \n                        \n                          \n                            d\n                          \n                          \n                            N\n                            \n                              B\n                            \n                          \n                        \n                        \n                          \n                            d\n                          \n                          t\n                        \n                      \n                    \n                    +\n                    \n                      \n                        \n                          \n                            d\n                          \n                          \n                            N\n                            \n                              C\n                            \n                          \n                        \n                        \n                          \n                            d\n                          \n                          t\n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n            \n              \n                \u2212\n                \u03bb\n                \n                  N\n                  \n                    A\n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  N\n                  \n                    A\n                  \n                \n                \n                  (\n                  \n                    \n                      \u03bb\n                      \n                        B\n                      \n                    \n                    +\n                    \n                      \u03bb\n                      \n                        C\n                      \n                    \n                  \n                  )\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\frac {\\mathrm {d} N_{A}}{\\mathrm {d} t}}&=-\\left({\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} N_{C}}{\\mathrm {d} t}}\\right)\\\\-\\lambda N_{A}&=-N_{A}\\left(\\lambda _{B}+\\lambda _{C}\\right)\\\\\\end{aligned}}}\n  defining the total decay constant \u03bb in terms of the sum of partial decay constants \u03bbB and \u03bbC:\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        .\n      \n    \n    {\\displaystyle \\lambda =\\lambda _{B}+\\lambda _{C}.}\n  Notice that \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  A\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        <\n        0\n        ,\n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  B\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        >\n        0\n        ,\n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  C\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        >\n        0.\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{A}}{\\mathrm {d} t}}<0,{\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}>0,{\\frac {\\mathrm {d} N_{C}}{\\mathrm {d} t}}>0.}\n  Solving this equation for NA:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \u03bb\n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle N_{A}=N_{A0}e^{-\\lambda t}.}\n  where NA0 is the initial number of nuclide A. When measuring the production of one nuclide, one can only observe the total decay constant \u03bb. The decay constants \u03bbB and \u03bbC determine the probability for the decay to result in products B or C as follows:\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \u03bb\n              \n                B\n              \n            \n            \u03bb\n          \n        \n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bb\n                t\n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle N_{B}={\\frac {\\lambda _{B}}{\\lambda }}N_{A0}\\left(1-e^{-\\lambda t}\\right),}\n  \n  \n    \n      \n        \n          N\n          \n            C\n          \n        \n        =\n        \n          \n            \n              \u03bb\n              \n                C\n              \n            \n            \u03bb\n          \n        \n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bb\n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{C}={\\frac {\\lambda _{C}}{\\lambda }}N_{A0}\\left(1-e^{-\\lambda t}\\right).}\n  because the fraction \u03bbB/\u03bb of nuclei decay into B while the fraction \u03bbC/\u03bb of nuclei decay into C.\n\n\n=== Corollaries of the decay laws ===\nThe above equations can also be written using quantities related to the number of nuclide particles N in a sample;\n\nThe activity: A = \u03bbN.\nThe amount of substance: n = N/L.\nThe mass: M = Arn = ArN/L.where L = 6.022\u00d71023 is Avogadro's constant, Ar is the relative atomic mass number, and the amount of the substance is in moles.\n\n\n=== Decay timing: definitions and relations ===\n\n\n==== Time constant and mean-life ====\nFor the one-decay solution A \u2192 B:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  the equation indicates that the decay constant \u03bb has units of t\u22121, and can thus also be represented as 1/\u03c4, where \u03c4 is a characteristic time of the process called the time constant.\nIn a radioactive decay process, this time constant is also the mean lifetime for decaying atoms. Each atom \"lives\" for a finite amount of time before it decays, and it may be shown that this mean lifetime is the arithmetic mean of all the atoms' lifetimes, and that it is \u03c4, which again is related to the decay constant as follows:\n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            1\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau ={\\frac {1}{\\lambda }}.}\n  This form is also true for two-decay processes simultaneously A \u2192 B + C, inserting the equivalent values of decay constants (as given above)\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        \n      \n    \n    {\\displaystyle \\lambda =\\lambda _{B}+\\lambda _{C}\\,}\n  into the decay solution leads to:\n\n  \n    \n      \n        \n          \n            1\n            \u03c4\n          \n        \n        =\n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        =\n        \n          \n            1\n            \n              \u03c4\n              \n                B\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              \u03c4\n              \n                C\n              \n            \n          \n        \n        \n      \n    \n    {\\displaystyle {\\frac {1}{\\tau }}=\\lambda =\\lambda _{B}+\\lambda _{C}={\\frac {1}{\\tau _{B}}}+{\\frac {1}{\\tau _{C}}}\\,}\n  \n\n\n==== Half-life ====\nA more commonly used parameter is the half-life. Given a sample of a particular radionuclide, the half-life is the time taken for half the radionuclide's atoms to decay. For the case of one-decay nuclear reactions:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  the half-life is related to the decay constant as follows: set N = N0/2 and t = T1/2 to obtain\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              2\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        2.\n      \n    \n    {\\displaystyle t_{1/2}={\\frac {\\ln 2}{\\lambda }}=\\tau \\ln 2.}\n  This relationship between the half-life and the decay constant shows that highly radioactive substances are quickly spent, while those that radiate weakly endure longer. Half-lives of known radionuclides vary widely, from more than 1019 years, such as for the very nearly stable nuclide 209Bi, to 10\u221223 seconds for highly unstable ones.\nThe factor of ln(2) in the above relations results from the fact that the concept of \"half-life\" is merely a way of selecting a different base other than the natural base e for the lifetime expression. The time constant \u03c4 is the e -1 -life, the time until only 1/e remains, about 36.8%, rather than the 50% in the half-life of a radionuclide. Thus, \u03c4 is longer than t1/2. The following equation can be shown to be valid:\n\n  \n    \n      \n        N\n        (\n        t\n        )\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          2\n          \n            \u2212\n            t\n            \n              /\n            \n            \n              t\n              \n                1\n                \n                  /\n                \n                2\n              \n            \n          \n        \n        .\n        \n        \n      \n    \n    {\\displaystyle N(t)=N_{0}\\,e^{-t/\\tau }=N_{0}\\,2^{-t/t_{1/2}}.\\,\\!}\n  Since radioactive decay is exponential with a constant probability, each process could as easily be described with a different constant time period that (for example) gave its \"(1/3)-life\" (how long until only 1/3 is left) or \"(1/10)-life\" (a time period until only 10% is left), and so on. Thus, the choice of \u03c4 and t1/2 for marker-times, are only for convenience, and from convention. They reflect a fundamental principle only in so much as they show that the same proportion of a given radioactive substance will decay, during any time-period that one chooses.\nMathematically, the nth life for the above situation would be found in the same way as above\u2014by setting N = N0/n, t = T1/n and substituting into the decay solution to obtain\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            n\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              n\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        n\n        .\n      \n    \n    {\\displaystyle t_{1/n}={\\frac {\\ln n}{\\lambda }}=\\tau \\ln n.}\n  \n\n\n=== Example ===\nA sample of 14C has a half-life of 5,730 years and a decay rate of 14 disintegration per minute (dpm) per gram of natural carbon.\nIf an artifact is found to have radioactivity of 4 dpm per gram of its present C, we can find the approximate age of the object using the above equation:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-t/\\tau },}\n  where: \n  \n    \n      \n        \n          \n            N\n            \n              N\n              \n                0\n              \n            \n          \n        \n        =\n        4\n        \n          /\n        \n        14\n        \u2248\n        0.286\n        ,\n      \n    \n    {\\displaystyle {\\frac {N}{N_{0}}}=4/14\\approx 0.286,}\n  \n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            \n              T\n              \n                1\n                \n                  /\n                \n                2\n              \n            \n            \n              ln\n              \u2061\n              2\n            \n          \n        \n        \u2248\n        8267\n      \n    \n    {\\displaystyle \\tau ={\\frac {T_{1/2}}{\\ln 2}}\\approx 8267}\n   years,\n\n  \n    \n      \n        t\n        =\n        \u2212\n        \u03c4\n        \n        ln\n        \u2061\n        \n          \n            N\n            \n              N\n              \n                0\n              \n            \n          \n        \n        \u2248\n        10356\n      \n    \n    {\\displaystyle t=-\\tau \\,\\ln {\\frac {N}{N_{0}}}\\approx 10356}\n   years.\n\n\n== Changing decay rates ==\nThe radioactive decay modes of electron capture and internal conversion are known to be slightly sensitive to chemical and environmental effects that change the electronic structure of the atom, which in turn affects the presence of 1s and 2s electrons that participate in the decay process. A small number of mostly light nuclides are affected. For example, chemical bonds can affect the rate of electron capture to a small degree (in general, less than 1%) depending on the proximity of electrons to the nucleus. In 7Be, a difference of 0.9% has been observed between half-lives in metallic and insulating environments. This relatively large effect is because beryllium is a small atom whose valence electrons are in 2s atomic orbitals, which are subject to electron capture in 7Be because (like all s atomic orbitals in all atoms) they naturally penetrate into the nucleus.\nIn 1992, Jung et al. of the Darmstadt Heavy-Ion Research group observed an accelerated \u03b2\u2212 decay of 163Dy66+. Although neutral 163Dy is a stable isotope, the fully ionized 163Dy66+ undergoes \u03b2\u2212 decay into the K and L shells to 163Ho66+ with a half-life of 47 days.Rhenium-187 is another spectacular example. 187Re normally beta decays to 187Os with a half-life of 41.6 \u00d7 109 years, but studies using fully ionised 187Re atoms (bare nuclei) have found that this can decrease to only 33 years. This is attributed to \"bound-state \u03b2\u2212 decay\" of the fully ionised atom \u2013 the electron is emitted into the \"K-shell\" (1s atomic orbital), which cannot occur for neutral atoms in which all low-lying bound states are occupied.\n\nA number of experiments have found that decay rates of other modes of artificial and naturally occurring radioisotopes are, to a high degree of precision, unaffected by external conditions such as temperature, pressure, the chemical environment, and electric, magnetic, or gravitational fields. Comparison of laboratory experiments over the last century, studies of the Oklo natural nuclear reactor (which exemplified the effects of thermal neutrons on nuclear decay), and astrophysical observations of the luminosity decays of distant supernovae (which occurred far away so the light has taken a great deal of time to reach us), for example, strongly indicate that unperturbed decay rates have been constant (at least to within the limitations of small experimental errors) as a function of time as well.Recent results suggest the possibility that decay rates might have a weak dependence on environmental factors. It has been suggested that measurements of decay rates of silicon-32, manganese-54, and radium-226 exhibit small seasonal variations (of the order of 0.1%).  However, such measurements are highly susceptible to systematic errors, and a subsequent paper has found no evidence for such correlations in seven other isotopes (22Na, 44Ti, 108Ag, 121Sn, 133Ba, 241Am, 238Pu), and sets upper limits on the size of any such effects. The decay of radon-222 was once reported to exhibit large 4% peak-to-peak seasonal variations (see plot),  which were proposed to be related to either solar flare activity or the distance from the Sun, but detailed analysis of the experiment's design flaws, along with comparisons to other, much more stringent and systematically controlled, experiments refute this claim.\n\n\n=== GSI anomaly ===\n\nAn unexpected series of experimental results for the rate of decay of heavy highly charged radioactive ions circulating in a storage ring has provoked theoretical activity in an effort to find a convincing explanation. The rates of weak decay of two radioactive species with half lives of about 40 s and 200 s are found to have a significant oscillatory modulation, with a period of about 7 s.\nThe observed phenomenon is known as the GSI anomaly, as the storage ring is a facility at the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany.  As the decay process produces an electron neutrino, some of the proposed explanations for the observed rate oscillation invoke neutrino properties. Initial ideas related to flavour oscillation met with skepticism.  A more recent proposal involves mass differences between neutrino mass eigenstates.\n\n\n== Theoretical basis of decay phenomena ==\nThe neutrons and protons that constitute nuclei, as well as other particles that approach close enough to them, are governed by several interactions. The strong nuclear force, not observed at the familiar macroscopic scale, is the most powerful force over subatomic distances. The electrostatic force is almost always significant, and, in the case of beta decay, the weak nuclear force is also involved.\nThe combined effects of these forces produces a number of different phenomena in which energy may be released by rearrangement of particles in the nucleus, or else the change of one type of particle into others. These rearrangements and transformations may be hindered energetically, so that they do not occur immediately. In certain cases, random quantum vacuum fluctuations are theorized to promote relaxation to a lower energy state (the \"decay\") in a phenomenon known as quantum tunneling. Radioactive decay half-life of nuclides has been measured over timescales of 55 orders of magnitude, from 2.3 \u00d7 10\u221223 seconds (for hydrogen-7) to 6.9 \u00d7 1031 seconds (for tellurium-128). The limits of these timescales are set by the sensitivity of instrumentation only, and there are no known natural limits to how brief or long a decay half-life for radioactive decay of a radionuclide may be.\nThe decay process, like all hindered energy transformations, may be analogized by a snowfield on a mountain. While friction between the ice crystals may be supporting the snow's weight, the system is inherently unstable with regard to a state of lower potential energy. A disturbance would thus facilitate the path to a state of greater entropy; the system will move towards the ground state, producing heat, and the total energy will be distributable over a larger number of quantum states thus resulting in an avalanche. The total energy does not change in this process, but, because of the second law of thermodynamics, avalanches have only been observed in one direction and that is toward the \"ground state\" \u2014 the state with the largest number of ways in which the available energy could be distributed.\nSuch a collapse (a gamma-ray decay event) requires a specific activation energy. For a snow avalanche, this energy comes as a disturbance from outside the system, although such disturbances can be arbitrarily small. In the case of an excited atomic nucleus decaying by gamma radiation in a spontaneous emission of electromagnetic radiation, the arbitrarily small disturbance comes from quantum vacuum fluctuations.A radioactive nucleus (or any excited system in quantum mechanics) is unstable, and can, thus, spontaneously stabilize to a less-excited system. The resulting transformation alters the structure of the nucleus and results in the emission of either a photon or a high-velocity particle that has mass (such as an electron, alpha particle, or other type).\n\n\n== Occurrence and applications ==\nAccording to the Big Bang theory, stable isotopes of the lightest five elements (H, He, and traces of Li, Be, and B) were produced very shortly after the emergence of the universe, in a process called Big Bang nucleosynthesis. These lightest stable nuclides (including deuterium) survive to today, but any radioactive isotopes of the light elements produced in the Big Bang (such as tritium) have long since decayed. Isotopes of elements heavier than boron were not produced at all in the Big Bang, and these first five elements do not have any long-lived radioisotopes. Thus, all radioactive nuclei are, therefore, relatively young with respect to the birth of the universe, having formed later in various other types of nucleosynthesis in stars (in particular, supernovae), and also during ongoing interactions between stable isotopes and energetic particles. For example, carbon-14, a radioactive nuclide with a half-life of only 5,730 years, is constantly produced in Earth's upper atmosphere due to interactions between cosmic rays and nitrogen.\nNuclides that are produced by radioactive decay are called radiogenic nuclides, whether they themselves are stable or not. There exist stable radiogenic nuclides that were formed from short-lived extinct radionuclides in the early solar system. The extra presence of these stable radiogenic nuclides (such as Xe-129 from primordial I-129) against the background of primordial stable nuclides can be inferred by various means.\nRadioactive decay has been put to use in the technique of radioisotopic labeling, which is used to track the passage of a chemical substance through a complex system (such as a living organism). A sample of the substance is synthesized with a high concentration of unstable atoms. The presence of the substance in one or another part of the system is determined by detecting the locations of decay events.\nOn the premise that radioactive decay is truly random (rather than merely chaotic), it has been used in hardware random-number generators. Because the process is not thought to vary significantly in mechanism over time, it is also a valuable tool in estimating the absolute ages of certain materials. For geological materials, the radioisotopes and some of their decay products become trapped when a rock solidifies, and can then later be used (subject to many well-known qualifications) to estimate the date of the solidification. These include checking the results of several simultaneous processes and their products against each other, within the same sample. In a similar fashion, and also subject to qualification, the rate of formation of carbon-14 in various eras, the date of formation of organic matter within a certain period related to the isotope's half-life may be estimated, because the carbon-14 becomes trapped when the organic matter grows and incorporates the new carbon-14 from the air. Thereafter, the amount of carbon-14 in organic matter decreases according to decay processes that may also be independently cross-checked by other means (such as checking the carbon-14 in individual tree rings, for example).\n\n\n=== Szilard\u2013Chalmers effect ===\nThe Szilard\u2013Chalmers effect is defined as the breaking of a chemical bond between an atom and the molecule that the atom is part of, as a result of a nuclear reaction of the atom. The effect can be used to separate isotopes by chemical means. The discovery of this effect is due to Le\u00f3 Szil\u00e1rd and Thomas A. Chalmers.\n\n\n== Origins of radioactive nuclides ==\n\nRadioactive primordial nuclides found in the Earth are residues from ancient supernova explosions that occurred before the formation of the solar system. They are the fraction of radionuclides that survived from that time, through the formation of the primordial solar nebula, through planet accretion, and up to the present time. The naturally occurring short-lived radiogenic radionuclides found in today's rocks, are the daughters of those radioactive primordial nuclides. Another minor source of naturally occurring radioactive nuclides are cosmogenic nuclides, that are formed by cosmic ray bombardment of material in the Earth's atmosphere or crust. The decay of the radionuclides in rocks of the Earth's mantle and crust contribute significantly to Earth's internal heat budget.\n\n\n== Decay chains and multiple modes ==\n\nThe daughter nuclide of a decay event may also be unstable (radioactive). In this case, it too will decay, producing radiation. The resulting second daughter nuclide may also be radioactive. This can lead to a sequence of several decay events called a decay chain (see this article for specific details of important natural decay chains). Eventually, a stable nuclide is produced.\n\nAn example is the natural decay chain of 238U:\n\nUranium-238 decays, through alpha-emission, with a half-life of 4.5 billion years to thorium-234\nwhich decays, through beta-emission, with a half-life of 24 days to protactinium-234\nwhich decays, through beta-emission, with a half-life of 1.2 minutes to uranium-234\nwhich decays, through alpha-emission, with a half-life of 240 thousand years to thorium-230\nwhich decays, through alpha-emission, with a half-life of 77 thousand years to radium-226\nwhich decays, through alpha-emission, with a half-life of 1.6 thousand years to radon-222\nwhich decays, through alpha-emission, with a half-life of 3.8 days to polonium-218\nwhich decays, through alpha-emission, with a half-life of 3.1 minutes to lead-214\nwhich decays, through beta-emission, with a half-life of 27 minutes to bismuth-214\nwhich decays, through beta-emission, with a half-life of 20 minutes to polonium-214\nwhich decays, through alpha-emission, with a half-life of 160 microseconds to lead-210\nwhich decays, through beta-emission, with a half-life of 22 years to bismuth-210\nwhich decays, through beta-emission, with a half-life of 5 days to polonium-210\nwhich decays, through alpha-emission, with a half-life of 140 days to lead-206, which is a stable nuclide.Some radionuclides may have several different paths of decay. For example, approximately 36% of bismuth-212 decays, through alpha-emission, to thallium-208 while approximately 64% of bismuth-212 decays, through beta-emission, to polonium-212. Both thallium-208 and polonium-212 are radioactive daughter products of bismuth-212, and both decay directly to stable lead-208.\n\n\n== Associated hazard warning signs ==\n\n\t\t\n\t\t\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Inline ===\n\n\n=== General ===\n\"Radioactivity\", Encyclop\u00e6dia Britannica. 2006. Encyclop\u00e6dia Britannica Online. December 18, 2006\nRadio-activity by Ernest Rutherford Phd, Encyclop\u00e6dia Britannica Eleventh Edition\n\n\n== External links ==\nThe Lund/LBNL Nuclear Data Search \u2013 Contains tabulated information on radioactive decay types and energies.\nNomenclature of nuclear chemistry\nSpecific activity and related topics.\nThe Live Chart of Nuclides \u2013 IAEA\nInteractive Chart of Nuclides\nHealth Physics Society Public Education Website\n Beach, Chandler B., ed. (1914). \"Becquerel Rays\". The New Student's Reference Work. Chicago: F. E. Compton and Co.\nAnnotated bibliography for radioactivity from the Alsos Digital Library for Nuclear Issues\nStochastic Java applet on the decay of radioactive atoms by Wolfgang Bauer\nStochastic Flash simulation on the decay of radioactive atoms by David M. Harrison\n\"Henri Becquerel: The Discovery of Radioactivity\", Becquerel's 1896 articles online and analyzed on BibNum [click '\u00e0 t\u00e9l\u00e9charger' for English version].\n\"Radioactive change\", Rutherford & Soddy article (1903), online and analyzed on Bibnum [click '\u00e0 t\u00e9l\u00e9charger' for English version].",
        "unit": "radioactivity",
        "url": "https://en.wikipedia.org/wiki/Radioactive_decay"
    },
    {
        "_id": "Magnetic_field",
        "clean": "Magnetic field",
        "text": "A magnetic field is a vector field that describes the magnetic influence of electrical currents and magnetized materials. In everyday life, the effects of magnetic fields are often seen in permanent magnets, which pull on magnetic materials (such as iron) and attract or repel other magnets. Magnetic fields surround and are created by magnetized material and by moving electric charges (electric currents) such as those used in electromagnets. Magnetic fields exert forces on nearby moving electrical charges and torques on nearby magnets. In addition, a magnetic field that varies with location exerts a force on magnetic materials. Both the strength and direction of a magnetic field varies with location. As such, it is an example of a vector field.\nThe term 'magnetic field' is used for two distinct but closely related fields denoted by the symbols B and H. In the International System of Units, H is measured in units of amperes per meter and B is measured in teslas or newtons per meter per ampere.  H and B differ in how they account for magnetization. In a vacuum, B and H are the same aside from units; but in a magnetized material, B/\n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   and H differ by the magnetization M of the material at that point in the material.\nMagnetic fields are produced by moving electric charges and the intrinsic magnetic moments of elementary particles associated with a fundamental quantum property, their spin. Magnetic fields and electric fields are interrelated, and are both components of the electromagnetic force, one of the four fundamental forces of nature.\nMagnetic fields are widely used throughout modern technology, particularly in electrical engineering and electromechanics. Rotating magnetic fields are used in both electric motors and generators. The interaction of magnetic fields in electric devices such as transformers is studied in the discipline of magnetic circuits. Magnetic forces give information about the charge carriers in a material through the Hall effect. The Earth produces its own magnetic field, which shields the Earth's ozone layer from the solar wind and is important in navigation using a compass.\n\n\n== History ==\n\nAlthough magnets and magnetism were studied much earlier, the research of magnetic fields began in 1269 when French scholar Petrus Peregrinus de Maricourt mapped out the magnetic field on the surface of a spherical magnet using iron needles. Noting that the resulting field lines crossed at two points he named those points 'poles' in analogy to Earth's poles. He also clearly articulated the principle that magnets always have both a north and south pole, no matter how finely one slices them.\nAlmost three centuries later, William Gilbert of Colchester replicated Petrus Peregrinus' work and was the first to state explicitly that Earth is a magnet. Published in 1600, Gilbert's work, De Magnete, helped to establish magnetism as a science.\nIn 1750, John Michell stated that magnetic poles attract and repel in accordance with an inverse square law. Charles-Augustin de Coulomb experimentally verified this in 1785 and stated explicitly that the north and south poles cannot be separated. Building on this force between poles, Sim\u00e9on Denis Poisson (1781\u20131840) created the first successful model of the magnetic field, which he presented in 1824. In this model, a magnetic H-field is produced by 'magnetic poles' and magnetism is due to small pairs of north/south magnetic poles.\n\nThree discoveries challenged this foundation of magnetism, though. First, in 1819, Hans Christian \u00d8rsted discovered that an electric current generates a magnetic field encircling it. Then in 1820, Andr\u00e9-Marie Amp\u00e8re showed that parallel wires with currents attract one another if the currents are in the same direction and repel if they are in opposite directions. Finally, Jean-Baptiste Biot and F\u00e9lix Savart discovered the Biot\u2013Savart law in 1820, which correctly predicts the magnetic field around any current-carrying wire.\nExtending these experiments, Amp\u00e8re published his own successful model of magnetism in 1825. In it, he showed the equivalence of electrical currents to magnets and proposed that magnetism is due to perpetually flowing loops of current instead of the dipoles of magnetic charge in Poisson's model. This has the additional benefit of explaining why magnetic charge can not be isolated. Further, Amp\u00e8re derived both Amp\u00e8re's force law describing the force between two currents and Amp\u00e8re's law, which, like the Biot\u2013Savart law, correctly described the magnetic field generated by a steady current. Also in this work, Amp\u00e8re introduced the term electrodynamics to describe the relationship between electricity and magnetism.\nIn 1831, Michael Faraday discovered electromagnetic induction when he found that a changing magnetic field generates an encircling electric field. He described this phenomenon in what is known as Faraday's law of induction. Later, Franz Ernst Neumann proved that, for a moving conductor in a magnetic field, induction is a consequence of Amp\u00e8re's force law. In the process, he introduced the magnetic vector potential, which was later shown to be equivalent to the underlying mechanism proposed by Faraday.\nIn 1850, Lord Kelvin, then known as William Thomson, distinguished between two magnetic fields now denoted H and B. The former applied to Poisson's model and the latter to Amp\u00e8re's model and induction. Further, he derived how H and B relate to each other.\nThe reason H and B are used for the two magnetic fields has been a source of some debate among science historians. Most agree that Kelvin avoided M to prevent confusion with the SI fundamental unit of length, the Metre, abbreviated \"m\". Others believe the choices were purely random.Between 1861 and 1865, James Clerk Maxwell developed and published Maxwell's equations, which explained and united all of classical electricity and magnetism. The first set of these equations was published in a paper entitled On Physical Lines of Force in 1861. These equations were valid although incomplete. Maxwell completed his set of equations in his later 1865 paper A Dynamical Theory of the Electromagnetic Field and demonstrated the fact that light is an electromagnetic wave. Heinrich Hertz experimentally confirmed this fact in 1887.\nThe twentieth century extended electrodynamics to include relativity and quantum mechanics. Albert Einstein, in his paper of 1905 that established relativity, showed that both the electric and magnetic fields are part of the same phenomena viewed from different reference frames. (See moving magnet and conductor problem for details about the thought experiment that eventually helped Albert Einstein to develop special relativity.) Finally, the emergent field of quantum mechanics was merged with electrodynamics to form quantum electrodynamics (QED).\n\n\n== Definitions, units and measurement ==\n\n\n=== The B-field ===\nThe magnetic field can be defined in several equivalent ways based on the effects it has on its environment.\nOften the magnetic field is defined by the force it exerts on a moving charged particle. It is known from experiments in electrostatics that a particle of charge q in an electric field E experiences a force F = qE. However, in other situations, such as when a charged particle moves in the vicinity of a current-carrying wire, the force also depends on the velocity of that particle. The velocity dependent portion can be separated such that the force on the particle satisfies the Lorentz force law,\n\n  \n    \n      \n        \n          F\n        \n        =\n        q\n        (\n        \n          E\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {F} =q(\\mathbf {E} +\\mathbf {v} \\times \\mathbf {B} ).}\n  Here v is the particle's velocity and \u00d7 denotes the cross product. The vector B is termed the magnetic field, and it is defined as the vector field necessary to make the Lorentz force law correctly describe the motion of a charged particle. This definition allows the determination of B in the following way\n[T]he command, \"Measure the direction and magnitude of the vector B at such and such a place,\" calls for the following operations: Take a particle of known charge q. Measure the force on q at rest, to determine E. Then measure the force on the particle when its velocity is v; repeat with v in some other direction. Now find a B that makes the Lorentz force law fit all these results\u2014that is the magnetic field at the place in question.\n\nAlternatively, the magnetic field can be defined in terms of the torque it produces on a magnetic dipole (see magnetic torque on permanent magnets below).\n\n\n=== The H-field ===\nIn addition to B, there is a quantity H, which is often called the magnetic field. In a vacuum, B and H are proportional to each other, with the multiplicative constant depending on the physical units. Inside a material they are different (see H and B inside and outside magnetic materials). The term \"magnetic field\" is historically reserved for H while using other terms for B. Informally, though, and formally for some recent textbooks mostly in physics, the term 'magnetic field' is used to describe B as well as or in place of H.\nThere are many alternative names for both (see sidebar).\n\n\n=== Units ===\nIn SI units, B is measured in teslas (symbol: T) and correspondingly \u03a6B (magnetic flux) is measured in webers (symbol: Wb) so that a flux density of 1 Wb/m2 is 1 tesla. The SI unit of tesla is equivalent to (newton\u00b7second)/(coulomb\u00b7metre). In Gaussian-cgs units, B is measured in gauss (symbol: G). (The conversion is 1 T = 10000 G.) One nanotesla is equivalent to 1 gamma (symbol: \u03b3). The H-field is measured in amperes per metre (A/m) in SI units, and in oersteds (Oe) in cgs units.\n\n\n=== Measurement ===\nThe precision attained for a magnetic field measurement for Gravity Probe B experiment is 5 attoteslas (5\u00d710\u221218 T); the largest magnetic field produced in a laboratory is 2.8 kT (VNIIEF in Sarov, Russia, 1998). The magnetic field of some astronomical objects such as magnetars are much higher; magnetars range from 0.1 to 100 GT (108 to 1011 T).  See orders of magnitude (magnetic field).\nDevices used to measure the local magnetic field are called magnetometers. Important classes of magnetometers include using induction magnetometer (or search-coil magnetometer) which measure only varying magnetic field, rotating coil magnetometer, Hall effect magnetometers, NMR magnetometers, SQUID magnetometers, and fluxgate magnetometers. The magnetic fields of distant astronomical objects are measured through their effects on local charged particles. For instance, electrons spiraling around a field line produce synchrotron radiation that is detectable in radio waves.\n\n\n== Magnetic field lines ==\n\nMapping the magnetic field of an object is simple in principle. First, measure the strength and direction of the magnetic field at a large number of locations (or at every point in space). Then, mark each location with an arrow (called a vector) pointing in the direction of the local magnetic field with its magnitude proportional to the strength of the magnetic field.\nAn alternative method to map the magnetic field is to 'connect' the arrows to form magnetic field lines. The direction of the magnetic field at any point is parallel to the direction of nearby field lines, and the local density of field lines can be made proportional to its strength. Magnetic field lines are like streamlines in fluid flow, in that they represent something continuous, and a different resolution would show more or fewer lines.\nAn advantage of using magnetic field lines as a representation is that many laws of magnetism (and electromagnetism) can be stated completely and concisely using simple concepts such as the 'number' of field lines through a surface. These concepts can be quickly 'translated' to their mathematical form. For example, the number of field lines through a given surface is the surface integral of the magnetic field.\nVarious phenomena have the effect of \"displaying\" magnetic field lines as though the field lines were physical phenomena. For example, iron filings placed in a magnetic field, form lines that correspond to 'field lines'. Magnetic field \"lines\" are also visually displayed in polar auroras, in which plasma particle dipole interactions create visible streaks of light that line up with the local direction of Earth's magnetic field.\nField lines can be used as a qualitative tool to visualize magnetic forces. In ferromagnetic substances like iron and in plasmas, magnetic forces can be understood by imagining that the field lines exert a tension, (like a rubber band) along their length, and a pressure perpendicular to their length on neighboring field lines.  'Unlike' poles of magnets attract because they are linked by many field lines; 'like' poles repel because their field lines do not meet, but run parallel, pushing on each other. The rigorous form of this concept is the electromagnetic stress\u2013energy tensor.\n\n\n== Magnetic field and permanent magnets ==\n\nPermanent magnets are objects that produce their own persistent magnetic fields. They are made of ferromagnetic materials, such as iron and nickel, that have been magnetized, and they have both a north and a south pole.\n\n\n=== Magnetic field of permanent magnets ===\n\nThe magnetic field of permanent magnets can be quite complicated, especially near the magnet. The magnetic field of a small straight magnet is proportional to the magnet's strength (called its magnetic dipole moment m). The equations are non-trivial and also depend on the distance from the magnet and the orientation of the magnet. For simple magnets, m points in the direction of a line drawn from the south to the north pole of the magnet. Flipping a bar magnet is equivalent to rotating its m by 180 degrees.\nThe magnetic field of larger magnets can be obtained by modeling them as a collection of a large number of small magnets called dipoles each having their own m. The magnetic field produced by the magnet then is the net magnetic field of these dipoles. And, any net force on the magnet is a result of adding up the forces on the individual dipoles.\nThere are two competing models for the nature of these dipoles. These two models produce two different magnetic fields, H and B. Outside a material, though, the two are identical (to a multiplicative constant) so that in many cases the distinction can be ignored. This is particularly true for magnetic fields, such as those due to electric currents, that are not generated by magnetic materials.\n\n\n=== Magnetic pole model and the H-field ===\n\nIt is sometimes useful to model the force and torques between two magnets as due to magnetic poles repelling or attracting each other in the same manner as the Coulomb force between electric charges. This is called the Gilbert model of magnetism, after William Gilbert. In this model, a magnetic H-field is produced by magnetic charges that are 'smeared' around each pole. These magnetic charges are in fact related to the magnetization field M.\nThe H-field, therefore, is analogous to the electric field E, which starts at a positive electric charge and ends at a negative electric charge. Near the north pole, therefore, all H-field lines point away from the north pole (whether inside the magnet or out) while near the south pole all H-field lines point toward the south pole (whether inside the magnet or out). Too, a north pole feels a force in the direction of the H-field while the force on the south pole is opposite to the H-field.\nIn the magnetic pole model, the elementary magnetic dipole m is formed by two opposite magnetic poles of pole strength qm separated by a small distance vector d, such that m = qm\u2009d. The magnetic pole model predicts correctly the field H both inside and outside magnetic materials, in particular the fact that  H is opposite to the magnetization field M inside a permanent magnet.\nSince it is based on the fictitious idea of a magnetic charge density, the Gilbert model has limitations. Magnetic poles cannot exist apart from each other as electric charges can, but always come in north/south pairs. If a magnetized object is divided in half, a new pole appears on the surface of each piece, so each has a pair of complementary poles. The magnetic pole model does not account for magnetism that is produced by electric currents.\n\n\n=== Amperian loop model and the B-field ===\n\nAfter \u00d8rsted discovered that electric currents produce a magnetic field and Ampere discovered that electric currents attracted and repelled each other similar to magnets, it was natural to hypothesize that all magnetic fields are due to electric current loops. In this model developed by Ampere, the elementary magnetic dipole that makes up all magnets is a sufficiently small Amperian loop of current I. The dipole moment of this loop is m = IA where A is the area of the loop.\nThese magnetic dipoles produce a magnetic B-field. One important property of the B-field produced this way is that magnetic B-field lines neither start nor end (mathematically, B is a solenoidal vector field); a field line either extends to infinity or wraps around to form a closed curve. To date, no exception to this rule has been found. (See magnetic monopole below.) Magnetic field lines exit a magnet near its north pole and enter near its south pole, but inside the magnet B-field lines continue through the magnet from the south pole back to the north. If a B-field line enters a magnet somewhere it has to leave somewhere else; it is not allowed to have an end point. Magnetic poles, therefore, always come in N and S pairs.\nMore formally, since all the magnetic field lines that enter any given region must also leave that region, subtracting the 'number' of field lines that enter the region from the number that exit gives identically zero. Mathematically this is equivalent to:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        0\n        ,\n      \n    \n    {\\displaystyle \\oint _{S}\\mathbf {B} \\cdot \\mathrm {d} \\mathbf {A} =0,}\n  where the integral is a surface integral over the closed surface S (a closed surface is one that completely surrounds a region with no holes to let any field lines escape). Since dA points outward, the dot product in the integral is positive for B-field pointing out and negative for B-field pointing in.\nThere is also a corresponding differential form of this equation covered in Maxwell's equations below.\n\n\n=== Force between magnets ===\n\nThe force between two small magnets is quite complicated and depends on the strength and orientation of both magnets and the distance and direction of the magnets relative to each other. The force is particularly sensitive to rotations of the magnets due to magnetic torque. The force on each magnet depends on its magnetic moment and the magnetic field of the other.\nTo understand the force between magnets, it is useful to examine the magnetic pole model given above. In this model, the H-field of one magnet pushes and pulls on both poles of a second magnet. If this H-field is the same at both poles of the second magnet then there is no net force on that magnet since the force is opposite for opposite poles. If, however, the magnetic field of the first magnet is nonuniform (such as the H near one of its poles), each pole of the second magnet sees a different field and is subject to a different force. This difference in the two forces moves the magnet in the direction of increasing magnetic field and may also cause a net torque.\nThis is a specific example of a general rule that magnets are attracted (or repulsed depending on the orientation of the magnet) into regions of higher magnetic field. Any non-uniform magnetic field, whether caused by permanent magnets or electric currents, exerts a force on a small magnet in this way.\nThe details of the Amperian loop model are different and more complicated but yield the same result: that magnetic dipoles are attracted/repelled into regions of higher magnetic field.\nMathematically, the force on a small magnet having a magnetic moment m due to a magnetic field B is:\n\n  \n    \n      \n        \n          F\n        \n        =\n        \n          \u2207\n        \n        \n          (\n          \n            \n              m\n            \n            \u22c5\n            \n              B\n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =\\mathbf {\\nabla } \\left(\\mathbf {m} \\cdot \\mathbf {B} \\right),}\n  where the gradient \u2207 is the change of the quantity m \u00b7 B per unit distance and the direction is that of maximum increase of m \u00b7 B. To understand this equation, note that the dot product m \u00b7 B = mBcos(\u03b8), where m and B represent the magnitude of the m and B vectors and \u03b8 is the angle between them. If m is in the same direction as B then the dot product is positive and the gradient points 'uphill' pulling the magnet into regions of higher B-field (more strictly larger m \u00b7 B). This equation is strictly only valid for magnets of zero size, but is often a good approximation for not too large magnets. The magnetic force on larger magnets is determined by dividing them into smaller regions each having their own m then summing up the forces on each of these very small regions.\n\n\n=== Magnetic torque on permanent magnets ===\n\nIf two like poles of two separate magnets are brought near each other, and one of the magnets is allowed to turn, it promptly rotates to align itself with the first. In this example, the magnetic field of the stationary magnet creates a magnetic torque on the magnet that is free to rotate. This magnetic torque \u03c4 tends to align a magnet's poles with the magnetic field lines. A compass, therefore, turns to align itself with Earth's magnetic field.\nMagnetic torque is used to drive electric motors. In one simple motor design, a magnet is fixed to a freely rotating shaft and subjected to a magnetic field from an array of electromagnets. By continuously switching the electric current through each of the electromagnets, thereby flipping the polarity of their magnetic fields, like poles are kept next to the rotor; the resultant torque is transferred to the shaft. See Rotating magnetic fields below.\n\nAs is the case for the force between magnets, the magnetic pole model leads more readily to the correct equation. Here, two equal and opposite magnetic charges experiencing the same H also experience equal and opposite forces. Since these equal and opposite forces are in different locations, this produces a torque proportional to the distance (perpendicular to the force) between them. With the definition of m as the pole strength times the distance between the poles, this leads to \u03c4 = \u03bc0mHsin\u03b8, where \u03bc0 is a constant called the vacuum permeability, measuring 4\u03c0\u00d710\u22127 V\u00b7s/(A\u00b7m) and \u03b8 is the angle between H and m.\nThe Amperian loop model also predicts the same magnetic torque. Here, it is the B field interacting with the Amperian current loop through a Lorentz force described below. Again, the results are the same although the models are completely different.\n\nMathematically, the torque \u03c4 on a small magnet is proportional both to the applied magnetic field and to the magnetic moment m of the magnet:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          m\n        \n        \u00d7\n        \n          B\n        \n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          m\n        \n        \u00d7\n        \n          H\n        \n        ,\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {m} \\times \\mathbf {B} =\\mu _{0}\\mathbf {m} \\times \\mathbf {H} ,\\,}\n  where \u00d7 represents the vector cross product. Note that this equation includes all of the qualitative information included above. There is no torque on a magnet if m is in the same direction as the magnetic field. (The cross product is zero for two vectors that are in the same direction.) Further, all other orientations feel a torque that twists them toward the direction of magnetic field.\n\n\n== Magnetic field and electric currents ==\nCurrents of electric charges both generate a magnetic field and feel a force due to magnetic B-fields.\n\n\n=== Magnetic field due to moving charges and electric currents ===\n\nAll moving charged particles produce magnetic fields. Moving point charges, such as electrons, produce complicated but well known magnetic fields that depend on the charge, velocity, and acceleration of the particles.Magnetic field lines form in concentric circles around a cylindrical current-carrying conductor, such as a length of wire. The direction of such a magnetic field can be determined by using the \"right hand grip rule\" (see figure at right). The strength of the magnetic field decreases with distance from the wire. (For an infinite length wire the strength is inversely proportional to the distance.)\n\nBending a current-carrying wire into a loop concentrates the magnetic field inside the loop while weakening it outside. Bending a wire into multiple closely spaced loops to form a coil or \"solenoid\" enhances this effect. A device so formed around an iron core may act as an electromagnet, generating a strong, well-controlled magnetic field. An infinitely long cylindrical electromagnet has a uniform magnetic field inside, and no magnetic field outside. A finite length electromagnet produces a magnetic field that looks similar to that produced by a uniform permanent magnet, with its strength and polarity determined by the current flowing through the coil.\nThe magnetic field generated by a steady current I (a constant flow of electric charges, in which charge neither accumulates nor is depleted at any point) is described by the Biot\u2013Savart law:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              I\n            \n            \n              4\n              \u03c0\n            \n          \n        \n        \n          \u222b\n          \n            \n              w\n              i\n              r\n              e\n            \n          \n        \n        \n          \n            \n              \n                d\n              \n              \n                \u2113\n              \n              \u00d7\n              \n                \n                  \n                    r\n                    ^\n                  \n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} ={\\frac {\\mu _{0}I}{4\\pi }}\\int _{\\mathrm {wire} }{\\frac {\\mathrm {d} {\\boldsymbol {\\ell }}\\times \\mathbf {\\hat {r}} }{r^{2}}},}\n  where the integral sums over the wire length where vector d\u2113 is the vector line element with direction in the same sense as the current I, \u03bc0 is the magnetic constant, r is the distance between the location of d\u2113 and the location where the magnetic field is calculated, and r\u0302 is a unit vector in the direction of r.  In the case of a sufficiently long wire, this becomes:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              I\n            \n            \n              2\n              \u03c0\n              r\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {B} ={\\frac {\\mu _{0}I}{2\\pi r}}}\n  where r is the distance from the wire.A slightly more general way of relating the current \n  \n    \n      \n        \n          I\n        \n      \n    \n    {\\displaystyle {I}}\n   to the B-field is through Amp\u00e8re's law:\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          I\n          \n            \n              e\n              n\n              c\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {B} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=\\mu _{0}I_{\\mathrm {enc} },}\n  where the line integral is over any arbitrary loop and \n  \n    \n      \n        \n          I\n        \n      \n    \n    {\\displaystyle {I}}\n  enc is the current enclosed by that loop. Amp\u00e8re's law is always valid for steady currents and can be used to calculate the B-field for certain highly symmetric situations such as an infinite wire or an infinite solenoid.\nIn a modified form that accounts for time varying electric fields, Amp\u00e8re's law is one of four Maxwell's equations that describe electricity and magnetism.\n\n\n=== Force on moving charges and current ===\n\n\n==== Force on a charged particle ====\n\nA charged particle moving in a B-field experiences a sideways force that is proportional to the strength of the magnetic field, the component of the velocity that is perpendicular to the magnetic field and the charge of the particle. This force is known as the Lorentz force, and is given by\n\n  \n    \n      \n        \n          F\n        \n        =\n        q\n        \n          E\n        \n        +\n        q\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =q\\mathbf {E} +q\\mathbf {v} \\times \\mathbf {B} ,}\n  where\nF is the force, q is the electric charge of the particle, v is the instantaneous velocity  of the particle, and B is the magnetic field (in teslas).\nThe Lorentz force is always perpendicular to both the velocity of the particle and the magnetic field that created it. When a charged particle moves in a static magnetic field, it traces a helical path in which the helix axis is parallel to the magnetic field, and in which the speed of the particle remains constant. Because the magnetic force is always perpendicular to the motion, the magnetic field can do no work on an isolated charge. It can only do work indirectly, via the electric field generated by a changing magnetic field. It is often claimed that the magnetic force can do work to a non-elementary magnetic dipole, or to charged particles whose motion is constrained by other forces, but this is incorrect because the work in those cases is performed by the electric forces of the charges deflected by the magnetic field.\n\n\n==== Force on current-carrying wire ====\n\nThe force on a current carrying wire is similar to that of a moving charge as expected since a current carrying wire is a collection of moving charges. A current-carrying wire feels a force in the presence of a magnetic field. The Lorentz force on a macroscopic current is often referred to as the Laplace force.\nConsider a conductor of length \u2113, cross section A, and charge q due to electric current i. If this conductor is placed in a magnetic field of magnitude B that makes an angle \u03b8 with the velocity of charges in the conductor, the force exerted on a single charge q is\n\n  \n    \n      \n        F\n        =\n        q\n        v\n        B\n        sin\n        \u2061\n        \u03b8\n        ,\n      \n    \n    {\\displaystyle F=qvB\\sin \\theta ,}\n  so, for N charges where \n\n  \n    \n      \n        N\n        =\n        n\n        \u2113\n        A\n      \n    \n    {\\displaystyle N=n\\ell A}\n  ,the force exerted on the conductor is\n\n  \n    \n      \n        f\n        =\n        F\n        N\n        =\n        q\n        v\n        B\n        n\n        \u2113\n        A\n        sin\n        \u2061\n        \u03b8\n        =\n        B\n        i\n        \u2113\n        sin\n        \u2061\n        \u03b8\n      \n    \n    {\\displaystyle f=FN=qvBn\\ell A\\sin \\theta =Bi\\ell \\sin \\theta }\n  ,where i = nqvA.\n\n\n==== Direction of force ====\n\nThe direction of force on a charge or a current can be determined by a mnemonic known as the right-hand rule (see the figure). Using the right hand, pointing the thumb in the direction of the current, and the fingers in the direction of the magnetic field, the resulting force on the charge points outwards from the palm. The force on a negatively charged particle is in the opposite direction. If both the speed and the charge are reversed then the direction of the force remains the same. For that reason a magnetic field measurement (by itself) cannot distinguish whether there is a positive charge moving to the right or a negative charge moving to the left. (Both of these cases produce the same current.)  On the other hand, a magnetic field combined with an electric field can distinguish between these, see Hall effect below.\nAn alternative mnemonic to the right hand rule is Flemings's left hand rule.\n\n\n== Relation between H and B ==\nThe formulas derived for the magnetic field above are correct when dealing with the entire current. A magnetic material placed inside a magnetic field, though, generates its own bound current, which can be a challenge to calculate.  (This bound current is due to the sum of atomic sized current loops and the spin of the subatomic particles such as electrons that make up the material.)  The H-field as defined above helps factor out this bound current; but to see how, it helps to introduce the concept of magnetization first.\n\n\n=== Magnetization ===\n\nThe magnetization vector field M represents how strongly a region of material is magnetized. It is defined as the net magnetic dipole moment per unit volume of that region. The magnetization of a uniform magnet is therefore a material constant, equal to the magnetic moment m of the magnet divided by its volume. Since the SI unit of magnetic moment is A\u22c5m2, the SI unit of magnetization M is ampere per meter, identical to that of the H-field.\nThe magnetization M field of a region points in the direction of the average magnetic dipole moment in that region. Magnetization field lines, therefore, begin near the magnetic south pole and ends near the magnetic north pole. (Magnetization does not exist outside the magnet.)\nIn the Amperian loop model, the magnetization is due to combining many tiny Amperian loops to form a resultant current called bound current. This bound current, then, is the source of the magnetic B field due to the magnet. (See Magnetic dipoles below and magnetic poles vs. atomic currents for more information.) Given the definition of the magnetic dipole, the magnetization field follows a similar law to that of Ampere's law:\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          M\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          I\n          \n            \n              b\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {M} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=I_{\\mathrm {b} },}\n  where the integral is a line integral over any closed loop and Ib is the 'bound current' enclosed by that closed loop.\nIn the magnetic pole model, magnetization begins at and ends at magnetic poles. If a given region, therefore, has a net positive 'magnetic pole strength' (corresponding to a north pole) then it has more magnetization field lines entering it than leaving it. Mathematically this is equivalent to:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          M\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        \u2212\n        \n          q\n          \n            \n              M\n            \n          \n        \n      \n    \n    {\\displaystyle \\oint _{S}\\mu _{0}\\mathbf {M} \\cdot \\mathrm {d} \\mathbf {A} =-q_{\\mathrm {M} }}\n  ,where the integral is a closed surface integral over the closed surface S and qM is the 'magnetic charge' (in units of magnetic flux) enclosed by S. (A closed surface completely surrounds a region with no holes to let any field lines escape.) The negative sign occurs because the magnetization field moves from south to north.\n\n\n=== H-field and magnetic materials ===\n\nIn SI units, the H-field is related to the B-field by\n\n  \n    \n      \n        \n          H\n        \n         \n        \u2261\n         \n        \n          \n            \n              B\n            \n            \n              \u03bc\n              \n                0\n              \n            \n          \n        \n        \u2212\n        \n          M\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {H} \\ \\equiv \\ {\\frac {\\mathbf {B} }{\\mu _{0}}}-\\mathbf {M} .}\n  In terms of the H-field, Ampere's law is\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          (\n          \n            \n              \n                \n                  B\n                \n                \n                  \u03bc\n                  \n                    0\n                  \n                \n              \n            \n            \u2212\n            \n              M\n            \n          \n          )\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          I\n          \n            \n              t\n              o\n              t\n            \n          \n        \n        \u2212\n        \n          I\n          \n            \n              b\n            \n          \n        \n        =\n        \n          I\n          \n            \n              f\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {H} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=\\oint \\left({\\frac {\\mathbf {B} }{\\mu _{0}}}-\\mathbf {M} \\right)\\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=I_{\\mathrm {tot} }-I_{\\mathrm {b} }=I_{\\mathrm {f} },}\n  where If represents the 'free current' enclosed by the loop so that the line integral of H does not depend at all on the bound currents.For the differential equivalent of this equation see Maxwell's equations. Ampere's law leads to the boundary condition \n\n  \n    \n      \n        \n          (\n          \n            \n              \n                H\n                \n                  1\n                \n                \n                  \u2225\n                \n              \n            \n            \u2212\n            \n              \n                H\n                \n                  2\n                \n                \n                  \u2225\n                \n              \n            \n          \n          )\n        \n        =\n        \n          \n            K\n          \n          \n            \n              f\n            \n          \n        \n        \u00d7\n        \n          \n            \n              \n                n\n              \n              ^\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\left(\\mathbf {H_{1}^{\\parallel }} -\\mathbf {H_{2}^{\\parallel }} \\right)=\\mathbf {K} _{\\mathrm {f} }\\times {\\hat {\\mathbf {n} }},}\n  where Kf is the surface free current density and the unit normal \n  \n    \n      \n        \n          \n            \n              \n                n\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {n} }}}\n   points in the direction from medium 2 to medium 1.Similarly, a surface integral of H over any closed surface is independent of the free currents and picks out the \"magnetic charges\" within that closed surface:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        (\n        \n          B\n        \n        \u2212\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          M\n        \n        )\n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        0\n        \u2212\n        (\n        \u2212\n        \n          q\n          \n            \n              M\n            \n          \n        \n        )\n        =\n        \n          q\n          \n            \n              M\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint _{S}\\mu _{0}\\mathbf {H} \\cdot \\mathrm {d} \\mathbf {A} =\\oint _{S}(\\mathbf {B} -\\mu _{0}\\mathbf {M} )\\cdot \\mathrm {d} \\mathbf {A} =0-(-q_{\\mathrm {M} })=q_{\\mathrm {M} },}\n  which does not depend on the free currents.\nThe H-field, therefore, can be separated into two independent parts:\n\n  \n    \n      \n        \n          H\n        \n        =\n        \n          \n            H\n          \n          \n            0\n          \n        \n        +\n        \n          \n            H\n          \n          \n            \n              d\n            \n          \n        \n        ,\n        \n      \n    \n    {\\displaystyle \\mathbf {H} =\\mathbf {H} _{0}+\\mathbf {H} _{\\mathrm {d} },\\,}\n  where H0 is the applied magnetic field due only to the free currents and Hd is the demagnetizing field due only to the bound currents.\nThe magnetic H-field, therefore, re-factors the bound current in terms of \"magnetic charges\". The H field lines loop only around 'free current' and, unlike the magnetic B field, begins and ends near magnetic poles as well.\n\n\n=== Magnetism ===\n\nMost materials respond to an applied B-field by producing their own magnetization M and therefore their own B-field. Typically, the response is weak and exists only when the magnetic field is applied. The term magnetism describes how materials respond on the microscopic level to an applied magnetic field and is used to categorize the magnetic phase of a material. Materials are divided into groups based upon their magnetic behavior:\n\nDiamagnetic materials produce a magnetization that opposes the magnetic field.\nParamagnetic materials produce a magnetization in the same direction as the applied magnetic field.\nFerromagnetic materials and the closely related ferrimagnetic materials and antiferromagnetic materials  can have a magnetization independent of an applied B-field with a complex relationship between the two fields.\nSuperconductors (and ferromagnetic superconductors) are materials that are characterized by perfect conductivity below a critical temperature and magnetic field. They also are highly magnetic and can be perfect diamagnets below a lower critical magnetic field. Superconductors often have a broad range of temperatures and magnetic fields (the so-named mixed state) under which they exhibit a complex hysteretic dependence of M on B.In the case of paramagnetism and diamagnetism, the magnetization M is often proportional to the applied magnetic field such that:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \u03bc\n        \n          H\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} =\\mu \\mathbf {H} ,}\n  where \u03bc is a material dependent parameter called the permeability. In some cases the permeability may be a second rank tensor so that H may not point in the same direction as B. These relations between B  and H are examples of constitutive equations. However, superconductors and ferromagnets have a more complex B to H relation; see magnetic hysteresis.\n\n\n== Energy stored in magnetic fields ==\n\nEnergy is needed to generate a magnetic field both to work against the electric field that a changing magnetic field creates and to change the magnetization of any material within the magnetic field. For non-dispersive materials, this same energy is released when the magnetic field is destroyed so that this energy can be modeled as being stored in the magnetic field.\nFor linear, non-dispersive, materials (such that B = \u03bcH where \u03bc is frequency-independent), the energy density is:\n\n  \n    \n      \n        u\n        =\n        \n          \n            \n              \n                B\n              \n              \u22c5\n              \n                H\n              \n            \n            2\n          \n        \n        =\n        \n          \n            \n              \n                B\n              \n              \u22c5\n              \n                B\n              \n            \n            \n              2\n              \u03bc\n            \n          \n        \n        =\n        \n          \n            \n              \u03bc\n              \n                H\n              \n              \u22c5\n              \n                H\n              \n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle u={\\frac {\\mathbf {B} \\cdot \\mathbf {H} }{2}}={\\frac {\\mathbf {B} \\cdot \\mathbf {B} }{2\\mu }}={\\frac {\\mu \\mathbf {H} \\cdot \\mathbf {H} }{2}}.}\n  If there are no magnetic materials around then \u03bc can be replaced by \u03bc0. The above equation cannot be used for nonlinear materials, though; a more general expression given below must be used.\nIn general, the incremental amount of work per unit volume \u03b4W needed to cause a small change of magnetic field \u03b4B is:\n\n  \n    \n      \n        \u03b4\n        W\n        =\n        \n          H\n        \n        \u22c5\n        \u03b4\n        \n          B\n        \n        .\n      \n    \n    {\\displaystyle \\delta W=\\mathbf {H} \\cdot \\delta \\mathbf {B} .}\n  Once the relationship between H and B is known this equation is used to determine the work needed to reach a given magnetic state. For hysteretic materials such as ferromagnets and superconductors, the work needed also depends on how the magnetic field is created. For linear non-dispersive materials, though, the general equation leads directly to the simpler energy density equation given above.\n\n\n== Electromagnetism: the relationship between magnetic and electric fields ==\n\n\n=== Faraday's Law: Electric force due to a changing B-field ===\n\nA changing magnetic field, such as a magnet moving through a conducting coil, generates an electric field (and therefore tends to drive a current in such a coil). This is known as Faraday's law and forms the basis of many electrical generators and electric motors.\nMathematically, Faraday's law is:\n\n  \n    \n      \n        \n          \n            E\n          \n        \n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              \u03a6\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\mathcal {E}}=-{\\frac {\\mathrm {d} \\Phi }{\\mathrm {d} t}},}\n  where \n  \n    \n      \n        \n          \n            \n              E\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\mathcal {E}}}\n   is the electromotive force (or EMF, the voltage generated around a closed loop) and \u03a6 is the magnetic flux\u2014the product of the area times the magnetic field normal to that area.  (This definition of magnetic flux is why B is often referred to as magnetic flux density.)The negative sign represents the fact that any current generated by a changing magnetic field in a coil produces a magnetic field that opposes the change in the magnetic field that induced it. This phenomenon is known as Lenz's law.\nThis integral formulation of Faraday's law can be converted into a differential form, which applies under slightly different conditions. This form is covered as one of Maxwell's equations below.\n\n\n=== Maxwell's correction to Amp\u00e8re's Law: The magnetic field due to a changing electric field ===\n\nSimilar to the way that a changing magnetic field generates an electric field, a changing electric field generates a magnetic field. This fact is known as Maxwell's correction to Amp\u00e8re's law and is applied as an additive term to Ampere's law as given above. This additional term is proportional to the time rate of change of the electric flux and is similar to Faraday's law above but with a different and positive constant out front. (The electric flux through an area is proportional to the area times the perpendicular part of the electric field.)\nThe full law including the correction term is known as the Maxwell\u2013Amp\u00e8re equation. It is not commonly given in integral form because the effect is so small that it can typically be ignored in most cases where the integral form is used.\nThe Maxwell term is critically important in the creation and propagation of electromagnetic waves. Maxwell's correction to Amp\u00e8re's Law together with Faraday's law of induction describes how mutually changing electric and magnetic fields interact to sustain each other and thus to form electromagnetic waves, such as light: a changing electric field generates a changing magnetic field, which generates a changing electric field again. These, though, are usually described using the differential form of this equation given below.\n\n\n=== Maxwell's equations ===\n\nLike all vector fields, a magnetic field has two important mathematical properties that relates it to its sources.  (For B the sources are currents and changing electric fields.) These two properties, along with the two corresponding properties of the electric field, make up Maxwell's Equations. Maxwell's Equations together with the Lorentz force law form a complete description of classical electrodynamics including both electricity and magnetism.\nThe first property is the divergence of a vector field A, \u2207 \u00b7 A, which represents how A 'flows' outward from a given point. As discussed above, a B-field line never starts or ends at a point but instead forms a complete loop. This is mathematically equivalent to saying that the divergence of B is zero. (Such vector fields are called solenoidal vector fields.) This property is called Gauss's law for magnetism and is equivalent to the statement that there are no isolated magnetic poles or magnetic monopoles. The electric field on the other hand begins and ends at electric charges so that its divergence is non-zero and proportional to the charge density (See Gauss's law).\nThe second mathematical property is called the curl, such that \u2207 \u00d7 A represents how A curls or 'circulates' around a given point. The result of the curl is called a 'circulation source'. The equations for the curl of B and of E are called the Amp\u00e8re\u2013Maxwell equation and Faraday's law respectively. They represent the differential forms of the integral equations given above.\nThe complete set of Maxwell's equations then are:\n\n  \n    \n      \n        \n          \n            \n              \n                \u2207\n                \u22c5\n                \n                  B\n                \n              \n              \n                \n                =\n                0\n                ,\n              \n            \n            \n              \n                \u2207\n                \u22c5\n                \n                  E\n                \n              \n              \n                \n                =\n                \n                  \n                    \u03c1\n                    \n                      \u03b5\n                      \n                        0\n                      \n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  B\n                \n              \n              \n                \n                =\n                \n                  \u03bc\n                  \n                    0\n                  \n                \n                \n                  J\n                \n                +\n                \n                  \u03bc\n                  \n                    0\n                  \n                \n                \n                  \u03b5\n                  \n                    0\n                  \n                \n                \n                  \n                    \n                      \u2202\n                      \n                        E\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        B\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\nabla \\cdot \\mathbf {B} &=0,\\\\\\nabla \\cdot \\mathbf {E} &={\\frac {\\rho }{\\varepsilon _{0}}},\\\\\\nabla \\times \\mathbf {B} &=\\mu _{0}\\mathbf {J} +\\mu _{0}\\varepsilon _{0}{\\frac {\\partial \\mathbf {E} }{\\partial t}},\\\\\\nabla \\times \\mathbf {E} &=-{\\frac {\\partial \\mathbf {B} }{\\partial t}},\\end{aligned}}}\n  where J = complete microscopic current density and \u03c1 is the charge density.\nAs discussed above, materials respond to an applied electric E field and an applied magnetic B field by producing their own internal 'bound' charge and current distributions that contribute to E and B but are difficult to calculate. To circumvent this problem, H and D fields are used to re-factor Maxwell's equations in terms of the free current density Jf and free charge density \u03c1f:\n\n  \n    \n      \n        \n          \n            \n              \n                \u2207\n                \u22c5\n                \n                  B\n                \n              \n              \n                \n                =\n                0\n                ,\n              \n            \n            \n              \n                \u2207\n                \u22c5\n                \n                  D\n                \n              \n              \n                \n                =\n                \n                  \u03c1\n                  \n                    \n                      f\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  H\n                \n              \n              \n                \n                =\n                \n                  \n                    J\n                  \n                  \n                    \n                      f\n                    \n                  \n                \n                +\n                \n                  \n                    \n                      \u2202\n                      \n                        D\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        B\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\nabla \\cdot \\mathbf {B} &=0,\\\\\\nabla \\cdot \\mathbf {D} &=\\rho _{\\mathrm {f} },\\\\\\nabla \\times \\mathbf {H} &=\\mathbf {J} _{\\mathrm {f} }+{\\frac {\\partial \\mathbf {D} }{\\partial t}},\\\\\\nabla \\times \\mathbf {E} &=-{\\frac {\\partial \\mathbf {B} }{\\partial t}}.\\end{aligned}}}\n  These equations are not any more general than the original equations (if the 'bound' charges and currents in the material are known). They also must be supplemented by the relationship between B and H as well as that between E and D. On the other hand, for simple relationships between these quantities this form of Maxwell's equations can circumvent the need to calculate the bound charges and currents.\n\n\n=== Electric and magnetic fields: different aspects of the same phenomenon ===\n\nAccording to the special theory of relativity, the partition of the electromagnetic force into separate electric and magnetic components is not fundamental, but varies with the observational frame of reference: An electric force perceived by one observer may be perceived by another (in a different frame of reference) as a magnetic force, or a mixture of electric and magnetic forces.\nFormally, special relativity combines the electric and magnetic fields into a rank-2 tensor, called the electromagnetic tensor. Changing reference frames mixes these components. This is analogous to the way that special relativity mixes space and time into spacetime, and mass, momentum and energy into four-momentum.\n\n\n=== Magnetic vector potential ===\n\nIn advanced topics such as quantum mechanics and relativity it is often easier to work with a potential formulation of electrodynamics rather than in terms of the electric and magnetic fields. In this representation, the magnetic vector potential A, and the electric scalar potential \u03c6, are defined such that:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  B\n                \n              \n              \n                \n                =\n                \u2207\n                \u00d7\n                \n                  A\n                \n                ,\n              \n            \n            \n              \n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \u2207\n                \u03c6\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        A\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {B} &=\\nabla \\times \\mathbf {A} ,\\\\\\mathbf {E} &=-\\nabla \\varphi -{\\frac {\\partial \\mathbf {A} }{\\partial t}}.\\end{aligned}}}\n  The vector potential A may be interpreted as a generalized potential momentum per unit charge just as \u03c6 is interpreted as a generalized potential energy per unit charge.\nMaxwell's equations when expressed in terms of the potentials can be cast into a form that agrees with special relativity with little effort. In relativity A together with \u03c6 forms the four-potential, analogous to the four-momentum that combines the momentum and energy of a particle. Using the four potential instead of the electromagnetic tensor has the advantage of being much simpler\u2014and it can be easily modified to work with quantum mechanics.\n\n\n=== Quantum electrodynamics ===\n\nIn modern physics, the electromagnetic field is understood to be not a classical field, but rather a quantum field; it is represented not as a vector of three numbers at each point, but as a vector of three quantum operators at each point. The most accurate modern description of the electromagnetic interaction (and much else) is quantum electrodynamics (QED), which is incorporated into a more complete theory known as the Standard Model of particle physics.\nIn QED, the magnitude of the electromagnetic interactions between charged particles (and their antiparticles) is computed using perturbation theory. These rather complex formulas produce a remarkable pictorial representation as Feynman diagrams in which virtual photons are exchanged.\nPredictions of QED agree with experiments to an extremely high degree of accuracy: currently about 10\u221212 (and limited by experimental errors); for details see precision tests of QED. This makes QED one of the most accurate physical theories constructed thus far.\nAll equations in this article are in the classical approximation, which is less accurate than the quantum description mentioned here. However, under most everyday circumstances, the difference between the two theories is negligible.\n\n\n== Important uses and examples of magnetic field ==\n\n\n=== Earth's magnetic field ===\n\nThe Earth's magnetic field is produced by convection of a liquid iron alloy in the outer core. In a dynamo process, the movements drive a feedback process in which electric currents create electric and magnetic fields that in turn act on the currents.The field at the surface of the Earth is approximately the same as if a giant bar magnet were positioned at the center of the Earth and tilted at an angle of about 11\u00b0 off the rotational axis of the Earth (see the figure). The north pole of a magnetic compass needle points roughly north, toward the North Magnetic Pole. However, because a magnetic pole is attracted to its opposite, the North Magnetic Pole is actually the south pole of the geomagnetic field. This confusion in terminology arises because the pole of a magnet is defined by the geographical direction it points.Earth's magnetic field is not constant\u2014the strength of the field and the location of its poles vary. Moreover, the poles periodically reverse their orientation in a process called geomagnetic reversal. The most recent reversal occurred 780,000 years ago.\n\n\n=== Rotating magnetic fields ===\n\nThe rotating magnetic field is a key principle in the operation of alternating-current motors. A permanent magnet in such a field rotates so as to maintain its alignment with the external field. This effect was conceptualized by Nikola Tesla, and later utilized in his, and others', early AC (alternating current) electric motors.\nA rotating magnetic field can be constructed using two orthogonal coils with 90 degrees phase difference in their AC currents. However, in practice such a system would be supplied through a three-wire arrangement with unequal currents.\nThis inequality would cause serious problems in standardization of the conductor size and so, to overcome it, three-phase systems are used where the three currents are equal in magnitude and have 120 degrees phase difference. Three similar coils having mutual geometrical angles of 120 degrees create the rotating magnetic field in this case. The ability of the three-phase system to create a rotating field, utilized in electric motors, is one of the main reasons why three-phase systems dominate the world's electrical power supply systems.\nSynchronous motors use DC-voltage-fed rotor windings, which lets the excitation of the machine be controlled\u2014and induction motors use short-circuited rotors (instead of a magnet) following the rotating magnetic field of a multicoiled stator. The short-circuited turns of the rotor develop eddy currents in the rotating field of the stator, and these currents in turn move the rotor by the Lorentz force.\nIn 1882, Nikola Tesla identified the concept of the rotating magnetic field. In 1885, Galileo Ferraris independently researched the concept. In 1888, Tesla gained U.S. Patent 381,968 for his work. Also in 1888, Ferraris published his research in a paper to the Royal Academy of Sciences in Turin.\n\n\n=== Hall effect ===\n\nThe charge carriers of a current-carrying conductor placed in a transverse magnetic field experience a sideways Lorentz force; this results in a charge separation in a direction perpendicular to the current and to the magnetic field. The resultant voltage in that direction is proportional to the applied magnetic field. This is known as the Hall effect.\nThe Hall effect is often used to measure the magnitude of a magnetic field. It is used as well to find the sign of the dominant charge carriers in materials such as semiconductors (negative electrons or positive holes).\n\n\n=== Magnetic circuits ===\n\nAn important use of H is in magnetic circuits where B = \u03bcH inside a linear material. Here, \u03bc is the magnetic permeability of the material. This result is similar in form to Ohm's law J = \u03c3E, where J is the current density, \u03c3 is the conductance and E is the electric field. Extending this analogy, the counterpart to the macroscopic Ohm's law (I = V\u2044R) is:\n\n  \n    \n      \n        \u03a6\n        =\n        \n          \n            \n              F\n              R\n            \n          \n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\Phi ={\\frac {F}{R}}_{\\mathrm {m} },}\n  where \n  \n    \n      \n        \u03a6\n        =\n        \u222b\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n      \n    \n    {\\displaystyle \\Phi =\\int \\mathbf {B} \\cdot \\mathrm {d} \\mathbf {A} }\n   is the magnetic flux in the circuit, \n  \n    \n      \n        F\n        =\n        \u222b\n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\displaystyle F=\\int \\mathbf {H} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n   is the magnetomotive force  applied to the circuit, and Rm is the reluctance of the circuit. Here the reluctance Rm is a quantity similar in nature to resistance for the flux.\nUsing this analogy it is straightforward to calculate the magnetic flux of complicated magnetic field geometries, by using all the available techniques of circuit theory.\n\n\n=== Magnetic field shape descriptions ===\n\nAn azimuthal magnetic field is one that runs east\u2013west.\nA meridional magnetic field is one that runs north\u2013south. In the solar dynamo model of the Sun, differential rotation of the solar plasma causes the meridional magnetic field to stretch into an azimuthal magnetic field, a process called the omega-effect. The reverse process is called the alpha-effect.\nA dipole magnetic field is one seen around a bar magnet or around a charged elementary particle with nonzero spin.\nA quadrupole magnetic field is one seen, for example, between the poles of four bar magnets. The field strength grows linearly with the radial distance from its longitudinal axis.\nA solenoidal magnetic field is similar to a dipole magnetic field, except that a solid bar magnet is replaced by a hollow electromagnetic coil magnet.\nA toroidal magnetic field occurs in a doughnut-shaped coil, the electric current spiraling around the tube-like surface, and is found, for example, in a tokamak.\nA poloidal magnetic field is generated by a current flowing in a ring, and is found, for example, in a tokamak.\nA radial magnetic field is one in which field lines are directed from the center outwards, similar to the spokes in a bicycle wheel. An example can be found in a loudspeaker transducers (driver).\nA helical magnetic field is corkscrew-shaped, and sometimes seen in space plasmas such as the Orion Molecular Cloud.\n\n\n=== Magnetic dipoles ===\n\nThe magnetic field of a magnetic dipole is depicted in the figure. From outside, the ideal magnetic dipole is identical to that of an ideal electric dipole of the same strength. Unlike the electric dipole, a magnetic dipole is properly modeled as a current loop having a current I and an area a. Such a current loop has a magnetic moment of:\n\n  \n    \n      \n        m\n        =\n        I\n        a\n        ,\n        \n      \n    \n    {\\displaystyle m=Ia,\\,}\n  where the direction of m is perpendicular to the area of the loop and depends on the direction of the current using the right-hand rule. An ideal magnetic dipole is modeled as a real magnetic dipole whose area a has been reduced to zero and its current I increased to infinity such that the product m = Ia is finite. This model clarifies the connection between angular momentum and magnetic moment, which is the basis of the Einstein\u2013de Haas effect rotation by magnetization and its inverse, the Barnett effect or magnetization by rotation. Rotating the loop faster (in the same direction) increases the current and therefore the magnetic moment, for example.\nIt is sometimes useful to model the magnetic dipole similar to the electric dipole with two equal but opposite magnetic charges (one south the other north) separated by distance d. This model produces an H-field not a B-field. Such a model is deficient, though, both in that there are no magnetic charges and in that it obscures the link between electricity and magnetism. Further, as discussed above it fails to explain the inherent connection between angular momentum and magnetism.\n\n\n=== Magnetic monopole (hypothetical) ===\n\nA magnetic monopole is a hypothetical particle (or class of particles) that has, as its name suggests, only one magnetic pole (either a north pole or a south pole). In other words, it would possess a \"magnetic charge\" analogous to an electric charge. Magnetic field lines would start or end on magnetic monopoles, so if they exist, they would give exceptions to the rule that magnetic field lines neither start nor end.\nModern interest in this concept stems from particle theories, notably Grand Unified Theories and superstring theories, that predict either the existence, or the possibility, of magnetic monopoles. These theories and others have inspired extensive efforts to search for monopoles. Despite these efforts, no magnetic monopole has been observed to date.In recent research, materials known as spin ices can simulate monopoles, but do not contain actual monopoles.\n\n\n== See also ==\n\n\n=== General ===\nMagnetohydrodynamics \u2013 the study of the dynamics of electrically conducting fluids\nMagnetic hysteresis \u2013 application to ferromagnetism\nMagnetic nanoparticles \u2013 extremely small magnetic particles that are tens of atoms wide\nMagnetic reconnection \u2013 an effect that causes solar flares and auroras\nMagnetic potential \u2013 the vector and scalar potential representation of magnetism\nSI electromagnetism units \u2013 common units used in electromagnetism\nOrders of magnitude (magnetic field) \u2013 list of magnetic field sources and measurement devices from smallest magnetic fields to largest detected\nUpward continuation\n\n\n=== Mathematics ===\nMagnetic helicity \u2013 extent to which a magnetic field wraps around itself\n\n\n=== Applications ===\nDynamo theory \u2013 a proposed mechanism for the creation of the Earth's magnetic field\nHelmholtz coil \u2013 a device for producing a region of nearly uniform magnetic field\nMagnetic field viewing film \u2013 Film used to view the magnetic field of an area\nMaxwell coil \u2013 a device for producing a large volume of an almost constant magnetic field\nStellar magnetic field \u2013 a discussion of the magnetic field of stars\nTeltron tube \u2013 device used to display an electron beam and demonstrates effect of electric and magnetic fields on moving charges\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==",
        "unit": "magnetic field",
        "url": "https://en.wikipedia.org/wiki/Magnetic_field"
    },
    {
        "_id": "Gigayear",
        "clean": "Gigayear",
        "text": "A billion years (109 years) is a unit of time on the petasecond scale, more precisely equal to 3.16\u00d71016 seconds.\nIt is sometimes abbreviated  Gy, Ga (\"giga-annum\"), Byr and variants. The abbreviations Gya or bya are for \"billion years ago\", i.e. billion years before present.  \nThe terms are  used in geology, paleontology, geophysics,  astronomy and physical cosmology.\nThe prefix giga- is preferred over billion- to avoid confusion in the long and short scales over the meaning of billion; the postfix annum may be further qualified for precision as a sidereal year or Julian year:\n\n1 Gaj=3.15576\u00d71016 s,\n1 Gas=3.15581\u00d71016 s (epoch J2000.0).Byr was formerly used in English-language geology and astronomy as a unit of one billion years. Subsequently, the term gigaannum (Ga) has increased in usage, with Gy or Gyr still sometimes used in English-language works (at the risk of confusion with Gy as abbreviation for the gray, a unit of radiation exposure). Astronomers use Gyr or Gy as an abbreviation for gigayear.\n\n\n== See also ==\nMyr\nmya (unit)\nAnnum\nYear#SI prefix multipliers\nOrders of magnitude (time)\nYear#Symbols y and yr\n\n\n== References ==",
        "unit": "gigayear",
        "url": "https://en.wikipedia.org/wiki/Gigayear"
    },
    {
        "_id": "Base_pair",
        "clean": "Base pair",
        "text": "A base pair (bp) is a unit consisting of two nucleobases bound to each other by hydrogen bonds.  They form the building blocks of the DNA double helix and contribute to the folded structure of both DNA and RNA. Dictated by specific hydrogen bonding patterns, Watson-Crick base pairs (guanine-cytosine and adenine-thymine) allow the DNA helix to maintain a regular helical structure that is subtly dependent on its nucleotide sequence. The complementary nature of this based-paired structure provides a redundant copy of the genetic information encoded within each strand of DNA. The regular structure and data redundancy provided by the DNA double helix make DNA well suited to the storage of genetic information, while base-pairing between DNA and incoming nucleotides provides the mechanism through which DNA polymerase replicates DNA and RNA polymerase transcribes DNA into RNA. Many DNA-binding proteins can recognize specific base pairing patterns that identify particular regulatory regions of genes.\nIntramolecular base pairs can occur within single-stranded nucleic acids. This is particularly important in RNA molecules (e.g., transfer RNA), where Watson-Crick base pairs (guanine-cytosine and adenine-uracil) permit the formation of short double-stranded helices, and a wide variety of non-Watson-Crick interactions (e.g., G-U or A-A) allow RNAs to fold into a vast range of specific three-dimensional structures. In addition, base-pairing between transfer RNA (tRNA) and messenger RNA (mRNA) forms the basis for the molecular recognition events that result in the nucleotide sequence of mRNA becoming translated into the amino acid sequence of proteins via the genetic code.\nThe size of an individual gene or an organism's entire genome is often measured in base pairs because DNA is usually double-stranded. Hence, the number of total base pairs is equal to the number of nucleotides in one of the strands (with the exception of non-coding single-stranded regions of telomeres). The haploid human genome (23 chromosomes) is estimated to be about 3.2 billion bases long and to contain 20,000\u201325,000 distinct protein-coding genes. A kilobase (kb) is a unit of measurement in molecular biology equal to 1000 base pairs of DNA or RNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 \u00d7 1037 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).\n\n\n== Hydrogen bonding and stability ==\n\nHydrogen bonding is the chemical interaction that underlies the base-pairing rules described above. Appropriate geometrical correspondence of hydrogen bond donors and acceptors allows only the \"right\" pairs to form stably. DNA with high GC-content is more stable than DNA with low GC-content. But, contrary to popular belief, the hydrogen bonds do not stabilize the DNA significantly; stabilization is mainly due to stacking interactions.The larger nucleobases, adenine and guanine, are members of a class of double-ringed chemical structures called purines; the smaller nucleobases, cytosine and thymine (and uracil), are members of a class of single-ringed chemical structures called pyrimidines. Purines are complementary only with pyrimidines: pyrimidine-pyrimidine pairings are energetically unfavorable because the molecules are too far apart for hydrogen bonding to be established; purine-purine pairings are energetically unfavorable because the molecules are too close, leading to overlap repulsion. Purine-pyrimidine base pairing of AT or GC or UA (in RNA) results in proper duplex structure. The only other purine-pyrimidine pairings would be AC and GT and UG (in RNA); these pairings are mismatches because the patterns of hydrogen donors and acceptors do not correspond. The GU pairing, with two hydrogen bonds, does occur fairly often in RNA (see wobble base pair).\nPaired DNA and RNA molecules are comparatively stable at room temperature, but the two nucleotide strands will separate above a melting point that is determined by the length of the molecules, the extent of mispairing (if any), and the GC content. Higher GC content results in higher melting temperatures; it is, therefore, unsurprising that the genomes of extremophile organisms such as Thermus thermophilus are particularly GC-rich. On the converse, regions of a genome that need to separate frequently \u2014 for example, the promoter regions for often-transcribed genes \u2014 are comparatively GC-poor (for example, see TATA box). GC content and melting temperature must also be taken into account when designing  primers for PCR reactions.\n\n\n=== Examples ===\nThe following DNA sequences illustrate pair double-stranded patterns. By convention, the top strand is written from the 5' end to the 3' end; thus, the bottom strand is written 3' to 5'.\n\nA base-paired DNA sequence:\nATCGATTGAGCTCTAGCG\nTAGCTAACTCGAGATCGCThe corresponding RNA sequence, in which uracil is substituted for thymine where uracil takes its place in the RNA strand:\nAUCGAUUGAGCUCUAGCG\nUAGCUAACUCGAGAUCGC\n\n\n== Base analogs and intercalators ==\n\nChemical analogs of nucleotides can take the place of proper nucleotides and establish non-canonical base-pairing, leading to errors (mostly point mutations) in DNA replication and DNA transcription. This is due to their isosteric chemistry. One common mutagenic base analog is 5-bromouracil, which resembles thymine but can base-pair to guanine in its enol form.\nOther chemicals, known as DNA intercalators, fit into the gap between adjacent bases on a single strand and induce frameshift mutations by \"masquerading\" as a base, causing the DNA replication machinery to skip or insert additional nucleotides at the intercalated site. Most intercalators are large polyaromatic compounds and are known or suspected carcinogens. Examples include ethidium bromide and acridine.\n\n\n== Unnatural base pair (UBP) ==\n\nAn unnatural base pair (UBP) is a designed subunit (or nucleobase) of DNA which is created in a laboratory and does not occur in nature.  DNA sequences have been described which use newly created nucleobases to form a third base pair, in addition to the two base pairs found in nature, A-T (adenine \u2013 thymine) and G-C (guanine \u2013 cytosine).  A few research groups have been searching for a third base pair for DNA, including teams led by Steven A. Benner, Philippe Marliere, Floyd Romesberg and Ichiro Hirao. Some new base pairs have been reported.In 1989 Steven Benner (then working at the Swiss Federal Institute of Technology in Zurich) and his team led with modified forms of cytosine and guanine into DNA molecules in vitro. The nucleotides, which encoded RNA and proteins, were successfully replicated in vitro. Since then, Benner's team has been trying to engineer cells that can make foreign bases from scratch, obviating the need for a feedstock.In 2002, Ichiro Hirao\u2019s group in Japan developed an unnatural base pair between 2-amino-8-(2-thienyl)purine (s) and pyridine-2-one (y) that functions in transcription and translation, for the site-specific incorporation of non-standard amino acids into proteins. In 2006, they created 7-(2-thienyl)imidazo[4,5-b]pyridine (Ds) and pyrrole-2-carbaldehyde (Pa) as a third base pair for replication and transcription. Afterward, Ds and 4-[3-(6-aminohexanamido)-1-propynyl]-2-nitropyrrole (Px) was discovered as a high fidelity pair in PCR amplification. In 2013, they applied the Ds-Px pair to DNA aptamer generation by in vitro selection (SELEX) and demonstrated the genetic alphabet expansion significantly augment DNA aptamer affinities to target proteins.In 2012, a group of American scientists led by Floyd Romesberg, a chemical biologist at the Scripps Research Institute in San Diego, California, published that his team designed an unnatural base pair (UBP).  The two new artificial nucleotides or Unnatural Base Pair (UBP) were named d5SICS and dNaM. More technically, these artificial nucleotides bearing hydrophobic nucleobases, feature two fused aromatic rings that form a (d5SICS\u2013dNaM) complex or base pair in DNA. His team designed a variety of in vitro or \"test tube\" templates containing the unnatural base pair and they confirmed that it was efficiently replicated with high fidelity in virtually all sequence contexts using the modern standard in vitro techniques, namely PCR amplification of DNA and PCR-based applications. Their results show that for PCR and PCR-based applications, the d5SICS\u2013dNaM unnatural base pair is functionally equivalent to a natural base pair, and when combined with the other two natural base pairs used by all organisms, A\u2013T and G\u2013C, they provide a fully functional and expanded six-letter \"genetic alphabet\".In 2014 the same team from the Scripps Research Institute reported that they synthesized a stretch of circular DNA known as a plasmid containing natural T-A and C-G base pairs along with the best-performing UBP Romesberg's laboratory had designed and inserted it into cells of the common bacterium E. coli that successfully replicated the unnatural base pairs through multiple generations. The transfection did not hamper the growth of the E. coli cells and showed no sign of losing its unnatural base pairs to its natural DNA repair mechanisms. This is the first known example of a living organism passing along an expanded genetic code to subsequent generations. Romesberg said he and his colleagues created 300 variants to refine the design of nucleotides that would be stable enough and would be replicated as easily as the natural ones when the cells divide.  This was in part achieved by the addition of a supportive algal gene that expresses a nucleotide triphosphate transporter which efficiently imports the triphosphates of both d5SICSTP and dNaMTP into E. coli bacteria. Then, the natural bacterial replication pathways use them to accurately replicate a plasmid containing d5SICS\u2013dNaM. Other researchers were surprised that the bacteria replicated these human-made DNA subunits.The successful incorporation of a third base pair is a significant breakthrough toward the goal of greatly expanding the number of amino acids which can be encoded by DNA, from the existing 20 amino acids to a theoretically possible 172, thereby expanding the potential for living organisms to produce novel proteins. The artificial strings of DNA do not encode for anything yet, but scientists speculate they could be designed to manufacture new proteins which could have industrial or pharmaceutical uses. Experts said the synthetic DNA incorporating the unnatural base pair raises the possibility of life forms based on a different DNA code.\n\n\n== Length measurements ==\nThe following abbreviations are commonly used to describe the length of a D/RNA molecule:\n\nbp  = base pair(s)\u2014one bp corresponds to approximately 3.4 \u00c5 (340 pm)  of length along the strand, and to roughly 618 or 643 daltons for DNA and RNA respectively.\nkb (= kbp) = kilo base pairs = 1,000 bp\nMb (= Mbp) = mega base pairs = 1,000,000 bp\nGb = giga base pairs = 1,000,000,000 bp.For single-stranded DNA/RNA, units of nucleotides are used\u2014abbreviated nt (or knt, Mnt, Gnt)\u2014as they are not paired.\nTo distinguish between units of computer storage and bases, kbp, Mbp, Gbp, etc. may be used for base pairs.\nThe centimorgan is also often used to imply distance along a chromosome, but the number of base pairs it corresponds to varies widely. In the Human genome, the centimorgan is about 1 million base pairs.\n\n\n== See also ==\nList of Y-DNA single-nucleotide polymorphisms\nNon-canonical base pairing\n\n\n== References ==\n\n\n== Further reading ==\nWatson JD; Baker TA; Bell SP; Gann A; Levine M; Losick R (2004). Molecular Biology of the Gene (5th ed.). Pearson Benjamin Cummings: CSHL Press. (See esp. ch. 6 and 9)\nAstrid Sigel; Helmut Sigel; Roland K. O. Sigel, eds. (2012). Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. Springer. doi:10.1007/978-94-007-2172-2. ISBN 978-9-4007-2171-5.\nClever, Guido H.; Shionoya, Mitsuhiko (2012). \"Chapter 10. Alternative DNA Base-Pairing through Metal Coordination\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 269\u2013294. doi:10.1007/978-94-007-2172-2_10. ISBN 978-94-007-2171-5. PMID 22210343.\nMegger, Dominik A.; Megger, Nicole; Mueller, Jens (2012). \"Chapter 11. Metal-Mediated Base Pairs in Nucleic Acids with Purine and Pyrimidine-Derived Neucleosides\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 295\u2013317. doi:10.1007/978-94-007-2172-2_11. ISBN 978-94-007-2171-5. PMID 22210344.\n\n\n== External links ==\nDAN\u2014webserver version of the EMBOSS tool for calculating melting temperatures",
        "unit": "giga base pair",
        "url": "https://en.wikipedia.org/wiki/Base_pair"
    },
    {
        "_id": "Japanese_yen",
        "clean": "Japanese yen",
        "text": "The yen (Japanese: \u5186, Hepburn: en, symbol: \u00a5; code: JPY; also abbreviated as JP\u00a5) is the official currency of Japan. It is the third most traded currency in the foreign exchange market after the United States dollar and the euro. It is also widely used as a reserve currency after the U.S. dollar, the euro, and the pound sterling.\nThe concept of the yen was a component of the Meiji government's modernization program of Japan's economy; which postulated the pursuit of a uniform currency throughout the country modeled after the European decimal currency system.\nBefore the Meiji Restoration, Japan's feudal fiefs all issued their own money, hansatsu, in an array of incompatible denominations. The New Currency Act of 1871 did away with these and established the yen, which was defined as 1.5 g (0.048 troy ounces) of gold, or 24.26 g (0.780 troy ounces) of silver, as the new decimal currency. The former han (fiefs) became prefectures and their mints private chartered banks, which initially retained the right to print money. To bring an end to this situation the Bank of Japan was founded in 1882 and given a monopoly on controlling the money supply.Following World War II the yen lost much of its prewar value. To stabilize the Japanese economy the exchange rate of the yen was fixed at \u00a5360 per $1 as part of the Bretton Woods system. When that system was abandoned in 1971, the yen became undervalued and was allowed to float. The yen had appreciated to a peak of \u00a5271 per $1 in 1973, then underwent periods of depreciation and appreciation due to the 1973 oil crisis, arriving at a value of \u00a5227 per $1 by 1980.\nSince 1973, the Japanese government has maintained a policy of currency intervention, and the yen is therefore under a \"dirty float\" regime. This intervention continues to this day. The Japanese government focuses on a competitive export market, and tries to ensure a low yen value through a trade surplus. The Plaza Accord of 1985 temporarily changed this situation from its average of \u00a5239 per US$1 in 1985 to \u00a5128 in 1988 and led to a peak value of \u00a580 against the U.S. dollar in 1995, effectively increasing the value of Japan\u2019s GDP to almost that of the United States. Since that time, however, the yen has greatly decreased in value. The Bank of Japan maintains a policy of zero to near-zero interest rates and the Japanese government has an extreme anti-inflation policy.\n\n\n== Pronunciation and etymology ==\nYen derives from the Japanese word \u5713 (\u3048\u3093, en, [e\u0274]; lit. \"round\"), which is cognate with the Chinese yuan, North Korean won and South Korean won. Originally, the Chinese had traded silver in mass called sycees and when Spanish and Mexican silver coins arrived, the Chinese called them \"silver rounds\" (Chinese: \u9280\u5713) for their circular shapes. The coins and the name also appeared in Japan. While the Chinese eventually replaced \u5713 with \u5143, the Japanese continued to use the same word, which was given the shinjitai form \u5186 in reforms at the end of World War II.\nThe spelling and pronunciation \"yen\" is standard in English. This is because mainly English speakers who visited Japan at the end of the Edo period to the early Meiji period spelled words this way. \u3091\u3093 /wen/ in historical kana orthography. In the 16th century, Japanese /e/ (\u3048) and /we/ (\u3091) both had been pronounced [je] and Portuguese missionaries had spelled them \"ye\". Some time thereafter, by the middle of the 18th century, /e/ and /we/ came to be pronounced [e] as in modern Japanese, although some regions retain the [je] pronunciation. Walter Henry Medhurst, who had neither been to Japan nor met any Japanese, having consulted mainly a Japanese-Dutch dictionary, spelled some \"e\"s as \"ye\" in his An English and Japanese, and Japanese and English Vocabulary (1830). In the early Meiji era, James Curtis Hepburn, following Medhurst, spelled all \"e\"s as \"ye\" in his A Japanese and English dictionary (1867); in Japanese, e and i are slightly palatalized, somewhat as in Russian. That was the first full-scale Japanese-English/English-Japanese dictionary, which had a strong influence on Westerners in Japan and probably prompted the spelling \"yen\". Hepburn revised most of \"ye\"s to \"e\" in the 3rd edition (1886) in order to mirror the contemporary pronunciation, except \"yen\". This was probably already fixed and has remained so ever since.\n\n\n== History ==\n\n\n=== Introduction ===\n\nIn the 19th century, silver Spanish dollar coins were common throughout Southeast Asia, the China coast, and Japan. These coins had been introduced through Manila over a period of two hundred and fifty years, arriving on ships from Acapulco in Mexico. These ships were known as the Manila galleons. Until the 19th century, these silver dollar coins were actual Spanish dollars minted in the new world, mostly at Mexico City. But from the 1840s, they were increasingly replaced by silver dollars of the new Latin American republics. In the later half of the 19th century, some local coins in the region were made in the resemblance of the Mexican peso. The first of these local silver coins was the Hong Kong silver dollar coin that was minted in Hong Kong between the years 1866 and 1869. The Chinese were slow to accept unfamiliar coinage and preferred the familiar Mexican dollars, and so the Hong Kong government ceased minting these coins and sold the mint machinery to Japan.\n\nThe Japanese then decided to adopt a silver dollar coinage under the name of 'yen', meaning 'a round object'. The yen was officially adopted by the Meiji government in an Act signed on June 27, 1871. The new currency was gradually introduced beginning from July of that year. The yen was therefore basically a dollar unit, like all dollars, descended from the Spanish Pieces of eight, and up until the year 1873, all the dollars in the world had more or less the same value. The yen replaced Tokugawa coinage, a complex monetary system of the Edo period based on the mon. The New Currency Act of 1871, stipulated the adoption of the decimal accounting system of yen (1, \u5713), sen (\u200b1\u2044100, \u9322), and rin (\u200b1\u20441000, \u5398), with the coins being round and manufactured using Western machinery. The yen was legally defined as 0.78 troy ounces (24.26 g) of pure silver, or 1.5 grams of pure gold (as recommended by the European Congress of Economists in Paris in 1867; the 5-yen coin was equivalent to the Argentine 5 peso fuerte coin),\nhence putting it on a bimetallic standard. (The same amount of silver is worth about 1300 modern yen, while the same amount of gold is worth about 6500 yen.)\n\nFollowing the silver devaluation of 1873, the yen devalued against the U.S. dollar and the Canadian dollar (since those two countries adhered to a gold standard), and by the year 1897, the yen was worth only about US$0.50. In that year, Japan adopted a gold exchange standard and hence froze the value of the yen at $0.50. This exchange rate remained in place until Japan left the gold standard in December 1931, after which the yen fell to $0.30 by July 1932 and to $0.20 by 1933. It remained steady at around $0.30 until the start of the Second World War on December 7, 1941, at which time it fell to $0.23.The sen and the rin were eventually taken out of circulation at the end of 1953.\n\n\n=== Fixed value of the yen to the U.S. dollar ===\nNo true exchange rate existed for the yen between December 7, 1941, and April 25, 1949; wartime inflation reduced the yen to a fraction of its pre-war value. After a period of instability, on April 25, 1949, the U.S. occupation government fixed the value of the yen at \u00a5360 per US$1 through a United States plan, which was part of the Bretton Woods System, to stabilize prices in the Japanese economy. That exchange rate was maintained until 1971, when the United States abandoned the gold standard, which had been a key element of the Bretton Woods System, and imposed a 10 percent surcharge on imports, setting in motion changes that eventually led to floating exchange rates in 1973.\n\n\n=== Undervalued yen ===\nBy 1971, the yen had become undervalued. Japanese exports were costing too little in international markets, and imports from abroad were costing the Japanese too much. This undervaluation was reflected in the current account balance, which had risen from the deficits of the early 1960s, to a then-large surplus of US$5.8 billion in 1971. The belief that the yen, and several other major currencies, were undervalued motivated the United States' actions in 1971.\n\n\n=== Yen and major currencies float ===\nFollowing the United States' measures to devalue the dollar in the summer of 1971, the Japanese government agreed to a new, fixed exchange rate as part of the Smithsonian Agreement, signed at the end of the year. This agreement set the exchange rate at \u00a5308 per US$1. However, the new fixed rates of the Smithsonian Agreement were difficult to maintain in the face of supply and demand pressures in the foreign-exchange market. In early 1973, the rates were abandoned, and the major nations of the world allowed their currencies to float.\n\n\n=== Japanese government intervention in the currency market ===\nIn the 1970s, Japanese government and business people were very concerned that a rise in the value of the yen would hurt export growth by making Japanese products less competitive and would damage the industrial base. The government therefore continued to intervene heavily in foreign-exchange marketing (buying or selling dollars), even after the 1973 decision to allow the yen to float.\nDespite intervention, market pressures caused the yen to continue climbing in value, peaking temporarily at an average of \u00a5271 per US$1 in 1973, before the impact of the 1973 oil crisis was felt. The increased costs of imported oil caused the yen to depreciate to a range of \u00a5290 to \u00a5300 between 1974 and 1976. The re-emergence of trade surpluses drove the yen back up to \u00a5211 in 1978. This currency strengthening was again reversed by the second oil shock in 1979, with the yen dropping to \u00a5227 by 1980.\n\n\n=== Yen in the early 1980s ===\nDuring the first half of the 1980s, the yen failed to rise in value even though current account surpluses returned and grew quickly. From \u00a5221 in 1981, the average value of the yen actually dropped to \u00a5239 in 1985. The rise in the current account surplus generated stronger demand for yen in foreign-exchange markets, but this trade-related demand for yen was offset by other factors. A wide differential in interest rates, with United States interest rates much higher than those in Japan, and the continuing moves to deregulate the international flow of capital, led to a large net outflow of capital from Japan. This capital flow increased the supply of yen in foreign-exchange markets, as Japanese investors changed their yen for other currencies (mainly dollars) to invest overseas. This kept the yen weak relative to the dollar and fostered the rapid rise in the Japanese trade surplus that took place in the 1980s.\n\n\n=== Effect of the Plaza Accord ===\n\nIn 1985, a dramatic change began. Finance officials from major nations signed an agreement (the Plaza Accord) affirming that the dollar was overvalued (and, therefore, the yen undervalued). This agreement, and shifting supply and demand pressures in the markets, led to a rapid rise in the value of the yen. From its average of \u00a5239 per US$1 in 1985, the yen rose to a peak of \u00a5128 in 1988, virtually doubling its value relative to the dollar. After declining somewhat in 1989 and 1990, it reached a new high of \u00a5123 to US$1 in December 1992. In April 1995, the yen hit a peak of under 80 yen per dollar, temporarily making Japan's economy nearly the size of the US.\n\n\n=== Post-bubble years ===\nThe yen declined during the Japanese asset price bubble and continued to do so afterwards, reaching a low of \u00a5134 to US$1 in February 2002. The Bank of Japan's policy of zero interest rates has discouraged yen investments, with the carry trade of investors borrowing yen and investing in better-paying currencies (thus further pushing down the yen) estimated to be as large as $1 trillion. In February 2007, The Economist estimated that the yen was 15% undervalued against the dollar, and as much as 40% undervalued against the euro.\n\n\n=== After the global economic crisis of 2008 ===\n\nHowever, this trend of depreciation reversed after the global economic crisis of 2008. Other major currencies, except the Swiss franc, have been declining relative to the yen.\nOn April 4, 2013, the Bank of Japan announced that they would expand their Asset Purchase Program by $1.4 trillion in two years. The Bank of Japan hopes to bring Japan from deflation to inflation, aiming for 2% inflation. The amount of purchases is so large that it is expected to double the money supply. But this move has sparked concerns that the authorities in Japan are deliberately devaluing the yen in order to boost exports. However, the commercial sector in Japan worried that the devaluation would trigger an increase in import prices, especially for energy and raw materials.\nOn May 9, 2013, the currency weakened to 100 yen = 1 US$ for the first time since April 2009.\n\n\n== Coins ==\n\nCoins were introduced in 1870. There were silver 5-, 10-, 20- and 50-sen and 1-yen, and gold 2-, 5-, 10- and 20-yen. Gold 1-yen were introduced in 1871, followed by copper 1-rin, \u200b1\u20442-, 1- and 2-sen in 1873.\n\nCupronickel 5-sen coins were introduced in 1889. In 1897, the silver 1-yen coin was demonetized and the sizes of the gold coins were reduced by 50%, with 5-, 10- and 20-yen coins issued. In 1920, cupro-nickel 10-sen coins were introduced.\nProduction of silver coins ceased in 1938, after which a variety of base metals were used to produce 1-, 5- and 10-sen coins during the Second World War. Clay 5- and 10-sen coins were produced in 1945, but not issued for circulation.\nAfter the war, brass 50-sen, 1- and 5-yen were introduced between 1946 and 1948. In 1949, the current type of holed 5-yen was introduced, followed by bronze 10-yen (of the type still in circulation) in 1951.\nCoins in denominations of less than 1-yen became invalid on December 31, 1953, following enforcement of the Small Currency Disposition and Fractional Rounding in Payments Act (\u5c0f\u984d\u901a\u8ca8\u306e\u6574\u7406\u53ca\u3073\u652f\u6255\u91d1\u306e\u7aef\u6570\u8a08\u7b97\u306b\u95a2\u3059\u308b\u6cd5\u5f8b, Sh\u014dgaku ts\u016bka no seiri oyobi shiharaikin no has\u016bkeisan ni kan suru h\u014dritsu).\nIn 1955, the current type of aluminium 1-yen was introduced, along with unholed, nickel 50-yen. In 1957, silver 100-yen pieces were introduced. These were replaced in 1967, by the current cupro-nickel type, along with the holed 50-yen coin. In 1982, the first 500-yen coins were introduced.The date (expressed as the year in the reign of the emperor at the time the coin was stamped) is on the reverse of all coins, and, in most cases, country name (through 1945, Dai Nippon (\u5927\u65e5\u672c, \"Great Japan\"); after 1945, Nippon-koku (\u65e5\u672c\u56fd, \"State of Japan\") and the value in kanji is on the obverse, except for the present 5-yen coin where the country name is on the reverse.\nAlongside with the 5-Swiss franc coin and the rarely used 5-Cuban convertible peso coin, the 500-yen coin is one of the highest-valued coin to be used regularly in the world, with value of US$4.5 as of  October 2017. Because of this high face value, the 500-yen coin has been a favorite target for counterfeiters; it was counterfeited to such an extent, that in 2000, a new series of coins was issued with various security features, but counterfeiting continued.The 1-yen coin is made out of 100% aluminum and can float on water if placed correctly.\nOn various occasions, commemorative coins are minted, often in gold and silver with face values up to 100,000 yen. The first of these were silver \u00a5100 and \u00a51000 Summer Olympic coins issued on the occasion of the 1964 games. Recently this practice is undertaken with the 500-yen coin, the first two types were issued in 1985, in commemoration of the science and technology exposition in Tsukuba and the 100th anniversary of the Governmental Cabinet system. The current commemorative 500- and 1000-yen coin series honouring the 47 prefectures of Japan commenced in 2008, with 47 unique designs planned for each denomination. Only one coin per customer is available from banks in each prefecture. 100,000 of each 1000-yen silver coin have been minted. Even though all commemorative coins can be spent like ordinary (non-commemorative) coins, they are not seen often in typical daily use and normally do not circulate.\nInstead of displaying the Gregorian calendar year of mintage like most nations' coins, yen coins instead display the year of the current emperor's reign. For example, a coin minted in 2009, would bear the date Heisei 21 (the 21st year of Emperor Akihito's reign).\nDue to the great differences in style, size, weight and the pattern present on the edge of the coin they are very easy for people with visual impairments to tell apart from one another.\n\n\n== Banknotes ==\n\nThe issuance of the yen banknotes began in 1872, two years after the currency was introduced. Throughout its history, the denominations have ranged from 10 yen to 10,000 yen.\n\nBefore and during World War II, various bodies issued banknotes in yen, such as the Ministry of Finance and the Imperial Japanese National Bank. The Allied forces also issued some notes shortly after the war. Since then, the Bank of Japan has been the exclusive note issuing authority. The bank has issued five series after World War II. Series E, the current series introduced in 2004, consists of \u00a51000, \u00a55000, and \u00a510,000 notes. The EURion constellation pattern is present in the designs.\nJapan is generally considered a cash-based society, with 38% of payments in Japan made by cash in 2014. Possible explanations are that cash payments protect one's privacy, merchants do not have to wait for payment, and it does not carry any negative connotation like credit.\n\n\n== Determinants of value ==\nBeginning in December 1931, Japan gradually shifted from the gold standard system to the managed currency system.The relative value of the yen is determined in foreign exchange markets by the economic forces of supply and demand. The supply of the yen in the market is governed by the desire of yen holders to exchange their yen for other currencies to purchase goods, services, or assets. The demand for the yen is governed by the desire of foreigners to buy goods and services in Japan and by their interest in investing in Japan (buying yen-denominated real and financial assets).\nSince the 1990s, the Bank of Japan, the country's central bank, has kept interest rates low in order to spur economic growth. Short-term lending rates have responded to this monetary relaxation and fell from 3.7% to 1.3% between 1993 and 2008. Low interest rates combined with a ready liquidity for the yen prompted investors to borrow money in Japan and invest it in other countries (a practice known as carry trade). This has helped to keep the value of the yen low compared to other currencies.\n\n\n== International reserve currency ==\n\nThe percental composition of currencies of official foreign exchange reserves from 1995 to 2017.\n\n\n=== SDR basket ===\nThe special drawing rights (SDR) valuation is an IMF basket of currencies, including the Japanese yen. The SDR is linked to a basket of currencies with 41.9% for the U.S. dollar, 37.4% for the euro, 11.3% for the pound sterling, and 9.4% for the yen (as of 2011). The percentage for the yen has, however, declined from 18% in 2000. The exchange rate for the Japanese yen is expressed in terms of currency units per U.S. dollar; other rates are expressed as U.S. dollars per currency unit. The SDR currency value is calculated daily and the valuation basket is reviewed and adjusted every five years. The SDR was created in 1969, to support the fixed exchange system.\n\n\n== Historical exchange rate ==\nThe table below shows the monthly average of the U.S. dollar\u2013yen spot rate (JPY per USD) at 17:00 JST:\n\n\n== See also ==\n\nJapan Mint\nJapanese military yen\nEconomy of Japan\nCapital flows in Japan\nMonetary and fiscal policy of Japan\nBalance of payments accounts of Japan (1960\u201390)\n\n\n=== Older currency ===\nJapanese mon (currency)\nKoban (coin)\nRy\u014d (Japanese coin)\nWad\u014dkaichin\n\n\n== Footnotes ==\n\n\n== Notes ==\n This article incorporates public domain material from the Library of Congress Country Studies website http://lcweb2.loc.gov/frd/cs/.\n\n\n== Further reading ==\n\n\n== External links ==\nJapanese Yen on Wikinvest\nJapanese currency FAQ in Currency Museum, Bank of Japan\nMoney in Japan. A guide while traveling.\nImages of historic and modern Japanese bank notes\nChart: US dollar in yen) (in German)\nChart: 100 yen in euros (in German)\nHistorical Currency Converter Estimates the historical value of the yen into other currencies",
        "unit": "japanese yen",
        "url": "https://en.wikipedia.org/wiki/Japanese_yen"
    },
    {
        "_id": "Base_pair",
        "clean": "Base pair",
        "text": "A base pair (bp) is a unit consisting of two nucleobases bound to each other by hydrogen bonds.  They form the building blocks of the DNA double helix and contribute to the folded structure of both DNA and RNA. Dictated by specific hydrogen bonding patterns, Watson-Crick base pairs (guanine-cytosine and adenine-thymine) allow the DNA helix to maintain a regular helical structure that is subtly dependent on its nucleotide sequence. The complementary nature of this based-paired structure provides a redundant copy of the genetic information encoded within each strand of DNA. The regular structure and data redundancy provided by the DNA double helix make DNA well suited to the storage of genetic information, while base-pairing between DNA and incoming nucleotides provides the mechanism through which DNA polymerase replicates DNA and RNA polymerase transcribes DNA into RNA. Many DNA-binding proteins can recognize specific base pairing patterns that identify particular regulatory regions of genes.\nIntramolecular base pairs can occur within single-stranded nucleic acids. This is particularly important in RNA molecules (e.g., transfer RNA), where Watson-Crick base pairs (guanine-cytosine and adenine-uracil) permit the formation of short double-stranded helices, and a wide variety of non-Watson-Crick interactions (e.g., G-U or A-A) allow RNAs to fold into a vast range of specific three-dimensional structures. In addition, base-pairing between transfer RNA (tRNA) and messenger RNA (mRNA) forms the basis for the molecular recognition events that result in the nucleotide sequence of mRNA becoming translated into the amino acid sequence of proteins via the genetic code.\nThe size of an individual gene or an organism's entire genome is often measured in base pairs because DNA is usually double-stranded. Hence, the number of total base pairs is equal to the number of nucleotides in one of the strands (with the exception of non-coding single-stranded regions of telomeres). The haploid human genome (23 chromosomes) is estimated to be about 3.2 billion bases long and to contain 20,000\u201325,000 distinct protein-coding genes. A kilobase (kb) is a unit of measurement in molecular biology equal to 1000 base pairs of DNA or RNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 \u00d7 1037 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).\n\n\n== Hydrogen bonding and stability ==\n\nHydrogen bonding is the chemical interaction that underlies the base-pairing rules described above. Appropriate geometrical correspondence of hydrogen bond donors and acceptors allows only the \"right\" pairs to form stably. DNA with high GC-content is more stable than DNA with low GC-content. But, contrary to popular belief, the hydrogen bonds do not stabilize the DNA significantly; stabilization is mainly due to stacking interactions.The larger nucleobases, adenine and guanine, are members of a class of double-ringed chemical structures called purines; the smaller nucleobases, cytosine and thymine (and uracil), are members of a class of single-ringed chemical structures called pyrimidines. Purines are complementary only with pyrimidines: pyrimidine-pyrimidine pairings are energetically unfavorable because the molecules are too far apart for hydrogen bonding to be established; purine-purine pairings are energetically unfavorable because the molecules are too close, leading to overlap repulsion. Purine-pyrimidine base pairing of AT or GC or UA (in RNA) results in proper duplex structure. The only other purine-pyrimidine pairings would be AC and GT and UG (in RNA); these pairings are mismatches because the patterns of hydrogen donors and acceptors do not correspond. The GU pairing, with two hydrogen bonds, does occur fairly often in RNA (see wobble base pair).\nPaired DNA and RNA molecules are comparatively stable at room temperature, but the two nucleotide strands will separate above a melting point that is determined by the length of the molecules, the extent of mispairing (if any), and the GC content. Higher GC content results in higher melting temperatures; it is, therefore, unsurprising that the genomes of extremophile organisms such as Thermus thermophilus are particularly GC-rich. On the converse, regions of a genome that need to separate frequently \u2014 for example, the promoter regions for often-transcribed genes \u2014 are comparatively GC-poor (for example, see TATA box). GC content and melting temperature must also be taken into account when designing  primers for PCR reactions.\n\n\n=== Examples ===\nThe following DNA sequences illustrate pair double-stranded patterns. By convention, the top strand is written from the 5' end to the 3' end; thus, the bottom strand is written 3' to 5'.\n\nA base-paired DNA sequence:\nATCGATTGAGCTCTAGCG\nTAGCTAACTCGAGATCGCThe corresponding RNA sequence, in which uracil is substituted for thymine where uracil takes its place in the RNA strand:\nAUCGAUUGAGCUCUAGCG\nUAGCUAACUCGAGAUCGC\n\n\n== Base analogs and intercalators ==\n\nChemical analogs of nucleotides can take the place of proper nucleotides and establish non-canonical base-pairing, leading to errors (mostly point mutations) in DNA replication and DNA transcription. This is due to their isosteric chemistry. One common mutagenic base analog is 5-bromouracil, which resembles thymine but can base-pair to guanine in its enol form.\nOther chemicals, known as DNA intercalators, fit into the gap between adjacent bases on a single strand and induce frameshift mutations by \"masquerading\" as a base, causing the DNA replication machinery to skip or insert additional nucleotides at the intercalated site. Most intercalators are large polyaromatic compounds and are known or suspected carcinogens. Examples include ethidium bromide and acridine.\n\n\n== Unnatural base pair (UBP) ==\n\nAn unnatural base pair (UBP) is a designed subunit (or nucleobase) of DNA which is created in a laboratory and does not occur in nature.  DNA sequences have been described which use newly created nucleobases to form a third base pair, in addition to the two base pairs found in nature, A-T (adenine \u2013 thymine) and G-C (guanine \u2013 cytosine).  A few research groups have been searching for a third base pair for DNA, including teams led by Steven A. Benner, Philippe Marliere, Floyd Romesberg and Ichiro Hirao. Some new base pairs have been reported.In 1989 Steven Benner (then working at the Swiss Federal Institute of Technology in Zurich) and his team led with modified forms of cytosine and guanine into DNA molecules in vitro. The nucleotides, which encoded RNA and proteins, were successfully replicated in vitro. Since then, Benner's team has been trying to engineer cells that can make foreign bases from scratch, obviating the need for a feedstock.In 2002, Ichiro Hirao\u2019s group in Japan developed an unnatural base pair between 2-amino-8-(2-thienyl)purine (s) and pyridine-2-one (y) that functions in transcription and translation, for the site-specific incorporation of non-standard amino acids into proteins. In 2006, they created 7-(2-thienyl)imidazo[4,5-b]pyridine (Ds) and pyrrole-2-carbaldehyde (Pa) as a third base pair for replication and transcription. Afterward, Ds and 4-[3-(6-aminohexanamido)-1-propynyl]-2-nitropyrrole (Px) was discovered as a high fidelity pair in PCR amplification. In 2013, they applied the Ds-Px pair to DNA aptamer generation by in vitro selection (SELEX) and demonstrated the genetic alphabet expansion significantly augment DNA aptamer affinities to target proteins.In 2012, a group of American scientists led by Floyd Romesberg, a chemical biologist at the Scripps Research Institute in San Diego, California, published that his team designed an unnatural base pair (UBP).  The two new artificial nucleotides or Unnatural Base Pair (UBP) were named d5SICS and dNaM. More technically, these artificial nucleotides bearing hydrophobic nucleobases, feature two fused aromatic rings that form a (d5SICS\u2013dNaM) complex or base pair in DNA. His team designed a variety of in vitro or \"test tube\" templates containing the unnatural base pair and they confirmed that it was efficiently replicated with high fidelity in virtually all sequence contexts using the modern standard in vitro techniques, namely PCR amplification of DNA and PCR-based applications. Their results show that for PCR and PCR-based applications, the d5SICS\u2013dNaM unnatural base pair is functionally equivalent to a natural base pair, and when combined with the other two natural base pairs used by all organisms, A\u2013T and G\u2013C, they provide a fully functional and expanded six-letter \"genetic alphabet\".In 2014 the same team from the Scripps Research Institute reported that they synthesized a stretch of circular DNA known as a plasmid containing natural T-A and C-G base pairs along with the best-performing UBP Romesberg's laboratory had designed and inserted it into cells of the common bacterium E. coli that successfully replicated the unnatural base pairs through multiple generations. The transfection did not hamper the growth of the E. coli cells and showed no sign of losing its unnatural base pairs to its natural DNA repair mechanisms. This is the first known example of a living organism passing along an expanded genetic code to subsequent generations. Romesberg said he and his colleagues created 300 variants to refine the design of nucleotides that would be stable enough and would be replicated as easily as the natural ones when the cells divide.  This was in part achieved by the addition of a supportive algal gene that expresses a nucleotide triphosphate transporter which efficiently imports the triphosphates of both d5SICSTP and dNaMTP into E. coli bacteria. Then, the natural bacterial replication pathways use them to accurately replicate a plasmid containing d5SICS\u2013dNaM. Other researchers were surprised that the bacteria replicated these human-made DNA subunits.The successful incorporation of a third base pair is a significant breakthrough toward the goal of greatly expanding the number of amino acids which can be encoded by DNA, from the existing 20 amino acids to a theoretically possible 172, thereby expanding the potential for living organisms to produce novel proteins. The artificial strings of DNA do not encode for anything yet, but scientists speculate they could be designed to manufacture new proteins which could have industrial or pharmaceutical uses. Experts said the synthetic DNA incorporating the unnatural base pair raises the possibility of life forms based on a different DNA code.\n\n\n== Length measurements ==\nThe following abbreviations are commonly used to describe the length of a D/RNA molecule:\n\nbp  = base pair(s)\u2014one bp corresponds to approximately 3.4 \u00c5 (340 pm)  of length along the strand, and to roughly 618 or 643 daltons for DNA and RNA respectively.\nkb (= kbp) = kilo base pairs = 1,000 bp\nMb (= Mbp) = mega base pairs = 1,000,000 bp\nGb = giga base pairs = 1,000,000,000 bp.For single-stranded DNA/RNA, units of nucleotides are used\u2014abbreviated nt (or knt, Mnt, Gnt)\u2014as they are not paired.\nTo distinguish between units of computer storage and bases, kbp, Mbp, Gbp, etc. may be used for base pairs.\nThe centimorgan is also often used to imply distance along a chromosome, but the number of base pairs it corresponds to varies widely. In the Human genome, the centimorgan is about 1 million base pairs.\n\n\n== See also ==\nList of Y-DNA single-nucleotide polymorphisms\nNon-canonical base pairing\n\n\n== References ==\n\n\n== Further reading ==\nWatson JD; Baker TA; Bell SP; Gann A; Levine M; Losick R (2004). Molecular Biology of the Gene (5th ed.). Pearson Benjamin Cummings: CSHL Press. (See esp. ch. 6 and 9)\nAstrid Sigel; Helmut Sigel; Roland K. O. Sigel, eds. (2012). Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. Springer. doi:10.1007/978-94-007-2172-2. ISBN 978-9-4007-2171-5.\nClever, Guido H.; Shionoya, Mitsuhiko (2012). \"Chapter 10. Alternative DNA Base-Pairing through Metal Coordination\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 269\u2013294. doi:10.1007/978-94-007-2172-2_10. ISBN 978-94-007-2171-5. PMID 22210343.\nMegger, Dominik A.; Megger, Nicole; Mueller, Jens (2012). \"Chapter 11. Metal-Mediated Base Pairs in Nucleic Acids with Purine and Pyrimidine-Derived Neucleosides\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 295\u2013317. doi:10.1007/978-94-007-2172-2_11. ISBN 978-94-007-2171-5. PMID 22210344.\n\n\n== External links ==\nDAN\u2014webserver version of the EMBOSS tool for calculating melting temperatures",
        "unit": "base pair",
        "url": "https://en.wikipedia.org/wiki/Base_pair"
    },
    {
        "_id": "Statcoulomb",
        "clean": "Statcoulomb",
        "text": "The statcoulomb (statC) or franklin (Fr) or electrostatic unit of charge (esu) is the physical unit for electrical charge used in the esu-cgs (centimetre\u2013gram\u2013second system of units) and Gaussian units. It is a derived unit given by\n\n1 statC = dyn1/2 cm = cm3/2 g1/2 s\u22121.It can be converted using\n\n1 newton = 105 dyne\n1 cm = 10\u22122 mThe SI system of units uses the coulomb (C) instead. The conversion between C and statC is different in different contexts. The most common contexts are:\n\nFor electric charge:\n1 C \u2194 2997924580 statC \u2248 3.00\u00d7109 statC\n\u21d2 1 statC \u2194 ~3.33564\u00d710\u221210 C.\nFor electric flux (\u03a6D):\n1 C \u2194 4\u03c0 \u00d7 2997924580 statC \u2248 3.77\u00d71010 statC\n\u21d2 1 statC \u2194 ~2.65\u00d710\u221211 C.The symbol \"\u2194\" is used instead of \"=\" because the two sides are not necessarily interchangeable, as discussed below. The number 2997924580 is 10 times the value of the speed of light expressed in meters/second, and the conversions are exact except where indicated.  The second context implies that the SI and cgs units for an electric displacement field (D) are related by:\n\n1 C/m2 \u2194 4\u03c0 \u00d7 2997924580\u00d710\u22124 statC/cm2 \u2248 3.77\u00d7106 statC/cm2\n\u21d2 1 statC/cm2 \u2194 ~2.65\u00d710\u22127 C/m2due to the relation between the metre and the centimetre.  The coulomb is an extremely large charge rarely encountered in electrostatics, while the statcoulomb is closer to everyday charges.\n\n\n== Definition and relation to cgs base units ==\nThe statcoulomb is defined as follows: if two stationary objects each carry a charge of 1 statC and are 1 cm apart, they will electrically repel each other with a force of 1 dyne. This repulsion is governed by Coulomb's law, which in the Gaussian-cgs system states:\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{r^{2}}}}\n  where F is the force, q1 and q2 are the two charges, and r is the distance between the charges. Performing dimensional analysis on Coulomb's law, the dimension of electrical charge in cgs must be [mass]1/2 [length]3/2 [time]\u22121. (This statement is not true in SI units; see below.) We can be more specific in light of the definition above: Substituting F = 1 dyn, q1 = q2 = 1 statC, and r = 1 cm, we get:\n\n1 statC = g1/2 cm3/2 s\u22121as expected.\n\n\n== Dimensional relation between Statcoulomb and Coulomb ==\n\n\n=== General incompatibility ===\nCoulomb's law in cgs-Gaussian unit system and SI are respectively:\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{r^{2}}}}\n   (cgs-Gaussian)\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                \u03f5\n                \n                  0\n                \n              \n              \n                r\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{4\\pi \\epsilon _{0}r^{2}}}}\n   (SI)Since \u03b50, the vacuum permittivity, is not dimensionless, the coulomb (the SI unit of charge) is not dimensionally equivalent to [mass]1/2 [length]3/2 [time]\u22121, unlike the statcoulomb. In fact, it is impossible to express the coulomb in terms of mass, length, and time alone.\nConsequently, a conversion equation like \"1 C = N statC\" can be misleading: the units on the two sides are not consistent. One cannot freely switch between coulombs and statcoulombs within a formula or equation, as one would freely switch between centimeters and meters. One can, however, find a correspondence between coulombs and statcoulombs in different contexts. As described below, \"1 C corresponds to 3.00\u00d7109 statC\" when describing the charge of objects. In other words, if a physical object has a charge of 1 C, it also has a charge of 3.00\u00d7109 statC. Likewise, \"1 C corresponds to 3.77\u00d71010 statC\" when describing an electric displacement field flux.\n\n\n=== As a unit of charge ===\nThe statcoulomb is defined as follows: If two stationary objects each carry a charge of 1 statC and are 1 cm apart in vacuum, they will electrically repel each other with a force of 1 dyne. From this definition, it is straightforward to find an equivalent charge in SI coulombs. Using the SI equation\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                \u03f5\n                \n                  0\n                \n              \n              \n                r\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{4\\pi \\epsilon _{0}r^{2}}}}\n   (SI),and plugging in F = 1 dyn = 10\u22125 N, and r = 1 cm = 10\u22122 m, and then solving for q = q1 = q2, the result is q = (1/2997924580)C \u2248 3.34\u00d710\u221210 C. Therefore, an object with a charge of 1 statC has a charge of 3.34\u00d710\u221210 C.\nThis can also be expressed by the following conversion, which is fully dimensionally consistent, and often useful for switching between SI and cgs formulae:\n\n  \n    \n      \n        1\n        \n        \n          C\n        \n        \n          \n            \n              \n                \n                  10\n                  \n                    9\n                  \n                \n                \n                  4\n                  \u03c0\n                  \n                    \u03f5\n                    \n                      0\n                    \n                  \n                \n              \n            \n          \n        \n        =\n        2997924580\n        \n        \n          s\n          t\n          a\n          t\n          C\n        \n      \n    \n    {\\displaystyle 1\\;\\mathrm {C} {\\sqrt {\\tfrac {10^{9}}{4\\pi \\epsilon _{0}}}}=2997924580\\;\\mathrm {statC} }\n  \n\n\n=== As a unit of electric displacement field or flux ===\nAn electric flux (specifically, a flux of the electric displacement field D) has units of charge: statC in cgs and coulombs in SI. The conversion factor can be derived from Gauss's law:\n\n  \n    \n      \n        \n          \u03a6\n          \n            D\n          \n        \n        =\n        4\n        \u03c0\n        Q\n      \n    \n    {\\displaystyle \\Phi _{D}=4\\pi Q}\n   (cgs)\n\n  \n    \n      \n        \n          \u03a6\n          \n            D\n          \n        \n        =\n        Q\n      \n    \n    {\\displaystyle \\Phi _{D}=Q}\n   (SI)where\n\n  \n    \n      \n        \n          \u03a6\n          \n            D\n          \n        \n        \u2261\n        \n          \u222b\n          \n            S\n          \n        \n        \n          D\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n      \n    \n    {\\displaystyle \\Phi _{D}\\equiv \\int _{S}\\mathbf {D} \\cdot \\mathrm {d} \\mathbf {A} }\n  Therefore, the conversion factor for flux is 4\u03c0 different from the conversion factor for charge:\n\n  \n    \n      \n        1\n        \n        \n          C\n        \n        \n           corresponds to \n        \n        3.7673\n        \u00d7\n        \n          10\n          \n            10\n          \n        \n        \n        \n          s\n          t\n          a\n          t\n          C\n        \n      \n    \n    {\\displaystyle 1\\;\\mathrm {C} {\\text{ corresponds to }}3.7673\\times 10^{10}\\;\\mathrm {statC} }\n   (as unit of \u03a6D).The dimensionally consistent version is:\n\n  \n    \n      \n        1\n        \n        \n          C\n        \n        \n          \n            \n              \n                \n                  4\n                  \u03c0\n                  \n                    10\n                    \n                      9\n                    \n                  \n                \n                \n                  \u03f5\n                  \n                    0\n                  \n                \n              \n            \n          \n        \n        =\n        3.7673\n        \u00d7\n        \n          10\n          \n            10\n          \n        \n        \n        \n          s\n          t\n          a\n          t\n          C\n        \n      \n    \n    {\\displaystyle 1\\;\\mathrm {C} {\\sqrt {\\tfrac {4\\pi 10^{9}}{\\epsilon _{0}}}}=3.7673\\times 10^{10}\\;\\mathrm {statC} }\n   (as unit of \u03a6D)",
        "unit": "statcoulomb",
        "url": "https://en.wikipedia.org/wiki/Statcoulomb"
    },
    {
        "_id": "Barn_(unit)",
        "clean": "Barn (unit)",
        "text": "A barn (symbol: b) is a unit of area equal to 10\u221228 m2 (100 fm2). Originally used in nuclear physics for expressing the cross sectional area of nuclei and nuclear reactions, today it is also used in all fields of high-energy physics to express the cross sections of any scattering process, and is best understood as a measure of the probability of interaction between small particles. A barn is  approximately the cross-sectional area of a uranium nucleus. The barn is also the unit of area used in nuclear quadrupole resonance and nuclear magnetic resonance to quantify the interaction of a nucleus with an electric field gradient. While the barn is not an SI unit, the SI standards body acknowledges its existence due to its continued use in particle physics.\n\n\n== Etymology ==\nThe etymology of the unit barn is whimsical: during Manhattan Project research on the atomic bomb during World War II, American physicists at Purdue University needed a secretive unit to describe the approximate cross sectional area presented by the typical nucleus (10\u221228 m2) and decided on \"barn\". This was particularly applicable because they considered this a large target for particle accelerators that needed to have direct strikes on nuclei and the American idiom \"couldn't hit the broad side of a barn\" refers to someone whose aim is terrible. Initially they hoped the name would obscure any reference to the study of nuclear structure; eventually, the word became a standard unit in nuclear and particle physics.\n\n\n== Commonly used prefixed versions ==\nOther related units are the outhouse (1 \u03bcb, or 10\u221234 m2) and the shed (10\u221224 b (1 yb), or 10\u221252 m2), although these are rarely used in practice.\n\n\n== Conversions ==\nCalculated cross sections are often given in terms of gigaelectronvolts (GeV), via the conversion \u01272c2/GeV2 = 0.3894 mb = 38 940 am2.\nIn natural units (where \u0127 = c = 1), this simplifies to GeV\u22122 = 0.3894 mb = 38 940 am2.\n\n\n=== SI units with prefix ===\nIn SI, one can use units such as square femtometers (fm2).\n\n\n== Inverse femtobarn ==\nThe inverse femtobarn (fb\u22121) is the unit typically used to measure the number of particle collision events per femtobarn of target cross-section, and is the conventional unit for time-integrated luminosity. Thus if a detector has accumulated 100 fb\u22121 of integrated luminosity, one expects to find 100 events per femtobarn of cross-section within these data.\nConsider a particle accelerator where two streams of particles, with cross-sectional areas measured in femtobarns, are directed to collide over a period of time. The total number of collisions will be directly proportional to the luminosity of the collisions measured over this time. Therefore, the collision count can be calculated by multiplying the integrated luminosity by the sum of the cross-section for those collision processes. This count is then expressed as inverse femtobarns for the time period (e.g., 100 fb\u22121 in nine months). Inverse femtobarns are often quoted as an indication of particle collider productivity.Fermilab produced 10 fb\u22121 in the first decade of the 21st century.  Fermilab's Tevatron took about 4 years to reach 1 fb\u22121 in 2005, while two of CERN's LHC experiments, ATLAS and CMS, reached over 5 fb\u22121 of proton-proton data in 2011 alone. In April 2012 the LHC achieved the collision energy of 8 TeV with a luminosity peak of 6760 inverse microbarns per second; by May 2012 the LHC delivered 1 inverse femtobarn of data per week to each detector collaboration. A record of over 23 fb\u22121 was achieved during 2012. As of November 2016, the LHC had achieved 40  fb\u22121 over that year, significantly exceeding the stated goal of 25  fb\u22121.\n\n\n=== Usage example ===\nAs a simplified example, if a beamline runs for 8 hours (28 800 seconds) at an instantaneous luminosity of 300 \u00d7 1030 cm\u22122s\u22121 = 300 \u03bcb\u22121s\u22121, then it will gather data totaling an integrated luminosity of 8 640 000 \u03bcb\u22121 = 8.64 pb\u22121 = 0.008 64 fb\u22121 during this period. If this is multiplied by the cross-section, then a dimensionless number is obtained which would be simply the number of expected scattering events.\n\n\n== See also ==\nOrders of magnitude (area)\nList of unusual units of measurement\n\n\n== References ==\n\n\n== External links ==\nIUPAC citation for this usage of \"barn\"",
        "unit": "barn",
        "url": "https://en.wikipedia.org/wiki/Barn_(unit)"
    },
    {
        "_id": "Kelvin",
        "clean": "Kelvin",
        "text": "The Kelvin scale is an absolute thermodynamic temperature scale using as its null point absolute zero, the temperature at which all thermal motion ceases in the classical description of thermodynamics.  The kelvin (symbol: K) is the base unit of temperature in the International System of Units (SI).  The kelvin is defined as the fraction \u200b1\u2044273.16 of the thermodynamic temperature of the triple point of water (exactly 0.01 \u00b0C or 32.018 \u00b0F). In other words, it is defined such that the triple point of water is exactly 273.16 K.\nThe Kelvin scale is named after the Belfast-born, Glasgow University engineer and physicist William Thomson, 1st Baron Kelvin (1824\u20131907), who wrote of the need for an \"absolute thermometric scale\". Unlike the degree Fahrenheit and degree Celsius, the kelvin is not referred to or written as a degree. The kelvin is the primary unit of temperature measurement in the physical sciences, but is often used in conjunction with the degree Celsius, which has the same magnitude. The definition implies that absolute zero (0 K) is equivalent to \u2212273.15 \u00b0C (\u2212459.67 \u00b0F).\nFor expressing temperature difference or interval, using kelvins instead of degrees Celsius helps to avoid situations when people mistake such quantities for Celsius temperature. The kelvin is the proper temperature unit to be used in derived units, like W/(m\u00b7K) or to have a prefix, like milli in mK.\n\n\n== History ==\n\nIn 1848, William Thomson, who later was made Lord Kelvin, wrote in his paper, On an Absolute Thermometric Scale, of the need for a scale whereby \"infinite cold\" (absolute zero) was the scale's null point, and which used the degree Celsius for its unit increment. Kelvin calculated that absolute zero was equivalent to \u2212273 \u00b0C on the air thermometers of the time. This absolute scale is known today as the Kelvin thermodynamic temperature scale. Kelvin's value of \"\u2212273\" was the negative reciprocal of 0.00366\u2014the accepted expansion coefficient of gas per degree Celsius relative to the ice point, giving a remarkable consistency to the currently accepted value.\nIn 1954, Resolution 3 of the 10th General Conference on Weights and Measures (CGPM) gave the Kelvin scale its modern definition by designating the triple point of water as its second defining point and assigned its temperature to exactly 273.16 kelvins.In 1967/1968  Resolution 3 of the 13th CGPM renamed the unit increment of thermodynamic temperature \"kelvin\", symbol K, replacing \"degree Kelvin\", symbol \u00b0K. Furthermore, feeling it useful to more explicitly define the magnitude of the unit increment, the 13th CGPM also held in Resolution 4 that \"The kelvin, unit of thermodynamic temperature, is equal to the fraction \u200b1\u2044273.16 of the thermodynamic temperature of the triple point of water.\"In 2005  The Comit\u00e9 International des Poids et Mesures (CIPM), a committee of the CGPM, affirmed that for the purposes of delineating the temperature of the triple point of water, the definition of the Kelvin thermodynamic temperature scale would refer to water having an isotopic composition specified as VSMOW.\n\n\n== Usage conventions ==\nWhen spelled out or spoken, the unit is pluralised using the same grammatical rules as for other SI units such as the volt or ohm (e.g. \"the triple point of water is exactly 273.16 kelvins\"). When reference is made to the \"Kelvin scale\", the word \"kelvin\"\u2014which is normally a noun\u2014functions adjectivally to modify the noun \"scale\" and is capitalized. As with most other SI unit symbols (angle symbols, e.g. 45\u00b0 3\u2032 4\u2033, are the exception) there is a space between the numeric value and the kelvin symbol (e.g. \"99.987 K\").Before the 13th CGPM in 1967\u20131968, the unit kelvin was called a \"degree\", the same as with the other temperature scales at the time. It was distinguished from the other scales with either the adjective suffix \"Kelvin\" (\"degree Kelvin\") or with \"absolute\" (\"degree absolute\") and its symbol was \u00b0K. The latter term (degree absolute), which was the unit's official name from 1948 until 1954, was ambiguous since it could also be interpreted as referring to the Rankine scale. Before the 13th CGPM, the plural form was \"degrees absolute\". The 13th CGPM changed the unit name to simply \"kelvin\" (symbol: K). The omission of \"degree\" indicates that it is not relative to an arbitrary reference point like the Celsius and Fahrenheit scales (although the Rankine scale continued to use \"degree Rankine\"), but rather an absolute unit of measure which can be manipulated algebraically (e.g. multiplied by two to indicate twice the amount of \"mean energy\" available among elementary degrees of freedom of the system).\n\n\n=== Use in conjunction with degrees Celsius ===\n\nIn science and engineering, degrees Celsius and kelvins are often used simultaneously in the same article, where absolute temperatures are given in degrees Celsius, but temperature intervals are given in kelvins.  E.g. \"its measured value was 0.01028 \u00b0C with an uncertainty of 60 \u00b5K.\"\nThis practice is permissible because the degree Celsius is a special name for the kelvin for use in expressing relative temperatures, and the magnitude of the degree Celsius is exactly equal to that of the kelvin. Notwithstanding that the official endorsement provided by Resolution 3 of the 13th CGPM states \"a temperature interval may also be expressed in degrees Celsius\", the practice of simultaneously using both \u00b0C and K is widespread throughout the scientific world. The use of SI prefixed forms of the degree Celsius (such as \u00b5\u00b0C or microdegree Celsius) to express a temperature interval has not been widely adopted.\n\n\n== Proposed redefinition ==\n\nIn 2005 the CIPM embarked on a programme to redefine the kelvin (along with the other SI units) using a more experimentally rigorous methodology. The current definition as of  2016 is unsatisfactory for temperatures below 20 K and above 1300 K. In particular, the committee proposed redefining the kelvin such that Boltzmann's constant takes the exact value 1.3806505\u00d710\u221223 J/K. The committee had hoped that the programme would be completed in time for its adoption by the CGPM at its 2011 meeting, but at the 2011 meeting the decision was postponed to the 2014 meeting when it would be considered as part of a larger programme.The redefinition was further postponed in 2014, pending more accurate measurements of Boltzmann's constant in terms of the current definition, but it is expected to be adopted at the 26th CGPM in late 2018.From a scientific point of view, this will link temperature to the rest of SI and result in a stable definition that is independent of any particular substance. From a practical point of view, the redefinition will pass unnoticed; water will still freeze at 273.15 K (0 \u00b0C).\n\n\n== Practical uses ==\n\n\n=== Colour temperature ===\n\nThe kelvin is often used in the measure of the colour temperature of light sources. Colour temperature is based upon the principle that a black body radiator emits light whose colour depends on the temperature of the radiator. Black bodies with temperatures below about 4000 K appear reddish, whereas those above about 7500 K appear bluish. Colour temperature is important in the fields of image projection and photography, where a colour temperature of approximately 5600 K is required to match \"daylight\" film emulsions. In astronomy, the stellar classification of stars and their place on the Hertzsprung\u2013Russell diagram are based, in part, upon their surface temperature, known as effective temperature. The photosphere of the Sun, for instance, has an effective temperature of 5778 K.\nDigital cameras and photographic software often use colour temperature in K in edit and setup menus. The simple guide is that the higher the colour temperature, the more white or blue the image will be. The reduction in colour temperature will give an image more dominated by reddish, \"warmer\" colours.\n\n\n=== Kelvin as a measure of noise ===\n\nIn electronics, the kelvin is used as an indicator of how noisy a circuit is in relation to an ultimate noise floor, i.e. the noise temperature. The so-called Johnson\u2013Nyquist noise of discrete resistors and capacitors is a type of thermal noise derived from the Boltzmann constant and can be used to determine the noise temperature of a circuit using the Friis formulas for noise.\n\n\n== Unicode character ==\nThe symbol is encoded in Unicode at code point U+212A K kelvin sign. However, this is a compatibility character provided for compatibility with legacy encodings. The Unicode standard recommends using U+004B K latin capital letter k instead; that is, a normal capital K. \"Three letterlike symbols have been given canonical equivalence to regular letters: U+2126 \u03a9 ohm sign, U+212A K kelvin sign, and U+212B \u00c5 angstrom sign. In all three instances, the regular letter should be used.\"\n\n\n== See also ==\nComparison of temperature scales\nInternational Temperature Scale of 1990\nNegative temperature\n\n\n== Notes and references ==\n\n\n== External links ==\nBureau International des Poids et Mesures (2006). \"The International System of Units (SI) Brochure\" (PDF). 8th Edition. International Committee for Weights and Measures. Retrieved 2008-02-06.\nOnlineConversion.com \u2013 Convert different temperature units (Celsius, Fahrenheit, Rankine, R\u00e9aumur, kelvin)",
        "unit": "kelvin",
        "url": "https://en.wikipedia.org/wiki/Kelvin"
    },
    {
        "_id": "Fahrenheit",
        "clean": "Fahrenheit",
        "text": "The Fahrenheit scale is a temperature scale based on one proposed in 1724 by Dutch\u2013German\u2013Polish physicist Daniel Gabriel Fahrenheit (1686\u20131736). It uses the degree Fahrenheit (symbol: \u00b0F) as the unit. Several accounts of how he originally defined his scale exist. The lower defining point, 0 \u00b0F, was established as the temperature of a solution of brine made from equal parts of ice, water and salt (ammonium chloride). Further limits were established as the melting point of ice (32 \u00b0F) and his best estimate of the average human body temperature (96 \u00b0F, about 2.6 \u00b0F less than the modern value due to a later redefinition of the scale). The scale is now usually defined by two fixed points: the temperature at which water freezes into ice is defined as 32 \u00b0F, and the boiling point of water is defined to be 212 \u00b0F, a 180 \u00b0F separation, as defined at sea level and standard atmospheric pressure.\nAt the end of the 2010s, Fahrenheit was used as the official temperature scale only in the United States (including its unincorporated territories), its freely associated states in the Western Pacific (Palau, the Federated States of Micronesia and the Marshall Islands), the Bahamas, the Cayman Islands and Liberia. Antigua and Barbuda and other islands which use the same meteorological service, such as Anguilla, the British Virgin Islands, Montserrat and Saint Kitts and Nevis, as well as Bermuda, Belize and the Turks and Caicos Islands, use Fahrenheit and Celsius. All other countries in the world now use the Celsius scale, named after Swedish astronomer Anders Celsius, defined since 1954 by absolute zero being \u2212273.15 \u00b0C and the triple point of water being at 0.01 \u00b0C. Before 1954, the Celsius scale was based on 0 \u00b0C for the freezing point of water and 100 \u00b0C for the boiling point of water at 1 atm. Since the conversion between \u00b0C and \u00b0F was kept unchanged the definition of \u00b0F is now based on the triple point, too; the freezing and boiling points of water are only very good approximations.\n\n\n== Definition and conversion ==\nOn the Fahrenheit scale, the freezing point of water is 32 degrees Fahrenheit (\u00b0F) and the boiling point is 212 \u00b0F (at standard atmospheric pressure). This puts the boiling and freezing points of water 180 degrees apart. Therefore, a degree on the Fahrenheit scale is \u200b1\u2044180 of the interval between the freezing point and the boiling point. On the Celsius scale, the freezing and boiling points of water are 100 degrees apart. A temperature interval of 1 \u00b0F is equal to an interval of \u200b5\u20449 degrees Celsius. The Fahrenheit and Celsius scales intersect at \u221240\u00b0 (i.e., \u221240 \u00b0F = \u221240 \u00b0C).\nAbsolute zero is \u2212273.15 \u00b0C or \u2212459.67 \u00b0F. The Rankine temperature scale uses degree intervals of the same size as those of the Fahrenheit scale, except that absolute zero is 0 \u00b0R \u2014 the same way that the Kelvin temperature scale matches the Celsius scale, except that absolute zero is 0 K.The Fahrenheit scale uses the symbol \u00b0 to denote a point on the temperature scale (as does Celsius) and the letter F to indicate the use of the Fahrenheit scale (e.g. \"Gallium melts at 85.5763 \u00b0F\"), as well as to denote a difference between temperatures or an uncertainty in temperature (e.g. \"The output of the heat exchanger experiences an increase of 72 \u00b0F\" and \"Our standard uncertainty is \u00b15 \u00b0F\").\nFor an exact conversion, the following formulas can be applied. Here, f is the value in Fahrenheit and c the value in Celsius:\n\nf \u00b0Fahrenheit to c \u00b0Celsius : (f \u2212 32) \u00b0F \u00d7 5\u00b0C/9\u00b0F = (f \u2212 32)/1.8 \u00b0C = c \u00b0C\nc \u00b0Celsius to f \u00b0Fahrenheit : (c \u00b0C \u00d7 9\u00b0F/5\u00b0C) + 32 \u00b0F = (c \u00d7 1.8) \u00b0F + 32 \u00b0F = f \u00b0FThis is also an exact conversion making use of the identity -40 \u00b0F = -40 \u00b0C. Again, f is the value in Fahrenheit and c the value in Celsius:\n\nf \u00b0Fahrenheit to c \u00b0Celsius : ((f + 40) \u00f7 1.8) \u2212 40 = c.\nc \u00b0Celsius to f \u00b0Fahrenheit : ((c + 40) \u00d7 1.8) \u2212 40 = f.\n\n\n== History ==\n\nFahrenheit proposed his temperature scale in 1724, basing it on two reference points of temperature. In his initial scale (which is not the final Fahrenheit scale), the zero point was determined by placing the thermometer in  a mixture of ice, water, and ammonium chloride (salis Armoniaci). This is a frigorific mixture which stabilizes its temperature automatically: that stable temperature was defined as 0 \u00b0F (\u221217.78 \u00b0C). The second point, 96 degrees, was approximately the human body's temperature (sanguine hominis sani, the blood of a healthy man).According to a story in Germany, Fahrenheit actually chose the lowest air temperature measured in his hometown Danzig in winter 1708/09 as 0 \u00b0F, and only later had the need to be able to make this value reproducible using brine. This is one explanation given why 0 \u00b0F is \u221217.78 \u00b0C, but the ammonium chloride cooling temperature actually is \u22123 \u00b0C, whereas that of NaCl is \u221221.1 \u00b0C; the other explanation is that he did not have a good enough brine solution to obtain the eutectic equilibrium exactly (i.e. he might have had a mixture of salts, or it had not fully dissolved). In any case, the definition of the Fahrenheit scale has changed since.\nAccording to a letter Fahrenheit wrote to his friend Herman Boerhaave, his scale was built on the work of Ole R\u00f8mer, whom he had met earlier. In R\u00f8mer's scale, brine freezes at zero, water freezes and melts at 7.5 degrees, body temperature is 22.5, and water boils at 60 degrees. Fahrenheit multiplied each value by four in order to eliminate fractions and increase the granularity of the scale. He then re-calibrated his scale using the melting point of ice and normal human body temperature (which were at 30 and 90 degrees); he adjusted the scale so that the melting point of ice would be 32 degrees and body temperature 96 degrees, so that 64 intervals would separate the two, allowing him to mark degree lines on his instruments by simply bisecting the interval six times (since 64 is 2 to the sixth power).Fahrenheit observed that water boils at about 212 degrees using this scale. The use of the freezing and boiling points of water as thermometer fixed reference points became popular following the work of Anders Celsius and these fixed points were adopted by a committee of the Royal Society led by Henry Cavendish in 1776. Under this system, the Fahrenheit scale is redefined slightly so that the freezing point of water is exactly 32 \u00b0F, and the boiling point is exactly 212 \u00b0F or 180 degrees higher. It is for this reason that normal human body temperature is approximately 98\u00b0 (oral temperature) on the revised scale (whereas it was 90\u00b0 on Fahrenheit's multiplication of R\u00f8mer, and 96\u00b0 on his original scale).The Rankine temperature scale was based upon the Fahrenheit temperature scale, with its zero representing absolute zero instead.\n\n\n== Usage ==\n\nThe Fahrenheit scale was the primary temperature standard for climatic, industrial and medical purposes in English-speaking countries until the 1960s. In the late 1960s and 1970s, the Celsius scale replaced Fahrenheit in almost all of those countries\u2014with the notable exception of the United States\u2014typically during their metrication process.\nFahrenheit is used in the United States, its territories and associated states (all served by the U.S. National Weather Service), as well as the Bahamas, the Cayman Islands and Liberia for everyday applications. For example, U.S. weather forecasts, food cooking, and freezing temperatures are typically given in degrees Fahrenheit. Scientists, such as meteorologists, use Celsius or Kelvin in all countries.Early in the 20th century, Halsey and Dale suggested that the resistance to the use of centigrade (now Celsius) system in the U.S. included the larger size of each degree Celsius and the lower zero point in the Fahrenheit system.Canada has passed legislation favoring the International System of Units, while also maintaining legal definitions for traditional Canadian imperial units. Canadian weather reports are conveyed using degrees Celsius with occasional reference to Fahrenheit especially for cross-border broadcasts. Virtually all Canadian ovens make legal use of the Fahrenheit scale. Thermometers, both digital and analog, sold in Canada usually employ both the Celsius and Fahrenheit scales.  Also, in some instances (swimming pool temperature, thermostats, or cooking temperatures for example), temperatures are still expressed in Fahrenheit.\n\nWithin the European Union, it is mandatory to use kelvins or degrees Celsius when quoting temperature for \"economic, public health, public safety and administrative\" purposes, though degrees Fahrenheit may be used alongside degrees Celsius as a supplementary unit. For example, the laundry symbols used in the United Kingdom follow the recommendations of ISO 3758:2005 showing the temperature of the washing machine water in degrees Celsius only. The equivalent label in North America uses one to six dots to denote temperature with an optional temperature in degrees Celsius.Within the unregulated sector, such as journalism, the use of Fahrenheit in the United Kingdom follows no fixed pattern with degrees Fahrenheit often appearing alongside degrees Celsius. The Daily Mail, on its daily weather page, quotes Celsius first, followed by Fahrenheit in brackets, The Daily Telegraph does not mention Fahrenheit on its daily weather page while The Times also has an all-metric daily weather page but has a Celsius-to-Fahrenheit conversion table. When publishing news stories, much of the UK  press and population have adopted a convention of using degrees Celsius in headlines and discussion relating to low temperatures and Fahrenheit for high temperatures. In February 2006, the writer of an article in The Times suggested that the rationale was one of emphasis:  \"\u22126 \u00b0C\" sounds colder than \"21 \u00b0F\" and \"94 \u00b0F\" sounds more impressive than \"34 \u00b0C\".\n\n\n== Unicode representation of symbol ==\nUnicode provides the Fahrenheit symbol at code point U+2109 \u2109 degree fahrenheit. However, this is a compatibility character encoded for roundtrip compatibility with legacy encodings. The Unicode standard explicitly discourages the use of this character: \"The sequence U+00B0 \u00b0 degree sign +U+0046 F latin capital letter f is preferred over U+2109 \u2109 degree fahrenheit, and those two sequences should be treated as identical for searching.\"\n\n\n== See also ==\n\nComparison of temperature scales\nDegree of frost\n\n\n== Notes and references ==\n\n\n== External links ==\nDaniel Gabriel Fahrenheit (Polish-born Dutch physicist) -- Encyclop\u00e6dia Britannica\n\"At Auction | One of Only Three Original Fahrenheit Thermometers\" Enfilade page for 2012 Christie's sale of a Fahrenheit mercury thermometer with some nice pictures\nChristie's press release",
        "unit": "degree fahrenheit",
        "url": "https://en.wikipedia.org/wiki/Fahrenheit"
    },
    {
        "_id": "Barn_(unit)",
        "clean": "Barn (unit)",
        "text": "A barn (symbol: b) is a unit of area equal to 10\u221228 m2 (100 fm2). Originally used in nuclear physics for expressing the cross sectional area of nuclei and nuclear reactions, today it is also used in all fields of high-energy physics to express the cross sections of any scattering process, and is best understood as a measure of the probability of interaction between small particles. A barn is  approximately the cross-sectional area of a uranium nucleus. The barn is also the unit of area used in nuclear quadrupole resonance and nuclear magnetic resonance to quantify the interaction of a nucleus with an electric field gradient. While the barn is not an SI unit, the SI standards body acknowledges its existence due to its continued use in particle physics.\n\n\n== Etymology ==\nThe etymology of the unit barn is whimsical: during Manhattan Project research on the atomic bomb during World War II, American physicists at Purdue University needed a secretive unit to describe the approximate cross sectional area presented by the typical nucleus (10\u221228 m2) and decided on \"barn\". This was particularly applicable because they considered this a large target for particle accelerators that needed to have direct strikes on nuclei and the American idiom \"couldn't hit the broad side of a barn\" refers to someone whose aim is terrible. Initially they hoped the name would obscure any reference to the study of nuclear structure; eventually, the word became a standard unit in nuclear and particle physics.\n\n\n== Commonly used prefixed versions ==\nOther related units are the outhouse (1 \u03bcb, or 10\u221234 m2) and the shed (10\u221224 b (1 yb), or 10\u221252 m2), although these are rarely used in practice.\n\n\n== Conversions ==\nCalculated cross sections are often given in terms of gigaelectronvolts (GeV), via the conversion \u01272c2/GeV2 = 0.3894 mb = 38 940 am2.\nIn natural units (where \u0127 = c = 1), this simplifies to GeV\u22122 = 0.3894 mb = 38 940 am2.\n\n\n=== SI units with prefix ===\nIn SI, one can use units such as square femtometers (fm2).\n\n\n== Inverse femtobarn ==\nThe inverse femtobarn (fb\u22121) is the unit typically used to measure the number of particle collision events per femtobarn of target cross-section, and is the conventional unit for time-integrated luminosity. Thus if a detector has accumulated 100 fb\u22121 of integrated luminosity, one expects to find 100 events per femtobarn of cross-section within these data.\nConsider a particle accelerator where two streams of particles, with cross-sectional areas measured in femtobarns, are directed to collide over a period of time. The total number of collisions will be directly proportional to the luminosity of the collisions measured over this time. Therefore, the collision count can be calculated by multiplying the integrated luminosity by the sum of the cross-section for those collision processes. This count is then expressed as inverse femtobarns for the time period (e.g., 100 fb\u22121 in nine months). Inverse femtobarns are often quoted as an indication of particle collider productivity.Fermilab produced 10 fb\u22121 in the first decade of the 21st century.  Fermilab's Tevatron took about 4 years to reach 1 fb\u22121 in 2005, while two of CERN's LHC experiments, ATLAS and CMS, reached over 5 fb\u22121 of proton-proton data in 2011 alone. In April 2012 the LHC achieved the collision energy of 8 TeV with a luminosity peak of 6760 inverse microbarns per second; by May 2012 the LHC delivered 1 inverse femtobarn of data per week to each detector collaboration. A record of over 23 fb\u22121 was achieved during 2012. As of November 2016, the LHC had achieved 40  fb\u22121 over that year, significantly exceeding the stated goal of 25  fb\u22121.\n\n\n=== Usage example ===\nAs a simplified example, if a beamline runs for 8 hours (28 800 seconds) at an instantaneous luminosity of 300 \u00d7 1030 cm\u22122s\u22121 = 300 \u03bcb\u22121s\u22121, then it will gather data totaling an integrated luminosity of 8 640 000 \u03bcb\u22121 = 8.64 pb\u22121 = 0.008 64 fb\u22121 during this period. If this is multiplied by the cross-section, then a dimensionless number is obtained which would be simply the number of expected scattering events.\n\n\n== See also ==\nOrders of magnitude (area)\nList of unusual units of measurement\n\n\n== References ==\n\n\n== External links ==\nIUPAC citation for this usage of \"barn\"",
        "unit": "millibarn",
        "url": "https://en.wikipedia.org/wiki/Barn_(unit)"
    },
    {
        "_id": "Gray_(unit)",
        "clean": "Gray (unit)",
        "text": "The gray (symbol: Gy) is a derived unit of ionizing radiation dose in the International System of Units (SI). It is defined as the absorption of one joule of radiation energy per kilogram of matter.It is used as a unit of the radiation quantity absorbed dose which measures the energy deposited in a unit mass at a certain position, and of the radiation quantity kerma, which is the amount of energy that is transferred from photons to electrons per unit mass at a certain position.\nThe corresponding cgs unit to the gray is the rad (equivalent to 0.01 Gy), which remains common largely in the United States, though \"strongly discouraged\" in the style guide for U.S. National Institute of Standards and Technology authors.The gray was named after British physicist Louis Harold Gray, a pioneer in the measurement of X-ray and radium radiation and their effects on living tissue. It was adopted as part of the International System of Units in 1975.\n\n\n== Definition ==\n\nOne gray is the absorption of one joule of energy, in the form of ionizing radiation, per kilogram of  matter.\n\n  \n    \n      \n        1\n         \n        \n          G\n          y\n        \n        =\n        1\n         \n        \n          \n            \n              J\n            \n            \n              k\n              g\n            \n          \n        \n        =\n        1\n         \n        \n          \n            \n              \n                m\n              \n              \n                2\n              \n            \n            \n              \n                s\n              \n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 1\\ \\mathrm {Gy} =1\\ {\\frac {\\mathrm {J} }{\\mathrm {kg} }}=1\\ {\\frac {\\mathrm {m} ^{2}}{\\mathrm {s} ^{2}}}}\n  The CIPM states: \"In order to avoid any risk of confusion between the absorbed dose D and the dose equivalent H, the special names for the respective units should be used, that is, the name gray should be used instead of joules per kilogram for the unit of absorbed dose D and the name sievert instead of joules per kilogram for the unit of dose equivalent H.\"\n\n\n== Applications ==\nThe gray has a number of fields of application in measuring dose:\n\n\n=== Absorbed dose in matter ===\nThe gray is used to measure absorbed dose rates in non-tissue materials for processes such as radiation hardening, food irradiation and electron irradiation. Measuring and controlling the value of absorbed dose is vital to ensuring correct operation of these processes.\n\n\n=== Kerma ===\nKerma (\"kinetic energy released per unit mass\") is a measure of the liberated energy of ionisation due to irradiation, and is expressed in grays. Importantly, kerma dose is different from absorbed dose, depending on the radiation energies involved, partially because ionization energy is not accounted for. Whilst roughly equal at low energies, kerma is much higher than absorbed dose at higher energies, because some energy escapes from the absorbing volume in the form of bremsstrahlung (X-rays) or fast-moving electrons.\nKerma, when applied to air, is equivalent to the legacy roentgen unit of radiation exposure, but there is a difference in the definition of these two units. The gray is defined independently of any target material, however, the roengten was defined specifically by the ionisation effect in dry air, which did not necessarily represent the effect on other media.\n\n\n=== Absorbed dose in tissue ===\nThe measurement of absorbed dose in tissue is of fundamental importance in radiobiology and radiation therapy as it is the measure of the amount of energy the incident radiation is imparting to the target tissue. The measurement of absorbed dose is a complex problem, and so many different dosimeters are available for these measurements. These dosimeters cover measurements that can be done in 1-D, 2-D and 3-D.In radiation therapy, the amount of radiation applied varies depending on the type and stage of cancer being treated. For curative cases, the typical dose for a solid epithelial tumor ranges from 60 to 80 Gy, while lymphomas are treated with 20 to 40 Gy. Preventive (adjuvant) doses are typically around 45\u201360 Gy in 1.8\u20132 Gy fractions (for breast, head, and neck cancers).\nThe average radiation dose from an abdominal X-ray is 0.7 milli-Grays (0.0007 Gy), that from an abdominal CT scan is 8 mGy, that from a pelvic CT scan is 6 mGy, and that from a selective CT scan of the abdomen and the pelvis is 14 mGy.The absorbed dose also plays an important role in radiation protection, as it is the starting point for calculating the effect of low levels of radiation. In radiation protection dose assessment, the \"stochastic health risk\" is defined as the probability of cancer induction and genetic damage. The gray measures the total absorbed energy of radiation, but the probability of damage also depends on the type and energy of the individual particles or photons of which the radiation consists, and on the tissues involved. This probability is related to the equivalent dose in sieverts (Sv), which has the same dimensions as the gray. It is related to the gray by weighting factors described in the articles on equivalent dose and effective dose. To avoid any risk of confusion between the absorbed dose and the equivalent dose, the absorbed dose is stated in grays and the equivalent dose is stated in sieverts.\nThe accompanying diagrams show how absorbed dose (in grays) is first obtained by computational techniques, and from this value the equivalent doses are derived. For X-rays and gamma rays the gray is numerically the same value when expressed in sieverts, but for alpha particles one gray is equivalent to 20 sieverts, and a radiation weighting factor is applied accordingly.\nRadiation poisoning - The gray is conventionally used to express the severity of what are known as \"tissue effects\" from doses received in acute exposure to high levels of ionizing radiation. These are effects which are certain to happen, as opposed to the uncertain effects of low levels of radiation which have a probability of causing damage. A whole-body acute exposure to 5 grays or more of high-energy radiation usually leads to death within 14 days. This dose represents 375 joules for a 75 kg adult.\n\n\n== Leading up to the gray ==\nWilhelm R\u00f6ntgen first discovered X-rays on November 8, 1895, and very quickly their use spread internationally for medical diagnostics - particularly broken bones and embedded foreign objects, where they were a revolutionary improvement over previous techniques.\nMeasurement standards were soon required for radiation protection and various countries developed their own standards, but in order to promote international standardisation and cooperation, the First International Congress of Radiology (ICR) which met in London in 1925 proposed a separate body to consider units of measure. This new body, called the International Commission on Radiation Units and Measurements (ICRU), came into being at the Second ICR in Stockholm in 1928 under the chairmanship of Manne SiegbahnOne of the earliest techniques of measuring the intensity of X-rays was to measure their ionisation potential in air. At the first ICRU meeting it was proposed that one unit of X-ray dose should be defined as the quantity of X-rays that would produce one esu of charge in one cubic centimetre of dry air at 0 \u00b0C and 1 standard atmosphere of pressure. This unit of radiation exposure was named the roentgen in honour of R\u00f6ntgen, who had died five years previously. At the 1937 meeting of the ICRU, this definition was extended to apply to gamma radiation as well as X-rays. This approach, although appropriate for the technology of the day, had the disadvantage that it was not a direct measure of either the intensity of X-rays or their absorption in target material, but rather was a measurement of the effect of the X-rays in a specific circumstance; the ionisation of dry air.In 1940, Louis Harold Gray, who had been studying the effect of neutron damage on human tissue, together with William Valentine Mayneord and the radiobiologist John Read, published a paper in which a unit of measure, dubbed the \"gram roentgen\" (symbol: gr) defined as \"that amount of neutron radiation which produces an increment in energy in unit volume of tissue equal to the increment of energy produced in unit volume of water by one roentgen of radiation\" was proposed. This unit was found to be equivalent to 88 ergs in air. In 1953 the ICRU recommended the rad, equal to 100 erg/g, as the new unit of measure of absorbed radiation. The rad was expressed in coherent cgs units.In the late 1950s the CGPM invited the ICRU to join other scientific bodies to work with the International Committee for Weights and Measures (CIPM) in the development of a system of units that could be used consistently over many disciplines. This body, initially known as the \"Commission for the System of Units\", renamed in 1964 as the \"Consultative Committee for Units\" (CCU), was responsible for overseeing the development of the International System of Units (SI). At the same time it was becoming increasingly obvious that the definition of the roentgen was unsound, and many calls were made for its redefinition, and in 1962 it was redefined. The definition of the roentgen had the advantage over the gray of being simpler to measure, but the gray is independent of the primary ionizing radiation.The CCU decided to define the SI unit of absorbed radiation in terms of energy per unit mass, which in MKS units was J/kg. This was confirmed in 1975 by the 15th CGPM, and the unit was named the \"gray\" in honour of Louis Harold Gray, who had died in 1965. The gray was equal to 100 rad.\nThe adoption of the gray by the 15th General Conference on Weights and Measures as the unit of measure of the absorption of ionizing radiation, specific energy absorption, and of kerma in 1975 was the culmination of over half a century of work, both in the understanding of the nature of ionizing radiation and in the refinement of measuring techniques.\n\n\n== Radiation-related quantities ==\n\nThe following table shows radiation quantities in SI and non-SI units.\n\n\n== See also ==\nDose area product (Gy\u00b7cm2)\nInternational System of Units base units\nOrders of magnitude (radiation)\nOrder of magnitude (unit)\nRad (unit)\nRoentgen equivalent man\nSI derived unit\nSievert, SI derived unit of dose equivalent radiation\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nBoyd, M.A. (2009). \"The confusing world of radiation dosimetry\" (PDF). WM2009 Conference. \u2014 An account of chronological differences between USA and ICRP dosimetry systems.",
        "unit": "gray",
        "url": "https://en.wikipedia.org/wiki/Gray_(unit)"
    },
    {
        "_id": "Swiss_franc",
        "clean": "Swiss franc",
        "text": "The franc (German: Franken, French and Romansh: franc, Italian: franco; sign: Fr. or SFr.; code: CHF) is the currency and legal tender of Switzerland and Liechtenstein; it is also legal tender in the Italian exclave Campione d'Italia. The Swiss National Bank (SNB) issues banknotes and the federal mint Swissmint issues coins.\nThe smaller denomination, a hundredth of a franc, is a Rappen (Rp.) in German, centime (c.) in French, centesimo (ct.) in Italian, and rap (rp.) in Romansh. The ISO code of the currency used by banks and financial institutions is CHF, although Fr. is also widely used by businesses and advertisers; some use SFr. for Swiss Franc and to a lesser extent Fr.sv. The Latinate \"CH\" stands for Confoederatio Helvetica.\nGiven the different languages used in Switzerland, Latin is used for language-neutral inscriptions on its coins.\n\n\n== History ==\n\n\n=== Before the Helvetic Republic ===\nBefore 1798, about 75 entities were making coins in Switzerland, including the 25 cantons and half-cantons, 16 cities, and abbeys, resulting in about 860 different coins in circulation, with different values, denominations and monetary systems.The local Swiss currencies included the Basel thaler, Berne thaler, Fribourg gulden, Geneva thaler, Geneva genevoise, Luzern gulden, Neuch\u00e2tel gulden, St. Gallen thaler, Schwyz gulden, Solothurn thaler, Valais thaler, and Z\u00fcrich thaler.\n\n\t\t\n\n\n=== Helvetic Republic to Regeneration 1798\u20131847 ===\nIn 1798, the Helvetic Republic introduced the franc, a currency based on the Berne thaler, subdivided into 10 batzen or 100 centimes. The Swiss franc was equal to \u200b6 3\u20444 grams of pure silver or \u200b1 1\u20442 French francs.\n\nThis franc was issued until the end of the Helvetic Republic in 1803, but served as the model for the currencies of several cantons in the Mediation period (1803\u20131814). These 19 cantonal currencies were the  Appenzell frank, Argovia frank, Basel frank, Berne frank, Fribourg frank, Geneva franc, Glarus frank, Graub\u00fcnden frank, Luzern frank, St. Gallen frank, Schaffhausen frank, Schwyz frank, Solothurn frank, Thurgau frank, Ticino franco, Unterwalden frank, Uri frank, Vaud franc, and Z\u00fcrich frank.\n\nAfter 1815, the restored Swiss Confederacy attempted to simplify the system of currencies once again. \nAs of 1820, a total of 8,000 distinct coins were current in Switzerland: those issued by cantons, cities, abbeys, and principalities or lordships, mixed with surviving coins of the Helvetic Republic and the pre-1798 Helvetic Republic. In 1825, the cantons of Berne, Basel, Fribourg, Solothurn, Aargau, and Vaud formed a monetary concordate, issuing standardised coins, the so-called Konkordanzbatzen, still carrying the coat of arms of the issuing canton, but interchangeable and identical in value. The reverse side of the coin displayed a Swiss cross with the letter C in the center.\n\n\n=== Franc of the Swiss Confederation, 1850\u2013present ===\nAlthough 22 cantons and half-cantons issued coins between 1803 and 1850, less than 15% of the money in circulation in Switzerland in 1850 was locally produced, with the rest being foreign, mainly brought back by mercenaries. In addition, some private banks also started issuing the first banknotes, so that in total, at least 8000 different coins and notes were in circulation at that time, making the monetary system extremely complicated.To solve this problem, the new Swiss Federal Constitution of 1848 specified that the federal government would be the only entity allowed to issue money in Switzerland. This was followed two years later by the first Federal Coinage Act, passed by the Federal Assembly on 7 May 1850, which introduced the franc as the monetary unit of Switzerland. The franc was introduced at par with the French franc. It replaced the different currencies of the Swiss cantons, some of which had been using a franc (divided into 10 batzen and 100 centimes) which was worth 1.5 French francs.\n\nIn 1865, France, Belgium, Italy, and Switzerland formed the Latin Monetary Union, in which they agreed to value their national currencies to a standard of 4.5 grams of silver or 0.290322 grams of gold. Even after the monetary union faded away in the 1920s and officially ended in 1927, the Swiss franc remained on that standard until 1936, when it suffered its sole devaluation, on 27 September during the Great Depression. The currency was devalued by 30% following the devaluations of the British pound, U.S. dollar and French franc. In 1945, Switzerland joined the Bretton Woods system and pegged the franc to the US dollar at a rate of $1 = 4.30521 francs (equivalent to 1 franc = 0.206418 grams of gold). This was changed to $1 = 4.375 francs (1 franc = 0.203125 grams of gold) in 1949.\nThe Swiss franc has historically been considered a safe-haven currency, with virtually zero inflation and a legal requirement that a minimum of 40% be backed by gold reserves. However, this link to gold, which dated from the 1920s, was terminated on 1 May 2000 following a referendum. By March 2005, following a gold-selling program, the Swiss National Bank held 1,290 tonnes of gold in reserves, which equated to 20% of its assets.In November 2014, the referendum on the \"Swiss Gold Initiative\" which proposed a restoration of 20% gold backing for the Swiss franc, was voted down.\n\n\n==== 2011\u20132014: Big movements and capping ====\nIn March 2011, the franc climbed past the US$1.10 mark (CHF 0.91 per U.S. dollar). In June 2011, the franc climbed past US$1.20 (CHF 0.833 per U.S. dollar) as investors sought safety as the Greek sovereign debt crisis continued. Continuation of the same crisis in Europe and the debt crisis in the US propelled the Swiss franc past US$1.30 (CHF 0.769 per U.S. dollar) as of August 2011, prompting the Swiss National Bank to boost the franc's liquidity to try to counter its \"massive overvaluation\". The Economist argued that its Big Mac Index in July 2011 indicated an overvaluation of 98% over the dollar, and cited Swiss companies releasing profit warnings and threatening to move operations out of the country due to the strength of the franc. Demand for francs and franc-denominated assets was so strong that nominal short-term Swiss interest rates became negative.On 6 September 2011, when the exchange rate was 1.095 CHF/\u20ac and appeared to be heading for parity with the euro, the SNB set a minimum exchange rate of 1.20 francs to the euro (capping franc's appreciation), saying \"the value of the franc is a threat to the economy\", and that it was \"prepared to buy foreign currency in unlimited quantities\". In response to this announcement the franc fell against the euro, to 1.22 francs from 1.12 francs and lost 9% against the U.S. dollar within fifteen minutes. The intervention stunned currency traders, since the franc had long been regarded as a safe haven.The franc fell 8.8% against the euro, 9.5% against the dollar, and at least 8.2% against all 16 of the most active currencies on the day of the announcement. It was the largest plunge of the franc ever against the euro. The SNB had previously set an exchange rate target in 1978 against the Deutsche mark and maintained it, although at the cost of high inflation. Until mid-January 2015, the franc continued to trade below the target level set by the SNB, though the ceiling was broken at least once on 5 April 2012, albeit briefly.\n\n\n==== End of capping ====\nOn 18 December 2014, the Swiss central bank introduced a negative interest rate on bank deposits to support its CHF ceiling. However, with the euro declining in value over the following weeks, in a move dubbed Francogeddon for its effect on markets, the Swiss National Bank abandoned the ceiling on 15 January 2015, and the franc promptly increased in value compared with the euro by 30%, although this only lasted a few minutes before part of the increase was reversed. The move was not announced in advance and resulted in \"turmoil\" in stock and currency markets. By the close of trading that day, the franc was up 23% against the euro and 21% against the US dollar. The full daily appreciation of the franc was equivalent to $31,000 per single futures contract: more than the market had moved collectively in the previous thousand days. The key CHF interest rate was also lowered from \u22120.25% to \u22120.75%, meaning depositors would be paying an increased fee to keep their funds in a Swiss bank account. This devaluation of the euro against the franc was expected to hurt Switzerland's large export industry. The Swatch Group, for example, saw its shares drop 15% (in Swiss franc terms) with the announcements so that the share price may have increased on that day in terms of other major currencies.\nThe large and unexpected jump caused major losses for some currency traders. Alpari, a Russian-owned spread betting firm established in the UK, temporarily declared insolvency before announcing its desire to be acquired (and later denied rumours of an acquisition) by FXCM. FXCM was bailed out by its parent company. Saxo Bank of Denmark reported losses on 19 January 2015. New Zealand foreign exchange broker Global Brokers NZ announced it \"could no longer meet New Zealand regulators' minimum capital requirements\" and terminated its business.Media questioned the ongoing credibility of the Swiss central bank, and indeed central banks in general. Using phrases like \"extend-and-pretend\" to describe central bank exchange rate control measures, Saxobank chief economist Steen Jakobsen said, \"As a group, central banks have lost credibility and when the ECB starts QE this week, the beginning of the end for central banks will be well under way\". BT Investment Management's head of income and fixed interest Vimal Gor said, \"Central banks are becoming more and more impotent. It also ultimately proves that central banks cannot drive economic growth like they think they can\". UBS interest rate strategist Andrew Lilley commented, \"central banks can have inconsistent goals from one-day to another\".\n\n\n== Coins ==\n\n\n=== Coins of the Helvetic Republic ===\n\nBetween 1798 and 1803, billon coins were issued in denominations of 1 centime, \u200b1\u20442 batzen, and 1 batzen. Silver coins were issued for 10, 20 and 40 batzen, with the 40-batzen coin also issued with the denomination given as 4 francs. Gold 16- and 32-franc coins were issued in 1800.\n\n\n=== Coins of the Swiss Confederation ===\nIn 1850, coins were introduced in denominations of 1, 2, 5, 10, and 20 centimes and \u200b1\u20442, 1, 2, and 5 francs, with the 1 and 2 centimes struck in bronze, the 5, 10, and 20 centimes in billon (with 5% to 15% silver content), and the franc denominations in .900 fine silver. Between 1860 and 1863, .800 fine silver was used, before the standard used in France of .835 fineness was adopted for all silver coins except the 5 francs (which remained .900 fineness) in 1875. In 1879, billon was replaced by cupronickel in the 5 and 10 centimes and by nickel in the 20 centimes. Gold coins in denominations of 10, 20, and 100 francs, known as Vreneli, circulated until 1936.Both world wars only had a small effect on the Swiss coinage, with brass and zinc coins temporarily being issued. In 1931, the size of the 5-franc coin was reduced from 25 grams to 15, with the silver content reduced to .835 fineness. The next year, nickel replaced cupronickel in the 5 and 10 centimes.In the late 1960s, the prices of internationally traded commodities rose significantly. A silver coin's metal value exceeded its monetary value, and many were being sent abroad for melting, which prompted the federal government to make this practice illegal. The statute was of little effect, and the melting of francs only subsided when the collectible value of the remaining francs again exceeded their material value.The 1-centime coin was still produced until 2006, albeit in ever decreasing quantities, but its importance declined. Those who could justify the use of 1-centime coins for monetary purposes could obtain them at face value; any other user (such as collectors) had to pay an additional four centimes per coin to cover the production costs, which had exceeded the actual face value of the coin for many years. The coin fell into disuse in the late 1970s and early 1980s, but was only officially fully withdrawn from circulation and declared to be no longer legal tender on 1 January 2007. The long-forgotten 2-centime coin, not minted since 1974, was demonetized on 1 January 1978.\n\nThe designs of the coins have changed very little since 1879. Among the notable changes were new designs for the 5-franc coins in 1888, 1922, 1924 (minor), and 1931 (mostly just a size reduction). A new design for the bronze coins was used from 1948. Coins depicting a ring of stars (such as the 1-franc coin seen beside this paragraph) were altered from 22 stars to 23 stars in 1983; since the stars represent the Swiss cantons, the design was updated when in 1979 Jura seceded from the Canton of Bern and became the 23rd canton of the Swiss Confederation.\n\nThe 10-centime coins from 1879 onwards (except the years 1918\u201319 and 1932\u201339) have had the same composition, size, and design until 2014 and are still legal tender and found in circulation.\n\nAll Swiss coins are language-neutral with respect to Switzerland's four national languages, featuring only numerals, the abbreviation \"Fr.\" for franc, and the Latin phrases Helvetia or Conf\u0153deratio Helvetica (depending on the denomination) or the inscription Libertas (Roman goddess of liberty) on the small coins. The name of the artist is present on the coins with the standing Helvetia and the herder.In addition to these general-circulation coins, numerous series of commemorative coins have been issued, as well as silver and gold coins. These coins are no longer legal tender, but can in theory be exchanged at face value at post offices, and at national and cantonal banks, although their metal or collectors' value equals or exceeds their face value.\n\n\n== Banknotes ==\n\nIn 1907, the Swiss National Bank took over the issuance of banknotes from the cantons and various banks. It introduced denominations of 50, 100, 500 and 1000 francs. 20-franc notes were introduced in 1911, followed by 5-franc notes in 1913. In 1914, the Federal Treasury issued paper money in denominations of 5, 10 and 20 francs. These notes were issued in three different versions: French, German and Italian. The State Loan Bank also issued 25-franc notes that year. In 1952, the national bank ceased issuing 5-franc notes but introduced 10-franc notes in 1955. In 1996, 200-franc notes were introduced whilst the 500-franc note was discontinued.\nEight series of banknotes have been printed by the Swiss National Bank, six of which have been released for use by the general public. The sixth series from 1976, designed by Ernst and Ursula Hiestand, depicted persons from the world of science.\nThis series was recalled on 1 May 2000 and is no longer legal tender, but notes can still be exchanged for valid ones of the same face value at any National Bank branch or authorized agent, or mailed in by post to the National Bank in exchange for a bank account deposit. The exchange program will end on 30 April 2020, after which sixth-series notes will lose all value. As of 2016, 1.1 billion francs' worth of sixth-series notes had not yet been exchanged, even though they had not been legal tender for 16 years and only 4 more years remained to exchange them. To avoid having to expire such large amounts of money in 2020, the Federal Council (cabinet) and National Bank proposed in April 2017 to remove the time limit on exchanges for the sixth and future recalled series; this proposal is still in the draft bill stage as of early 2018.\nThe seventh series was printed in 1984, but kept as a \"reserve series\", ready to be used if, for example, wide counterfeiting of the current series suddenly happened. When the Swiss National Bank decided to develop new security features and to abandon the concept of a reserve series, the details of the seventh series were released and the printed notes were destroyed.\nThe current, eighth series of banknotes was designed by J\u00f6rg Zintzmeyer around the theme of the arts and released starting in 1995. In addition to its new vertical design, this series was different from the previous one on several counts. Probably the most important difference from a practical point of view was that the seldom-used 500-franc note was replaced by a new 200-franc note; this new note has indeed proved more successful than the old 500-franc note. The base colours of the new notes were kept similar to the old ones, except that the 20-franc note was changed from blue to red to prevent a frequent confusion with the 100-franc note, and that the 10-franc note was changed from red to yellow. The size of the notes was changed as well, with all notes from the eighth series having the same height (74 mm), while the widths were changed as well, still increasing with the value of the notes. The new series contains many more security features than the previous one; many of them are now visibly displayed and have been widely advertised, in contrast with the previous series for which most of the features were kept secret.\n\nAll banknotes are quadrilingual, displaying all information in the four national languages. The banknotes depicting a Germanophone person have German and Romansch on the same side as the picture, whereas banknotes depicting a Francophone or an Italophone person have French and Italian on the same side as the picture. The reverse has the other two languages.\nWhen the fifth series lost its validity at the end of April 2000, the banknotes that had not been exchanged represented a total value of 244.3 million Swiss francs; in accordance with Swiss law, this amount was transferred to the Swiss Fund for Emergency Losses in the Case of Non-insurable Natural Disasters.\nNinth series of the Swiss franc\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\nIn February 2005, a competition was announced for the design of the ninth series, planned to be released around 2010 on the theme \"Switzerland open to the world\". The results were announced in November 2005, but the selected design drew widespread criticisms from the population. As a result, the release date has been repeatedly postponed. In February 2010, it was announced that the release would take place in 2012, and in December 2012 the date was given as \"2015 at the earliest\". In August 2015 it was announced that the new series would start being issued in April 2016. The first denomination to be released was the 50-franc note, which was first issued on 12 April 2016; the new 20-franc banknote followed on 17 May 2017, and the new 10-franc banknote on 18 October 2017. The 200 franc note's release is due on 15 August 2018. The final two notes will follow in 2019.\n\n\n== Circulation ==\nThe Swiss franc is the currency and legal tender of Switzerland and Liechtenstein and also legal tender in the Italian exclave of Campione d'Italia. Although not formally legal tender in the German exclave of B\u00fcsingen am Hochrhein (the sole legal currency is the euro), it is in wide daily use there; prices are quoted in Swiss francs. The Swiss franc is the only version of the franc still issued in Europe.\nAs of March 2010, the total value of released Swiss coins and banknotes was 49.6640 billion Swiss francs.\nCombinations of up to 100 circulating Swiss coins (not including special or commemorative coins) are legal tender; banknotes are legal tender for any amount.\n\n\n== Current exchange rates ==\n\n\n== See also ==\nBanking in Switzerland\nEconomy of Switzerland\nHard currency\nIraqi Swiss dinar, a common name for the old Iraqi currency but not related to Swiss currency.\nLiechtenstein franc\nGold standard\nList of currencies in Europe\n\n\n== Notes and references ==\n\n\n== Bibliography ==\n\n\n== External links ==\n(in German) CashFollow.ch, Swiss Franc Tracker\n(in German) Schweizer-Franken.ch, Information about the Swiss Franc\n(in English) Switzerland Banknotes, Swiss Franc: Banknote Catalog from 1907\nhttp://www.forexuklv.net/Major_Currency_Pairs/Chart_07.html  -  historical exchange rates of USD/CHF (from the year 1800 to present time).\nhttp://www.forexuklv.net/Major_Currency_Pairs/Chart_01.html  -  historical chart of USD/CHF (from the year 1800 to present time).\n(in English) (in German) The Banknotes of Switzerland",
        "unit": "swiss franc",
        "url": "https://en.wikipedia.org/wiki/Swiss_franc"
    },
    {
        "_id": "Pint",
        "clean": "Pint",
        "text": "The pint (,  listen ; symbol pt, sometimes abbreviated as \"p\") is a unit of volume or capacity in both the imperial and United States customary measurement systems. In both of those systems it is traditionally one-eighth of a gallon. The British imperial pint is about 20% larger than the American pint because the two systems are defined differently. Almost all other countries have standardized on the metric system, so the size of what may be called a pint varies depending on local custom.\n\nThe imperial pint (\u2248 568 ml) is used in the United Kingdom and Ireland and to a limited extent in Commonwealth nations. In the United States, two pints are used: a liquid pint (\u2248 473 ml) and a less-common dry pint (\u2248 551 ml). Each of these pints is one-eighth of its respective gallon, but the gallons differ. This difference dates back to 1824, when the British Weights and Measures Act standardised various liquid measures throughout the British Empire, while the United States continued to use the earlier English measure. The imperial pint consists of 20 imperial fluid ounces and the US liquid pint is 16 US fluid ounces, making the imperial fluid ounce about 4% smaller than the US fluid ounce.\nAll of the other former British colonies, such as Canada, Australia, South Africa and New Zealand, converted to the metric system in the 1960s and 1970s; so, while the term \"pint\" may still be in common use in these countries, it may no longer refer to the British imperial pint once used throughout the British Empire. In the United Kingdom, the imperial pint is still the primary unit for draught beer and cider, as it is for milk sold in returnable bottles and some cartons. In the UK, legislation mandates that draught beer and cider may be sold by the imperial pint in perpetuity, and in public houses can only be sold in a third of a pint, two-thirds of a pint or multiples of half a pint, which must be served in stamped measured glasses or from government-stamped meters.Since the majority of countries in the world no longer use American or British imperial units, and most are non-English speaking, a \"pint of beer\" served in a tavern outside the United Kingdom and the United States may be measured by other standards. In Commonwealth countries it may be a British imperial pint of 568 ml, in countries serving large numbers of American tourists it might be a US liquid pint of 473 ml, in many metric counties it is a half-litre of 500 ml, or in some places it is another measure reflecting national and local laws and customs.Historically, units called a pint (or the equivalent in the local language) were used across much of Europe, with values varying between countries from less than half a litre to over one litre. Within continental Europe, these pints were replaced with liquid measures based on the metric system during the 19th century. The term is still in limited use in parts of France, and in Quebec\u2014where \"une pinte\" means an imperial quart, which is 2 imperial pints, whereas a pint is \"une chopine\"\u2014and Central Europe, notably some areas of Germany and Switzerland, where \"ein Schoppen\" is colloquially used for roughly half a litre. In Spanish holiday resorts frequented by British tourists, 'pint' is often taken to mean a beer glass (especially a dimple mug). Half-pint and pint mugs may therefore be referred to as pinta peque\u00f1a ('small pint') and pinta grande ('large pint').\n\n\n== Name ==\nPint comes from the Old French word pinte and perhaps ultimately from Vulgar Latin pincta meaning \"painted\", for marks painted on the side of a container to show capacity.\n\n\n== Definitions ==\n\n\n=== Imperial pint ===\nThe imperial pint is equal to one-eighth of an imperial gallon. \n\n\n=== US liquid pint ===\nIn the United States, the liquid pint is legally defined as one-eighth of a liquid gallon of precisely 231 cubic inches.\n\n\n=== US dry pint ===\nIn the United States, the dry pint is one-eighth of a dry gallon.\n\n\n=== Other pints ===\n\nThe United States dry pint is equal to one-eighth of a United States dry gallon. It is used in the United States, but is not as common as the liquid pint.\nA now-obsolete unit of measurement in Scotland known as the Scottish pint or joug equals three imperial pints. It remained in use until the 19th century, surviving significantly longer than most of the old Scottish measurements.\nThis is one of numerous false friends which exist between English and French. They are not the same unit although they have the same linguistic origin. The French word pinte is etymologically related, but historically described a larger unit. The Royal pint (pinte du roi) was 48 French cubic inches (952.1 ml). but regional pints varied in size depending on locality and on commodity (usually wine or olive oil) varying from 0.95 L to over 2 L.In Canada, the Weights and Measures Act (R.S. 1985), which has the laws in English and French printed side-by-side, defines a pint in English as 1/8 of a gallon, but defines a pinte in French as 1/4 of a gallon. Thus, if you speak English and order \"a pint of beer\", servers are legally required to serve you 568 ml of beer, but if you speak French and order \"une pinte de bi\u00e8re\", they are legally required to serve an Imperial quart (une pinte), which is 1136 ml\u2014twice as much. To order an Imperial pint when speaking French in Canada, one must instead order une chopine de bi\u00e8re.\nIn Flanders, the word pintje, meaning 'little pint', refers only to a 250 ml glass of lager. Some West- and East-Flemish dialects use it as a word for beaker. The equivalent word in German, Pintchen, refers to a glass of a third of a litre in Cologne and the Rhineland.\nIn South Australia, ordering \"a pint of beer\" results in 425 ml (15 fl oz) being served. Customers must specifically request \"an Imperial pint of beer\" to get 570 ml (20 fl oz). Australians from other states often contest the size of their beers in Adelaide.\n\n\n== Equivalence ==\nOne US fluid pint of water weighs about a pound (16 ounces), resulting in the popular saying, \"A pint's a pound, the world around.\" However, a US pint of water weighs 1.04375 pounds and the statement does not hold the world around because the imperial (UK) pint, which was also the standard measure in Australia, India, Malaya, New Zealand, South Africa, etc., weighs 1.25 pounds. A different saying for the imperial pint is \"a pint of pure water weighs a pound and a quarter\".\n\n\n== History ==\nThe pint is traditionally one-eighth of a gallon. In the Latin of the apothecaries' system, octavius or octarius (plural octavii or octarii; symbol O) reflected the \"eighth\" concept in its octa- syllable. Because of the variety of definitions of a gallon, there have been equally many versions of the pint.\nAmerica adopted the British wine gallon, defined in 1707 as 231 cubic inches exactly (3 in \u00d7 7 in \u00d7 11 in) as its basic liquid measure, from which the US wet pint is derived; and the British corn gallon (\u200b1\u20448 of a standard \"Winchester\" bushel of corn, or 268.8 cubic inches) as its dry measure, from which the US dry pint is derived.\nIn 1824, the British parliament replaced all the various gallons with a new imperial gallon based on ten pounds of distilled water at 62 \u00b0F (16.667 \u00b0C) (277.42 cubic inches), from which the current UK pint is derived.\nThe various Canadian provinces continued to use the Queen Anne Winchester wine gallon as a basis for their pint until 1873, well after Britain adopted the imperial system in 1824. This made the Canadian pint compatible with the American pint, but after 1824 it was incompatible with the British pint. The traditional French \"pinte\" used in Lower Canada (Quebec) was twice the size of the traditional English \"pint\" used in Upper Canada (Ontario), about 1 litre versus 0.5 litres. After four of the British provinces united in the Canadian Confederation in 1867, Canada legally adopted the British imperial system of measure in 1873, making Canadian liquid units incompatible with American ones from that year forward. In 1873, the French Canadian \"pinte\" was defined as being one imperial quart or two imperial pints, while the imperial pint was legally called a \"chopine\" in French Canada. Canadian imperial units of liquid measure remain incompatible with American traditional units to this day, and although the Canadian pint, quart, and gallon are still legal units of measure in Canada, they are still 20% larger than the American ones.\n\n\n=== Effects of metrication ===\nIn the British and Irish metrication processes, the pint was replaced by metric units as the legally defined primary unit of measure for trading by volume or capacity, except for the sale of draught beer and cider, and milk in returnable containers. The pint can still be used in those countries as a supplementary unit in all circumstances. Local legislation in the UK mandates the use of the pint as a measure for draught beer and cider (in pubs for instance). For milk, if returnable containers are used, the pint can still be the principal unit used, otherwise metric units (usually the non-SI litre) must be used. There is no requirement for the litre quantity to be round numbers: thus the quantity of milk sold in a non-returnable container may be 1 pint, but will have \"568 ml 1 pint\", or just \"568 ml\" on the label. Many recipes published in the UK and Ireland still give ingredient quantities in imperial, where the pint is often used as a unit for larger liquid quantities. The Guild of Food Writers recommends that new recipes be published in metric units.The British Virgin Islands also requires that beer and cider be sold in pints. Also, in Canada, water amounts in air purifiers are advertised in pints as well as BTUs (\"British thermal units\"), see metrication.\nIn Australia and New Zealand, a subtle change was made to 1 pint milk bottles during the conversion from imperial to metric in the 1970s. The height and diameter of the milk bottle remained unchanged, so that existing equipment for handling and storing the bottles was unaffected, but the shape was adjusted to increase the capacity from 568 ml to 600 ml \u2013 a conveniently rounded metric measure. Such milk bottles are no longer officially referred to as pints. However, the \"pint glass\" in pubs in Australia remains closer to the standard imperial pint, at 570 ml. It holds about 500 ml of beer and about 70 ml of froth, except in South Australia, where a pint is served in a 425 ml glass and a 570 ml glass is called an \"imperial pint\". In New Zealand, there is no longer any legal requirement for beer to be served in standard measures: in pubs, the largest size of glass, which is referred to as a pint, varies, but usually contains 425 ml.In Canada, the \"pint of beer\" served in pubs and bars has long been considered a colloquial term for \"a large glass of beer\". Legally speaking, after 1873, it was defined as one British imperial pint of 20 imperial ounces. On the other hand, the United States continued to use a smaller 16 ounce pint, while in French Canada after 1873 a \"pinte de bi\u00e8re\" was defined as a much larger 40 ounce quart of beer, so confusion arose to which was being used. Prior to 1961, bottled beer in Canada was served in two sizes, colloquially known as \"quarts\" and \"pints\". They were 22 and 12 imperial ounces (625 and 341 ml), respectively, which were much smaller than the British units. Some provinces banned the sale of beer in the larger bottle. For example, in Ontario in the 1950s only the smaller size could be sold, but in Quebec both sizes were about equally common. The numerous incompatibilities between traditional Canadian, British, French, and American unit systems was one of the driving forces behind metrication in Canada.\nDraft beer in Canada, when advertised as a \"pint\", is legally required to be 568 ml (20 fluid ounces). With the allowed margin of error of 0.5 fluid ounces, a \"pint\" that is less than 554 ml of beer is an offence, though\u2014to the detriment of consumers\u2014this regulation is often violated and rarely enforced.After metrication in Canada, companies sold milk and other liquids in metric units so conversion issues could no longer arise. Legally speaking, although some British imperial units are still legally usable in Canada, as a result of Canada's colonial history, the \"pint\" served in drinking establishments in Canada should be the larger 20 ounce British imperial pint, rather than the smaller 16 ounce American traditional pint. Under the Canada Weights and Measures Act, if asked for a \"pint of beer\", businesses should serve customers 0.568 litres of beer with an accuracy of 0.5%, and if asked for a \"pinte de bi\u00e8re\" they should serve them 1.136 litres. The Imperial system of measurement is no longer taught in Canadian schools, which leads to confusion when customers ask how big a drinking establishment's pints are. Servers and even managers may not know. To avoid legal issues, many drinking establishments are moving away from using the term \"pint\" and are selling \"glasses\" or \"sleeves\" of beer, neither of which have a legal definition.A 375 ml bottle of liquor in the US and the Canadian maritime provinces is sometimes referred to as a \"pint\" and a 200 ml bottle is called a \"half-pint\", harking back to the days when liquor came in US pints, fifths, quarts, and half-gallons. Liquor in the US has been sold in metric-sized bottles since 1980 although beer is still sold in US traditional units.In France, a standard 250 ml measure of beer is known as un demi (\"a half\"), originally meaning a half pint.\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nEuropean Commission press release (IP/07/1297, 11 September 2007): Pints and miles will not disappear due to European Commission proposal",
        "unit": "pint",
        "url": "https://en.wikipedia.org/wiki/Pint"
    },
    {
        "_id": "Concentration",
        "clean": "Concentration",
        "text": "In chemistry, concentration is the abundance of a constituent divided by the total volume of a mixture. Several types of mathematical description can be distinguished: mass concentration, molar concentration, number concentration, and volume concentration. A concentration can be any kind of chemical mixture, but most frequently solutes and solvents in solutions. The molar (amount) concentration has variants such as normal concentration and osmotic concentration.\n\n\n== Qualitative description ==\n\nOften in informal, non-technical language, concentration is described in a qualitative way, through the use of adjectives such as \"dilute\" for solutions of relatively low concentration and \"concentrated\" for solutions of relatively high concentration. To concentrate a solution, one must add more solute (for example, alcohol), or reduce the amount of solvent (for example, water). By contrast, to dilute a solution, one must add more solvent, or reduce the amount of solute. Unless two substances are fully miscible there exists a concentration at which no further solute will dissolve in a solution. At this point, the solution is said to be saturated. If additional solute is added to a saturated solution, it will not dissolve, except in certain circumstances, when supersaturation may occur. Instead, phase separation will occur, leading to coexisting phases, either completely separated or mixed as a suspension. The point of saturation depends on many variables such as ambient temperature and the precise chemical nature of the solvent and solute.\nConcentrations are often called levels, reflecting the mental schema of levels on the vertical axis of a graph, which can be high or low (for example, \"high serum levels of bilirubin\" are concentrations of bilirubin in the blood serum that are greater than normal).\n\n\n== Quantitative notation ==\nThere are four quantities that describe concentration:\n\n\n=== Mass concentration ===\n\nThe mass concentration \n  \n    \n      \n        \n          \u03c1\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\rho _{i}}\n   is defined as the mass of a constituent \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          \u03c1\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle \\rho _{i}={\\frac {m_{i}}{V}}.}\n  The SI unit is kg/m3 (equal to g/L).\n\n\n=== Molar concentration ===\n\nThe molar concentration \n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle c_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle c_{i}={\\frac {n_{i}}{V}}.}\n  The SI unit is mol/m3. However, more commonly the unit mol/L (= mol/dm3) is used.\n\n\n=== Number concentration ===\n\nThe number concentration \n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle C_{i}}\n   is defined as the number of entities of a constituent \n  \n    \n      \n        \n          N\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle N_{i}}\n   in a mixture divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n        =\n        \n          \n            \n              N\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle C_{i}={\\frac {N_{i}}{V}}.}\n  The SI unit is 1/m3.\n\n\n=== Volume concentration ===\nThe volume concentration \n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\phi _{i}}\n   (not to be confused with volume fraction) is defined as the volume of a constituent \n  \n    \n      \n        \n          V\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle V_{i}}\n   divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n        =\n        \n          \n            \n              V\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle \\phi _{i}={\\frac {V_{i}}{V}}.}\n  Being dimensionless, it is expressed as a number, e.g., 0.18 or 18%; its unit is 1.\n\n\n== Related quantities ==\nSeveral other quantities can be used to describe the composition of a mixture. Note that these should not be called concentrations.\n\n\n=== Normality ===\n\nNormality is defined as the molar concentration \n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle c_{i}}\n   divided by an equivalence factor \n  \n    \n      \n        \n          f\n          \n            \n              e\n              q\n            \n          \n        \n      \n    \n    {\\displaystyle f_{\\mathrm {eq} }}\n  . Since the definition of the equivalence factor depends on context (which reaction is being studied), IUPAC and NIST discourage the use of normality.\n\n\n=== Molality ===\n\n(Not to be confused with Molarity)\nThe molality of a solution \n  \n    \n      \n        \n          b\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle b_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the mass of the solvent \n  \n    \n      \n        \n          m\n          \n            \n              s\n              o\n              l\n              v\n              e\n              n\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {solvent} }}\n   (not the mass of the solution):\n\n  \n    \n      \n        \n          b\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              m\n              \n                \n                  s\n                  o\n                  l\n                  v\n                  e\n                  n\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle b_{i}={\\frac {n_{i}}{m_{\\mathrm {solvent} }}}.}\n  The SI unit for molality is mol/kg.\n\n\n=== Mole fraction ===\n\nThe mole fraction \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the total amount of all constituents in a mixture \n  \n    \n      \n        \n          n\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle n_{\\mathrm {tot} }}\n  :\n\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              n\n              \n                \n                  t\n                  o\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle x_{i}={\\frac {n_{i}}{n_{\\mathrm {tot} }}}.}\n  The SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole fractions.\n\n\n=== Mole ratio ===\n\nThe mole ratio \n  \n    \n      \n        \n          r\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle r_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   divided by the total amount of all other constituents in a mixture:\n\n  \n    \n      \n        \n          r\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              \n                n\n                \n                  \n                    t\n                    o\n                    t\n                  \n                \n              \n              \u2212\n              \n                n\n                \n                  i\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle r_{i}={\\frac {n_{i}}{n_{\\mathrm {tot} }-n_{i}}}.}\n  If \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   is much smaller than \n  \n    \n      \n        \n          n\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle n_{\\mathrm {tot} }}\n  , the mole ratio is almost identical to the mole fraction.\nThe SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole ratios.\n\n\n=== Mass fraction ===\n\nThe mass fraction \n  \n    \n      \n        \n          w\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle w_{i}}\n   is the fraction of one substance with mass \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   to the mass of the total mixture \n  \n    \n      \n        \n          m\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {tot} }}\n  , defined as:\n\n  \n    \n      \n        \n          w\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            \n              m\n              \n                \n                  t\n                  o\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle w_{i}={\\frac {m_{i}}{m_{\\mathrm {tot} }}}.}\n  The SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass fractions.\n\n\n=== Mass ratio ===\n\nThe mass ratio \n  \n    \n      \n        \n          \u03b6\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\zeta _{i}}\n   is defined as the mass of a constituent \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   divided by the total mass of all other constituents in a mixture:\n\n  \n    \n      \n        \n          \u03b6\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            \n              \n                m\n                \n                  \n                    t\n                    o\n                    t\n                  \n                \n              \n              \u2212\n              \n                m\n                \n                  i\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\zeta _{i}={\\frac {m_{i}}{m_{\\mathrm {tot} }-m_{i}}}.}\n  If \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   is much smaller than \n  \n    \n      \n        \n          m\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {tot} }}\n  , the mass ratio is almost identical to the mass fraction.\nThe SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass ratios.\n\n\n== Dependence on volume ==\nConcentration depends on the variation of the volume of the solution with temperature due mainly to thermal expansion.\n\n\n== Table of concentrations and related quantities ==\n\n\n== See also ==\nDilution ratio\nDose concentration\nSerial dilution\nWine/water mixing problem\n\n\n== References ==",
        "unit": "concentration",
        "url": "https://en.wikipedia.org/wiki/Concentration"
    },
    {
        "_id": "Fuel_efficiency",
        "clean": "Fuel efficiency",
        "text": "Fuel efficiency is a form of thermal efficiency, meaning the ratio from effort to result of a process that converts chemical potential energy contained in a carrier (fuel) into kinetic energy or work. Overall fuel efficiency may vary per device, which in turn may vary per application fuel efficiency, especially fossil fuel power plants or industries dealing with combustion, such as ammonia production during the Haber process.\nIn the context of transport, fuel economy is the energy efficiency of a particular vehicle,  given as a ratio of distance traveled per unit of fuel consumed. It is dependent on engine efficiency, transmission design, and tire design. Fuel economy is expressed in miles per gallon (mpg) in the USA and usually also in the UK (imperial gallon); there is sometimes confusion as the imperial gallon is 20% larger than the US gallon so that mpg values are not directly comparable. In countries using the metric system fuel economy is stated as \"fuel consumption\" in liters per 100 kilometers (L/100 km). Litres per mil are used in Norway and Sweden.\nFuel consumption is a more accurate measure of a vehicle\u2019s performance because it is a linear relationship while fuel economy leads to distortions in efficiency improvements.Weight-specific efficiency (efficiency per unit weight) may be stated for freight, and passenger-specific efficiency (vehicle efficiency per passenger).\n\n\n== Vehicle design ==\nFuel efficiency is dependent on many parameters of a vehicle, including its engine parameters, aerodynamic drag, weight, AC usage, fuel and rolling resistance. There have been advances in all areas of vehicle design in recent decades. Fuel efficiency of vehicles can also be improved by careful maintenance and driving habits.Hybrid vehicles use two or more power sources for propulsion. In many designs, a small combustion engine is combined with electric motors.  Kinetic energy which would otherwise be lost to heat during braking is recaptured as electrical power to improve fuel efficiency. Engines automatically shut off when vehicles come to a stop and start again when the accelerator is pressed preventing wasted energy from idling.\n\n\n== Fleet efficiency ==\nFleet efficiency describes the average efficiency of a population of vehicles.  Technological advances in efficiency may be offset by a change in buying habits with a propensity to heavier vehicles, which are less efficient, all else being equal.\n\n\n== Energy efficiency terminology ==\nEnergy efficiency is similar to fuel efficiency but the input is usually in units of energy such as British thermal units (BTU), megajoules (MJ), gigajoules (GJ), kilocalories (kcal), or kilowatt-hours (kW\u00b7h).  The inverse of \"energy efficiency\" is \"energy intensity\", or the amount of input energy required for a unit of output such as MJ/passenger-km (of passenger transport), BTU/ton-mile or kJ/t-km (of freight transport), GJ/t (for production of steel and other materials), BTU/(kW\u00b7h) (for electricity generation), or litres/100 km (of vehicle travel). Litres per 100 km is also a measure of \"energy intensity\" where the input is measured by the amount of fuel and the output is measured by the distance travelled.  For example: Fuel economy in automobiles.\nGiven a heat value of a fuel, it would be trivial to convert from fuel units (such as litres of gasoline) to energy units (such as MJ) and conversely. But there are two problems with comparisons made using energy units:\n\nThere are two different heat values for any hydrogen-containing fuel which can differ by several percent (see below).\nWhen comparing transportation energy costs, it must be remembered that a kilowatt hour of electric energy may require an amount of fuel with heating value of 2 or 3 kilowatt hours to produce it.\n\n\n== Energy content of fuel ==\nThe specific energy content of a fuel is the heat energy obtained when a certain quantity is burned (such as a gallon, litre, kilogram).  It is sometimes called the heat of combustion.  There exists two different values of specific heat energy for the same batch of fuel.  One is the high (or gross) heat of combustion and the other is the low (or net) heat of combustion.  The high value is obtained when, after the combustion, the water in the exhaust is in liquid form.  For the low value, the exhaust has all the water in vapor form (steam).  Since water vapor gives up heat energy when it changes from vapor to liquid, the liquid water value is larger since it includes the latent heat of vaporization of water.  The difference between the high and low values is significant, about 8 or 9%.  This accounts for most of the apparent discrepancy in the heat value of gasoline. In the U.S. (and the table) the high heat values have traditionally been used, but in many other countries, the low heat values are commonly used.\n\nNeither the gross heat of combustion nor the net heat of combustion gives the theoretical amount of mechanical energy (work) that can be obtained from the reaction. (This is given by the change in Gibbs free energy, and is around 45.7 MJ/kg for gasoline.) The actual amount of mechanical work obtained from fuel (the inverse of the specific fuel consumption) depends on the engine. A figure of 17.6 MJ/kg is possible with a gasoline engine, and 19.1 MJ/kg for a diesel engine. See Brake specific fuel consumption for more information.\n\n\n== Fuel efficiency of motor vehicles ==\n\nThe fuel efficiency of motor vehicles can be expressed in more ways:\n\nFuel consumption is the amount of fuel used per unit distance; for example, litres per 100 kilometres (L/100 km). In this case, the lower the value, the more economic a vehicle is (the less fuel it needs to travel a certain distance); this is the measure generally used across Europe (except the UK, Denmark and The Netherlands - see below), New Zealand, Australia and Canada. Also in Uruguay, Paraguay, Guatemala, Colombia, China, and Madagascar., as also in post-Soviet space.\nFuel economy is the distance travelled per unit volume of fuel used; for example, kilometres per litre (km/L) or miles per gallon (MPG), where 1 MPG (imperial) \u2248 0.354006 km/L.  In this case, the higher the value, the more economic a vehicle is (the more distance it can travel with a certain volume of fuel). This measure is popular in the USA and the UK (mpg), but in Europe, India, Japan, South Korea and Latin America the metric unit km/L is used instead.Converting from mpg or to L/100 km (or vice versa) involves the use of the reciprocal function, which is not distributive. Therefore, the average of two fuel economy numbers gives different values if those units are used, because one of the functions is reciprocal, thus not linear. If two people calculate the fuel economy average of two groups of cars with different units, the group with better fuel economy may be one or the other. However, from the point of energy used as a shared method of measure, the result shall be the same in both the cases.\nThe formula for converting to miles per US gallon (exactly 3.785411784 L) from L/100 km is \n  \n    \n      \n        \n          \n            \n              235.215\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {235.215}{x}}}\n  , where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is value of L/100 km. For miles per Imperial gallon (exactly 4.54609 L) the formula is \n  \n    \n      \n        \n          \n            \n              282.481\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {282.481}{x}}}\n  .\nIn parts of Europe, the two standard measuring cycles for \"litre/100 km\" value are \"urban\" traffic with speeds up to 50 km/h from a cold start, and then \"extra urban\" travel at various speeds up to 120 km/h which follows the urban test. A combined figure is also quoted showing the total fuel consumed in divided by the total distance traveled in both tests. A reasonably modern European supermini and many mid-size cars, including station wagons, may manage motorway travel at 5 L/100 km (47 mpg US/56 mpg imp) or 6.5 L/100 km in city traffic (36 mpg US/43 mpg imp), with carbon dioxide emissions of around 140 g/km.\nAn average North American mid-size car travels 21 mpg (US) (11 L/100 km) city, 27 mpg (US) (9 L/100 km) highway; a full-size SUV usually travels 13 mpg (US) (18 L/100 km) city and 16 mpg (US) (15 L/100 km) highway.  Pickup trucks vary considerably; whereas a 4 cylinder-engined light pickup can achieve 28 mpg (8 L/100 km), a V8 full-size pickup with extended cabin only travels 13 mpg (US) (18 L/100 km) city and 15 mpg (US) (15 L/100 km) highway.\nThe average fuel economy is higher in Europe due to the higher cost of fuel. In the UK, a gallon of gas without tax would cost US$1.97, but with taxes cost US$6.06 in 2005. The average cost in the United States was US$2.61. Consumers prefer \"muscle cars\" but choose more fuel efficient ones when gas prices increase.European-built cars are generally more fuel-efficient than US vehicles. While Europe has many higher efficiency diesel cars, European gasoline vehicles are on average also more efficient than gasoline-powered vehicles in the USA. Most European vehicles cited in the CSI study run on diesel engines, which tend to achieve greater fuel efficiency than gas engines. Selling those cars in the United States is difficult because of emission standards, notes Walter McManus, a fuel economy expert at the University of Michigan Transportation Research Institute. \"For the most part, European diesels don\u2019t meet U.S. emission standards\", McManus said in 2007. Another reason why many European models are not marketed in the United States is that labor unions object to having the big 3 import any new foreign built models regardless of fuel economy while laying off workers at home.An example of European cars' capabilities of fuel economy is the microcar Smart Fortwo cdi, which can achieve up to 3.4 l/100 km (69.2 mpg US) using a turbocharged three-cylinder 41 bhp (30 kW) Diesel engine. The Fortwo is produced by Daimler AG and is currently only sold by one company in the United States. Furthermore, the current (and to date already 10-year-old) world record in fuel economy of production cars is held by the Volkswagen Group, with special production models (labeled \"3L\") of the Volkswagen Lupo and the Audi A2, consuming as little as 3 L/100 km (94 mpg\u2011imp; 78 mpg\u2011US).Diesel engines generally achieve greater fuel efficiency than petrol (gasoline) engines. Passenger car diesel engines have energy efficiency of up to 41% but more typically 30%, and petrol engines of up to 37.3%, but more typically 20%. That is one of the reasons why diesels have better fuel efficiency than equivalent petrol cars. A common margin is 25% more miles per gallon for an efficient turbodiesel.\nFor example, the current model Skoda Octavia, using Volkswagen engines, has a combined European fuel efficiency of 41.3 mpg for the 105 bhp (78 kW) petrol engine and 52.3 mpg for the 105 bhp (78 kW) \u2014 and heavier \u2014 diesel engine. The higher compression ratio is helpful in raising the energy efficiency, but diesel fuel also contains approximately 10% more energy per unit volume than gasoline which contributes to the reduced fuel consumption for a given power output.\nIn 2002, the United States had 85,174,776 trucks, and averaged 13.5 miles per US gallon (17.4 L/100 km; 16.2 mpg\u2011imp). Large trucks, over 33,000 pounds (15,000 kg), averaged 5.7 miles per US gallon (41 L/100 km; 6.8 mpg\u2011imp).\nThe average economy of automobiles in the United States in 2002 was 22.0 miles per US gallon (10.7 L/100 km; 26.4 mpg\u2011imp). By 2010 this had increased to 23.0 miles per US gallon (10.2 L/100 km; 27.6 mpg\u2011imp). Average fuel economy in the United States gradually declined until 1973, when it reached a low of 13.4 miles per US gallon (17.6 L/100 km; 16.1 mpg\u2011imp) and gradually has increased since, as a result of higher fuel cost. A study indicates that a 10% increase in gas prices will eventually produce a 2.04% increase in fuel economy. One method by car makers to increase fuel efficiency is lightweighting in which lighter-weight materials are substituted in for improved engine performance and handling.\n\n\n== Fuel efficiency in microgravity ==\nHow fuel combusts affects how much energy is produced. The National Aeronautics and Space Administration (NASA) has investigated fuel consumption in microgravity.\nThe common distribution of a flame under normal gravity conditions depends on convection, because soot tends to rise to the top of a flame, such as in a candle, making the flame yellow. In microgravity or zero gravity, such as an environment in outer space, convection no longer occurs, and the flame becomes spherical, with a tendency to become more blue and more efficient. There are several possible explanations for this difference, of which the most likely one given is the hypothesis that the temperature is evenly distributed enough that soot is not formed and complete combustion occurs., National Aeronautics and Space Administration, April 2005. Experiments by NASA in microgravity reveal that diffusion flames in microgravity allow more soot to be completely oxidised after they are produced than diffusion flames on Earth, because of a series of mechanisms that behaved differently in microgravity when compared to normal gravity conditions.LSP-1 experiment results, National Aeronautics and Space Administration, April 2005. Premixed flames in microgravity burn at a much slower rate and more efficiently than even a candle on Earth, and last much longer.\n\n\n== Transportation ==\n\n\n=== Fuel efficiency in transportation ===\n\n\n=== Vehicle efficiency and transportation pollution ===\n\nFuel efficiency directly affects emissions causing pollution by affecting the amount of fuel used. However, it also depends on the fuel source used to drive the vehicle concerned. Cars for example, can run on a number of fuel types other than gasoline, such as natural gas, LPG or biofuel or electricity which creates various quantities of atmospheric pollution.\nA kilogram of carbon, whether contained in petrol, diesel, kerosene, or any other hydrocarbon fuel in a vehicle, leads to approximately 3.6 kg of CO2 emissions.  Due to the carbon content of gasoline, its combustion emits 2.3 kg/l (19.4 lb/US gal) of CO2; since diesel fuel is more energy dense per unit volume, diesel emits 2.6 kg/l (22.2 lb/US gal).  This figure is only the CO2 emissions of the final fuel product and does not include additional CO2 emissions created during the drilling, pumping, transportation and refining steps required to produce the fuel. Additional measures to reduce overall emission includes improvements to the efficiency of air conditioners, lights and tires.\n\n\n=== Driving technique ===\n\nMany drivers have the potential to improve their fuel efficiency significantly. These five basic fuel-efficient driving techniques can be effective. Simple things such as keeping tires properly inflated, having a vehicle well-maintained and avoiding idling can dramatically improve fuel efficiency.There is a growing community of enthusiasts known as hypermilers who develop and practice driving techniques to increase fuel efficiency and reduce consumption. Hypermilers have broken records of fuel efficiency, for example, achieving 109 miles per gallon in a Prius. In non-hybrid vehicles these techniques are also beneficial, with fuel efficiencies of up to 59 MPG in a Honda Accord or 30 MPG in an Acura MDX.\n\n\n== Advanced technology improvements to improve fuel efficiency ==\nThe most efficient machines for converting energy to rotary motion are electric motors, as used in electric vehicles. However, electricity is not a primary energy source so the efficiency of the electricity production has also to be taken into account. Currently railway trains can be powered using electricity, delivered through an additional running rail, overhead catenary system or by on-board generators used in diesel-electric locomotives as common on the US and UK rail networks. Pollution produced from centralised generation of electricity is emitted at a distant power station, rather than \"on site\". Pollution can be reduced by using more railway electrification and low carbon power for electricity. Some railways, such as the French SNCF and Swiss federal railways derive most, if not 100% of their power, from hydroelectric or nuclear power stations, therefore atmospheric pollution from their rail networks is very low. This was reflected in a study by AEA Technology between a Eurostar train and airline journeys between London and Paris, which showed the trains on average emitting 10 times less CO2, per passenger, than planes, helped in part by French nuclear generation.\n\n\n=== Hydrogen Fuel Cells ===\nIn the future, hydrogen cars may be commercially available. Toyota is test marketing hydrogen fuel cell powered vehicles in southern California where a series of hydrogen fueling stations has been established. Powered either through chemical reactions in a fuel cell that create electricity to drive very efficient electrical motors or by directly burning hydrogen in a combustion engine (near identically to a natural gas vehicle, and similarly compatible with both natural gas and gasoline); these vehicles promise to have near-zero pollution from the tailpipe (exhaust pipe). Potentially the atmospheric pollution could be minimal, provided the hydrogen is made by electrolysis using electricity from non-polluting sources such as solar, wind or hydroelectricity or nuclear. Commercial hydrogen production uses fossil fuels and produces more carbon dioxide than hydrogen.\nBecause there are pollutants involved in the manufacture and destruction of a car and the production, transmission and storage of electricity and hydrogen, the use of the label \"zero pollution\" should be understood as applying only to the car's conversion of stored energy into transportation.\nIn 2004, a consortium of major auto-makers \u2014 BMW, General Motors, Honda, Toyota and Volkswagen/Audi \u2014 came up with \"Top Tier Detergent Gasoline Standard\" to gasoline brands in the US and Canada that meet their minimum standards for detergent content and do not contain metallic additives. Top Tier gasoline contains higher levels of detergent additives in order to prevent the build-up of deposits (typically, on fuel injector and intake valve) known to reduce fuel economy and engine performance.\n\n\n=== Electric Turbo Compounding (ETC) ===\nElectric Turbo Compounding (ETC) is a technology solution to the challenge of improving energy efficiency for the stationary power generation industry.\nFossil fuel based power generation is predicted to continue for decades, especially in developing economies. This is against the global need to reduce carbon emissions, of which, a high percentage is produced by the power sector worldwide.\nETC works by making gas and diesel-powered gensets (Electric Generators) work more effectively and cleaner, by recovering waste energy from the exhaust to improve power density and fuel efficiency.\n\n\n==== Advantages of using ETC ====\nHelps developing economies with unreliable or insufficient power infrastructure. \nGives independent power providers (IPPs), power rental companies and generator OEMs (original equipment manufacturers) a competitive advantage and potential increased market share.\nImproves overall efficiency of the genset, including fuel input costs and helping end-users reduce amount of fuel burned. \nTypically 4-7% less fuel consumption for both diesel and gas gensets. \nFewer carbon emissions.\nIncreased power density. \nCapability to increase power output and capacity, with improved fuel efficiency.\nETC system integration offers a step change in efficiency without increasing service or maintenance requirements.\nThe cost of generating power through waste heat recovery is substantially less than burning more fuel, even with low diesel prices.\n\n\n==== Disadvantages of using ETC ====\nUpfront costs incur an additional expense for businesses.\nThe need to update existing turbomachinery and recertification of the unit adds additional costs and can be time consuming.\nThere will be additional weight to add an ETC to a current unit.\nProcess still uses fossil fuels, thus still has a carbon footprint in a renewable age.\nThey are bespoke to each generator so the design, build and implementation can be a lengthy process.\nThere are challenges with high speed turbo generators such as high stress in the rotors, heat generation of the electrical machine and rotordynamics of the turbo generator system.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\nUS Government website on fuel economy\nUK DfT comparisons on road and rail\nNASA Offers a $1.5 Million Prize for a Fast and Fuel-Efficient Aircraft\nCar Fuel Consumption Official Figures\nSpritmonitor.de \"the most fuel efficient cars\" - Database of thousands of (mostly German) car owners' actual fuel consumption figures (cf. Spritmonitor)\nSearchable fuel economy data from the EPA - United States Environmental Protection Agency\npenghemat bbm - Alat penghemat bbm\nNy Times: A Road Test of Alternative Fuel Visions",
        "unit": "fuel consumption",
        "url": "https://en.wikipedia.org/wiki/Fuel_efficiency"
    },
    {
        "_id": "Minute",
        "clean": "Minute",
        "text": "The minute is a unit of time or angle. As a unit of time, the minute is most of times equal to \u200b1\u204460 (the first sexagesimal fraction) of an hour, or 60 seconds. In the UTC time standard, a minute on rare occasions has 61 seconds, a consequence of leap seconds (there is a provision to insert a negative leap second, which would result in a 59-second minute, but this has never happened in more than 40 years under this system). As a unit of angle, the minute of arc is equal to \u200b1\u204460 of a degree, or 60 seconds (of arc). Although not an SI unit for either time or angle, the minute is accepted for use with SI units for both. The SI symbols for minute or minutes are min for time measurement, and the prime symbol after a number, e.g. 5\u2032, for angle measurement. The prime is also sometimes used informally to denote minutes of time.\n\n\n== History ==\nOne of the earliest known uses of the minute (and the second) is found in John of Sacrobosco's Computus (ca. 1235), where he used them when discussing the length of the tropical year.  No earlier records for the origin of the minute as \u200b1\u204460 of the hour and the second \u200b1\u204460 of the minute have ever been found. Another motivation that has been suggested for the emergence of these fine divisions of time was the construction of \"precision\" timepieces (mechanical and water clocks). \nHistorically, the word \"minute\" comes from the Latin pars minuta prima, meaning \"first small part\".  This division of the hour can be further refined with a \"second small part\" (Latin: pars minuta secunda), and this is where the word \"second\" comes from.  For even further refinement, the term \"third\" (\u200b1\u204460 of a second) remains in some languages, for example Polish (tercja) and Turkish (salise), although most modern usage subdivides seconds by using decimals.  The symbol notation of the prime for minutes and double prime for seconds can be seen as indicating the first and second cut of the hour (similar to how the foot is the first cut of the yard or perhaps chain, with inches as the second cut).  In 1267, the medieval scientist Roger Bacon, writing in Latin, defined the division of time between full moons as a number of hours, minutes, seconds, thirds, and fourths (horae, minuta, secunda, tertia, and quarta) after noon on specified calendar dates.\n\n\n== See also ==\nInternational System of Units\nLatitude and longitude\nOrders of magnitude (time)\n\n\n== Notes and references ==\n\n\n== Bibliography ==\nHenry Campbell Black, Black's Law Dictionary, 6th Edition, entry on Minute. West Publishing Company, St. Paul, Minnesota, 1991.\nEric W. Weisstein. \"Arc Minute.\" From MathWorld\u2014A Wolfram",
        "unit": "minute",
        "url": "https://en.wikipedia.org/wiki/Minute"
    },
    {
        "_id": "Kilobit",
        "clean": "Kilobit",
        "text": "The kilobit is a multiple of the unit bit for digital information or computer storage. The prefix kilo- (symbol k) is defined in the International System of Units (SI) as a multiplier of 103 (1 thousand), and therefore,\n\n1 kilobit = 103bits = 1000 bits.The kilobit has the unit symbol kbit or kb.\nUsing the common byte size of 8 bits, 1 kbit is equal to 125 bytes.\nThe kilobit is commonly used in the expression of data rates of digital communication circuits as kilobits per second (kbit/s or kb/s), or abbreviated as kbps, as in, for example, a 56 kbps PSTN circuit, or a 512 kbit/s broadband Internet connection.\nThe unit symbol kb (lowercase 'b') is typographically similar to the international standard unit symbol for the kilobyte, i.e. kB (upper case 'B'). The International Electrotechnical Commission (IEC) recommends the symbol bit instead of b. The prefix kilo- is often used in fields of computer science and information technology with a meaning of multiplication by 1024 instead of 1000, contrary to international standards, in conjunction with the base unit byte and bit, in which case it is to be written as Ki-, with a capital letter K, e.g., 1 Kibit = 1024 bits. The decimal SI definition, 1 kbit/s = 1000 bit/s, is used uniformly in the context of telecommunication transmission speeds.\nThe kilobit is closely related to the much less used kibibit, a unit multiple derived from the binary prefix kibi- (symbol Ki) of the same order of magnitude, which is equal to 210bits = 1024 bits, or approximately 2% larger than the kilobit. Despite the definitions of these new prefixes, meant for binary-based quantities of storage by international standards organizations, memory semiconductor chips are still marketed using the metric prefix names to designate binary multiples.\n\n\n== See also ==\nData rate units\nOrders of magnitude (data)\nSI prefix\n\n\n== References ==",
        "unit": "kilobit",
        "url": "https://en.wikipedia.org/wiki/Kilobit"
    },
    {
        "_id": "Candela_per_square_metre",
        "clean": "Candela per square metre",
        "text": "The candela per square metre (cd/m2) is the derived SI unit of luminance. The unit is based on the candela, the SI unit of luminous intensity, and the square metre, the SI unit of area. \nNit (nt) is a non-SI name also used for this unit (1 nt = 1 cd/m2).  The term nit is believed to come from the Latin word nitere, to shine.As a measure of light emitted per unit area, this unit is frequently used to specify the brightness of a display device.  The sRGB spec for monitors targets 80 cd/m2. Typically, calibrated monitors should have a brightness of 120 cd/m2. Most consumer desktop liquid crystal displays have luminances of 200 to 300 cd/m2.  High-definition televisions range from 450 to about 1500 cd/m2. \n\n\n== Comparison to other units of luminance ==\nOne candela per square metre is equal to:\n\n10\u22124 stilbs (the CGS unit of luminance)\n\u03c0\u00d710\u22124 lamberts\n\u03c0 apostilbs\n0.292 foot-lamberts\n\u03c0\u00d7103 skots\n\u03c0\u00d7107 brils\n1 nit\n\n\n== See also ==\nOrders of magnitude (luminance)\nPhotometry (optics)\n\n\n== References ==\n\n\n== External links ==\nIEC 61966-2-1:1999 Multimedia systems and equipment - Colour measurement and management - Part 2-1: Colour management - Default RGB colour space - sRGB\nIEC International System of Units zone",
        "unit": "candela per square metre",
        "url": "https://en.wikipedia.org/wiki/Candela_per_square_metre"
    },
    {
        "_id": "Celsius",
        "clean": "Celsius",
        "text": "The Celsius scale, previously known as the centigrade scale, is a temperature scale used by the International System of Units (SI). As an SI derived unit, it is used by all countries except the United States, the Bahamas, Belize, the Cayman Islands and Liberia. It is named after the Swedish astronomer Anders Celsius (1701\u20131744), who developed a similar temperature scale. The degree Celsius (\u00b0C) can refer to a specific temperature on the Celsius scale or a unit to indicate a difference between two temperatures or an uncertainty. Before being renamed to honor Anders Celsius in 1948, the unit was called centigrade, from the Latin centum, which means 100, and gradus, which means steps.\nBefore 1954, the Celsius scale was based on 0 \u00b0C for the freezing point of water and 100 \u00b0C for the boiling point of water at 1 atm pressure following a change introduced in 1743 by Jean-Pierre Christin to reverse the Celsius thermometer scale (from water boiling at 0 degrees and ice melting at 100 degrees). \nBy international agreement, since 1954 the unit degree Celsius and the Celsius scale are defined by absolute zero and the triple point of Vienna Standard Mean Ocean Water (VSMOW), a specially purified water. This definition also precisely relates the Celsius scale to the Kelvin scale, which defines the SI base unit of thermodynamic temperature with symbol K. Absolute zero, the lowest temperature possible, is defined as being exactly 0 K and \u2212273.15 \u00b0C. The temperature of the triple point of water is defined as exactly 273.16 K (0.01 \u00b0C). This means that a temperature difference of one degree Celsius and that of one kelvin are exactly the same.\n\n\n== History ==\n\nIn 1742, Swedish astronomer Anders Celsius (1701\u20131744) created a temperature scale that was the reverse of the scale now known as \"Celsius\": 0 represented the boiling point of water, while 100 represented the freezing point of water. In his paper Observations of two persistent degrees on a thermometer, he recounted his experiments showing that the melting point of ice is essentially unaffected by pressure. He also determined with remarkable precision how the boiling point of water varied as a function of atmospheric pressure. He proposed that the zero point of his temperature scale, being the boiling point, would be calibrated at the mean barometric pressure at mean sea level. This pressure is known as one standard atmosphere. The BIPM's 10th General Conference on Weights and Measures (CGPM) later defined one standard atmosphere to equal precisely 1,013,250 dynes per square centimetre (101.325 kPa).In 1743, the Lyonnais physicist Jean-Pierre Christin, permanent secretary of the Acad\u00e9mie des sciences, belles-lettres et arts de LyonFR, working independently of Celsius, developed a scale where zero represented the freezing point of water and 100 represented the boiling point of water. On 19 May 1743 he published the design of a mercury thermometer, the \"Thermometer of Lyon\" built by the craftsman Pierre Casati that used this scale.In 1744, coincident with the death of Anders Celsius, the Swedish botanist Carl Linnaeus (1707\u20131778) reversed Celsius's scale. His custom-made \"linnaeus-thermometer\", for use in his greenhouses, was made by Daniel Ekstr\u00f6m, Sweden's leading maker of scientific instruments at the time, whose workshop was located in the basement of the Stockholm observatory. As often happened in this age before modern communications, numerous physicists, scientists, and instrument makers are credited with having independently developed this same scale; among them were Pehr Elvius, the secretary of the Royal Swedish Academy of Sciences (which had an instrument workshop) and with whom Linnaeus had been corresponding; Daniel Ekstr\u00f6m[SV], the instrument maker; and M\u00e5rten Str\u00f6mer (1707\u20131770) who had studied astronomy under Anders Celsius.\nThe first known Swedish document reporting temperatures in this modern \"forward\" Celsius scale is the paper Hortus Upsaliensis dated 16 December 1745 that Linnaeus wrote to a student of his, Samuel Naucl\u00e9r. In it, Linnaeus recounted the temperatures inside the orangery at the University of Uppsala Botanical Garden:\n\n...since the caldarium (the hot part of the greenhouse) by the angle of the windows, merely from the rays of the sun, obtains such heat that the thermometer often reaches 30 degrees, although the keen gardener usually takes care not to let it rise to more than 20 to 25 degrees, and in winter not under 15 degrees...\n\n\n=== Centigrade, hectograde and Celsius ===\nSince the 19th century, the scientific and thermometry communities worldwide have used the phrase \"centigrade scale\". Temperatures on the centigrade scale were often reported simply as degrees or, when greater specificity was desired, as degrees centigrade (symbol: \u00b0C). Because the term centigrade was also the Spanish and French language name for a unit of angular measurement (1/10000 of a right angle) and had a similar connotation in other languages, the term centesimal degree (known as the gradian, \"grad\" or \"gon\": 1\u1d4d = 0.9\u00b0, 100\u1d4d = 90\u00b0) was used when very precise, unambiguous language was required by international standards bodies such as the BIPM. More properly, what was defined as \"centigrade\" then would now be \"hectograde\".\nTo eliminate any confusion, the 9th CGPM and the CIPM (Comit\u00e9 international des poids et mesures) formally adopted \"degree Celsius\" in 1948, formally keeping the recognized degree symbol, rather than adopting the gradian/centesimal degree symbol.\nFor scientific use, \"Celsius\" is the term usually used, with \"centigrade\" remaining in common but decreasing use, especially in informal contexts in English-speaking countries. It was not until February 1985 that the forecasts issued by the BBC switched from \"centigrade\" to \"Celsius\".\n\n\n=== Common temperatures ===\nSome key temperatures relating the Celsius scale to other temperature scales are shown in the table below.\n\n\n== Name and symbol typesetting ==\nThe \"degree Celsius\" has been the only SI unit whose full unit name contains an uppercase letter since the SI base unit for temperature, the kelvin, became the proper name in 1967 replacing the term degrees Kelvin. The plural form is degrees Celsius.The general rule of the International Bureau of Weights and Measures (BIPM) is that the numerical value always precedes the unit, and a space is always used to separate the unit from the number, e.g. \"30.2 \u00b0C\" (not \"30.2\u00b0C\" or \"30.2\u00b0 C\"). The only exceptions to this rule are for the unit symbols for degree, minute, and second for plane angle (\u00b0, \u2032, and \u2033, respectively), for which no space is left between the numerical value and the unit symbol. Other languages, and various publishing houses, may follow different typographical rules.\n\n\n=== Unicode character ===\nUnicode provides the Celsius symbol at code point U+2103 \u2103 degree celsius. However, this is a compatibility character provided for roundtrip compatibility with legacy encodings. It easily allows correct rendering for vertically written East Asian scripts, such as Chinese. The Unicode standard explicitly discourages the use of this character: \"In normal use, it is better to represent degrees Celsius \"\u00b0C\" with a sequence of U+00B0 \u00b0 degree sign + U+0043 C latin capital letter c, rather than U+2103 \u2103 degree celsius. For searching, treat these two sequences as identical.\"Shown below is the degree Celsius character followed immediately by the two-component version:\n\n\u2103 \u00b0CWhen viewed on computers that properly support Unicode, the above line may be similar to the image in the line below (enlarged for clarity):\n\nThe canonical decomposition is simply an ordinary degree sign and \"C\", so some browsers may simply display \"\u00b0C\" in its place due to Unicode normalization.\n\n\n== Temperatures and intervals ==\nThe degree Celsius is subject to the same rules as the kelvin with regard to the use of its unit name and symbol. Thus, besides expressing specific temperatures along its scale (e.g. \"Gallium melts at 29.7646 \u00b0C\" and \"The temperature outside is 23 degrees Celsius\"), the degree Celsius is also suitable for expressing temperature intervals: differences between temperatures or their uncertainties (e.g. \"The output of the heat exchanger is hotter by 40 degrees Celsius\", and \"Our standard uncertainty is \u00b13 \u00b0C\"). Because of this dual usage, one must not rely upon the unit name or its symbol to denote that a quantity is a temperature interval; it must be unambiguous through context or explicit statement that the quantity is an interval. This is sometimes solved by using the symbol \u00b0C (pronounced \"degrees Celsius\") for a temperature, and C\u00b0 (pronounced \"Celsius degrees\") for a temperature interval, although this usage is non-standard.Celsius measurement follows an interval system but not a ratio system; and it follows a relative scale not an absolute scale. For example, 20 \u00b0C is not twice the heat energy of 10 \u00b0C; and 0 \u00b0C is not the lowest Celsius value. Thus, degrees Celsius is a useful interval measurement but does not possess the characteristics of ratio measures like weight or distance.\n\n\n== Coexistence of Kelvin and Celsius scales ==\nIn science and in engineering, the Celsius scale and the Kelvin scale are often used in combination in close contexts, e.g. \"a measured value was 0.01023 \u00b0C with an uncertainty of 70 \u00b5K\". This practice is permissible because the magnitude of the degree Celsius is equal to that of the kelvin. Notwithstanding the official endorsement provided by decision #3 of Resolution 3 of the 13th CGPM, which stated \"a temperature interval may also be expressed in degrees Celsius\", the practice of simultaneously using both \u00b0C and K remains widespread throughout the scientific world as the use of SI-prefixed forms of the degree Celsius (such as \"\u00b5\u00b0C\" or \"microdegrees Celsius\") to express a temperature interval has not been well-adopted.\n\n\n== Melting and boiling points of water ==\nOne effect of defining the Celsius scale at the triple point of Vienna Standard Mean Ocean Water (VSMOW, 273.16 K and 0.01 \u00b0C), and at absolute zero (0 K and \u2212273.15 \u00b0C), is that neither the melting nor boiling point of water under one standard atmosphere (101.325 kPa) remains a defining point for the Celsius scale. In 1948 when the 9th General Conference on Weights and Measures (CGPM) in Resolution 3 first considered using the triple point of water as a defining point, the triple point was so close to being 0.01 \u00b0C greater than water's known melting point, it was simply defined as precisely 0.01 \u00b0C. However, current measurements show that the difference between the triple and melting points of VSMOW is actually very slightly (<0.001 \u00b0C) greater than 0.01 \u00b0C. Thus, the actual melting point of ice is very slightly (less than a thousandth of a degree) below 0 \u00b0C. Also, defining water's triple point at 273.16 K precisely defined the magnitude of each 1 \u00b0C increment in terms of the absolute thermodynamic temperature scale (referencing absolute zero). Now decoupled from the actual boiling point of water, the value \"100 \u00b0C\" is hotter than 0 \u00b0C \u2013 in absolute terms \u2013 by a factor of precisely 373.15/273.15 (approximately 36.61% thermodynamically hotter). When adhering strictly to the two-point definition for calibration, the boiling point of VSMOW under one standard atmosphere of pressure is actually 373.1339 K (99.9839 \u00b0C). When calibrated to ITS-90 (a calibration standard comprising many definition points and commonly used for high-precision instrumentation), the boiling point of VSMOW is slightly less, about 99.974 \u00b0C.This boiling-point difference of 16.1 millikelvin between the Celsius scale's original definition and the current one (based on absolute zero and the triple point) has little practical meaning in common daily applications because water's boiling point is very sensitive to variations in barometric pressure. For example, an altitude change of only 28 cm (11 in) causes the boiling point to change by one millikelvin.\n\n\n== See also ==\nComparison of temperature scales\nDegrees of frost\nITS-90\nR\u00e9aumur scale\nThermodynamic temperature\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n The dictionary definition of Celsius at Wiktionary\n\nNIST, Basic unit definitions: Kelvin\nThe Uppsala Astronomical Observatory, History of the Celsius temperature scale\nLondon South Bank University, Water, scientific data\nBIPM, SI brochure, section 2.1.1.5, Unit of thermodynamic temperature\nTAMPILE, Comparison of temperature scales\nC to F converter, Celsius to Fahrenheit Converter",
        "unit": "degree Celsius",
        "url": "https://en.wikipedia.org/wiki/Celsius"
    },
    {
        "_id": "Area",
        "clean": "Area",
        "text": "Area is the quantity that expresses the extent of a two-dimensional figure or shape, or planar lamina, in the plane. Surface area is its analog on the two-dimensional surface of a  three-dimensional object. Area can be understood as the amount of material with a given thickness that would be necessary to fashion a model of the shape, or the amount of paint necessary to cover the surface with a single coat. It is the two-dimensional analog of the length of a curve (a one-dimensional concept) or the volume of a solid (a three-dimensional concept).\nThe area of a shape can be measured by comparing the shape to squares of a fixed size. In the International System of Units (SI), the standard unit of area is the square metre (written as m2), which is the area of a square whose sides are one metre long.  A shape with an area of three square metres would have the same area as three such squares.  In mathematics, the unit square is defined to have area one, and the area of any other shape or surface is a dimensionless real number.\nThere are several well-known formulas for the areas of simple shapes such as triangles, rectangles, and circles.  Using these formulas, the area of any polygon can be found by dividing the polygon into triangles.  For shapes with curved boundary, calculus is usually required to compute the area.  Indeed, the problem of determining the area of plane figures was a major motivation for the historical development of calculus.For a solid shape such as a sphere, cone, or cylinder, the area of its boundary surface is called the surface area. Formulas for the surface areas of simple shapes were computed by the ancient Greeks, but computing the surface area of a more complicated shape usually requires multivariable calculus.\nArea plays an important role in modern mathematics.  In addition to its obvious importance in geometry and calculus, area is related to the definition of determinants in linear algebra, and is a basic property of surfaces in differential geometry. In analysis, the area of a subset of the plane is defined using Lebesgue measure, though not every subset is measurable.  In general, area in higher mathematics is seen as a special case of volume for two-dimensional regions.Area can be defined through the use of axioms, defining it as a function of a collection of certain plane figures to the set of real numbers. It can be proved that such a function exists.\n\n\n== Formal definition ==\n\nAn approach to defining what is meant by \"area\" is through axioms. \"Area\" can be defined as a function from a collection M of special kind of plane figures (termed measurable sets) to the set of real numbers which satisfies the following properties:\n\nFor all S in M, a(S) \u2265 0.\nIf S and T are in M then so are S \u222a T and S \u2229 T, and also a(S\u222aT) = a(S) + a(T) \u2212 a(S\u2229T).\nIf S and T are in M with S \u2286 T then T \u2212 S is in M and a(T\u2212S) = a(T) \u2212 a(S).\nIf a set S is in M and S is congruent to T then T is also in M and a(S) = a(T).\nEvery rectangle R is in M. If the rectangle has length h and breadth k then a(R) = hk.\nLet Q be a set enclosed between two step regions S and T. A step region is formed from a finite union of adjacent rectangles resting on a common base, i.e. S \u2286 Q \u2286 T. If there is a unique number c such that a(S) \u2264 c \u2264 a(T) for all such step regions S and T, then a(Q) = c.It can be proved that such an area function actually exists.\n\n\n== Units ==\n\nEvery unit of length has a corresponding unit of area, namely the area of a square with the given side length.  Thus areas can be measured in square metres (m2), square centimetres (cm2), square millimetres (mm2), square kilometres (km2), square feet (ft2), square yards (yd2), square miles (mi2), and so forth.  Algebraically, these units can be thought of as the squares of the corresponding length units.\nThe SI unit of area is the square metre, which is considered an SI derived unit.\n\n\n=== Conversions ===\n\nCalculation of the area of a square whose length and width are 1 metre would be:\n1 metre x 1 metre = 1 m2and so, a rectangle with different sides (say length of 3 metres and width of 2 metres) would have an area in square units that can be calculated as:\n3 metres x 2 metres = 6 m2. This is equivalent to 6 million square millimetres. Other useful conversions are:\n\n1 square kilometre = 1,000,000 square metres\n1 square metre = 10,000 square centimetres = 1,000,000 square millimetres\n1 square centimetre = 100 square millimetres.\n\n\n==== Non-metric units ====\nIn non-metric units, the conversion between two square units is the square of the conversion between the corresponding length units.\n\n1 foot = 12 inches,the relationship between square feet and square inches is\n\n1 square foot = 144 square inches,where 144 = 122 = 12 \u00d7 12.  Similarly:\n\n1 square yard = 9 square feet\n1 square mile = 3,097,600 square yards = 27,878,400 square feetIn addition, conversion factors include:\n\n1 square inch = 6.4516 square centimetres\n1 square foot = 0.09290304 square metres\n1 square yard = 0.83612736 square metres\n1 square mile = 2.589988110336 square kilometres\n\n\n=== Other units including historical ===\n\nThere are several other common units for area.  The are was the original unit of area in the metric system, with:\n\n1 are = 100 square metresThough the are has fallen out of use, the hectare is still commonly used to measure land:\n1 hectare = 100 ares = 10,000 square metres = 0.01 square kilometresOther uncommon metric units of area include the tetrad, the hectad, and the myriad.\nThe acre is also commonly used to measure land areas, where\n\n1 acre = 4,840 square yards = 43,560 square feet.An acre is approximately 40% of a hectare.\nOn the atomic scale, area is measured in units of barns, such that:\n1 barn = 10\u221228 square meters.The barn is commonly used in describing the cross-sectional area of interaction in nuclear physics.In India,\n\n20 dhurki = 1 dhur\n20 dhur = 1 khatha\n20 khata = 1 bigha\n32 khata = 1 acre\n\n\n== History ==\n\n\n=== Circle area ===\nIn the 5th century BCE, Hippocrates of Chios was the first to show that the area of a disk (the region enclosed by a circle) is proportional to the square of its diameter, as part of his quadrature of the lune of Hippocrates, but did not identify the constant of proportionality. Eudoxus of Cnidus, also in the 5th century BCE, also found that the area of a disk is proportional to its radius squared.Subsequently, Book I of Euclid's Elements dealt with equality of areas between two-dimensional figures. The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book Measurement of a Circle. (The circumference is 2\u03c0r, and the area of a triangle is half the base times the height, yielding the area \u03c0r2 for the disk.) Archimedes approximated the value of \u03c0 (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).\nSwiss scientist Johann Heinrich Lambert in 1761 proved that \u03c0, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers. In 1794 French mathematician Adrien-Marie Legendre proved that \u03c02 is irrational; this also proves that \u03c0 is irrational. In 1882, German mathematician Ferdinand von Lindemann proved that \u03c0 is transcendental (not the solution of any polynomial equation with rational coefficients), confirming a conjecture made by both Legendre and Euler.\n\n\n=== Triangle area ===\nHeron (or Hero) of Alexandria found what is known as Heron's formula for the area of a triangle in terms of its sides, and a proof can be found in his book, Metrica, written around 60 CE. It has been suggested that Archimedes knew the formula over two centuries earlier, and since Metrica is a collection of the mathematical knowledge available in the ancient world, it is possible that the formula predates the reference given in that work.In 499 Aryabhata, a great mathematician-astronomer from the classical age of Indian mathematics and Indian astronomy, expressed the area of a triangle as one-half the base times the height in the Aryabhatiya (section 2.6).\nA formula equivalent to Heron's was discovered by the Chinese independently of the Greeks. It was published in 1247 in Shushu Jiuzhang (\"Mathematical Treatise in Nine Sections\"), written by Qin Jiushao.\n\n\n=== Quadrilateral area ===\nIn the 7th century CE, Brahmagupta developed a formula, now known as Brahmagupta's formula, for the area of a cyclic quadrilateral (a quadrilateral inscribed in a circle) in terms of its sides. In 1842 the German mathematicians Carl Anton Bretschneider and Karl Georg Christian von Staudt independently found a formula, known as Bretschneider's formula, for the area of any quadrilateral.\n\n\n=== General polygon area ===\nThe development of Cartesian coordinates by Ren\u00e9 Descartes in the 17th century allowed the development of the surveyor's formula for the area of any polygon with known vertex locations by Gauss in the 19th century.\n\n\n=== Areas determined using calculus ===\nThe development of integral calculus in the late 17th century provided tools that could subsequently be used for computing more complicated areas, such as the area of an ellipse and the surface areas of various curved three-dimensional objects.\n\n\n== Area formulas ==\n\n\n=== Polygon formulas ===\n\nFor a non-self-intersecting (simple) polygon, the Cartesian coordinates \n  \n    \n      \n        (\n        \n          x\n          \n            i\n          \n        \n        ,\n        \n          y\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{i},y_{i})}\n   (i=0, 1, ..., n-1) of whose n vertices are known, the area is given by the surveyor's formula:\n\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          |\n        \n        \n          \u2211\n          \n            i\n            =\n            0\n          \n          \n            n\n            \u2212\n            1\n          \n        \n        (\n        \n          x\n          \n            i\n          \n        \n        \n          y\n          \n            i\n            +\n            1\n          \n        \n        \u2212\n        \n          x\n          \n            i\n            +\n            1\n          \n        \n        \n          y\n          \n            i\n          \n        \n        )\n        \n          |\n        \n      \n    \n    {\\displaystyle A={\\frac {1}{2}}|\\sum _{i=0}^{n-1}(x_{i}y_{i+1}-x_{i+1}y_{i})|}\n  where when i=n-1, then i+1 is expressed as modulus n and so refers to 0.\n\n\n==== Rectangles ====\n\nThe most basic area formula is the formula for the area of a rectangle.  Given a rectangle with length l and width w, the formula for the area is:\nA = lw (rectangle).That is, the area of the rectangle is the length multiplied by the width.  As a special case, as l = w in the case of a square, the area of a square with side length s is given by the formula:\nA = s2 (square).The formula for the area of a rectangle follows directly from the basic properties of area, and is sometimes taken as a definition or axiom.  On the other hand, if geometry is developed before arithmetic, this formula can be used to define multiplication of real numbers.\n\n\n==== Dissection, parallelograms, and triangles ====\n\nMost other simple formulas for area follow from the method of dissection.\nThis involves cutting a shape into pieces, whose areas must sum to the area of the original shape.\nFor an example, any parallelogram can be subdivided into a trapezoid and a right triangle, as shown in figure to the left.  If the triangle is moved to the other side of the trapezoid, then the resulting figure is a rectangle.  It follows that the area of the parallelogram is the same as the area of the rectangle:\nA = bh  (parallelogram).However, the same parallelogram can also be cut along a diagonal into two congruent triangles, as shown in the figure to the right.  It follows that the area of each triangle is half the area of the parallelogram:\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        b\n        h\n      \n    \n    {\\displaystyle A={\\frac {1}{2}}bh}\n    (triangle).Similar arguments can be used to find area formulas for the trapezoid as well as more complicated polygons.\n\n\n=== Area of curved shapes ===\n\n\n==== Circles ====\n\nThe formula for the area of a circle (more properly called the area enclosed by a circle or the area of a disk) is based on a similar method.  Given a circle of radius r, it is possible to partition the circle into sectors, as shown in the figure to the right.  Each sector is approximately triangular in shape, and the sectors can be rearranged to form an approximate parallelogram.  The height of this parallelogram is r, and the width is half the circumference of the circle, or \u03c0r.  Thus, the total area of the circle is \u03c0r2:\nA = \u03c0r2  (circle).Though the dissection used in this formula is only approximate, the error becomes smaller and smaller as the circle is partitioned into more and more sectors.  The limit of the areas of the approximate parallelograms is exactly \u03c0r2, which is the area of the circle.This argument is actually a simple application of the ideas of calculus.  In ancient times, the method of exhaustion was used in a similar way to find the area of the circle, and this method is now recognized as a precursor to integral calculus.  Using modern methods, the area of a circle can be computed using a definite integral:\n\n  \n    \n      \n        A\n        \n        =\n        \n        2\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n        \n        d\n        x\n        \n        =\n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle A\\;=\\;2\\int _{-r}^{r}{\\sqrt {r^{2}-x^{2}}}\\,dx\\;=\\;\\pi r^{2}.}\n  \n\n\n==== Ellipses ====\n\nThe formula for the area enclosed by an ellipse is related to the formula of a circle; for an ellipse with semi-major and semi-minor axes x and y the formula is:\n\n  \n    \n      \n        A\n        =\n        \u03c0\n        x\n        y\n        .\n      \n    \n    {\\displaystyle A=\\pi xy.}\n  \n\n\n==== Surface area ====\n\nMost basic formulas for surface area can be obtained by cutting surfaces and flattening them out.  For example, if the side surface of a cylinder (or any prism) is cut lengthwise, the surface can be flattened out into a rectangle.  Similarly, if a cut is made along the side of a cone, the side surface can be flattened out into a sector of a circle, and the resulting area computed.\nThe formula for the surface area of a sphere is more difficult to derive: because a sphere has nonzero Gaussian curvature, it cannot be flattened out.  The formula for the surface area of a sphere was first obtained by Archimedes in his work On the Sphere and Cylinder.  The formula is:\nA = 4\u03c0r2  (sphere),where r is the radius of the sphere.  As with the formula for the area of a circle, any derivation of this formula inherently uses methods similar to calculus.\n\n\n=== General formulas ===\n\n\n==== Areas of 2-dimensional figures ====\nA triangle: \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        B\n        h\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}Bh}\n   (where B is any side, and h is the distance from the line on which B lies to the other vertex of the triangle). This formula can be used if the height h is known. If the lengths of the three sides are known then Heron's formula can be used: \n  \n    \n      \n        \n          \n            s\n            (\n            s\n            \u2212\n            a\n            )\n            (\n            s\n            \u2212\n            b\n            )\n            (\n            s\n            \u2212\n            c\n            )\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {s(s-a)(s-b)(s-c)}}}\n   where a, b, c are the sides of the triangle, and \n  \n    \n      \n        s\n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        (\n        a\n        +\n        b\n        +\n        c\n        )\n      \n    \n    {\\displaystyle s={\\tfrac {1}{2}}(a+b+c)}\n   is half of its perimeter. If an angle and its two included sides are given, the area is \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        a\n        b\n        sin\n        \u2061\n        (\n        C\n        )\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}ab\\sin(C)}\n   where C is the given angle and a and b are its included sides. If the triangle is graphed on a coordinate plane, a matrix can be used and is simplified to the absolute value of \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        (\n        \n          x\n          \n            1\n          \n        \n        \n          y\n          \n            2\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            3\n          \n        \n        +\n        \n          x\n          \n            3\n          \n        \n        \n          y\n          \n            1\n          \n        \n        \u2212\n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            1\n          \n        \n        \u2212\n        \n          x\n          \n            3\n          \n        \n        \n          y\n          \n            2\n          \n        \n        \u2212\n        \n          x\n          \n            1\n          \n        \n        \n          y\n          \n            3\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}(x_{1}y_{2}+x_{2}y_{3}+x_{3}y_{1}-x_{2}y_{1}-x_{3}y_{2}-x_{1}y_{3})}\n  . This formula is also known as the shoelace formula and is an easy way to solve for the area of a coordinate triangle by substituting the 3 points (x1,y1), (x2,y2), and (x3,y3). The shoelace formula can also be used to find the areas of other polygons when their vertices are known. Another approach for a coordinate triangle is to use calculus to find the area.\nA simple polygon constructed on a grid of equal-distanced points (i.e., points with integer coordinates) such that all the polygon's vertices are grid points: \n  \n    \n      \n        i\n        +\n        \n          \n            b\n            2\n          \n        \n        \u2212\n        1\n      \n    \n    {\\displaystyle i+{\\frac {b}{2}}-1}\n  , where i is the number of grid points inside the polygon and b is the number of boundary points. This result is known as Pick's theorem.\n\n\n==== Area in calculus ====\n\nThe area between a positive-valued curve and the horizontal axis, measured between two values a and b (b is defined as the larger of the two values) on the horizontal axis, is given by the integral from a to b of the function that represents the curve:\n  \n    \n      \n        A\n        =\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        f\n        (\n        x\n        )\n        \n        d\n        x\n        .\n      \n    \n    {\\displaystyle A=\\int _{a}^{b}f(x)\\,dx.}\n  The area between the graphs of two functions is equal to the integral of one function, f(x), minus the integral of the other function, g(x):\n  \n    \n      \n        A\n        =\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        (\n        f\n        (\n        x\n        )\n        \u2212\n        g\n        (\n        x\n        )\n        )\n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle A=\\int _{a}^{b}(f(x)-g(x))\\,dx,}\n   where \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n   is the curve with the greater y-value.An area bounded by a function r = r(\u03b8) expressed in polar coordinates is:\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        \u222b\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        \u03b8\n        .\n      \n    \n    {\\displaystyle A={1 \\over 2}\\int r^{2}\\,d\\theta .}\n  The area enclosed by a parametric curve \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        t\n        )\n        =\n        (\n        x\n        (\n        t\n        )\n        ,\n        y\n        (\n        t\n        )\n        )\n      \n    \n    {\\displaystyle {\\vec {u}}(t)=(x(t),y(t))}\n   with endpoints \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        \n          t\n          \n            0\n          \n        \n        )\n        =\n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        \n          t\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\vec {u}}(t_{0})={\\vec {u}}(t_{1})}\n   is given by the line integrals:\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        x\n        \n          \n            \n              y\n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        =\n        \u2212\n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        y\n        \n          \n            \n              x\n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        (\n        x\n        \n          \n            \n              y\n              \u02d9\n            \n          \n        \n        \u2212\n        y\n        \n          \n            \n              x\n              \u02d9\n            \n          \n        \n        )\n        \n        d\n        t\n      \n    \n    {\\displaystyle \\oint _{t_{0}}^{t_{1}}x{\\dot {y}}\\,dt=-\\oint _{t_{0}}^{t_{1}}y{\\dot {x}}\\,dt={1 \\over 2}\\oint _{t_{0}}^{t_{1}}(x{\\dot {y}}-y{\\dot {x}})\\,dt}\n  (see Green's theorem) or the z-component of\n\n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              \n                \n                  u\n                  \u2192\n                \n              \n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        .\n      \n    \n    {\\displaystyle {1 \\over 2}\\oint _{t_{0}}^{t_{1}}{\\vec {u}}\\times {\\dot {\\vec {u}}}\\,dt.}\n  \n\n\n==== Bounded area between two quadratic functions ====\nTo find the bounded area between two quadratic functions, we subtract one from the other to write the difference as\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        \u2212\n        g\n        (\n        x\n        )\n        =\n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        a\n        (\n        x\n        \u2212\n        \u03b1\n        )\n        (\n        x\n        \u2212\n        \u03b2\n        )\n      \n    \n    {\\displaystyle f(x)-g(x)=ax^{2}+bx+c=a(x-\\alpha )(x-\\beta )}\n  where f(x) is the quadratic upper bound and g(x) is the quadratic lower bound. Define the discriminant of f(x)-g(x) as\n\n  \n    \n      \n        \u0394\n        =\n        \n          b\n          \n            2\n          \n        \n        \u2212\n        4\n        a\n        c\n        .\n      \n    \n    {\\displaystyle \\Delta =b^{2}-4ac.}\n  By simplifying the integral formula between the graphs of two functions (as given in the section above) and using Vieta's formula, we can obtain\n\n  \n    \n      \n        A\n        =\n        \n          \n            \n              \u0394\n              \n                \n                  \u0394\n                \n              \n            \n            \n              6\n              \n                a\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            a\n            6\n          \n        \n        (\n        \u03b2\n        \u2212\n        \u03b1\n        \n          )\n          \n            3\n          \n        \n        ,\n        \n        a\n        \u2260\n        0.\n      \n    \n    {\\displaystyle A={\\frac {\\Delta {\\sqrt {\\Delta }}}{6a^{2}}}={\\frac {a}{6}}(\\beta -\\alpha )^{3},\\qquad a\\neq 0.}\n  The above remains valid if one of the bounding functions is linear instead of quadratic.\n\n\n==== Surface area of 3-dimensional figures ====\nCone: \n  \n    \n      \n        \u03c0\n        r\n        \n          (\n          \n            r\n            +\n            \n              \n                \n                  r\n                  \n                    2\n                  \n                \n                +\n                \n                  h\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\pi r\\left(r+{\\sqrt {r^{2}+h^{2}}}\\right)}\n  , where r is the radius of the circular base, and h is the height. That can also be rewritten as \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        +\n        \u03c0\n        r\n        l\n      \n    \n    {\\displaystyle \\pi r^{2}+\\pi rl}\n   or \n  \n    \n      \n        \u03c0\n        r\n        (\n        r\n        +\n        l\n        )\n        \n        \n      \n    \n    {\\displaystyle \\pi r(r+l)\\,\\!}\n   where r is the radius and l is the slant height of the cone. \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\pi r^{2}}\n   is the base area while \n  \n    \n      \n        \u03c0\n        r\n        l\n      \n    \n    {\\displaystyle \\pi rl}\n   is the lateral surface area of the cone.\ncube: \n  \n    \n      \n        6\n        \n          s\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 6s^{2}}\n  , where s is the length of an edge.\ncylinder: \n  \n    \n      \n        2\n        \u03c0\n        r\n        (\n        r\n        +\n        h\n        )\n      \n    \n    {\\displaystyle 2\\pi r(r+h)}\n  , where r is the radius of a base and h is the height. The 2\n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  r can also be rewritten as \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   d, where d is the diameter.\nprism: 2B + Ph, where B is the area of a base, P is the perimeter of a base, and h is the height of the prism.\npyramid: \n  \n    \n      \n        B\n        +\n        \n          \n            \n              P\n              L\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle B+{\\frac {PL}{2}}}\n  , where B is the area of the base, P is the perimeter of the base, and L is the length of the slant.\nrectangular prism: \n  \n    \n      \n        2\n        (\n        \u2113\n        w\n        +\n        \u2113\n        h\n        +\n        w\n        h\n        )\n      \n    \n    {\\displaystyle 2(\\ell w+\\ell h+wh)}\n  , where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length, w is the width, and h is the height.\n\n\n==== General formula for surface area ====\nThe general formula for the surface area of the graph of a continuously differentiable function \n  \n    \n      \n        z\n        =\n        f\n        (\n        x\n        ,\n        y\n        )\n        ,\n      \n    \n    {\\displaystyle z=f(x,y),}\n   where \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        \u2208\n        D\n        \u2282\n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (x,y)\\in D\\subset \\mathbb {R} ^{2}}\n   and \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   is a region in the xy-plane with the smooth boundary:\n\n  \n    \n      \n        A\n        =\n        \n          \u222c\n          \n            D\n          \n        \n        \n          \n            \n              \n                (\n                \n                  \n                    \n                      \u2202\n                      f\n                    \n                    \n                      \u2202\n                      x\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            +\n            \n              \n                (\n                \n                  \n                    \n                      \u2202\n                      f\n                    \n                    \n                      \u2202\n                      y\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            +\n            1\n          \n        \n        \n        d\n        x\n        \n        d\n        y\n        .\n      \n    \n    {\\displaystyle A=\\iint _{D}{\\sqrt {\\left({\\frac {\\partial f}{\\partial x}}\\right)^{2}+\\left({\\frac {\\partial f}{\\partial y}}\\right)^{2}+1}}\\,dx\\,dy.}\n  An even more general formula for the area of the graph of a parametric surface in the vector form \n  \n    \n      \n        \n          r\n        \n        =\n        \n          r\n        \n        (\n        u\n        ,\n        v\n        )\n        ,\n      \n    \n    {\\displaystyle \\mathbf {r} =\\mathbf {r} (u,v),}\n   where \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is a continuously differentiable vector function of \n  \n    \n      \n        (\n        u\n        ,\n        v\n        )\n        \u2208\n        D\n        \u2282\n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (u,v)\\in D\\subset \\mathbb {R} ^{2}}\n   is:\n\n  \n    \n      \n        A\n        =\n        \n          \u222c\n          \n            D\n          \n        \n        \n          |\n          \n            \n              \n                \n                  \u2202\n                  \n                    r\n                  \n                \n                \n                  \u2202\n                  u\n                \n              \n            \n            \u00d7\n            \n              \n                \n                  \u2202\n                  \n                    r\n                  \n                \n                \n                  \u2202\n                  v\n                \n              \n            \n          \n          |\n        \n        \n        d\n        u\n        \n        d\n        v\n        .\n      \n    \n    {\\displaystyle A=\\iint _{D}\\left|{\\frac {\\partial \\mathbf {r} }{\\partial u}}\\times {\\frac {\\partial \\mathbf {r} }{\\partial v}}\\right|\\,du\\,dv.}\n  \n\n\n=== List of formulas ===\nThe above calculations show how to find the areas of many common shapes.\nThe areas of irregular polygons can be calculated using the \"Surveyor's formula\".\n\n\n=== Relation of area to perimeter ===\nThe isoperimetric inequality states that, for a closed curve of length L (so the region it encloses has perimeter L) and for area A of the region that it encloses,\n\n  \n    \n      \n        4\n        \u03c0\n        A\n        \u2264\n        \n          L\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle 4\\pi A\\leq L^{2},}\n  and  equality holds if and only if the curve is a circle. Thus a circle has the largest area of any closed figure with a given perimeter.\nAt the other extreme, a figure with given perimeter L could have an arbitrarily small area, as illustrated by a rhombus that is \"tipped over\" arbitrarily far so that two of its angles are arbitrarily close to 0\u00b0 and the other two are arbitrarily close to 180\u00b0.\nFor a circle, the ratio of the area to the circumference (the term for the perimeter of a circle) equals half the radius r. This can be seen from the area formula \u03c0r2 and the circumference formula 2\u03c0r.\nThe area of a regular polygon is half its perimeter times the apothem (where the apothem is the distance from the center to the nearest point on any side).\n\n\n=== Fractals ===\nDoubling the edge lengths of a polygon multiplies its area by four, which is two (the ratio of the new to the old side length) raised to the power of two (the dimension of the space the polygon resides in). But if the one-dimensional lengths of a  fractal drawn in two dimensions are all doubled, the spatial content of the fractal scales by a power of two that is not necessarily an integer. This power is called the fractal dimension of the fractal.\n\n\n== Area bisectors ==\n\nThere are an infinitude of lines that bisect the area of a triangle. Three of them are the medians of the triangle (which connect the sides' midpoints with the opposite vertices), and these are concurrent at the triangle's centroid; indeed, they are the only area bisectors that go through the centroid. Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's incenter (the center of its incircle). There are either one, two, or three of these for any given triangle.\nAny line through the midpoint of a parallelogram bisects the area.\nAll area bisectors of a circle or other ellipse go through the center, and any chords through the center bisect the area. In the case of a circle they are the diameters of the circle.\n\n\n== Optimization ==\nGiven a wire contour, the surface of least area spanning (\"filling\") it is a minimal surface.  Familiar examples include soap bubbles.\nThe question of the filling area of the Riemannian circle remains open.The circle has the largest area of any two-dimensional object having the same perimeter.\nA cyclic polygon (one inscribed in a circle) has the largest area of any polygon with a given number of sides of the same lengths.\nA version of the isoperimetric inequality for triangles states that the triangle of greatest area among all those with a given perimeter is equilateral.The triangle of largest area of all those inscribed in a given circle is equilateral; and the triangle of smallest area of all those circumscribed around a given circle is equilateral.The ratio of the area of the incircle to the area of an equilateral triangle, \n  \n    \n      \n        \n          \n            \u03c0\n            \n              3\n              \n                \n                  3\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\pi }{3{\\sqrt {3}}}}}\n  , is larger than that of any non-equilateral triangle.The ratio of the area to the square of the perimeter of an equilateral triangle, \n  \n    \n      \n        \n          \n            1\n            \n              12\n              \n                \n                  3\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{12{\\sqrt {3}}}},}\n   is larger than that for any other triangle.\n\n\n== See also ==\nBrahmagupta quadrilateral, a cyclic quadrilateral with integer sides, integer diagonals, and integer area.\nEqui-areal mapping\nHeronian triangle, a triangle with integer sides and integer area.\nList of triangle inequalities#Area\nOne-seventh area triangle, an inner triangle with one-seventh the area of the reference triangle.Routh's theorem, a generalization of the one-seventh area triangle.Orders of magnitude (area)\u2014A list of areas by size.\nPentagon#Derivation of the area formula\nPlanimeter, an instrument for measuring small areas, e.g. on maps.\nQuadrilateral#Area of a convex quadrilateral\nRobbins pentagon, a cyclic pentagon whose side lengths and area are all rational numbers.\n\n\n== References ==\n\n\n== External links ==",
        "unit": "area",
        "url": "https://en.wikipedia.org/wiki/Area"
    },
    {
        "_id": "Minute_and_second_of_arc",
        "clean": "Minute and second of arc",
        "text": "A minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to 1/60 of one degree. Since one degree is 1/360 of a turn (or complete rotation), one minute of arc is 1/21600 of a turn. A minute of arc is \u03c0/10800 of a radian. A second of arc, arcsecond (arcsec), or arc second is 1/60 of an arcminute, 1/3600 of a degree, 1/1296000 of a turn, and \u03c0/648000 (about 1/206265) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying, and marksmanship.\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (\u03bcas), for instance, are commonly used in astronomy.\nThe number of square arcminutes in a complete sphere is \n  \n    \n      \n        4\n        \u03c0\n        \n          \n            (\n            \n              \n                \n                  10\n                  \n                  800\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \n              466\n              \n              560\n              \n              000\n            \n            \u03c0\n          \n        \n        \u2248\n      \n    \n    {\\displaystyle 4\\pi \\left({\\frac {10\\,800}{\\pi }}\\right)^{2}={\\frac {466\\,560\\,000}{\\pi }}\\approx }\n   148510660 square arcminutes (the surface area of a unit sphere in square units divided by the solid angle area subtended by a square arcminute, also in square units - so that the final result is a dimensionless number).\n\n\n== Symbols and abbreviations ==\nThe standard symbol for marking the arcminute is the prime (\u2032) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1\u2032. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (\n  \n    \n      \n        \n          \n            \n              \n                \n                \u2032\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {'}}}\n  ).\nThe standard symbol for the arcsecond is the double prime (\u2033) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1\u2033. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42\u00b0 25.32\u2032 or 42\u00b0 25.322\u2032. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\n\n== Common examples ==\nThe full moon's average apparent size is about 31 arcminutes (or 0.52\u00b0).\nAn arcminute is approximately the resolution of the human eye.\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of 4 kilometres (about 2.5 mi). An arcsecond is also the angle subtended by\n\nan object of diameter 725.27 km at a distance of one astronomical unit,\nan object of diameter 45866916 km at one light-year,\nan object of diameter one astronomical unit (149597871 km) at a distance of one parsec.A milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\nA nanoarcsecond is about the size of a penny on Neptune's moon Triton as observed from Earth.\nAlso notable examples of size in arcseconds are:\n\nHubble Space Telescope has calculational resolution of 0.05 arcseconds and actual resolution of almost 0.1 arcseconds, which is close to the diffraction limit.\ncrescent Venus measures between 60.2 and 66 seconds of arc.\n\n\n== Uses ==\n\n\n=== Astronomy ===\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (\u03b2) and longitude (\u03bb); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (\u03b4), are all measured in degrees, arcminutes and arcseconds. The principal exception is right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\u2033 and 60\u2033), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arc second, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\nThe ESA astrometric space probe Gaia, launched in 2013, can approximate star positions to 7 microarcseconds (\u00b5as).Apart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.Space telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble Space Telescope can reach an angular size of stars down to about 0.1\u2033. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\n\n=== Cartography ===\nMinutes (\u2032) and seconds (\u2033) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or \u22481.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use  base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places (1/1000 of a degree) have about 1/4 the precision of degrees-minutes-seconds (1/3600 of a degree) and specify locations within about 120 meters or 400 feet.\n\n\n=== Property cadastral surveying ===\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, North 65\u00b0 39\u2032 18\u2033 West 85.69 feet would describe a line running from the starting point 85.69 feet in a direction 65\u00b0 39\u2032 18\u2033 (or 65.655\u00b0) away from north toward the west.\n\n\n=== Firearms ===\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA is subtended by a sphere with a diameter of 1.047 inches at 100 yards (2.908 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, at 500 yards, 1 MOA is subtended by a sphere with a diameter of 5.235 inches, and at 1000 yards 1 MOA is subtended by a sphere with a diameter of 10.47 inches. \nSince many modern telescopic sights are adjustable in half (1/2), quarter (1/4), or eighth (1/8) MOA increments, also known as clicks, zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that click in fractions of MOA. This makes zeroing and adjustments much easier:\n\nTo adjust a \u200b1\u20442 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 \u00d7 2 = 6 clicks down and 1.5 x 2 = 3 clicks right\nTo adjust a \u200b1\u20444 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 4 = 12 clicks down and 1.5 \u00d7 4 = 6 clicks right\nTo adjust a \u200b1\u20448 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 8 = 24 clicks down and 1.5 \u00d7 8 = 12 clicks rightAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is 1/10 mil (which approximates \u200b1\u20443 MOA).\n\nTo adjust a 1/10 mil scope 0.9 mil down and 0.4 mil right, the scope needs to be adjusted 9 clicks down and 4 clicks right (which equals approximately 3 and 1.5 MOA respectively).One thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\nThe physical group size equivalent to m minutes of arc can be calculated as follows: group size = tan(m/60) \u00d7 distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan(1/60) \u2248 1.047 inches. In metric units 1 MOA at 100 meters \u2248 2.908 centimeters.\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a 1 MOA rifle should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\nRifle manufacturers and gun magazines often refer to this capability as sub-MOA, meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.The Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 \u00d7 \u03c0 \u00d7 1000, regardless the target range. Therefore, 1 MOA \u2248 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 mrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system.  A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\nIn the table below conversions from mil to metric values are exact (e.g. 0.1 mil equals exactly 1 cm at 100 meters), while conversions of minutes of arc to both metric and imperial values are approximate.\n\n(Values in bold face are exact. All mil fractions are given in tenths, which is more convenient for practical use.)\n\n1\u2032 at 100 yards equals 22619/ 21600 = 1.04717593 in \u2248 1.047 inches\n1\u2032 \u2248 0.291 mil (or 2.91 cm at 100 m, approximately  3 cm at 100 m)\n1 mil \u2248 3.44\u2032, so 1/10 mil \u2248 1/3\u2032\n0.1 mil equals exactly 1 cm at 100 m, or approximately 0.36 inches at 100 yards\n\n\n=== Human vision ===\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\n\n=== Materials ===\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (\u03c9-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n=== Manufacturing ===\nSome measurement devices make use of arcminutes and arcseconds to measure angles when the object being measured is too small for direct visual inspection. For instance, a toolmaker's optical comparator will often include an option to measure in \"minutes and seconds\".\n\n\n== See also ==\nDegree (angle) \u00a7 Subdivisions\nSexagesimal \u00a7 Modern usage\nSquare minute\nSquare second\nMilliradian\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nMOA / mils By Robert Simeone",
        "unit": "minute of arc",
        "url": "https://en.wikipedia.org/wiki/Minute_and_second_of_arc"
    },
    {
        "_id": "Knot_(unit)",
        "clean": "Knot (unit)",
        "text": "The knot () is a unit of speed equal to one nautical mile per hour, exactly 1.852 km/h (approximately 1.15078 mph). The ISO standard symbol for the knot is kn. The same symbol is preferred by the Institute of Electrical and Electronics Engineers (IEEE); kt is also common. The knot is a non-SI unit. Worldwide, the knot is used in meteorology, and in maritime and air navigation\u2014for example, a vessel travelling at 1 knot along a meridian travels approximately one minute of geographic latitude in one hour.\nEtymologically, the term derives from counting the number of knots in the line that unspooled from the reel of a chip log in a specific time.\n\n\n== Definitions ==\n1 international knot =\n1 nautical mile per hour (by definition),\n1.852 kilometres per hour (exactly),\n0.51444 metres per second (approximately),\n1.15078 miles per hour (approximately),\n20.25372 inches per second (approximately)\n1.68781 feet per second (approximately).1852 m is the length of the internationally agreed nautical mile. The US adopted the international definition in 1954, having previously used the US nautical mile (1853.248 m). The UK adopted the international nautical mile definition in 1970, having previously used the UK Admiralty nautical mile (6080 ft or 1853.184 m).\n\n (Values in bold face are exact.)\n\n\n== Usage ==\nThe speeds of vessels relative to the fluids in which they travel (boat speeds and air speeds) are measured in knots. For consistency, the speeds of navigational fluids (tidal streams, river currents and wind speeds) are also measured in knots. Thus, speed over the ground (SOG) (ground speed (GS) in aircraft) and rate of progress towards a distant point (\"velocity made good\", VMG) are also given in knots.\n\n\n== Origin ==\nUntil the mid-19th century, vessel speed at sea was measured using a chip log. This consisted of a wooden panel, attached by line to a reel, and weighted on one edge to float perpendicularly to the water surface and thus present substantial resistance to the water moving around it. The chip log was cast over the stern of the moving vessel and the line allowed to pay out. Knots placed at a distance of 47 feet 3 inches (14.4018 m) from each other, passed through a sailor's fingers, while another sailor used a 30-second sand-glass (28-second sand-glass is the currently accepted timing) to time the operation. The knot count would be reported and used in the sailing master's dead reckoning and navigation. This method gives a value for the knot of 20.25 in/s, or 1.85166 km/h. The difference from the modern definition is less than 0.02%.\nDerivation of knots spacing:\n\n  \n    \n      \n        1\n        \n          \n            kn\n          \n        \n        =\n        1852\n        \n          \n            m/h\n          \n        \n        =\n        0.5144\n        \n          \n            m/s\n          \n        \n      \n    \n    {\\displaystyle 1{\\textrm {kn}}=1852{\\textrm {m/h}}=0.5144{\\textrm {m/s}}}\n  , so in \n  \n    \n      \n        28\n      \n    \n    {\\displaystyle 28}\n   seconds that is \n  \n    \n      \n        14.40\n      \n    \n    {\\displaystyle 14.40}\n   meters per knot.\n\n\n== Modern use ==\n\nAlthough the unit knot does not fit within the SI system, its retention for nautical and aviation use is important because the length of a nautical mile, upon which the knot is based, is closely related to the size of the Earth. As a result, nautical miles and knots are convenient units to use when navigating an aircraft or ship.\nStandard nautical charts are on the Mercator projection and the horizontal (East-West) scale varies with latitude. On a chart of the North Atlantic, the scale varies by a factor of two from Florida to Greenland. A single graphic scale, of the sort on many maps, would therefore be useless on such a chart. Since the length of a nautical mile, for practical purposes, is equivalent to about a minute of latitude, a distance in nautical miles on a chart can easily be measured by using dividers and the latitude scales on the sides of the chart. Recent British Admiralty charts have a latitude scale down the middle to make this even easier.Speed is sometimes incorrectly expressed as \"knots per hour\", which is in fact a measure of acceleration.\n\n\n=== Aeronautical terms ===\nPrior to 1969, airworthiness standards for civil aircraft in the United States Federal Aviation Regulations specified that distances were to be in statute miles, and speeds in miles per hour. In 1969, these standards were progressively amended to specify that distances were to be in nautical miles, and speeds in knots.The following abbreviations are used to distinguish between various measurements of airspeed:\nKTAS is \"knots true airspeed\", the airspeed of an aircraft relative to undisturbed air\nKIAS is \"knots indicated airspeed\", the speed shown on an aircraft's pitot-static airspeed indicator\nKCAS is \"knots calibrated airspeed\", the indicated airspeed corrected for position error and instrument error\nKEAS is \"knots equivalent airspeed\", the calibrated airspeed corrected for adiabatic compressible flow for the particular altitudeThe indicated airspeed is close to the true airspeed only at sea level in standard conditions and at low speeds. At 11000 m (36000 ft), an indicated airspeed of 300 kn may correspond to a true airspeed of 500 kn in standard conditions.\n\n\n== See also ==\n\nBeaufort scale\nHull speed, which deals with theoretical estimates of practical maximum speed of displacement hulls\nKnot count\nKnotted cord\nMetre per second\nOrders of magnitude (speed)\nRope (unit)\n\n\n== References ==",
        "unit": "knot",
        "url": "https://en.wikipedia.org/wiki/Knot_(unit)"
    },
    {
        "_id": "Barn_(unit)",
        "clean": "Barn (unit)",
        "text": "A barn (symbol: b) is a unit of area equal to 10\u221228 m2 (100 fm2). Originally used in nuclear physics for expressing the cross sectional area of nuclei and nuclear reactions, today it is also used in all fields of high-energy physics to express the cross sections of any scattering process, and is best understood as a measure of the probability of interaction between small particles. A barn is  approximately the cross-sectional area of a uranium nucleus. The barn is also the unit of area used in nuclear quadrupole resonance and nuclear magnetic resonance to quantify the interaction of a nucleus with an electric field gradient. While the barn is not an SI unit, the SI standards body acknowledges its existence due to its continued use in particle physics.\n\n\n== Etymology ==\nThe etymology of the unit barn is whimsical: during Manhattan Project research on the atomic bomb during World War II, American physicists at Purdue University needed a secretive unit to describe the approximate cross sectional area presented by the typical nucleus (10\u221228 m2) and decided on \"barn\". This was particularly applicable because they considered this a large target for particle accelerators that needed to have direct strikes on nuclei and the American idiom \"couldn't hit the broad side of a barn\" refers to someone whose aim is terrible. Initially they hoped the name would obscure any reference to the study of nuclear structure; eventually, the word became a standard unit in nuclear and particle physics.\n\n\n== Commonly used prefixed versions ==\nOther related units are the outhouse (1 \u03bcb, or 10\u221234 m2) and the shed (10\u221224 b (1 yb), or 10\u221252 m2), although these are rarely used in practice.\n\n\n== Conversions ==\nCalculated cross sections are often given in terms of gigaelectronvolts (GeV), via the conversion \u01272c2/GeV2 = 0.3894 mb = 38 940 am2.\nIn natural units (where \u0127 = c = 1), this simplifies to GeV\u22122 = 0.3894 mb = 38 940 am2.\n\n\n=== SI units with prefix ===\nIn SI, one can use units such as square femtometers (fm2).\n\n\n== Inverse femtobarn ==\nThe inverse femtobarn (fb\u22121) is the unit typically used to measure the number of particle collision events per femtobarn of target cross-section, and is the conventional unit for time-integrated luminosity. Thus if a detector has accumulated 100 fb\u22121 of integrated luminosity, one expects to find 100 events per femtobarn of cross-section within these data.\nConsider a particle accelerator where two streams of particles, with cross-sectional areas measured in femtobarns, are directed to collide over a period of time. The total number of collisions will be directly proportional to the luminosity of the collisions measured over this time. Therefore, the collision count can be calculated by multiplying the integrated luminosity by the sum of the cross-section for those collision processes. This count is then expressed as inverse femtobarns for the time period (e.g., 100 fb\u22121 in nine months). Inverse femtobarns are often quoted as an indication of particle collider productivity.Fermilab produced 10 fb\u22121 in the first decade of the 21st century.  Fermilab's Tevatron took about 4 years to reach 1 fb\u22121 in 2005, while two of CERN's LHC experiments, ATLAS and CMS, reached over 5 fb\u22121 of proton-proton data in 2011 alone. In April 2012 the LHC achieved the collision energy of 8 TeV with a luminosity peak of 6760 inverse microbarns per second; by May 2012 the LHC delivered 1 inverse femtobarn of data per week to each detector collaboration. A record of over 23 fb\u22121 was achieved during 2012. As of November 2016, the LHC had achieved 40  fb\u22121 over that year, significantly exceeding the stated goal of 25  fb\u22121.\n\n\n=== Usage example ===\nAs a simplified example, if a beamline runs for 8 hours (28 800 seconds) at an instantaneous luminosity of 300 \u00d7 1030 cm\u22122s\u22121 = 300 \u03bcb\u22121s\u22121, then it will gather data totaling an integrated luminosity of 8 640 000 \u03bcb\u22121 = 8.64 pb\u22121 = 0.008 64 fb\u22121 during this period. If this is multiplied by the cross-section, then a dimensionless number is obtained which would be simply the number of expected scattering events.\n\n\n== See also ==\nOrders of magnitude (area)\nList of unusual units of measurement\n\n\n== References ==\n\n\n== External links ==\nIUPAC citation for this usage of \"barn\"",
        "unit": "kilobarn",
        "url": "https://en.wikipedia.org/wiki/Barn_(unit)"
    },
    {
        "_id": "Bit",
        "clean": "Bit",
        "text": "The bit (a portmanteau of binary digit) is a basic unit of information used in computing and digital communications.  A binary digit can have only one of two values, and may be physically represented with a two-state device. These state values are most commonly represented as either a 0or1.\nThe two values of a binary digit can also be interpreted as logical values (true/false, yes/no), algebraic signs (+/\u2212), activation states (on/off), or any other two-valued attribute. The correspondence between these values and the physical states of the underlying storage or device is a matter of convention, and different assignments may be used even within the same device or program. The length of a binary number may be referred to as its bit-length.\nIn information theory, one bit is typically defined as the information entropy of a binary random variable that is 0 or 1 with equal probability, or the information that is gained when the value of such a variable becomes known.Confusion often arises because the words bit and binary digit are used interchangeably. But, within Shannon's information theory, a bit and a binary digit are fundamentally different types of entities. A binary digit is a number that can adopt one of two possible values (0 or 1), whereas a bit is the maximum amount of information that can be conveyed by a binary digit (when averaged over both of its states). By analogy, just as a pint-sized bottle can contain between zero and one pint, so a binary digit can convey between zero and one bit of information. A less confusing terminology is to refer to bits as shannons (see below).\nIn quantum computing, a quantum bit or qubit is a quantum system that can exist in superposition of two classical (i.e., non-quantum) bit values; see also two-state quantum system.\nThe symbol for binary digit is either simply bit (recommended by the IEC 80000-13:2008 standard) or lowercase b (recommended by the IEEE 1541-2002 and IEEE Std 260.1-2004 standards). A group of eight binary digits is commonly called one byte, but historically the size of the byte is not strictly defined.\nAs a unit of information in information theory, the bit has alternatively been called a shannon, named after Claude Shannon, the founder of field of information theory. This usage distinguishes the quantity of information from the form of the state variables used to represent it. When the logical values are not equally probable or when a signal is not conveyed perfectly through a communication system, a binary digit in the representation of the information will convey less than one bit of information. However, the shannon unit terminology is uncommon in practice.\n\n\n== History ==\nThe encoding of data by discrete bits was used in the punched cards invented by Basile Bouchon and Jean-Baptiste Falcon (1732), developed by Joseph Marie Jacquard (1804), and later adopted by Semen Korsakov, Charles Babbage, Hermann Hollerith, and early computer manufacturers like IBM. Another variant of that idea was the perforated paper tape. In all those systems, the medium (card or tape) conceptually carried an array of hole positions; each position could be either punched through or not, thus carrying one bit of information. The encoding of text by bits was also used in Morse code (1844) and early digital communications machines such as teletypes and stock ticker machines (1870).\nRalph Hartley suggested the use of a logarithmic measure of information in 1928. Claude E. Shannon first used the word bit in his seminal 1948 paper A Mathematical Theory of Communication.\nHe attributed its origin to John W. Tukey, who had written a Bell Labs memo on 9 January 1947 in which he contracted \"binary information digit\" to simply \"bit\". Vannevar Bush had written in 1936 of \"bits of information\" that could be stored on the punched cards used in the mechanical computers of that time. The first programmable computer, built by Konrad Zuse, used binary notation for numbers.\n\n\n== Physical representation ==\nA bit can be stored by a digital device or other physical system that exists in either of two possible distinct states. These may be the two stable states of a flip-flop, two positions of an electrical switch, two distinct voltage or current levels allowed by a circuit, two distinct levels of light intensity, two directions of magnetization or polarization, the orientation of reversible double stranded DNA, etc.\nBits can be implemented in several forms. In most modern computing devices, a bit is usually represented by an electrical voltage or current pulse, or by the electrical state of a flip-flop circuit.\nFor devices using positive logic, a digit value of 1 (or a logical value of true) is represented by a more positive voltage relative to the representation of 0. The specific voltages are different for different logic families and variations are permitted to allow for component aging and noise immunity. For example, in transistor\u2013transistor logic (TTL) and compatible circuits, digit values 0 and 1 at the output of a device are represented by no higher than 0.4 volts and no lower than 2.6 volts, respectively; while TTL inputs are specified to recognize 0.8 volts or below as 0 and 2.2 volts or above as 1.\n\n\n=== Transmission and processing ===\nBits are transmitted one at a time in serial transmission, and by a multiple number of bits in parallel transmission. A bitwise operation optionally processes bits one at a time. Data transfer rates are usually measured in decimal SI multiples of the unit bit per second (bit/s), such as kbit/s.\n\n\n=== Storage ===\nIn the earliest non-electronic information processing devices, such as Jacquard's loom or Babbage's Analytical Engine, a bit was often stored as the position of a mechanical lever or gear, or the presence or absence of a hole at a specific point of a paper card or tape. The first electrical devices for discrete logic (such as elevator and traffic light control circuits, telephone switches, and Konrad Zuse's computer) represented bits as the states of electrical relays which could be either \"open\" or \"closed\". When relays were replaced by vacuum tubes, starting in the 1940s, computer builders experimented with a variety of storage methods, such as pressure pulses traveling down a mercury delay line, charges stored on the inside surface of a cathode-ray tube, or opaque spots printed on glass discs by photolithographic techniques.\nIn the 1950s and 1960s, these methods were largely supplanted by magnetic storage devices such as magnetic core memory, magnetic tapes, drums, and disks, where a bit was represented by the polarity of magnetization of a certain area of a ferromagnetic film, or by a change in polarity from one direction to the other. The same principle was later used in the magnetic bubble memory developed in the 1980s, and is still found in various magnetic strip items such as metro tickets and some credit cards.\nIn modern semiconductor memory, such as dynamic random-access memory, the two values of a bit may be represented by two levels of electric charge stored in a capacitor. In certain types of programmable logic arrays and read-only memory, a bit may be represented by the presence or absence of a conducting path at a certain point of a circuit. In optical discs, a bit is encoded as the presence or absence of a microscopic pit on a reflective surface. In one-dimensional bar codes, bits are encoded as the thickness of alternating black and white lines.\n\n\n== Unit and symbol ==\nThe bit is not defined in the International System of Units (SI). However, the International Electrotechnical Commission issued standard IEC 60027, which specifies that the symbol for binary digit should be bit, and this should be used in all multiples, such as kbit, for kilobit. However, the lower-case letter b is widely used as well and was recommended by the IEEE 1541 Standard (2002). In contrast, the upper case letter B is the standard and customary symbol for byte.\n\n\n=== Multiple bits ===\nMultiple bits may be expressed and represented in several ways. For convenience of representing commonly reoccurring groups of bits in information technology, several units of information have traditionally been used. The most common is the unit byte, coined by Werner Buchholz in June 1956, which historically was used to represent the group of bits used to encode a single character of text (until UTF-8 multibyte encoding took over) in a computer and for this reason it was used as the basic addressable element in many computer architectures. The trend in hardware design converged on the most common implementation of using eight bits per byte, as it is widely used today. However, because of the ambiguity of relying on the underlying hardware design, the unit octet was defined to explicitly denote a sequence of eight bits.\nComputers usually manipulate bits in groups of a fixed size, conventionally named \"words\". Like the byte, the number of bits in a word also varies with the hardware design, and is typically between 8 and 80 bits, or even more in some specialized computers. In the 21st century, retail personal or server computers have a word size of 32 or 64 bits.\nThe International System of Units defines a series of decimal prefixes for multiples of standardized units which are commonly also used with the bit and the byte. The prefixes kilo (103) through yotta (1024) increment by multiples of 1000, and the corresponding units are the kilobit (kbit) through the yottabit (Ybit).\n\n\n== Information capacity and information compression ==\nWhen the information capacity of a storage system or a communication channel is presented in bits or bits per second, this often refers to binary digits, which is a computer hardware capacity to store binary data (0 or 1, up or down, current or not, etc.). Information capacity of a storage system is only an upper bound to the quantity of information stored therein. If the two possible values of one bit of storage are not equally likely, that bit of storage contains less than one bit of information. Indeed, if the value is completely predictable, then the reading of that value provides no information at all (zero entropic bits, because no resolution of uncertainty occurs and therefore no information is available). If a computer file that uses n bits of storage contains only m < n bits of information, then that information can in principle be encoded in about m bits, at least on the average. This principle is the basis of data compression technology. Using an analogy, the hardware binary digits refer to the amount of storage space available (like the number of buckets available to store things), and the information content the filling, which comes in different levels of granularity (fine or coarse, that is, compressed or uncompressed information). When the granularity is finer\u2014when information is more compressed\u2014the same bucket can hold more.\nFor example, it is estimated that the combined technological capacity of the world to store information provides 1,300 exabytes of hardware digits in 2007. However, when this storage space is filled and the corresponding content is optimally compressed, this only represents 295 exabytes of information. When optimally compressed, the resulting carrying capacity approaches Shannon information or information entropy.\n\n\n== Bit-based computing ==\nCertain bitwise computer processor instructions (such as bit set) operate at the level of manipulating bits rather than manipulating data interpreted as an aggregate of bits.\nIn the 1980s, when bitmapped computer displays became popular, some computers provided specialized bit block transfer (\"bitblt\" or \"blit\") instructions to set or copy the bits that corresponded to a given rectangular area on the screen.\nIn most computers and programming languages, when a bit within a group of bits, such as a byte or word, is referred to, it is usually specified by a number from 0 upwards corresponding to its position within the byte or word. However, 0 can refer to either the most or least significant bit depending on the context.\n\n\n== Other information units ==\n\nSimilar to angular momentum and energy in physics; information-theoretic information and data storage size have the same dimensionality of units of measurement, but there is in general no meaning to adding, subtracting or otherwise combining the units mathematically.\nOther units of information, sometimes used in information theory, include the natural digit also called a nat or nit and defined as log2 e (\u2248 1.443) bits, where e is the base of the natural logarithms; and the dit, ban, or hartley, defined as log2 10 (\u2248 3.322) bits. This value, slightly less than 10/3, may be understood because 103 = 1000 \u2248 1024 = 210: three decimal digits are slightly less information than ten binary digits, so one decimal digit is slightly less than 10/3 binary digits. Conversely, one bit of information corresponds to about ln 2 (\u2248 0.693) nats, or log10 2 (\u2248 0.301) hartleys. As with the inverse ratio, this value, approximately 3/10, but slightly more, corresponds to the fact that 210 = 1024 ~ 1000 = 103: ten binary digits are slightly more information than three decimal digits, so one binary digit is slightly more than 3/10 decimal digits. Some authors also define a binit as an arbitrary information unit equivalent to some fixed but unspecified number of bits.\n\n\n== See also ==\nInteger (computer science)\nPrimitive data type\nTrit (Trinary digit)\nBitstream\nEntropy (information theory)\nBaud rate (bits per second)\nBinary numeral system\nTernary numeral system\nShannon (unit)\n\n\n== References ==\n\n\n== External links ==\nBit Calculator \u2013 a tool providing conversions between bit, byte, kilobit, kilobyte, megabit, megabyte, gigabit, gigabyte\nBitXByteConverter \u2013 a tool for computing file sizes, storage capacity, and digital information in various units",
        "unit": "bit",
        "url": "https://en.wikipedia.org/wiki/Bit"
    },
    {
        "_id": "Second",
        "clean": "Second",
        "text": "The second is the SI base unit of time, commonly understood and historically defined as \u200b1\u204486400 of a day \u2013 this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Another intuitive understanding is that it is about the time between beats of a human heart.  Mechanical and electric clocks and watches usually have a face with 60 tickmarks representing seconds and minutes, traversed by a second hand and minute hand.  Digital clocks and watches often have a two-digit counter that cycles through seconds.  In common parlance, a \"clock tick\" is a second, though most modern clocks are digital electronic, and do not actually tick.  The second is also part of several other units of measurement like velocity, acceleration, and frequency.\nThough the historical definition of the unit was based upon this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is  a much steadier timekeeper: 1 second is defined to be exactly 9 192 631 770 cycles of a Caesium atomic clock.\nBecause the Earth's rotation varies and is also slowing ever so slightly, a leap second is added to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths.  In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second.\nAn everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond.  Camera shutter speeds usually range from \u200b1\u204460 second to \u200b1\u2044250 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today.  Small divisions of time could not be counted back then, so such divisions were figurative.  The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century.  Starting in the 1950s, atomic clocks became better timekeepers than earth's rotation, and they continue to set the standard today.\n\n\n== Clocks and solar time ==\nA mechanical clock, one which does not depend on measuring the relative rotational position of the earth, keeps uniform time called mean time, within whatever accuracy is intrinsic to it. That means that every second, minute and every other division of time counted by the clock will be the same duration as any other identical division of time. But a sundial which measures the relative position of the sun in the sky called apparent time, does not keep uniform time.  The time kept by a sundial varies by time of year, meaning that seconds, minutes and every other division of time is a different duration at different times of the year. The time of day measured with mean time versus apparent time may differ by as much as 15 minutes, but a single day will differ from the next by only a small amount; 15 minutes is a cumulative difference over a part of the year. The effect is due chiefly to the obliqueness of earth's axis with respect to its orbit around the sun.\nThe difference between apparent solar time and mean time was recognized by astronomers since antiquity, but prior to the invention of accurate mechanical clocks in the mid-17th century, sundials were the only reliable timepieces, and apparent solar time was the generally accepted standard.\n\n\n== Events and units of time in seconds ==\nFractions of a second are usually denoted in decimal notation, i.e. 2.01 seconds, or two and one hundredth seconds. Multiples of seconds are usually expressed as minutes and seconds, or hours, minutes and seconds of clock time, separated by colons, such as 11:23:24, or 45:23 (the latter notation can give rise to ambiguity, because the same notation is used to denote hours and minutes).  It rarely makes sense to express longer periods of time like hours or days in seconds, because they are awkwardly large numbers.  For the metric unit of second, there are decimal prefixes representing 10\u221224 to 1024 seconds.\nSome common units of time in seconds are: a minute is 60 seconds; an hour is 3,600 seconds; a day is 86,400 seconds; a week is 604,800 seconds; a year (other than leap years) is 31,536,000 seconds; and a (Gregorian) century is typically 3,155,673,600 seconds; with all of the above excluding any possible leap seconds.\nSome common events in seconds are: a stone falls about 4.9 meters from rest in one second; a pendulum of length about one meter has a swing of one second, so pendulum clocks have pendulums about a meter long; the fastest human sprinters run 10 meters in a second; an ocean wave in deep water travels about 23 meters in one second; sound travels about 343 meters in one second in air; light takes 1.3 seconds to reach Earth from the surface of the Moon, a distance of 384,400 kilometers.\n\n\n== Other units incorporating seconds ==\nA second is part of other units, such as frequency measured in hertz (inverse seconds or second\u22121), speed (meters per second) and acceleration (meters per second squared).  The metric system unit becquerel, a measure of radioactive decay, is measured in inverse seconds.  The meter is defined in terms of the speed of light and the second; definitions of the metric base units ampere and candela also depend on the second. Of the 22 named derived units of the SI, only three: degree Celsius, radian, and steradian, do not depend on the second.  Many derivative units for everyday things are reported in terms of larger units of time, not seconds, such as clock time in hours and minutes, velocity of a car in miles per hour or kilometers per hour, kilowatt hours of electricity usage, and speed of a turntable in rotations per minute.\n\n\n== Timekeeping standards ==\nA set of atomic clocks throughout the world keeps time by consensus: the clocks \"vote\" on the correct time, and all voting clocks are steered to agree with the consensus, which is called International Atomic Time (TAI). TAI \"ticks\" atomic seconds.Civil time is defined to agree with the rotation of the earth. The international standard for timekeeping is Coordinated Universal Time (UTC). This time scale \"ticks\" the same atomic seconds as TAI, but inserts or omits leap seconds as necessary to correct for variations in the rate of rotation of the earth.A time scale in which the seconds are not exactly equal to atomic seconds is UT1, a form of universal time. UT1 is defined by the rotation of the earth with respect to the sun, and does not contain any leap seconds. UT1 always differs from UTC by less than a second.\n\n\n== Optical lattice clock ==\nWhile they are not yet part of any timekeeping standard, optical lattice clocks with frequencies in the visible light spectrum now exist and are the most accurate timekeepers of all.  A strontium clock with frequency 430 THz, in the red range of visible light, now holds the accuracy record: it will gain or lose less than a second in 15 billion years, which is longer than the estimated age of the universe. Such a clock can measure a change in its height of as little as 2 cm by the change in its rate due to gravitational time dilation.\n\n\n== History of definition ==\n\nThere have only ever been three definitions of the second: as a fraction of the day, as a fraction of an extrapolated year, and as the microwave frequency of a caesium atomic clock, and they have realized a sexagesimal division of the day from ancient astronomical calendars.\n\n\n=== Sexagesimal divisions of calendar time and day ===\nCivilizations in the classic period and before constructed divisions of the calendar as well as arcs according to a sexagesimal system of counting, but none used the term second, and none was a precursor to the modern second.  Sundials and water clocks were among the earliest timekeeping devices, and units of time were measured in degrees of arc.  Conceptual units of time smaller than realizable on sundials were also used.\nThere are references to 'second' as part of a lunar month in the writings of natural philosophers of the Middle Ages, but no evidence that 'seconds' were ever realizable or adopted as part of timekeeping based on the lunar calendar.\n\n\n=== Fraction of solar day ===\nThe earliest mechanical clocks which appeared starting in the 14th century had displays that divided the hour into halves, thirds, quarters and sometimes even 12 parts, but never by 60. In fact, the hour was not commonly understood to be the duration of 60 minutes. It was not practical for timekeepers to consider minutes until the first mechanical clocks that displayed minutes appeared near the end of the 16th century. By that time, sexagesimal divisions of time were well established in Europe.The earliest clocks to display seconds appeared during the last half of the 16th century. The second became accurately measurable with the development of mechanical clocks keeping mean time, as opposed to the apparent time displayed by sundials. The earliest spring-driven timepiece with a second hand which marked seconds is an unsigned clock depicting Orpheus in the Fremersdorf collection, dated between 1560 and 1570. During the 3rd quarter of the 16th century, Taqi al-Din built a clock with marks every 1/5 minute.\nIn 1579, Jost B\u00fcrgi built a clock for William of Hesse that marked seconds. In 1581, Tycho Brahe redesigned clocks that displayed minutes at his observatory so they also displayed seconds. However, they were not yet accurate enough for seconds. In 1587, Tycho complained that his four clocks disagreed by plus or minus four seconds.\nIn 1656, Dutch scientist Christiaan Huygens invented the first pendulum clock. It had a pendulum length of just under a meter which gave it a swing of one second, and an escapement that ticked every second. It was the first clock that could accurately keep time in seconds. By the 1730s, 80 years later, John Harrison's maritime chronometers could keep time accurate to within one second in 100 days.\nIn 1832, Gauss proposed using the second as the base unit of time in his millimeter-milligram-second system of units. The British Association for the Advancement of Science (BAAS) in 1862 stated that \"All men of science are agreed to use the second of mean solar time as the unit of time.\" BAAS formally proposed the CGS system in 1874, although this system was gradually replaced over the next 70 years by MKS units. Both the CGS and MKS systems used the same second as their base unit of time. MKS was adopted internationally during the 1940s, defining the second as \u200b1\u204486,400 of a mean solar day.\n\n\n=== Fraction of an ephemeris year ===\n\nSome time in the late 1940s, quartz crystal oscillator clocks with an operating frequency of ~100 kHz advanced to keep time with accuracy better than 1 part in 108 over an operating period of a day.  It became apparent that a consensus of such clocks kept better time than the rotation of the Earth. Metrologists also knew that Earth's orbit around the Sun (a year) was much more stable than earth's rotation. This led to proposals as early as 1950 to define the second as a fraction of a year.\nThe Earth's motion was described in Newcomb's Tables of the Sun (1895), which provided a formula for estimating the motion of the Sun relative to the epoch 1900 based on astronomical observations made between 1750 and 1892. This resulted in adoption of an ephemeris time scale expressed in units of the sidereal year at that epoch by the IAU in 1952. This extrapolated timescale brings the observed positions of the celestial bodies into accord with Newtonian dynamical theories of their motion. In 1955, the tropical year, considered more fundamental than the sidereal year, was chosen by the IAU as the unit of time. The tropical year in the definition was not measured but calculated from a formula describing a mean tropical year that decreased linearly over time.\nIn 1956, the second was redefined in terms of a year relative to that epoch. The second was thus defined as \"the fraction \u200b1\u204431,556,925.9747 of the tropical year for 1900 January 0 at 12 hours ephemeris time\". This definition was adopted as part of the International System of Units in 1960.\n\n\n=== \"Atomic\" second ===\nBut even the best mechanical, electric motorized and quartz crystal-based clocks develop discrepancies, and virtually none are good enough to realize an ephemeris second. Far better for timekeeping is the natural and exact \"vibration\" in an energized atom. The frequency of vibration (i.e., radiation) is very specific depending on the type of atom and how it is excited. Since 1967, the second has been defined as exactly 9,192,631,770 times the period of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom. This length of a second was selected to correspond exactly to the length of the ephemeris second previously defined. Atomic clocks use such a frequency to measure seconds by counting cycles per second at that frequency. Radiation of this kind is one of the most stable and reproducible phenomena of nature. The current generation of atomic clocks is accurate to within one second in a few hundred million years.\nAtomic clocks now set the length of a second and the time standard for the world.\n\n\n== SI multiples ==\nSI prefixes are commonly used to measure time less than a second, but rarely for multiples of a second (which is known as metric time). Instead, the non-SI units minutes, hours, days, Julian years, Julian centuries, and Julian millennia are used.\n\n\n== See also ==\n\nOrders of magnitude (time)\nTime standard\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nNational Physical Laboratory: Trapped ion optical frequency standards \nHigh-accuracy strontium ion optical clock; National Physical Laboratory (2005)\nNational Research Council of Canada: Optical frequency standard based on a single trapped ion\nNIST: Definition of the second; notice the cesium atom must be in its ground state at 0 K\nOfficial BIPM definition of the second\nThe leap second: its history and possible future\nWhat is a Cesium atom clock?\nAccuracy of the time \u2014 Astronoo",
        "unit": "second",
        "url": "https://en.wikipedia.org/wiki/Second"
    },
    {
        "_id": "Farad",
        "clean": "Farad",
        "text": "The farad (symbol: F) is the SI derived unit of electrical capacitance, the ability of a body to store an electrical charge. It is named after the English physicist Michael Faraday.\n\n\n== Definition ==\nOne farad is defined as the capacitance across which, when charged with one coulomb, there is a potential difference of one volt. Equally, one farad can be described as the capacitance which stores a one-coulomb charge across a potential difference of one volt.The relationship between capacitance, charge and potential difference is linear. For example, if the potential difference across a capacitor is halved, the quantity of charge stored by that capacitor will also be halved.\nFor most applications, the farad is an impractically large unit of capacitance. Most electrical and electronic applications are covered by the following SI prefixes:\n\n1 mF (millifarad, one thousandth (10\u22123) of a farad) = 1000 \u03bcF = 1000000 nF\n1 \u03bcF (microfarad, one millionth (10\u22126) of a farad) = 0.000 001 F = 1000 nF = 1000000 pF\n1 nF (nanofarad, one billionth (10\u22129) of a farad) = 0.001 \u03bcF = 1000 pF\n1 pF (picofarad, one trillionth (10\u221212) of a farad)\n\n\n=== Equalities ===\nA farad is represented in terms of SI base units as\ns4\u22c5A2\u22c5m\u22122\u22c5kg\u22121It can further be expressed as:\n\n  \n    \n      \n        \n          F\n        \n        =\n        \n          \n            \n              C\n              V\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  A\n                \n                \n                  \u22c5\n                \n                \n                  s\n                \n              \n              V\n            \n          \n        \n        =\n        \n          \n            \n              J\n              \n                \n                  V\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  W\n                \n                \n                  \u22c5\n                \n                \n                  s\n                \n              \n              \n                \n                  V\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  N\n                \n                \n                  \u22c5\n                \n                \n                  m\n                \n              \n              \n                \n                  V\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  C\n                \n                \n                  2\n                \n              \n              J\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  C\n                \n                \n                  2\n                \n              \n              \n                \n                  N\n                \n                \n                  \u22c5\n                \n                \n                  m\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    s\n                  \n                  \n                    2\n                  \n                \n                \n                  \u22c5\n                \n                \n                  \n                    C\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  \n                    m\n                  \n                  \n                    2\n                  \n                \n                \n                  \u22c5\n                \n                \n                  kg\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    s\n                  \n                  \n                    4\n                  \n                \n                \n                  \u22c5\n                \n                \n                  \n                    A\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  \n                    m\n                  \n                  \n                    2\n                  \n                \n                \n                  \u22c5\n                \n                \n                  kg\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              s\n              \u03a9\n            \n          \n        \n        =\n        \n          \n            \n              1\n              \n                \u03a9\n                \n                  \u22c5\n                \n                \n                  Hz\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  s\n                \n                \n                  2\n                \n              \n              H\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\text{F}}={\\dfrac {\\text{C}}{\\text{V}}}={\\dfrac {{\\text{A}}{\\cdot }{\\text{s}}}{\\text{V}}}={\\dfrac {\\text{J}}{{\\text{V}}^{2}}}={\\dfrac {{\\text{W}}{\\cdot }{\\text{s}}}{{\\text{V}}^{2}}}={\\dfrac {{\\text{N}}{\\cdot }{\\text{m}}}{{\\text{V}}^{2}}}={\\dfrac {{\\text{C}}^{2}}{\\text{J}}}={\\dfrac {{\\text{C}}^{2}}{{\\text{N}}{\\cdot }{\\text{m}}}}={\\dfrac {{\\text{s}}^{2}{\\cdot }{\\text{C}}^{2}}{{\\text{m}}^{2}{\\cdot }{\\text{kg}}}}={\\dfrac {{\\text{s}}^{4}{\\cdot }{\\text{A}}^{2}}{{\\text{m}}^{2}{\\cdot }{\\text{kg}}}}={\\dfrac {\\text{s}}{\\Omega }}={\\dfrac {1}{\\Omega {\\cdot }{\\text{Hz}}}}={\\dfrac {{\\text{s}}^{2}}{\\text{H}}},}\n  where F = farad, A = ampere, V = volt, C = coulomb, J = joule, m = metre, N = newton, s = second, W = watt, kg = kilogram, \u03a9 = ohm, Hz = hertz, H = henry.\n\n\n== History ==\nThe term \"farad\" was originally coined by Latimer Clark and Charles Bright in 1861, in honor of Michael Faraday, for a unit of quantity of charge but by 1873, the farad had become a unit of capacitance.  In 1881 at the International Congress of Electricians in Paris, the name farad was officially used for the unit of electrical capacitance.\n\n\n== Explanation ==\n\nA capacitor generally consists of two conducting surfaces, frequently referred to as plates, separated by an insulating layer usually referred to as a dielectric. The original capacitor was the Leyden jar developed in the 18th century. It is the accumulation of electric charge on the plates that results in capacitance. Modern capacitors are constructed using a range of manufacturing techniques and materials to provide the extraordinarily wide range of capacitance values used in electronics applications from femtofarads to farads, with maximum-voltage ratings ranging from a few volts to several kilovolts.\nValues of capacitors are usually specified in farads (F),  microfarads (\u03bcF), nanofarads (nF) and picofarads (pF). The millifarad is rarely used in practice (a capacitance of 4.7 mF (0.0047 F), for example, is instead written as 4700 \u00b5F), while the nanofarad is uncommon in North America. The size of commercially available capacitors ranges from around 0.1 pF to 5000F (5 kF) supercapacitors. Parasitic capacitance in high-performance integrated circuits can be measured in femtofarads (1 fF = 0.001 pF = 10\u221215 F), while high-performance test equipment can detect changes in capacitance on the order of tens of attofarads (1 aF = 10\u221218 F).A value of 0.1 pF is about the smallest available in capacitors for general use in electronic design, since smaller ones would be dominated by the parasitic capacitances of other components, wiring or printed circuit boards. Capacitance values of 1 pF or lower can be achieved by twisting two short lengths of insulated wire together.The capacitance of the Earth's ionosphere with respect to the ground is calculated to be about 1 F.\n\n\n=== Informal and deprecated terminology ===\nThe picofarad is sometimes colloquially pronounced as \"puff\" or \"pic\", as in \"a ten-puff capacitor\". Similarly, \"mic\" (pronounced \"mike\") is sometimes used informally to signify microfarads. If the Greek letter \u03bc is not available, the notation \"uF\" is often used as a substitute for \"\u03bcF\" in electronics literature. A \"micro-microfarad\" (\u03bc\u03bcF, and confusingly often mmf or MMF), an obsolete unit sometimes found in older texts, is the equivalent of a picofarad.  In texts prior to 1960, and on capacitor packages even much more recently, \"mf\" or \"MFD\" rather than the modern \"\u00b5F\" frequently represented microfarads. Similarly, \"mmf\" or \"MMFD\" represented picofarads.\n\n\n=== Related concepts ===\nThe reciprocal of capacitance is called electrical elastance, the (non-standard, non-SI) unit of which is the daraf.\n\n\n== CGS units ==\nThe abfarad (abbreviated abF) is an obsolete CGS unit of capacitance equal to 109 farads (1 gigafarad, GF).The statfarad (abbreviated statF) is a rarely used CGS unit equivalent to the capacitance of a capacitor with a charge of 1 statcoulomb across a potential difference of 1 statvolt. It is 1/(10\u22125c2) farad, approximately 1.1126 picofarads.\n\n\n== See also ==\nCapacitor\nSupercapacitor\nOrders of magnitude (capacitance)\n\n\n== Notes ==\n\n\n== External links ==\nFarad unit conversion tool",
        "unit": "farad",
        "url": "https://en.wikipedia.org/wiki/Farad"
    },
    {
        "_id": "Volume",
        "clean": "Volume",
        "text": "Volume is the quantity of three-dimensional space enclosed by a closed surface, for example, the space that a substance (solid, liquid, gas, or plasma) or shape occupies or contains. Volume is often quantified numerically using the SI derived unit, the cubic metre. The volume of a container is generally understood to be the capacity of the container; i. e., the amount of fluid (gas or liquid) that the container could hold, rather than the amount of space the container itself displaces.\nThree dimensional mathematical shapes are also assigned volumes. Volumes of some simple shapes, such as regular, straight-edged, and circular shapes can be easily calculated using arithmetic formulas. Volumes of complicated shapes can be calculated with integral calculus if a formula exists for the shape's boundary. One-dimensional figures (such as lines) and two-dimensional shapes (such as squares) are assigned zero volume in the three-dimensional space.\nThe volume of a solid (whether regularly or irregularly shaped) can be determined by fluid displacement. Displacement of liquid can also be used to determine the volume of a gas. The combined volume of two substances is usually greater than the volume of just one of the substances. However, sometimes one substance dissolves in the other and in such cases the combined volume is not additive.In differential geometry, volume is expressed by means of the volume form, and is an important global Riemannian invariant.\nIn thermodynamics, volume is a fundamental parameter, and is a conjugate variable to pressure.\n\n\n== Units ==\n\nAny unit of length gives a corresponding unit of volume: the volume of a cube whose sides have the given length.  For example, a cubic centimetre (cm3) is the volume of a cube whose sides are one centimetre (1 cm) in length.\nIn the International System of Units (SI), the standard unit of volume is the cubic metre (m3).  The metric system also includes the litre (L) as a unit of volume, where one litre is the volume of a 10-centimetre cube.  Thus\n\n1 litre = (10 cm)3 = 1000 cubic centimetres = 0.001 cubic metres,so\n\n1 cubic metre = 1000 litres.Small amounts of liquid are often measured in millilitres, where\n\n1 millilitre = 0.001 litres = 1 cubic centimetre.In the same way, large amounts can be measured in megalitres, where\n\n1 million litres = 1000 cubic metres = 1 megalitre.Various other traditional units of volume are also in use, including the cubic inch, the cubic foot, the cubic yard, the cubic mile, the teaspoon, the tablespoon, the fluid ounce, the fluid dram, the gill, the pint, the quart, the gallon, the minim, the barrel, the cord, the peck, the bushel, the hogshead, the acre-foot and the board foot.\n\n\n== Related terms ==\nCapacity is defined by the Oxford English Dictionary as \"the measure applied to the content of a vessel, and to liquids, grain, or the like, which take the shape of that which holds them\". (The word capacity has other unrelated meanings, as in e.g. capacity management.) Capacity is not identical in meaning to volume, though closely related; the capacity of a container is always the volume in its interior. Units of capacity are the SI litre and its derived units, and Imperial units such as gill, pint, gallon, and others. Units of volume are the cubes of units of length. In SI the units of volume and capacity are closely related: one litre is exactly 1 cubic decimetre, the capacity of a cube with a 10 cm side. In other systems the conversion is not trivial; the capacity of a vehicle's fuel tank is rarely stated in cubic feet, for example, but in gallons (an imperial gallon fills a volume of 0.1605 cu ft).\nThe density of an object is defined as the ratio of the mass to the volume. The inverse of density is specific volume which is defined as volume divided by mass. Specific volume is a concept important in thermodynamics where the volume of a working fluid is often an important parameter of a system being studied.\nThe volumetric flow rate in fluid dynamics is the volume of fluid which passes through a given surface per unit time (for example cubic meters per second [m3 s\u22121]).\n\n\n== Volume in calculus ==\n\nIn calculus, a branch of mathematics, the volume of a region D in R3 is given by a triple integral of the constant function \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        =\n        1\n      \n    \n    {\\displaystyle f(x,y,z)=1}\n   and is usually written as:\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        1\n        \n        d\n        x\n        \n        d\n        y\n        \n        d\n        z\n        .\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}1\\,dx\\,dy\\,dz.}\n  The volume integral in cylindrical coordinates is\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        r\n        \n        d\n        r\n        \n        d\n        \u03b8\n        \n        d\n        z\n        ,\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}r\\,dr\\,d\\theta \\,dz,}\n  and the volume integral in spherical coordinates (using the convention for angles with \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   as the azimuth and \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   measured from the polar axis; see more on conventions) has the form\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        \n          \u03c1\n          \n            2\n          \n        \n        sin\n        \u2061\n        \u03d5\n        \n        d\n        \u03c1\n        \n        d\n        \u03b8\n        \n        d\n        \u03d5\n        .\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}\\rho ^{2}\\sin \\phi \\,d\\rho \\,d\\theta \\,d\\phi .}\n  \n\n\n== Volume formulas ==\n\n\n=== Volume ratios for a cone, sphere and cylinder of the same radius and height ===\n\nThe above formulas can be used to show that the volumes of a cone, sphere and cylinder of the same radius and height are in the ratio 1 : 2 : 3, as follows.\nLet the radius be r and the height be h (which is 2r for the sphere), then the volume of cone is\n\n  \n    \n      \n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        =\n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          (\n          \n            2\n            r\n          \n          )\n        \n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        1\n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{3}}\\pi r^{2}h={\\frac {1}{3}}\\pi r^{2}\\left(2r\\right)=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 1,}\n  the volume of the sphere is\n\n  \n    \n      \n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        2\n        ,\n      \n    \n    {\\displaystyle {\\frac {4}{3}}\\pi r^{3}=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 2,}\n  while the volume of the cylinder is\n\n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        =\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        (\n        2\n        r\n        )\n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        3.\n      \n    \n    {\\displaystyle \\pi r^{2}h=\\pi r^{2}(2r)=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 3.}\n  The discovery of the 2 : 3 ratio of the volumes of the sphere and cylinder is credited to Archimedes.\n\n\n=== Volume formula derivations ===\n\n\n==== Sphere ====\nThe volume of a sphere is the integral of an infinite number of infinitesimally small circular disks of thickness dx. The calculation for the volume of a sphere with center 0 and radius r is as follows.\nThe surface area of the circular disk is \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\pi r^{2}}\n  .\nThe radius of the circular disks, defined such that the x-axis cuts perpendicularly through them, is\n\n  \n    \n      \n        y\n        =\n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle y={\\sqrt {r^{2}-x^{2}}}}\n  or\n\n  \n    \n      \n        z\n        =\n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle z={\\sqrt {r^{2}-x^{2}}}}\n  where y or z can be taken to represent the radius of a disk at a particular x value.\nUsing y as the disk radius, the volume of the sphere can be calculated as\n\n  \n    \n      \n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          y\n          \n            2\n          \n        \n        \n        d\n        x\n        =\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          (\n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n          )\n        \n        \n        d\n        x\n        .\n      \n    \n    {\\displaystyle \\int _{-r}^{r}\\pi y^{2}\\,dx=\\int _{-r}^{r}\\pi \\left(r^{2}-x^{2}\\right)\\,dx.}\n  Now\n\n  \n    \n      \n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        x\n        \u2212\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          x\n          \n            2\n          \n        \n        \n        d\n        x\n        =\n        \u03c0\n        \n          (\n          \n            \n              r\n              \n                3\n              \n            \n            +\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u2212\n        \n          \n            \u03c0\n            3\n          \n        \n        \n          (\n          \n            \n              r\n              \n                3\n              \n            \n            +\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        =\n        2\n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        \u2212\n        \n          \n            \n              2\n              \u03c0\n              \n                r\n                \n                  3\n                \n              \n            \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle \\int _{-r}^{r}\\pi r^{2}\\,dx-\\int _{-r}^{r}\\pi x^{2}\\,dx=\\pi \\left(r^{3}+r^{3}\\right)-{\\frac {\\pi }{3}}\\left(r^{3}+r^{3}\\right)=2\\pi r^{3}-{\\frac {2\\pi r^{3}}{3}}.}\n  Combining yields \n  \n    \n      \n        V\n        =\n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle V={\\frac {4}{3}}\\pi r^{3}.}\n  \nThis formula can be derived more quickly using the formula for the sphere's surface area, which is \n  \n    \n      \n        4\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 4\\pi r^{2}}\n  . The volume of the sphere consists of layers of infinitesimally thin spherical shells, and the sphere volume is equal to\n\n  \n    \n      \n        \n          \u222b\n          \n            0\n          \n          \n            r\n          \n        \n        4\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        r\n        =\n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle \\int _{0}^{r}4\\pi r^{2}\\,dr={\\frac {4}{3}}\\pi r^{3}.}\n  \n\n\n==== Cone ====\nThe cone is a type of pyramidal shape. The fundamental equation for pyramids, one-third times base times altitude, applies to cones as well.\nHowever, using calculus, the volume of a cone is the integral of an infinite number of infinitesimally thin circular disks of thickness dx. The calculation for the volume of a cone of height h, whose base is centered at (0, 0, 0) with radius r, is as follows.\nThe radius of each circular disk is r if x = 0 and 0 if x = h, and varying linearly in between\u2014that is,\n\n  \n    \n      \n        r\n        \n          \n            \n              h\n              \u2212\n              x\n            \n            h\n          \n        \n        .\n      \n    \n    {\\displaystyle r{\\frac {h-x}{h}}.}\n  The surface area of the circular disk is then\n\n  \n    \n      \n        \u03c0\n        \n          \n            (\n            \n              r\n              \n                \n                  \n                    h\n                    \u2212\n                    x\n                  \n                  h\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          \n            \n              (\n              h\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\pi \\left(r{\\frac {h-x}{h}}\\right)^{2}=\\pi r^{2}{\\frac {(h-x)^{2}}{h^{2}}}.}\n  The volume of the cone can then be calculated as\n\n  \n    \n      \n        \n          \u222b\n          \n            0\n          \n          \n            h\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          \n            \n              (\n              h\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle \\int _{0}^{h}\\pi r^{2}{\\frac {(h-x)^{2}}{h^{2}}}dx,}\n  and after extraction of the constants\n\n  \n    \n      \n        \n          \n            \n              \u03c0\n              \n                r\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        \n          \u222b\n          \n            0\n          \n          \n            h\n          \n        \n        (\n        h\n        \u2212\n        x\n        \n          )\n          \n            2\n          \n        \n        d\n        x\n      \n    \n    {\\displaystyle {\\frac {\\pi r^{2}}{h^{2}}}\\int _{0}^{h}(h-x)^{2}dx}\n  Integrating gives us\n\n  \n    \n      \n        \n          \n            \n              \u03c0\n              \n                r\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        \n          (\n          \n            \n              \n                h\n                \n                  3\n                \n              \n              3\n            \n          \n          )\n        \n        =\n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        .\n      \n    \n    {\\displaystyle {\\frac {\\pi r^{2}}{h^{2}}}\\left({\\frac {h^{3}}{3}}\\right)={\\frac {1}{3}}\\pi r^{2}h.}\n  \n\n\n==== Polyhedron ====\n\n\n== Volume in differential geometry ==\n\nIn differential geometry, a branch of mathematics, a volume form on a differentiable manifold is a differential form of top degree (i.e., whose degree is equal to the dimension of the manifold) that is nowhere equal to zero.  A manifold has a volume form if and only if it is orientable. An orientable manifold has infinitely many volume forms, since multiplying a volume form by a non-vanishing function yields another volume form. On non-orientable manifolds, one may instead define the weaker notion of a density. Integrating the volume form gives the volume of the manifold according to that form.\nAn oriented pseudo-Riemannian manifold has a natural volume form.  In local coordinates, it can be expressed as\n\n  \n    \n      \n        \u03c9\n        =\n        \n          \n            \n              |\n            \n            g\n            \n              |\n            \n          \n        \n        \n        d\n        \n          x\n          \n            1\n          \n        \n        \u2227\n        \u22ef\n        \u2227\n        d\n        \n          x\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\omega ={\\sqrt {|g|}}\\,dx^{1}\\wedge \\dots \\wedge dx^{n},}\n  where the \n  \n    \n      \n        d\n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle dx^{i}}\n   are 1-forms that form a positively oriented basis for the cotangent bundle of the manifold, and \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n   is the determinant of the matrix representation of the metric tensor on the manifold in terms of the same basis.\n\n\n== Volume in thermodynamics ==\n\nIn thermodynamics, the volume of a system is an important extensive parameter for describing its thermodynamic state. The specific volume, an intensive property, is the system's volume per unit of mass. Volume is a function of state and is interdependent with other thermodynamic properties such as pressure and temperature. For example, volume is related to the pressure and temperature of an ideal gas by the ideal gas law.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n Perimeters, Areas, Volumes at Wikibooks\n Volume at Wikibooks",
        "unit": "volume",
        "url": "https://en.wikipedia.org/wiki/Volume"
    },
    {
        "_id": "Pound_(mass)",
        "clean": "Pound (mass)",
        "text": "The pound or pound-mass is a unit of mass \nused in the imperial, United States customary and other systems of measurement. Various definitions have been used; the most common today is the international avoirdupois pound, which is legally defined as exactly 0.45359237 kilograms, and which is divided into 16 avoirdupois ounces. The international standard symbol for the avoirdupois pound is lb; an alternative symbol is lbm (for most pound definitions), # (chiefly in the U.S.), and \u2114 or \u2033\u0336 (specifically for the apothecaries' pound).\nThe unit is descended from the Roman libra (hence the abbreviation \"lb\").  The English word pound is cognate with, among others,  German Pfund, Dutch pond, and Swedish pund.  All ultimately derive from a borrowing into Proto-Germanic of the  Latin expression l\u012bbra pond\u014d (\"a pound by weight\"), in which the word pond\u014d is the ablative case of the Latin noun pondus (\"weight\").Usage of the unqualified term pound reflects the historical conflation of mass and weight. This accounts for the modern distinguishing terms pound-mass and pound-force.\n\n\n== Current use ==\nThe United States and countries of the Commonwealth of Nations agreed upon common definitions for the pound and the yard. Since 1 July 1959, the international avoirdupois pound (symbol lb) has been defined as exactly 0.45359237 kg.In the United Kingdom, the use of the international pound was implemented in the Weights and Measures Act 1963.\nThe yard or the metre shall be the unit of measurement of length and the pound or the kilogram shall be the unit of measurement of mass by reference to which any measurement involving a measurement of length or mass shall be made in the United Kingdom; and- (a) the yard shall be 0.9144 metre exactly; (b) the pound shall be 0.45359237 kilogram exactly.\n\nAn avoirdupois pound is equal to 16 avoirdupois ounces and to exactly 7,000 grains. The conversion factor between the kilogram and the international pound was therefore chosen to be divisible by 7, and an (international) grain is thus equal to exactly 64.79891 milligrams.\nIn the UK, the process of metrication and European units of measurement directives were expected to eliminate the use of the pound and ounce, but in 2007 the European Commission abandoned the requirement for metric-only labelling on packaged goods there, and allowed for dual metric\u2013imperial marking to continue indefinitely. When used as a measurement of body weight the UK practice remains to use the stone of 14 pounds as the primary measure e.g. \"11 stone 4 pounds\", rather than \"158 pounds\" (as done in the US), or \"72 kilograms\" as used elsewhere.\nThe US has not adopted the metric system despite many efforts to do so, and the pound remains widely used as one of the key United States customary units.\n\n\n== Historic use ==\n\nHistorically, in different parts of the world, at different points in time, and for different applications, the pound (or its translation) has referred to broadly similar but not identical standards of mass or force.\n\n\n=== Roman libra ===\n\nThe libra (Latin for \"scales / balance\") is an ancient Roman unit of mass that was equivalent to approximately 328.9 grams. It was divided into 12 unciae (singular: uncia), or ounces. The libra is the origin of the abbreviation for pound, \"lb\".\n\n\n=== In Britain ===\nA number of different definitions of the pound have historically been used in Britain. Amongst these were the avoirdupois pound and the obsolete Tower, merchant's and London pounds. Troy pounds and ounces remain in use only for the weight of certain precious metals, especially in the trade; these are normally quoted just in ounces (e.g. \"500 ounces\") and, when the type of ounce is not explicitly stated, the troy system is assumed.\nHistorically, the pound sterling was a Tower pound of silver. In 1528, the standard was changed to the Troy pound.\n\n\n==== Avoirdupois pound ====\nThe avoirdupois pound, also known as the wool pound, first came into general use c. 1300. It was initially equal to 6992 troy grains. The pound avoirdupois was divided into 16 ounces. During the reign of Queen Elizabeth, the avoirdupois pound was redefined as 7,000 troy grains. Since then, the grain has often been an integral part of the avoirdupois system. By 1758, two Elizabethan Exchequer standard weights for the avoirdupois pound existed, and when measured in troy grains they were found to be of 7,002 grains and 6,999 grains.\n\n\n==== Imperial Standard Pound ====\nIn the United Kingdom, weights and measures have been defined by a long series of Acts of Parliament, the intention of which has been to regulate the sale of commodities. Materials traded in the marketplace are quantified according to accepted units and standards in order to avoid fraud. The standards themselves are legally defined so as to facilitate the resolution of disputes brought to the courts; only legally defined measures will be recognised by the courts. Quantifying devices used by traders (weights, weighing machines, containers of volumes, measures of length) are subject to official inspection, and penalties apply if they are fraudulent.\nThe Weights and Measures Act of 1878 marked a major overhaul of the British system of weights and measures, and the definition of the pound given there remained in force until the 1960s. The pound was defined thus (Section 4) \"The ... platinum weight ... deposited in the Standards department of the Board of Trade ... shall continue to be the imperial standard of ... weight ... and the said platinum weight shall continue to be the Imperial Standard for determining the Imperial Standard Pound for the United Kingdom\". Paragraph 13 states that the weight in vacuo of this standard shall be called the Imperial Standard Pound, and that all other weights mentioned in the act and permissible for commerce shall be ascertained from it alone. The First Schedule of the Act gave more details of the standard pound: it is a platinum cylinder nearly 1.35 inches (34 mm) high, and 1.15 inches (29 mm) diameter, and the edges are carefully rounded off. It has a groove about 0.34 inches (8.6 mm) from the top, to allow the cylinder to be lifted using an ivory fork. It was constructed following the destruction of the Houses of Parliament by fire in 1834, and is stamped P.S. 1844, 1 lb (P.S. stands for \"Parliamentary Standard\"). This definition of the Imperial pound remains unchanged.\n\n\n==== Relationship to the kilogram ====\nThe 1878 Act said that contracts worded in terms of metric units would be deemed by the courts to be made according to the Imperial units defined in the Act, and a table of metric equivalents was supplied so that the Imperial equivalents could be legally calculated. This defined, in UK law, metric units in terms of Imperial ones. The equivalence for the pound was given as 1 lb = 453.59265 g or 0.45359 kg, which made the kilogram equivalent to about 2.2046213 lb. In 1883, it was determined jointly by the Standards Department of the Board of Trade and the Bureau International that 0.4535924277 kg was a better approximation, and this figure, rounded to 0.45359243 kg was given legal status by an Order in Council in May 1898.However, in 1963, a new Weights and Measures Act reversed this relationship and the pound was defined for the first time as a mass equal to 0.45359237 kg to match the definition of the international pound agreed in 1959.\n\n\n==== Troy pound ====\n\nA troy pound is equal to 12 troy ounces and to 5,760 grains, that is exactly 373.2417216 grams. Troy weights were used in England by jewellers. Apothecaries also used the troy pound and ounce, but added the drachms and scruples unit in the Apothecaries' system of weights.\nTroy weight may take its name from the French market town of Troyes in France where English merchants traded at least as early as the early 9th century.The troy pound is no longer in general use or a legal unit for trade (it was abolished in the United Kingdom on 6 January 1879 by the Weights and Measures Act of 1878), but the troy ounce, \u200b1\u204412 of a troy pound, is still used for measurements of gems such as opals, and precious metals such as silver, platinum and particularly gold.\n\n\n==== Tower pound ====\n\nThe system called Tower weight was the more general name for King Offa's pound. This dates to 757 AD and was based on the silver penny. This in turn was struck over Arabic dirhams (2d). The pound was based on the weight of 120 Arabic silver dirhams, which have been found in Offa's Dyke. The same coin weight was used throughout the Hanseatic League.The Tower pound was also called the Moneyers' Pound (referring to the Saxon moneyers before the Conquest), the easterling pound, which may refer to traders of eastern Germany, or to traders on the shore of the eastern Baltic sea, or dealers of Asiatic goods who settled at the Steelyard wharf; and the Rochelle Pound by French writers, because it was also in use at Rochelle. An almost identical weight was employed by the Germans for weighing gold and silver.\nThe mercantile pound (1304) of 6750 troy grains, or 9600 Tower grains, derives from this pound, as 25 shilling-weights or 15 Tower ounces, for general commercial use. Multiple pounds based on the same ounce were quite common. In much of Europe, the apothecaries' and commercial pounds were different numbers of the same ounce.The Tower system was referenced to a standard prototype found in the Tower of London and ran concurrently with the avoirdupois and troy systems until the reign of Henry VIII, when a royal proclamation dated 1526 required that the troy pound to be used for mint purposes instead of the Tower pound. No standards of the Tower pound are known to have survived.The Tower pound was equivalent to about 350 grams.\n\n\n==== Merchants' pound ====\nThe merchants' pound (mercantile pound, libra mercantoria, or commercial pound) was considered to be composed of 25 rather than 20 Tower shillings of 12 pence. It was equal to 9,600 wheat grains (15 tower ounces or 6,750 grains) and was used in England until the 14th century for goods other than money and medicine (\"electuaries\").\n\n\n==== London pound ====\nThe London pound is that of the Hansa, as used in their various trading places.  The London pound is based on 16 ounces, each ounce divided as the tower ounce.  It never became a legal standard in England; the use of this pound waxed and waned with the influence of the Hansa itself.\nA London pound was equal to 7,200 troy grains (16 troy ounces) or, equivalently, 10,240 tower grains (16 tower ounces).\n\n\n=== In the United States ===\nIn the United States, the avoirdupois pound as a unit of mass has been officially defined in terms of the kilogram since the Mendenhall Order of 1893. That Order defined the pound to be 2.20462 pounds to a kilogram. The following year, this relationship was refined as 2.20462234 pounds to a kilogram, following a determination of the British pound.According to a 1959 NIST publication, the United States 1894 pound differed from the international pound by approximately one part in 10 million. The difference is so insignificant that it can be ignored for almost all practical purposes.\n\n\n=== Byzantine litra ===\n\nThe Byzantines used a series of measurements known as pounds (Latin: libra, Greek: \u03bb\u03af\u03c4\u03c1\u03b1, litra). The most common was the logarik\u0113 litra (\u03bb\u03bf\u03b3\u03b1\u03c1\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"pound of account\"), established by Constantine the Great in 309/310. It formed the basis of the Byzantine monetary system, with one litra of gold equivalent to 72 solidi. A hundred litrai were known as a kent\u0113narion (\u03ba\u03b5\u03bd\u03c4\u03b7\u03bd\u03ac\u03c1\u03b9\u03bf\u03bd, \"hundredweight\"). Its weight seems to have decreased gradually from the original 324 grams to 319. Due to its association with gold, it was also known as the chrysaphik\u0113 litra (\u03c7\u03c1\u03c5\u03c3\u03b1\u03c6\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"gold pound\") or thalassia litra (\u03b8\u03b1\u03bb\u03ac\u03c3\u03c3\u03b9\u03b1 \u03bb\u03af\u03c4\u03c1\u03b1, \"maritime pound\"), but it could also be used as a measure of land, equalling a fortieth of the thalassios modios.The soualia litra was specifically used for weighing olive oil or wood, and corresponded to 4/5 of the logarik\u0113, i.e. 256 g. Some outlying regions, especially in later times, adopted various local measures, based on Italian, Arab or Turkish measures. The most important of these was the argyrik\u0113 litra (\u03b1\u03c1\u03b3\u03c5\u03c1\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"silver pound\") of 333 g, found in Trebizond and Cyprus, and probably of Arab origin.\n\n\n=== French livre ===\n\nSince the Middle Ages, various pounds (livre) have been used in France. Since the 19th century, a livre has referred to the metric pound, 500g.\nThe livre esterlin was equivalent to about 367.1 grams (5,665 gr) and was used between the late 9th century and the mid-14th century.The livre poids de marc or livre de Paris was equivalent to about 489.5 grams (7,554 gr) and was used between the 1350s and the late 18th century. It was introduced by the government of John II.\nThe livre m\u00e9trique was set equal to the kilogram by the decree of 13 Brumaire an IX between 1800 and 1812. This was a form of official metric pound.The livre usuelle (customary unit) was defined as 500 grams by the decree of 28 March 1812. It was abolished as a unit of mass effective 1 January 1840 by a decree of 4 July 1837, but is still used informally.\n\n\n=== German and Austrian Pfund ===\nOriginally derived from the Roman libra, the definition varied throughout Germany in the Middle Ages and onward. The measures and weights of the Habsburg monarchy were reformed in 1761 by Empress Maria Theresia of Austria. The unusually heavy Habsburg (civil) pound of 16 ounces was later defined in terms of 560.012 grams. Bavarian reforms in 1809 and 1811 adopted essentially the same standard pound. In Prussia, a reform in 1816 defined a uniform civil pound in terms of the Prussian foot and distilled water, resulting in a Prussian pound of 467.711 grams.\nBetween 1803 and 1815, all German regions west of the River Rhine were French, organised in the departements: Roer, Sarre, Rhin-et-Moselle, and Mont-Tonnerre. As a result of the Congress of Vienna, these became part of various German states. However, many of these regions retained the metric system and adopted a metric pound of precisely 500 grams. In 1854, the pound of 500 grams also became the official mass standard of the German Customs Union, but local pounds continued to co-exist with the Zollverein pound for some time in some German states. Nowadays, the term Pfund is still in common use and universally refers to a pound of 500 grams.\n\n\n=== Russian funt ===\nThe Russian pound (\u0424\u0443\u043d\u0442, funt) is an obsolete Russian unit of measurement of mass. It is equal to 409.51718 grams. In 1899, the Russian pound was the basic unit of weight and all other units of weight were formed from it.\n\n\n=== Sk\u00e5lpund ===\nThe Sk\u00e5lpund was a Scandinavian measurement that varied in weight between regions. From the 17th century onward, it was equal to 425.076 grams in Sweden but was abandoned in 1889 when Sweden switched to the metric system.\nIn Norway, the same name was used for a weight of 498.1 grams. In Denmark, it equalled 471 grams.\nIn the 19th century, Denmark followed Germany's lead and redefined the pound as 500 grams.\n\n\n=== Jersey pound ===\nA Jersey pound is an obsolete unit of mass used on the island of Jersey from the 14th century to the 19th century. It was equivalent to about 7,561 grains (490 grams). It may have been derived from the French livre poids de marc.\n\n\n=== Trone pound ===\nThe trone pound is one of a number of obsolete Scottish units of measurement. It was equivalent to between 21 and 28 avoirdupois ounces (about 600-800 grams).\n\n\n=== Metric pounds ===\nIn many countries, upon the introduction of a metric system, the pound (or its translation) became an informal term for 500 grams. In German, the term is Pfund, in French livre, in Dutch pond, in Spanish and Portuguese libra, in Italian libbra, and in Danish and Swedish pund.\nThough not from the same linguistic origin, the Chinese j\u012bn (\u65a4, also known as \"catty\") has a modern definition of exactly 500 grams, divided into 10 li\u01ceng (\u4e24). Traditionally about 605 grams, the jin has been in use for more than two thousand years, serving the same purpose as \"pound\" for the common-use measure of weight.\nHundreds of older pounds were replaced in this way. Examples of the older pounds are one of around 459 to 460 grams in Spain, Portugal, and Latin America; one of 498.1 grams in Norway; and several different ones in what is now Germany.\nAlthough the use of the pound as an informal term persists in these countries to a varying degree, scales and measuring devices are denominated only in grams and kilograms. A pound of product must be determined by weighing the product in grams as the use of the pound is not sanctioned for trade within the European Union.\n\n\n== Use in weaponry ==\nSmoothbore cannon and carronades are designated by the weight in imperial pounds of round solid iron shot of diameter to fit the barrel. A cannon that fires a six-pound ball, for example, is called a six-pounder. Standard sizes are 6, 12, 18, 24, 32 and 42 pounds; 68-pounders also exist, and other nonstandard weapons use the same scheme. See carronade.\nA similar definition, using lead balls, exists for determining the gauge of shotguns.\n\n\n== See also ==\nPound-force\n\n\n== Notes ==\n\n\n== External links ==\n\n\n=== Conversion between units ===\nU.S. National Institute of Standards and Technology Special Publication 811\nNational Institute of Standards and Technology Handbook 130",
        "unit": "pound-mass",
        "url": "https://en.wikipedia.org/wiki/Pound_(mass)"
    },
    {
        "_id": "Ton",
        "clean": "Ton",
        "text": "The ton is a unit of measure. It has a long history and has acquired a number of meanings and uses over the years. It is used principally as a unit of mass. Its original use as a measurement of volume has continued in the capacity of cargo ships and in terms such as the freight ton. It can also be used as a measure of energy, for truck classification, or as a colloquial term.\nIt is derived from the tun, the term applied to a cask of the largest capacity. This could contain a volume between 175 and 213 imperial gallons (210 and 256 US gal; 800 and 970 l), which could weigh around 2,000 pounds (910 kg) and occupy some 60 cubic feet (1.7 m3) of space.In the United Kingdom the ton is defined as 2,240 avoirdupois pounds (1,016 kg). This is equivalent to 20 hundredweight, a hundredweight being eight stone, and a stone weighing 14 pounds.  From 1965 the UK embarked upon a programme of metrication and gradually introduced metric units, including the tonne (metric ton), defined as 1000 kg (2,204 lb). The UK Weights and Measures Act 1985 explicitly excluded from use for trade many units and terms, including the ton and the term \"metric ton\" for \"tonne\".In the United States and Canada a ton is defined to be 2,000 pounds (907 kg).\nWhere confusion is possible, the 2240 lb ton is called \"long ton\" and the 2000 lb ton \"short ton\"; the tonne is distinguished by its spelling, but usually pronounced the same as ton, hence the US term \"metric ton\". In the UK the final \"e\" of \"tonne\" can also be pronounced (), or \"metric ton\" when it is necessary to make the distinction.\nWhere accuracy is required the correct term must be used, but for many purposes this is not necessary: the metric and long tons differ by only 1.6%, and the short ton is within 11% of both. The ton is the heaviest unit of weight referred to in colloquial speech.\nThe term \"ton\" is also  used to refer to a number of units of volume, ranging from 35 to 100 cubic feet (0.99 to 2.83 m3) in capacity.\nIt can also be used as a unit of energy, expressed as an equivalent of coal burnt or TNT detonated.\nIn refrigeration, a ton is a unit of power, sometimes called a ton of refrigeration.  It is the power required to melt or freeze one short ton of ice per day.  The refrigeration ton hour is a unit of energy, the energy required to melt or freeze \u200b1\u204424 short ton of ice.\n\n\n== Units of mass/weight ==\nThere are several similar units of mass or volume called the ton:\n\n\n=== Others ===\nThe long ton is used for petroleum products such as aviation fuel.\nDeadweight ton (abbreviation 'DWT' or 'dwt') is a measure of a ship's carrying capacity, including bunker oil, fresh water, ballast water, crew and provisions. It is expressed in tonnes (1000 kg) or long tons (2240 pounds, about 1016 kg). This measurement is also used in the U.S. tonnage of naval ships.\nIncreasingly, tonnes are being used rather than long tons in measuring the displacement of ships. See tonnage.\nHarbour ton used in South Africa in the 20th century, 2000 pounds or one short ton.Both the long ton and the short ton are 20 hundredweight, the long hundredweight and the short hundredweight being 112 and 100 pounds respectively. Before the twentieth century there were several definitions. Prior to the 15th century in England, the ton was 20 hundredweight, each of 108 lb, giving a ton of 2,160 pounds (980 kg).  In the nineteenth century in different parts of Britain, definitions of 2240, 2352, and 2400 lb were used, with 2000 lb for explosives; the legal ton was usually [sic] 2240 lb.\nAssay ton (abbreviation 'AT') is not a unit of measurement, but a standard quantity used in assaying ores of precious metals; it is \u200b29 1\u20446 grams (short assay ton) or \u200b32 2\u20443 grams (long assay ton), the amount which bears the same ratio to a milligram as a short or long ton bears to a troy ounce. In other words, the number of milligrams of a particular metal found in a sample of this size gives the number of troy ounces contained in a short or long ton of ore.\nIn documents that predate 1960 the word ton is sometimes spelled tonne, but in more recent documents tonne refers exclusively to the metric ton.\nIn nuclear power plants tHM and MTHM mean tonnes of heavy metals, and MTU means tonnes of uranium. In the steel industry, the abbreviation THM means 'tons/tonnes hot metal', which refers to the amount of liquid iron or steel that is produced, particularly in the context of blast furnace production or specific consumption.\nA dry ton or dry tonne has the same mass value, but the material (sludge, slurries, compost, and similar mixtures in which solid material is soaked with or suspended in water) has been dried to a relatively low, consistent moisture level (dry weight). If the material is in its natural, wet state, it is called a wet ton or wet tonne.\n\n\n== Units of volume ==\n\nThe displacement, essentially the weight, of a ship is traditionally expressed in long tons. To simplify measurement it is determined by measuring the volume, rather than weight, of water displaced, and calculating the weight from the volume and density.\nFor practical purposes the displacement ton (DT) is a unit of volume, 35 cubic feet (0.9911 m3), the approximate volume occupied by one ton of seawater (the actual volume varies with salinity and temperature). It is slightly less than the 224 imperial gallons (1.018 m3) of the water ton (based on distilled water).\nOne measurement ton or freight ton is equal to 40 cubic feet (1.133 m3), but historically it has had several different definitions. It is sometimes abbreviated as \"MTON\".  It is used to determine the amount of money to be charged as \"Freight\" in carrying different sorts of cargo. In general if a cargo is heavier than salt water, the actual tonnage is used. If it is lighter than salt water, e.g. feathers, freight is calculated using Measurement Tons of 40 cubic feet. The freight ton represents the volume of a truck, train or other freight carrier. In the past it has been used for a cargo ship but the register ton is now preferred. It is correctly abbreviated as \"FT\" but some users are now using freight ton to represent a weight of 1 tonne (1,000 kg; 2,205 lb), thus the more common abbreviations are now M/T, MT, or MTON (for measurement ton), which still cause it to be confused with the tonne, or even the megatonne.\nThe register ton is a unit of volume used for the cargo capacity of a ship, defined as 100 cubic feet (2.832 m3). It is often abbreviated RT or GRT for gross registered ton (The former providing confusion with the refrigeration ton). It is known as a tonneau de mer in Belgium, but, in France, a tonneau de mer is 1.44 cubic metres (50.85 cu ft).\nThe Panama Canal/Universal Measurement System (PC/UMS) is based on net tonnage, modified for Panama Canal billing purposes. PC/UMS is based on a mathematical formula to calculate a vessel's total volume; a PC/UMS net ton is equivalent to 100 cubic feet of capacity.The water ton is used chiefly in Great Britain, in statistics dealing with petroleum products, and is defined as 224 imperial gallons (35.96 cu ft; 1.018 m3), the volume occupied by 1 long ton (2,240 lb; 1,016 kg) of water under the conditions that define the imperial gallon.\n\n\n== Units of energy and power ==\n\n\n=== Ton of TNT ===\n\nA ton of TNT or tonne of TNT is a unit of energy equal to 109 (thermochemical) calories, also known as a gigacalorie (Gcal), equal to 4.184 gigajoules (GJ).\nA kiloton of TNT or kilotonne of TNT is a unit of energy equal to 1012 calories, also known as a teracalorie (Tcal), equal to 4.184 terajoules (TJ).\nA megaton of TNT (1,000,000 metric tonnes) or megatonne of TNT is a unit of energy equal to 1015 calories, also known (infrequently) as a petacalorie (Pcal), equal to 4.184 petajoules (PJ).Note that these are small calories (cal). The large or dietary calorie (Cal) is equal to one kilocalorie (kcal), and is gradually being replaced by the latter correct term.\nEarly values for the explosive energy released by trinitrotoluene (TNT) ranged from 900 to 1100 calories per gram. In order to standardise the use of the term TNT as a unit of energy, an arbitrary value was assigned based on 1000 calories (1 kcal or 4.184 kJ) per gram. Thus there is no longer a direct connection to the chemical TNT itself. It is now merely a unit of energy that happens to be expressed using words normally associated with mass (e.g., kilogram, tonne, pound). The definition applies for both spellings: ton of TNT and tonne of TNT.\nMeasurements in tons of TNT have been used primarily to express nuclear weapon yields, though they have also been used since in seismology as well.\n\n\n=== Tonne of oil equivalent ===\nA tonne of oil equivalent (toe), sometimes ton of oil equivalent, is a conventional value, based on the amount of energy released by burning one tonne of crude oil. The unit is used, for example, by the International Energy Agency (IEA), for the reported world energy consumption as TPES in millions of toe (Mtoe).\nOther sources convert 1 toe into 1.28 tonne of coal equivalent (tce). 1 toe is also standardized as 7.33 barrel of oil equivalent (boe).\n\n\n=== Tonne of coal equivalent ===\nA tonne of coal equivalent (tce), sometimes ton of coal equivalent, is a conventional value, based on the amount of energy released by burning one tonne of coal. Plural name is tonnes of coal equivalent.\n\nPer the World Coal Association: 1 tonne of coal equivalent (tce) corresponds to 0.697 tonne of oil equivalent (toe)\nPer the International Energy Agency 1 tonne of coal equivalent (tce) corresponds to 0.700 tonne of oil equivalent (toe)\n\n\n=== Refrigeration ===\n\nThe unit ton is used in refrigeration and air conditioning to measure the rate of heat absorption. Prior to the introduction of mechanical refrigeration, cooling was accomplished by delivering ice.  Installing one ton of mechanical refrigeration capacity replaced the daily delivery of one ton of ice.\n\nIn North America, a standard ton of refrigeration is 12,000 BTU/h (3,517 W). \"The heat absorption per day is approximately the heat of fusion of 1 ton of ice at 32 \u00b0F (0 \u00b0C).\" This is approximately the power required to melt one short ton (2,000 lb or 907 kg) of ice at 0 \u00b0C (32 \u00b0F) in 24 hours, thus representing the delivery of 1 short ton (0.893 long tons; 0.907 t) of ice per day.\nA less common usage is the power required to cool 1 long ton (2,240 lb or 1,016 kg = 1 long ton or 1.120 short tons or 1.016 t) of water by 1 \u00b0F (0.56 \u00b0C) every 10 minutes = 13,440 BTU/h (3,939 W).A refrigeration ton should be regarded as power produced by a chiller when operating in standard AHRI conditions, which are typically 44 \u00b0F (7 \u00b0C) for chilled water unit, and 95 \u00b0F (35 \u00b0C) air entering the condenser. This is commonly referred to as \"true ton\". Manufacturers can also provide tables for chillers operating at other chilled water temperature conditions (as 65 \u00b0F or 18.3 \u00b0C) which can show more favorable data, which are not valid when making performance comparisons among units unless conversion rates are applied.The refrigeration ton is commonly abbreviated as RT.\n\n\n== Informal tons ==\nTon is also used informally, often as slang, to mean a large amount of something, material or not.  For example, \"I have a ton of homework to do this weekend.\"\nIn Britain, a ton is colloquially used to refer to 100 of a given unit. Ton can thus refer to a speed of 100 miles per hour, and is prefixed by an indefinite article, e.g. \"Lee was doing a ton down the motorway\"; to money e.g. \"How much did you pay for that?\" \"A ton\" (\u00a3100); to 100 points in a game e.g. \"Eric just threw a ton in our darts game\" (in some games, e.g. cricket, more commonly called a century); or to a hundred of any other countable figure.\nIn Dutch, when talking about money a ton is used to indicate 100,000. For example a house costing 2 ton would cost 200,000 euros.  This convention has been in use since at least the 18th century.\nIn Finnish, tonni is often used as a synonym for one thousand (1000), especially when referring to money. For example, \"tonnin seteli\" was a 1000 mark's banknote and a popular TV show was called \"Kymppitonni\" (\"ten tons\" = 10,000 marks).\n\n\n== See also ==\n\n\n== References ==",
        "unit": "ton",
        "url": "https://en.wikipedia.org/wiki/Ton"
    },
    {
        "_id": "Pound_sterling",
        "clean": "Pound sterling",
        "text": "The pound sterling (symbol: \u00a3; ISO code: GBP), commonly known as the pound and less commonly referred to as Sterling, is the official currency of the United Kingdom, Jersey, Guernsey, the Isle of Man, South Georgia and the South Sandwich Islands, the British Antarctic Territory, and Tristan da Cunha. It is subdivided into 100 pence (singular: penny, abbreviated: p). A number of nations that do not use sterling also have currencies called the pound.  At various times, the pound sterling was commodity money or bank notes backed by silver or gold, but it is currently fiat money, backed only by the economy in the areas where it is accepted. The pound sterling is the world's oldest currency still in use and which has been in continuous use since its inception.Sterling is the fourth most-traded currency in the foreign exchange market, after the United States dollar, the euro, and the Japanese yen. Together with those three currencies and the Chinese yuan  it forms the basket of currencies which calculate the value of IMF special drawing rights. Sterling is also the third most-held reserve currency in global reserves (about 4%).The British Crown dependencies of Guernsey, Jersey and the Isle of Man produce their own local issues of sterling (the Guernsey pound, the Jersey pound and the Manx pound) which are considered fully equivalent to UK sterling in their respective regions. The pound sterling is also used in Gibraltar (alongside the Gibraltar pound), the Falkland Islands (alongside the Falkland Islands pound), Saint Helena and Ascension Island in Saint Helena, Ascension and Tristan da Cunha (alongside the Saint Helena pound). The Bank of England is the central bank for the pound sterling, issuing its own coins and banknotes, and regulating issuance of banknotes by private banks in Scotland and Northern Ireland. Banknotes issued by other jurisdictions are not regulated by the Bank of England; local governments use Bank of England notes as backing for local issuance by allowing them to be exchanged 1:1 at face value.\n\n\n== Names ==\nThe full official name pound sterling (plural: pounds sterling), is used mainly in formal contexts and also when it is necessary to distinguish the United Kingdom currency from other currencies with the same name. Otherwise the term pound is normally used. The currency name is sometimes abbreviated to just sterling, particularly in the wholesale financial markets, but not when referring to specific amounts; for example, \"Payment is accepted in sterling\" but never \"These cost five sterling\". The abbreviations \"ster.\" and \"stg.\" are sometimes used. The term \"British pound\" is sometimes incorrectly used in less formal contexts, and it is not an official name of the currency.\nThe exchange rate of the pound sterling against the US Dollar is referred to as \"cable\" in the wholesale foreign exchange markets. The origins of this term are attributed to the fact that in the 1800s, the GBP/USD exchange rate was transmitted via transatlantic cable. Forex traders of GBP/USD are sometimes referred to as \"cable dealers\". GBP/USD is now the only currency pair with its own name in the foreign exchange markets, after IEP/USD, known as \"wire\" particularly in the forward FX markets, no longer exists after the Irish Pound was replaced by the euro in 1999.\n\nThere is apparent convergence of opinion regarding the origin of the term \"pound sterling\", toward its derivation from the name of a small Norman silver coin, and away from its association with Easterlings (Germanic traders) or other etymologies. Hence, the Oxford English Dictionary (and sources derived therefrom) state that the \"most plausible\" etymology is derivation from the Old English steorra for \"star\" with the added diminutive suffix \"-ling\", to mean \"little star\" and to refer to a silver penny of the English Normans. As another established source notes, the compound expression was then derived:silver coins known as \"sterlings\" were issued in the Saxon kingdoms, 240 of them being minted from a pound of silver... Hence, large payments came to be reckoned in \"pounds of sterlings,\" a phrase later shortened...\n However, the perceived narrow window of the issuance of this coin, and the fact that coin designs changed frequently in the period in question, led Philip Grierson to reject this in favour of a more complex theory.Another argument that the Hanseatic League was the origin for both the origin of its definition and manufacture, and in its name is that the German name for the Baltic is \"Ost See\", or \"East Sea\", and from this the Baltic merchants were called \"Osterlings\", or \"Easterlings\". In 1260, Henry III granted them a charter of protection and land for their Kontor, the Steelyard of London, which by the 1340s was also called \"Easterlings Hall\", or Esterlingeshalle. Because the League's money was not frequently debased like that of England, English traders stipulated to be paid in pounds of the \"Easterlings\", which was contracted to \"'sterling\".For further discussion of the etymology of \"sterling\", see sterling silver.\nThe currency sign for the pound is \u00a3, which is usually written with a single cross-bar (as on sterling bank notes), though a version with a double cross-bar (\u20a4) is also sometimes seen. This symbol derives from medieval Latin documents; the Roman words libra, solidus, and denarius (\u00a3sd) referred to pounds, shillings and pence in the British pre-decimal (duodecimal) currency system and the black-letter \"L\" was the abbreviation for libra, the basic Roman unit of weight.\nThe ISO 4217 currency code is GBP, formed from \"GB\", the ISO 3166-1 alpha-2 code for the United Kingdom, and the first letter of \"pound\". It does not stand for \"Great Britain Pound\" or \"Great British Pound\". Occasionally, the abbreviation \"UKP\" is used but this is non-standard because the ISO 3166 country code for the United Kingdom is GB (see Terminology of the British Isles). The Crown dependencies use their own (non-ISO) codes: GGP (Guernsey pound), JEP (Jersey pound) and IMP (Isle of Man pound). Stocks are often traded in pence, so traders may refer to pence sterling, GBX (sometimes GBp), when listing stock prices.\nA common slang term for the pound sterling or pound is quid, which is singular and plural, except in the common phrase \"Quids in!\" The term may have come via Italian immigrants from \"scudo\", the name for a number of coins used in Italy until the 19th century; or from Latin 'quid' via the common phrase quid pro quo, literally, \"what for what,\" or, figuratively, \"An equal exchange or substitution\".\n\n\n== Subdivisions and other units ==\n\n\n=== Decimal coinage ===\nSince decimalisation in 1971 (see Decimal Day), the pound has been divided into 100 pence (until 1981 described on the coinage as \"new pence\"). The symbol for the penny is \"p\"; hence an amount such as 50p (\u00a30.50) properly pronounced \"fifty pence\" is more colloquially, quite often, pronounced \"fifty pee\" /f\u026afti pi/. This also helped to distinguish between new and old pence amounts during the changeover to the decimal system. A decimal halfpenny was issued until 1984, but was removed due to having a higher cost to manufacture than its face value.\n\n\n=== Pre-decimal ===\n\nBefore decimalisation, the pound was divided into 20 shillings and each shilling into 12 pence, making 240 pence to the pound. The symbol for the shilling was \"s.\"\u2014not from the first letter of the word, but from the Latin solidus. The symbol for the penny was \"d.\", from the French denier, from the Latin denarius (the solidus and denarius were Roman coins). A mixed sum of shillings and pence, such as 3 shillings and 6 pence, was written as \"3/6\" or \"3s. 6d.\" and spoken as \"three and six\" or \"three and sixpence\" except for \"1/1,\" \"2/1\" etc., which were spoken as \"one and a penny\", \"two and a penny\", etc.). 5 shillings, for example, was written as \"5s.\" or, more commonly, \"5/\u2013\".\nVarious coin denominations had, and in some cases continue to have, special names\u2014such as crown, farthing, sovereign and guinea. See Coins of the pound sterling and List of British coins and banknotes for details.\nBy the 1950s, coins of Kings George III, George IV and William IV had disappeared from circulation, but coins (at least the penny) bearing the head of any British king or queen from Queen Victoria onwards could be found in circulation. Silver coins were replaced by those in cupro-nickel in 1947, and by the 1960s the silver coins were rarely seen. Silver/cupro-nickel shillings (from any period after 1816) and florins (2 shillings) remained as legal tender after decimalisation (as 5p and 10p respectively) until 1993, but are now officially demonetised.\n\n\n== History ==\nThe pound sterling is the world's oldest currency still in use.\n\n\n=== Anglo-Saxon ===\n\nThe pound was a unit of account in Anglo-Saxon England, equal to 240 silver pennies and equivalent to one pound weight of silver. It evolved into the modern British currency, the pound sterling.\nThe accounting system of 4 farthings = 1 penny, 12 pence = 1 shilling, 20 shillings = 1 pound was adopted from that introduced by Charlemagne to the Frankish Empire (see French livre).\nThe origins of sterling lie in the reign of King Offa of Mercia (757\u2013796), who introduced the silver penny. It copied the denarius of the new currency system of Charlemagne's Frankish Empire. As in the Carolingian system, 240 pennies weighed 1 pound (corresponding to Charlemagne's libra), with the shilling corresponding to Charlemagne's solidus and equal to 12d. At the time of the penny's introduction, it weighed 22.5 troy grains of fine silver (32 tower grains; about 1.5 g), indicating that the Mercian pound weighed 5,400 troy grains (the Mercian pound became the basis of the tower pound, which also weighed 5,400 troy grains, equivalent to 7,680 tower grains, about 350g).\n\n\n=== Medieval ===\nThe early pennies were struck from fine silver (as pure as was available). However, in 1158, a new coinage was introduced by King Henry II (known as the Tealby penny) which was struck from 0.925 (92.5%) silver. This became the standard until the 20th century and is today known as sterling silver, named after its association with the currency. Sterling silver is harder than the 0.999 (99.9%) fine silver that was traditionally used, and so sterling silver coins did not wear down as rapidly as fine silver coins. The English currency was almost exclusively silver until 1344, when the gold noble was successfully introduced into circulation. However, silver remained the legal basis for sterling until 1816.\nDuring the time of Henry III, the pound sterling equalled the tower (weight) pound. In the 28th year of Edward I (around 1300), the tale (money) pound, or pound sterling, first began to differ from (weigh less than) the tower pound, from which it originated, for by indenture of that year the pound weight was to contain 20s. 3d. in tale pound. In the 27th year of Edward III (around 1354), the pound sterling was now only 80% of the pound weight, or 9 oz 12 dwt (or 9.6 oz) tower. By an Act of 13 Henry IV (around 1412), the pound weight of standard silver was to contain thirty shillings in tale, or one and a half pounds sterling; thus the pound sterling reduced to two-thirds of a pound weight, or 8 oz tower. The pound sterling was adjusted in weight several more times thereafter.\nIn the reign of Henry IV (1399\u20131413), the penny was reduced in weight to 15 grains (0.97 g) of silver, with a further reduction to 12 grains (0.78 g) in 1464.\n\n\n=== Tudor ===\nDuring the reigns of Henry VIII and Edward VI, the silver coinage was drastically debased, although the pound was redefined to the troy pound of 5,760 grains (373 g) in 1526. In 1544, a silver coinage was issued containing just one-third silver and two-thirds copper\u2014equating to .333 silver, or 33.3% pure. The result was a coin copper in appearance but relatively pale in colour. In 1552, a new silver coinage was introduced, struck in sterling silver. However, the penny's weight was reduced to 8 grains (0.52 g), so 1 troy pound of sterling silver produced 60 shillings of coins. This silver standard was known as the \"60-shilling standard\" and lasted until 1601 when a \"62-shilling standard\" was introduced, reducing the penny's weight to \u200b7 23\u204431 grains (0.50 g).\nThroughout this period, the size and value of the gold coinage fluctuated considerably.\n\n\n=== Unofficial gold standard ===\nIn 1663, a new gold coinage was introduced based on the 22 carat fine guinea. Fixed in weight at \u200b44 1\u20442 to the troy pound from 1670, this coin's value varied considerably until 1717, when it was fixed at 21 shillings (21/-, 1.05 pounds). However, despite the efforts of Sir Isaac Newton, Master of the Mint, to reduce the guinea's value, this valuation overvalued gold relative to silver when compared to the valuations in other European countries. In line with Gresham's Law, British merchants sent silver abroad in payments whilst goods for export were paid for with gold. As a consequence of these flows of silver out and gold in, Great Britain was effectively on a gold standard. Trade with China aggravated this outflow, as the Chinese refused to accept anything but silver in payment for exports. From the mid-17th century, around 28,000 metric tons (27,600 imperial tons) of silver were received by China, principally from European powers, in exchange for Chinese tea and other goods. In order to trade with China, Great Britain had first to trade with the other European nations to receive silver, which led to the East India Company redressing this trade imbalance through the indirect sale of opium to the Chinese.Domestic offtake further reduced silver in circulation, as the improving fortunes of the merchant class led to increased demand for tablewares. Silversmiths had always regarded coinage as a source of raw material, already verified for fineness by the government. As a result, sterling coins were being melted and fashioned into sterling silverware at an accelerating rate. A 1697 Act of Parliament tried to stem this tide by raising the minimum acceptable fineness on wrought plate from sterling's 92.5% to a new Britannia silver standard of 95.83%. Silverware made purely from melted coins would be found wanting when the silversmith took his wares to the Assay Office, thus discouraging the melting of coins.\n\n\n=== Establishment of modern currency ===\nThe Bank of England was founded in 1694, followed by the Bank of Scotland a year later. Both began to issue paper money.\n\n\n=== Currency of Great Britain (1707) and the United Kingdom (1801) ===\nThe pound Scots once had much the same value as the pound sterling, but it suffered far higher devaluation until in the 17th century it was pegged to sterling at a value of 12 pounds Scots = 1 pound sterling.\nIn 1707, the Kingdom of England and the Kingdom of Scotland merged to form the Kingdom of Great Britain. In accordance with the Treaty of Union, the currency of Great Britain was sterling, with the pound Scots soon being replaced by sterling at the pegged value.\nIn 1801, Great Britain and the Kingdom of Ireland were united to form the United Kingdom of Great Britain and Ireland. However, the Irish pound continued to exist and was not replaced by sterling until January 1826. The conversion rate had long been thirteen Irish pounds to twelve pounds sterling. The Irish pound was readopted in 1928, six years after the Anglo-Irish Treaty restored Irish independence.\n\n\n=== Use in the Empire ===\n\nSterling circulated in much of the British Empire. In some parts, it was used alongside local currencies. For example, the gold sovereign was legal tender in Canada despite the use of the Canadian dollar. Several colonies and dominions adopted the pound as their own currency. These included Australia, Barbados, British West Africa, Cyprus, Fiji, British India, the Irish Free State, Jamaica, New Zealand, South Africa and Southern Rhodesia. Some of these retained parity with sterling throughout their existence (e.g. the South African pound), whilst others deviated from parity after the end of the gold standard (e.g. the Australian pound). These currencies and others tied to sterling constituted the sterling area.\nThe original English colonies on mainland North America were not party to the sterling area because the above-mentioned silver shortage in England coincided with these colonies' formative years. As a result of equitable trade (and rather less equitable piracy), the Spanish milled dollar became the most common coin within the English colonies.\n\n\n=== Gold standard ===\nDuring the American war of independence and the Napoleonic wars, Bank of England notes were legal tender, and their value floated relative to gold. The Bank also issued silver tokens to alleviate the shortage of silver coins. In 1816, the gold standard was adopted officially, with the silver standard reduced to 66 shillings (66/-, \u00a33 6s), rendering silver coins a \"token\" issue (i.e. not containing their value in precious metal). In 1817, the sovereign was introduced, valued at 20 shillings. Struck in 22\u2011carat gold, it contained 113 grains (7.3 g) of gold and replaced the guinea as the standard British gold coin without changing the gold standard. In 1825, the Irish pound, which had been pegged to sterling since 1801 at a rate of 13 Irish pounds = 12 pounds sterling, was replaced, at the same rate, with sterling.\nBy the 19th century the pound sterling was widely accepted outside Britain. The American Nellie Bly carried Bank of England notes on her 1889\u20131890 trip around the world in 72 days. During the late 19th and early 20th centuries, many other countries adopted the gold standard. As a consequence, conversion rates between different currencies could be determined simply from the respective gold standards. The pound sterling was equal to 4.85 United States dollars, 5.25 Canadian dollars, 12.10 Dutch guilders, 26.28 French francs (or equivalent currencies in the Latin Monetary Union), 20.43 German marks or 24.02 Austro-Hungarian krone. After the International Monetary Conference of 1867 in Paris, the possibility of the UK joining the Latin Monetary Union was discussed, and a Royal Commission on International Coinage examined the issues, resulting in a decision against joining monetary union.\nThe gold standard was suspended at the outbreak of the war in 1914, with Bank of England and Treasury notes becoming legal tender. Before World War I, the United Kingdom had one of the world's strongest economies, holding 40% of the world's overseas investments. But after the end of the war, the country was indebted: Britain owed \u00a3850 million (\u00a337.3 billion as of 2015) with interest costing the country some 40% of all government spending. To try to resume stability, a version of the gold standard was reintroduced in 1925, under which the currency was fixed to gold at its pre-war peg, but one could only exchange currency for gold bullion, not for coins. This was abandoned on 21 September 1931, during the Great Depression, and sterling suffered an initial devaluation of some 25%.\n\n\n=== Bretton Woods ===\n\nIn 1940, an agreement with the US pegged the pound to the U.S. dollar at a rate of \u00a31 = $4.03. (Only the year before, it had been $4.86.) This rate was maintained through the Second World War and became part of the Bretton Woods system which governed post-war exchange rates. Under continuing economic pressure, and despite months of denials that it would do so, on 19 September 1949 the government devalued the pound by 30.5% to $2.80. The move prompted several other currencies to be devalued against the dollar.\nOperation Bernhard was the codename of a secret Nazi plan devised during the Second World War by the RSHA and the SS to destabilise the British economy via economic warfare by flooding the global economy and the British Empire with forged Bank of England \u00a35, \u00a310, \u00a320, and \u00a350 notes.\nIn 1961, 1964, and 1966, the pound came under renewed pressure, as speculators were selling pounds for dollars. In summer 1966, with the value of the pound falling in the currency markets, exchange controls were tightened by the Wilson government. Among the measures, tourists were banned from taking more than \u00a350 out of the country in travellers' cheques and remittances, plus \u00a315 in cash; this restriction was not lifted until 1979. The pound was devalued by 14.3% to $2.40 on 18 November 1967.\n\n\n=== Decimalisation ===\n\nUntil decimalisation, amounts were stated in pounds, shillings, and pence, with various widely understood notations. The same amount was denoted by 32s 6d, 32/6, \u00a31 12s 6d, \u00a31/12/6. It was customary to specify some prices (for example professional fees and auction prices for works of art) in guineas (one guinea was 21 shillings) although guinea coins were no longer in use.\nFormal parliamentary proposals to decimalise sterling were first made in 1824 when Sir John Wrottesley, MP for Staffordshire, asked in the British House of Commons whether consideration had been given to decimalising the currency. Wrottesley raised the issue in the House of Commons again in 1833, and it was again raised by John Bowring, MP for Kilmarnock Burghs, in 1847 whose efforts led to the introduction in 1848 of what was in effect the first decimal coin in the United Kingdom, the florin, valued at one-tenth of a pound sterling. However, full decimalisation was resisted, although the florin coin, re-designated as ten new pence, survived the transfer to a full decimal system in 1971, with examples surviving in British coinage until 1993.\nJohn Benjamin Smith, MP for Stirling Burghs, raised the issue of full decimalisation again in Parliament in 1853, resulting in the Chancellor of the Exchequer, William Gladstone, announcing soon afterwards that \"the great question of a decimal coinage\" was \"now under serious consideration\". A full proposal for the decimalisation of sterling was then tabled in the House of Commons in June 1855, by William Brown, MP for Lancashire Southern, with the suggestion that the pound sterling be divided into one thousand parts, each called a \"mil\", or alternatively a farthing, as the pound was then equivalent to 960 farthings which could easily be rounded up to one thousand farthings in the new system. This did not result in the conversion of the pound sterling into a decimal system, but it was agreed to establish a Royal Commission to look into the issue. However, largely due to the hostility to decimalisation of two of the appointed commissioners, Lord Overstone (a banker) and John Hubbard (Governor of the Bank of England), decimalisation in Britain was effectively quashed for over a hundred years.However, the pound sterling was decimalised in various British colonial territories before the United Kingdom (and in several cases in line with William Brown's proposal that the pound be divided into 1,000 parts, called mils). These included Hong Kong from 1863 to 1866; Cyprus from 1955 until 1960 (and continued on the island as the division of the Cypriot pound until 1983); and the Palestine Mandate from 1926 until 1948.Towards the end of the Second World War, various attempts to decimalise the pound sterling in the United Kingdom were made. Later, in 1966, the British government decided to include in the Queen's Speech a plan to convert the pound into a decimal currency. As a result of this, on 15 February 1971, the UK decimalised the pound sterling, replacing the shilling and penny with a single subdivision, the new penny. For example, a price tag of \u00a31 12s 6d became \u200b\u00a31.62 1\u20442. The word \"new\" was omitted from coins minted after 1981.\n\n\n=== Free-floating pound ===\nWith the breakdown of the Bretton Woods system, the pound floated from August 1971 onwards. At first it appreciated a little, rising to almost $2.65 in March 1972 from $2.42, the upper bound of the band in which it had been fixed. The sterling area effectively ended at this time, when the majority of its members also chose to float freely against the pound and the dollar.\n\n\n=== 1976 sterling crisis ===\nJames Callaghan became Prime Minister in 1976. He was immediately told the economy was facing huge problems, according to documents released in 2006 by the National Archives. The effects of the 1973 oil crisis were still being felt, with inflation rising to over 27% in 1975. Financial markets were beginning to believe the pound was overvalued, and in April that year The Wall Street Journal advised the sale of sterling investments in the face of high taxes, in a story that ended with \"goodbye, Great Britain. It was nice knowing you\". At the time the UK government was running a budget deficit, and Labour's strategy emphasised high public spending. Callaghan was told there were three possible outcomes: a disastrous free fall in sterling, an internationally unacceptable siege economy, or a deal with key allies to prop up the pound while painful economic reforms were put in place. The US government feared the crisis could endanger NATO and the European Economic Community (EEC), and in light of this the US Treasury set out to force domestic policy changes. In November 1976 the International Monetary Fund (IMF) announced the conditions for a loan, including deep cuts in public expenditure.\n\n\n=== 1979\u201389 ===\nThe Conservative Party was elected to office in 1979, on a programme of fiscal austerity. Initially the pound rocketed, moving above US$2.40, as interest rates rose in response to the monetarist policy of targeting money supply. The high exchange rate was widely blamed for the deep recession of 1981. Sterling fell sharply after 1980; at its lowest, the pound stood at just $1.03 in March 1985, before rising to $1.70 in December 1989.\n\n\n=== Following the Deutsche Mark ===\nIn 1988, Margaret Thatcher's Chancellor of the Exchequer, Nigel Lawson, decided that the pound should \"shadow\" the West German Deutsche Mark (DM), with the unintended result of a rapid rise in inflation as the economy boomed due to low interest rates. (For ideological reasons, the Conservative Government declined to use alternative mechanisms to control the explosion of credit. For this reason, former Prime Minister Edward Heath referred to Lawson as a \"one club golfer\".)Following German reunification in 1990, the reverse held true, as high German borrowing costs to fund Eastern reconstruction, exacerbated by the political decision to convert the Ostmark to the DM on a 1:1 basis, meant that interest rates in other countries shadowing the DM, especially the UK, were far too high relative to domestic circumstances, leading to a housing decline and recession.\n\n\n=== Following the European Currency Unit ===\nOn 8 October 1990 the Conservative government (Third Thatcher ministry) decided to join the European Exchange Rate Mechanism (ERM), with the pound set at DM2.95. However, the country was forced to withdraw from the system on \"Black Wednesday\" (16 September 1992) as Britain's economic performance made the exchange rate unsustainable.\n'Black Wednesday' saw interest rates jump from 10% to 15% in an unsuccessful attempt to stop the pound from falling below the ERM limits. The exchange rate fell to DM2.20. Those who had argued for a lower GBP/DM exchange rate were vindicated as the cheaper pound encouraged exports and contributed to the economic prosperity of the 1990s.\n\n\n=== Following inflation targets ===\nIn 1997, the newly elected Labour government handed over day-to-day control of interest rates to the Bank of England (a policy that had originally been advocated by the Liberal Democrats). The Bank is now responsible for setting its base rate of interest so as to keep inflation (as measured by the Consumer Price Index (CPI)) very close to 2% per annum. Should CPI inflation be more than one percentage point above or below the target, the governor of the Bank of England is required to write an open letter to the Chancellor of the Exchequer explaining the reasons for this and the measures which will be taken to bring this measure of inflation back in line with the 2% target. On 17 April 2007, annual CPI inflation was reported at 3.1% (inflation of the Retail Prices Index was 4.8%). Accordingly, and for the first time, the Governor had to write publicly to the government explaining why inflation was more than one percentage point higher than its target.\n\n\n=== Euro ===\n\nAs a member of the European Union, the United Kingdom could have adopted the euro as its currency. However, the subject was always politically controversial, and the UK negotiated an opt-out on this issue.\nIn 2007, Gordon Brown, then Chancellor of the Exchequer, ruled out membership for the foreseeable future, saying that the decision not to join had been right for Britain and for Europe.On 1 January 2008, with the Republic of Cyprus switching its currency from the Cypriot pound to the euro, the British sovereign bases on Cyprus (Akrotiri and Dhekelia) followed suit, making the Sovereign Base Areas the only territory under British sovereignty to officially use the euro.The 2016 referendum which started the process of United Kingdom's withdrawal from the European Union makes adoption of the euro extremely unlikely.\nThe government of former Prime Minister Tony Blair had pledged to hold a public referendum to decide on adoption of the Euro should \"five economic tests\" be met, to increase the likelihood that any adoption of the euro would be in the national interest. In addition to these internal (national) criteria, the UK would have to meet the European Union's economic convergence criteria (Maastricht criteria) before being allowed to adopt the euro. The Conservative and Liberal Democrat coalition government (2010\u20132015) ruled out joining the euro for that parliamentary term. Currently, the UK's annual government deficit, as a percentage of the GDP, is above the defined threshold.\nThe idea of replacing the pound with the euro was always controversial with the British public, partly because of the pound's identity as a symbol of British sovereignty and because it would, according to many critics, have led to suboptimal interest rates, harming the British economy. In December 2008, the results of a BBC poll of 1000 people suggested that 71% would vote no to the euro, 23% would vote yes, while 6% said they were unsure. The pound did not join the Second European Exchange Rate Mechanism (ERM II) after the euro was created. Denmark and the UK have opt-outs from entry to the euro. Theoretically, every other EU nation must eventually sign up.\nThe Scottish Conservative Party claimed that there was an issue for Scotland in that the adoption of the euro would mean the end of nationally distinctive banknotes, as the euro banknotes do not have national designs. Before the 'No' vote in the Scottish independence referendum in 2014, the Scottish National Party affirmed that the euro would not be the national currency of an independent Scotland.\n\n\n=== Recent exchange rates ===\n\nThe pound and the euro fluctuate in value against one another, although there may be correlation between movements in their respective exchange rates with other currencies such as the US dollar. Inflation concerns in the UK led the Bank of England to raise interest rates in late 2006 and 2007. This caused the pound to appreciate against other major currencies and, with the US dollar depreciating at the same time, the pound hit a 15-year high against the US dollar on 18 April 2007, reaching US$2 the day before, for the first time since 1992. The pound and many other currencies continued to appreciate against the dollar; sterling hit a 26-year high of US$2.1161 on 7 November 2007 as the dollar fell worldwide. From mid-2003 to mid-2007, the pound/euro rate remained within a narrow range (\u20ac1.45 \u00b1 5%).Following the global financial crisis in late 2008, the pound depreciated sharply, reaching $1.38 (US) on 23 January 2009 and falling below \u20ac1.25 against the euro in April 2008. There was a further decline during the remainder of 2008, most dramatically on 29 December when its euro rate hit an all-time low at \u20ac1.0219, while its US dollar rate depreciated. The pound appreciated in early 2009, reaching a peak against the euro of \u20ac1.17 in mid-July. In the following months the pound remained broadly steady against the euro, with the pound's valued on 27 May 2011 at \u20ac1.15 and US$1.65.\nOn 5 March 2009, the Bank of England announced that it would pump \u00a375 billion of new capital into the British economy, through a process known as quantitative easing (QE). This was the first time in the United Kingdom's history that this measure had been used, although the Bank's Governor Mervyn King suggested it was not an experiment.The process saw the Bank of England creating new money for itself, which it then used to purchase assets such as government bonds, secured commercial paper, or corporate bonds. The initial amount stated to be created through this method was \u00a375 billion, although Chancellor of the Exchequer Alistair Darling had given permission for up to \u00a3150 billion to be created if necessary. It was expected that the process would continue for three months, with results only likely in the long term. By 5 November 2009, some \u00a3175 billion had been injected using QE, and the process remained less effective in the long term. In July 2012, the final increase in QE meant it had peaked at \u00a3375 billion, then holding solely UK Government bonds, representing one third of the UK national debt.The result of the 2016 UK referendum on EU membership caused a major decline in the pound against other world currencies as the future of international trade relationships and domestic political leadership became unclear. The referendum result weakened sterling against the euro by 5% overnight. The night before the vote, the pound was trading at \u20ac1.30; the next day, this had fallen to \u20ac1.23. By October 2016, the exchange rate was \u20ac1.12 to the pound, a fall of 14% since the referendum. By the end of August 2017 the pound was even lower, at \u20ac1.08. Against the US dollar, meanwhile, the pound fell from $1.466 to $1.3694 when the referendum result was first revealed, and down to $1.2232 by October 2016, a fall of 16%.\n\n\n=== Annual inflation rate ===\nThe Bank of England had stated in 2009 that the decision had been taken to prevent the rate of inflation falling below the 2% target rate. Mervyn King, the Governor of the Bank of England, had also suggested there were no other monetary options left, as interest rates had already been cut to their lowest level ever (0.5%) and it was unlikely that they would be cut further.The inflation rate rose in following years, reaching 5.2% per year (based on the Consumer Price Index) in September 2011, then decreased to around 2.5% the following year.\n\n\n== Coins ==\n\n\n=== Pre-decimal coins ===\nThe silver penny (plural: pence; abbreviation: d) was the principal and often the only coin in circulation from the 8th century until the 13th century. Although some fractions of the penny were struck (see farthing and halfpenny), it was more common to find pennies cut into halves and quarters to provide smaller change. Very few gold coins were struck, with the gold penny (worth 20 silver pence) a rare example. However, in 1279, the groat, worth 4d, was introduced, with the half groat following in 1344. 1344 also saw the establishment of a gold coinage with the introduction (after the failed gold florin) of the noble worth six shillings and eight pence (6/8) (i.e. 3 nobles to the pound), together with the half and quarter noble. Reforms in 1464 saw a reduction in value of the coinage in both silver and gold, with the noble renamed the ryal and worth 10/- (i.e. 2 to the pound) and the angel introduced at the noble's old value of 6/8.\nThe reign of Henry VII saw the introduction of two important coins: the shilling (abbr.: s; known as the testoon) in 1487 and the pound (known as the sovereign, abbr.: \u00a3 or L) in 1489. In 1526, several new denominations of gold coins were added, including the crown and half crown worth five shillings (5/-), and two shillings and six pence (2/6, two and six) respectively. Henry VIII's reign (1509\u20131547) saw a high level of debasement which continued into the reign of Edward VI (1547\u20131553). This debasement was halted in 1552, and a new silver coinage was introduced, including coins for 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. In the reign of Elizabeth I (1558\u20131603), silver \u200b3\u20444d and \u200b1 1\u20442d coins were added, but these denominations did not last. Gold coins included the half-crown, crown, angel, half-sovereign and sovereign. Elizabeth's reign also saw the introduction of the horse-drawn screw press to produce the first \"milled\" coins.\nFollowing the succession of the Scottish King James VI to the English throne, a new gold coinage was introduced, including the spur ryal (15/-), the unite (20/-) and the rose ryal (30/-). The laurel, worth 20/-, followed in 1619. The first base metal coins were also introduced: tin and copper farthings. Copper halfpenny coins followed in the reign of Charles I. During the English Civil War, a number of siege coinages were produced, often in unusual denominations.\nFollowing the restoration of the monarchy in 1660, the coinage was reformed, with the ending of production of hammered coins in 1662. The guinea was introduced in 1663, soon followed by the \u200b1\u20442, 2 and 5 guinea coins. The silver coinage consisted of denominations of 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. Due to the widespread export of silver in the 18th century, the production of silver coins gradually came to a halt, with the half crown and crown not issued after the 1750s, the 6d and 1/- stopping production in the 1780s. In response, copper 1d and 2d coins and a gold \u200b1\u20443 guinea (7/-) were introduced in 1797. The copper penny was the only one of these coins to survive long.\nTo alleviate the shortage of silver coins, between 1797 and 1804, the Bank of England counterstamped Spanish dollars (8 reales) and other Spanish and Spanish colonial coins for circulation. A small counterstamp of the King's head was used. Until 1800, these circulated at a rate of 4/9 for 8 reales. After 1800, a rate of 5/- for 8 reales was used. The Bank then issued silver tokens for 5/- (struck over Spanish dollars) in 1804, followed by tokens for 1/6 and 3/- between 1811 and 1816.\nIn 1816, a new silver coinage was introduced in denominations of 6d, 1/-, 2/6 (half-crown) and 5/- (crown). The crown was only issued intermittently until 1900. It was followed by a new gold coinage in 1817 consisting of 10/- and \u00a31 coins, known as the half sovereign and sovereign. The silver 4d coin was reintroduced in 1836, followed by the 3d in 1838, with the 4d coin issued only for colonial use after 1855. In 1848, the 2/- florin was introduced, followed by the short-lived double florin in 1887. In 1860, copper was replaced by bronze in the farthing (quarter penny, \u200b1\u20444d), halfpenny and penny.\nDuring the First World War, production of the sovereign and half-sovereign was suspended, and although the gold standard was later restored, the coins saw little circulation thereafter. In 1920, the silver standard, maintained at .925 since 1552, was reduced to .500. In 1937, a nickel-brass 3d coin was introduced; the last silver 3d coins were issued seven years later. In 1947, the remaining silver coins were replaced with cupro-nickel, with the exception of Maundy coinage which was then restored to .925. Inflation caused the farthing to cease production in 1956 and be demonetised in 1960. In the run-up to decimalisation, the halfpenny and half-crown were demonetised in 1969.\n\n\n=== Decimal coins ===\nBritish coinage timeline:\n\n1968: The first decimal coins were introduced. These were cupro-nickel 5p and 10p coins which were equivalent to, and circulated alongside, the one shilling coin and the two shilling or florin coin respectively.\n1969: The curved equilateral heptagonal cupro-nickel 50p coin replaced the 10/- note.\n1971: The decimal coinage was completed when decimalisation came into effect in 1971 with the introduction of the bronze \u200b1\u20442p, 1p and 2p coins and the withdrawal of the 1d and 3d coins.\n1980: Withdrawal of 6d coins, which had circulated at a value of \u200b2 1\u20442p.\n1982: The word \"new\" was dropped from the coinage and a 20p coin was introduced.\n1983: A \u00a31 coin was introduced.\n1983: The \u200b1\u20442p coin was last produced.\n1984: The \u200b1\u20442p coin was demonetised.\n1990: The crown, worth 25p, was re-tariffed for future issues as a commemorative coin at \u00a35.\n1990s: The 5p, 10p and 50p coins became smaller.\n1991: Pre-decimal 1/- coins, which had continued to circulate with a value of 5p, were demonetised in 1991 after the 5p coin became smaller. At the same time larger first generation decimal 5p coins were demonetised.\n1992: Bronze was replaced with copper-plated steel.\n1993: Pre-decimal 2/- coins, or florin, a legacy of the 1848 attempt at decimalisation were demonetised. At the same time larger first generation decimal 10p coins were demonetised.\n1998: The bi-metallic \u00a32 coin was introduced.\n2007: By now the value of copper in the pre-1992 1p and 2p coins (which are 97% copper) exceeded those coins' face value to such an extent that melting down the coins by entrepreneurs was becoming worthwhile (with a premium of up to 11%, with smelting costs reducing this to around 4%)\u2014although this is illegal, and the market value of copper has subsequently fallen dramatically from these earlier peaks.\nIn April 2008, an extensive redesign of the coinage was unveiled. The 1p, 2p, 5p, 10p, 20p and 50p coins feature parts of the Royal Shield on their reverse; and the reverse of the pound coin showed the whole shield. The coins were issued gradually into circulation, starting in mid-2008. They have the same sizes, shapes and weights as those with the old designs which, apart from the round pound coin which was withdrawn in 2017, continue to circulate.\n2012: The 5p and 10p coins were changed from cupro-nickel to nickel-plated steel.\n2017: A more secure twelve-sided \u00a31 coin was introduced to reduce forgery. The old round \u00a31 coin ceased to be legal tender on 15 October 2017.At present, the oldest circulating coins in the UK are the 1p and 2p copper coins introduced in 1971. No other coins from before 1982 are in circulation. Prior to the demonetisation of the larger 10p in 1993, the oldest circulating coins had usually dated from 1947: although older coins (shilling; florin, sixpence to 1980) were still legal tender, inflation meant that their silver content was worth more than their face value, which meant that they tended to be removed from circulation. Before decimalisation in 1971, a handful of change might have contained coins 100 or more years old, bearing any of five monarchs' heads, especially in the copper coins.\n\n\n== Banknotes ==\n\nThe first sterling notes were issued by the Bank of England shortly after its foundation in 1694. Denominations were initially handwritten on the notes at the time of issue. From 1745, the notes were printed in denominations between \u00a320 and \u00a31000, with any odd shillings added by hand. \u00a310 notes were added in 1759, followed by \u00a35 in 1793 and \u00a31 and \u00a32 in 1797. The lowest two denominations were withdrawn after the end of the Napoleonic wars. In 1855, the notes were converted to being entirely printed, with denominations of \u00a35, \u00a310, \u00a320, \u00a350, \u00a3100, \u00a3200, \u00a3300, \u00a3500 and \u00a31000 issued.\nThe Bank of Scotland began issuing notes in 1695. Although the pound Scots was still the currency of Scotland, these notes were denominated in sterling in values up to \u00a3100. From 1727, the Royal Bank of Scotland also issued notes. Both banks issued some notes denominated in guineas as well as pounds. In the 19th century, regulations limited the smallest note issued by Scottish banks to be the \u00a31 denomination, a note not permitted in England.\nWith the extension of sterling to Ireland in 1825, the Bank of Ireland began issuing sterling notes, later followed by other Irish banks. These notes included the unusual denominations of 30/- and \u00a33. The highest denomination issued by the Irish banks was \u00a3100.\nIn 1826, banks at least 65 miles (105 km) from London were given permission to issue their own paper money. From 1844, new banks were excluded from issuing notes in England and Wales but not in Scotland and Ireland. Consequently, the number of private banknotes dwindled in England and Wales but proliferated in Scotland and Ireland. The last English private banknotes were issued in 1921.\nIn 1914, the Treasury introduced notes for 10/- and \u00a31 to replace gold coins. These circulated until 1928, when they were replaced by Bank of England notes. Irish independence reduced the number of Irish banks issuing sterling notes to five operating in Northern Ireland. The Second World War had a drastic effect on the note production of the Bank of England. Fearful of mass forgery by the Nazis (see Operation Bernhard), all notes for \u00a310 and above ceased production, leaving the bank to issue only 10/-, \u00a31 and \u00a35 notes. Scottish and Northern Irish issues were unaffected, with issues in denominations of \u00a31, \u00a35, \u00a310, \u00a320, \u00a350 and \u00a3100.\nThe Bank of England reintroduced \u00a310 notes in 1964. In 1969, the 10/- note was replaced by the 50p coin to prepare for decimalisation. \u00a320 Bank of England notes were reintroduced in 1970, followed by \u00a350 in 1981. A \u00a31 coin was introduced in 1983, and Bank of England \u00a31 notes were withdrawn in 1988. Scottish and Northern Irish banks followed, with only the Royal Bank of Scotland continuing to issue this denomination.\nUK notes include raised print (e.g. on the words \"Bank of England\"); watermarks; embedded metallic thread; holograms; and fluorescent ink visible only under UV lamps. Three printing techniques are involved: offset litho, intaglio and letterpress; and the notes incorporate a total of 85 specialized inks.The Bank of England produces notes named \"giant\" and \"titan\". A giant is a one million pound note, and a titan is a one hundred million pound bank note, of which there are about 40. Giants and titans are used only within the banking system.\n\n\n=== Polymer banknotes ===\nThe \u00a35 polymer banknote, issued by Northern Bank (now Danske Bank) in 2000, was the only polymer note in circulation until 2016, although Danske Bank also produces paper-based \u00a310, \u00a320 and \u00a350 notes. The Bank of England introduced \u00a35 polymer banknotes in September 2016, and the paper \u00a35 notes were withdrawn on 5 May 2017. This date was picked due to its short format, 5/5. A polymer \u00a310 banknote was introduced on 14 September 2017, and the paper note was withdrawn on 1 March 2018. A polymer \u00a320 banknote will be introduced in 2020.\n\n\n== Monetary policy ==\nAs the central bank of the United Kingdom which has been delegated authority by the government, the Bank of England sets the monetary policy for the British pound by controlling the amount of money in circulation.  It has a monopoly on issuance of banknotes in England and Wales, and regulates the amount of banknotes issued by seven authorized banks in Scotland and Northern Ireland.  HM Treasury has reserve powers to give orders to the committee \"if they are required in the public interest and by extreme economic circumstances\" but such orders must be endorsed by Parliament within 28 days.Unlike banknotes which have separate issuers in Scotland and Northern Ireland, all UK coins are issued by the Royal Mint, which is an independent enterprise (wholly owned by the Treasury) which also mints coins for other countries.\nIn Britain's Crown Dependencies, the Manx pound, Jersey pound, and Guernsey pound are unregulated by the Bank of England and are issued independently.  However, they are maintained at a fixed exchange rate by their respective governments, and Bank of England notes have been made legal tender on the islands, forming a sort of one-way de facto currency union.  These currencies do not have ISO 4217 codes so \"GBP\" is usually used to represent all of them; informal codes are used where the difference is important.\nBritish Overseas Territories are responsible for the monetary policy of their own currencies (where they exist), and have their own ISO 4217 codes.  The Falkland Islands pound, Gibraltar pound, and Saint Helena pound are set at a fixed 1:1 exchange rate with the British pound by local governments.\n\n\n== Legal tender and national issues ==\n\nLegal tender in the United Kingdom is defined such that \"a debtor cannot successfully be sued for non-payment if he pays into court in legal tender.\" Parties can alternatively settle a debt by other means with mutual consent. Strictly speaking it is necessary for the debtor to offer the exact amount due as there is no obligation for the other party to provide change.Throughout the UK, \u00a31 and \u00a32 coins are legal tender for any amount, with the other coins being legal tender only for limited amounts. Bank of England notes are legal tender for any amount in England and Wales, but not in Scotland or Northern Ireland. (Bank of England 10/- and \u00a31 notes were legal tender, as were Scottish banknotes, during World War II under the Currency (Defence) Act 1939, which was repealed on 1 January 1946.) Channel Islands and Isle of Man banknotes are legal tender only in their respective jurisdictions.Bank of England, Scottish, Northern Irish, Channel Islands, Isle of Man, Gibraltar, and Falkland banknotes may be offered anywhere in the UK, although there is no obligation to accept them as a means of payment, and acceptance varies. For example, merchants in England generally accept Scottish and Northern Irish bills, but some unfamiliar with them may reject them. However, Scottish and Northern Irish bills both tend to be accepted in Scotland and Northern Ireland, respectively. Merchants in England generally do not accept Jersey, Guernsey, Isle of Man, Gibraltar, and Falkland notes but Isle of Man notes are generally accepted in Northern Ireland. Bank of England notes are generally accepted in the Falklands and Gibraltar, but for example Scottish and Northern Irish notes are not. Since all of the bills are denominated in pounds sterling, banks will exchange them for locally issued bills at face value, though some in the UK have had trouble exchanging Falkland Islands pounds.Commemorative \u00a35 and 25p (crown) coins, rarely seen in circulation, are legal tender, as are the bullion coins issued by the Mint.\n\n\n== Value ==\nIn 2006, the House of Commons Library published a research paper which included an index of prices in pounds for each year between 1750 and 2005, where 1974 was indexed at 100.Regarding the period 1750\u20131914 the document states: \"Although there was considerable year on year fluctuation in price levels prior to 1914 (reflecting the quality of the harvest, wars, etc.) there was not the long-term steady increase in prices associated with the period since 1945\". It goes on to say that \"Since 1945 prices have risen in every year with an aggregate rise of over 27 times\".\nThe value of the index in 1751 was 5.1, increasing to a peak of 16.3 in 1813 before declining very soon after the end of the Napoleonic Wars to around 10.0 and remaining in the range 8.5\u201310.0 at the end of the 19th century. The index was 9.8 in 1914 and peaked at 25.3 in 1920, before declining to 15.8 in 1933 and 1934\u2014prices were only about three times as high as they had been 180 years earlier.Inflation has had a dramatic effect during and after World War II: the index was 20.2 in 1940, 33.0 in 1950, 49.1 in 1960, 73.1 in 1970, 263.7 in 1980, 497.5 in 1990, 671.8 in 2000 and 757.3 in 2005.\nThe following table shows the equivalent amount of goods and services that, in a particular year, could be purchased with \u00a31.The table shows that from 1971 to 2015 the British pound lost about 92% of its buying power.\n\nThe smallest coin in 1971 was the \u200b1\u20442p, worth about 6.4p in 2015 prices.\n\n\n== Exchange rate ==\nThe pound is freely bought and sold on the foreign exchange markets around the world, and its value relative to other currencies therefore fluctuates.As of  27 August 2017, \u00a31 was worth US$1.289, \u20ac1.0808, \u00a5141, CHF 1.22329, A$1.6247, C$1.6083 or INR 82.50.\n\n\n== Reserve ==\nSterling is used as a reserve currency around the world and is currently ranked fourth in value held as reserves.\n\nCurrency composition of official foreign exchange reserves (1965\u20132017)\n\n\n== See also ==\nAngevin pound\nGreen pound\nList of currencies in Europe\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nRoyal Mint\nCoin Types from Great Britain Lists, pictures, and values of Great Britain coin types\nBritish Coins \u2013 information about British coins (from 1656 to 1952)\nA history of sterling Daily Telegraph\nPurchasing Power of British Pounds from 1264 to 2007\nFive Ways to Compute the Relative Value of a UK Pound Amount, 1830\u2013present\nImages of historic and modern British bank notes\nCurrent wholesale exchange rates between currencies\nHistorical Currency Converter Historical value of the pound in other currencies\nThe banknotes of the United Kingdom (in English) (in German)\nPound Sterling Information about the coins of the modern British pound",
        "unit": "pound sterling",
        "url": "https://en.wikipedia.org/wiki/Pound_sterling"
    },
    {
        "_id": "Gigabit",
        "clean": "Gigabit",
        "text": "The gigabit is a multiple of the unit bit for digital information or computer storage. The prefix giga (symbol G) is defined in the International System of Units (SI) as a multiplier of 109 (1 billion, short scale), and therefore\n\n1 gigabit = 109bits = 1000000000bits.The gigabit has the unit symbol Gbit or Gb.\nUsing the common byte size of 8 bits, 1 Gbit is equal to 125 megabytes (MB) or approximately 119 mebibytes (MiB).\nThe gigabit is closely related to the gibibit, a unit multiple derived from the binary prefix gibi (symbol Gi) of the same order of magnitude, which is equal to 230bits = 1073741824bits, or approximately 7% larger than the gigabit.\n\n\n== See also ==\nSI prefix\nGigabyte\nGigabit per second\nGigabit Ethernet\n10 Gigabit Ethernet\n\n\n== References ==",
        "unit": "gigabit",
        "url": "https://en.wikipedia.org/wiki/Gigabit"
    },
    {
        "_id": "Short_ton",
        "clean": "Short ton",
        "text": "The short ton is a unit of weight equal to 2,000 pounds (907.18474 kg). The unit is most commonly used in the United States where it is known simply as the ton.\n\n\n== United States ==\n\nIn the United States, a short ton is usually known simply as a \"ton\", without distinguishing it from the tonne (1,000 kilograms or 2,204.62262 pounds), known there as the \"metric ton\", or the long ton also known as the \"Imperial ton\" (2,240 pounds or 1,016.0469088 kilograms). There are, however, some U.S. applications where unspecified tons normally means long tons (for example, naval ships) or metric tons (world grain production figures).\nBoth the long and short ton are defined as 20 hundredweights, but a hundredweight is 100 pounds (45.359237 kg) in the U.S. system (short or net hundredweight) and 112 pounds (50.80234544 kg) in the imperial system (long or gross hundredweight).A short ton\u2013force is 2,000 pounds-force (8,896.443230521 N).\n\n\n== United Kingdom ==\nIn the United Kingdom, short tons are rarely used.  The word \"ton\" is taken to refer to a long ton, and metric tons are distinguished by the \"tonne\" spelling.  Most Commonwealth countries followed British practice with the exception of Canada, which used short tons as well as long tons.  Canada now predominantly uses metric tons (tonnes).\n\n\n== See also ==\nLong ton, 2,240 lb (1,016.0469088 kg)\nTon\nTonne, also known as a metric ton (t), equal to 1,000 kg (2,204.6226218 lb) or 1 megagram.\nTonnage, volume measurement used in maritime shipping, originally based on 100 cubic feet (2.8316846592 m3).\n\n\n== References ==",
        "unit": "short ton",
        "url": "https://en.wikipedia.org/wiki/Short_ton"
    },
    {
        "_id": "TNT_equivalent",
        "clean": "TNT equivalent",
        "text": "TNT equivalent is a convention for expressing energy, typically used to describe the energy released in an explosion. The \"ton of TNT\" is a unit of energy defined by that convention to be 4.184 gigajoules, which is the approximate energy released in the detonation of a metric ton (1,000 kilograms or one megagram) of TNT. In other words, for each gram of TNT exploded, 4,184 joules of energy are released. \nThis convention intends to compare the destructiveness of an event with that of traditional explosive materials, of which TNT is a typical example, although other conventional explosives such as dynamite contain more energy.\n\n\n== Kiloton and megaton ==\nThe \"kiloton (of TNT)\" is a unit of energy equal to 4.184 terajoules.\nThe \"megaton (of TNT)\" is a unit of energy equal to 4.184 petajoules.\nThe kiloton and megaton of TNT have traditionally been used to describe the energy output, and hence the destructive power, of a nuclear weapon. The TNT equivalent appears in various nuclear weapon control treaties, and has been used to characterize the energy released in such other highly destructive events as an asteroid impact.\n\n\n== Historical derivation of the value ==\nA gram of TNT releases 2673\u20136702 J (joules) upon explosion. The energy liberated by one gram of TNT was arbitrarily defined as a matter of convention to be 4184 J, which is exactly one kilocalorie.\nAn explosive's energy is normally expressed as the thermodynamic work produced by its detonation, which for TNT has been accurately measured as 4686 J/g from a large sample of air blast experiments, and theoretically calculated to be 4853 J/g.The measured, pure heat output of a gram of TNT is only 2724 J, but this is not the important value for explosive blast effect calculations.\nAlternative TNT equivalency can be calculated as a function of when in the detonation the value is measured and which property is being compared.A kiloton of TNT can be visualized as a cube of TNT 8.46 metres (27.8 ft) on a side.\n\n\n== Conversion to other units ==\n1 ton TNT equivalent is approximately:\n\n1.0\u00d7109 calories\n4.184\u00d7109 joules\n3.96831\u00d7106 British thermal units\n3.08802\u00d7109 foot pounds\n1.162\u00d7103 kilowatt hours\n\n\n== Examples ==\n\n\n== Relative effectiveness factor ==\nThe relative effectiveness factor (RE factor) relates an explosive's demolition power to that of TNT, in units of the TNT equivalent/kg (TNTe/kg). The RE factor is the relative mass of TNT to which an explosive is equivalent: The greater the RE, the more powerful the explosive.\nThis enables engineers to determine the proper masses of different explosives when applying blasting formulas developed specifically for TNT. For example, if a timber-cutting formula calls for a charge of 1 kg of TNT, then based on octanitrocubane's RE factor of 2.38, it would take only 1.0/2.38 (or 0.42) kg of it to do the same job. Using PETN, engineers would need 1.0/1.66 (or 0.60) kg to obtain the same effects as 1 kg of TNT. With ANFO or ammonium nitrate, they would require 1.0/0.74 (or 1.35) kg or 1.0/0.42 (or 2.38) kg, respectively.\n\n\n=== RE factor examples ===\n*: TBX (thermobaric explosives) or EBX (enhanced blast explosives), in a small, confined space, may have over twice the power of destruction. The total power of aluminized mixtures strictly depends on the condition of explosions.\n\n\n=== Nuclear examples ===\n\n\n== See also ==\nBrisance\nNet explosive quantity\nNuclear weapon yield\nOrders of magnitude (energy)\nRelative effectiveness factor\nTable of explosive detonation velocities\nTon\nTonne\nTonne of oil equivalent, a unit of energy almost exactly 10 tonnes of TNT\n\n\n== References ==\n\nThompson, A.; Taylor, B.N. (July 2008). Guide for the Use of the International System of Units (SI). NIST Special Publication. 811. National Institute of Standards and Technology. Version 3.2.\nNuclear Weapons FAQ Part 1.3\nRhodes, Richard (2012). The Making of the Atomic Bomb (25th Anniversary ed.). Simon & Schuster. ISBN 978-1-4516-7761-4.\nCooper, Paul W. (1996), Explosives Engineering, New York: Wiley-VCH, ISBN 0-471-18636-8\nHQ Department of the Army (2004) [1967], Field Manual 5-25: Explosives and Demolitions, Washington, D.C.: Pentagon Publishing, pp. 83\u201384, ISBN 0-9759009-5-1\nExplosives - Compositions, Alexandria, VA: GlobalSecurity.org, retrieved September 1, 2010\nUrba\u0144ski, Tadeusz (1985) [1984], Chemistry and Technology of Explosives, Volumes I\u2013IV (second ed.), Oxford: Pergamon\nMathieu, J\u00f6rg; Stucki, Hans (2004), \"Military High Explosives\", CHIMIA International Journal for Chemistry, Schweizerische Chemische Gesellschaft, 58 (6): 383\u2013389, doi:10.2533/000942904777677669, ISSN 0009-4293\n3. Thermobaric Explosives, Advanced Energetic Materials, 2004., The National Academies Press, nap.edu, 2004",
        "unit": "kiloton",
        "url": "https://en.wikipedia.org/wiki/TNT_equivalent"
    },
    {
        "_id": "Speed_of_light",
        "clean": "Speed of light",
        "text": "The speed of light in vacuum, commonly denoted c, is a universal physical constant important in many areas of physics. Its exact value is 299,792,458 metres per second (approximately 300,000 km/s (186,000 mi/s)). It is exact because by international agreement a metre is defined to be the length of the path travelled by light in vacuum during a time interval of 1/299792458 second. According to special relativity, c is the maximum speed at which all conventional matter and hence all known forms of information in the universe can travel. Though this speed is most commonly associated with light, it is in fact the speed at which all massless particles and changes of the associated fields travel in vacuum (including electromagnetic radiation and gravitational waves). Such particles and waves travel at c regardless of the motion of the source or the inertial reference frame of the observer. In the special and general theories of relativity, c interrelates space and time, and also appears in the famous equation of mass\u2013energy equivalence E = mc2.The speed at which light propagates through transparent materials, such as glass or air, is less than c; similarly, the speed of electromagnetic waves in wire cables is slower than c. The ratio between c and the speed v at which light travels in a material is called the refractive index n of the material (n = c / v). For example, for visible light the refractive index of glass is typically around 1.5, meaning that light in glass travels at c / 1.5 \u2248 200,000 km/s (124,000 mi/s); the refractive index of air for visible light is about 1.0003, so the speed of light in air is about 299,700 km/s (186,220 mi/s), which is about 90 km/s (56 mi/s) slower than c.\nFor many practical purposes, light and other electromagnetic waves will appear to propagate instantaneously, but for long distances and very sensitive measurements, their finite speed has noticeable effects. In communicating with distant space probes, it can take minutes to hours for a message to get from Earth to the spacecraft, or vice versa. The light seen from stars left them many years ago, allowing the study of the history of the universe by looking at distant objects. The finite speed of light also limits the theoretical maximum speed of computers, since information must be sent within the computer from chip to chip. The speed of light can be used with time of flight measurements to measure large distances to high precision.\nOle R\u00f8mer first demonstrated in 1676 that light travels at a finite speed (as opposed to instantaneously) by studying the apparent motion of Jupiter's moon Io. In 1865, James Clerk Maxwell proposed that light was an electromagnetic wave, and therefore travelled at the speed c appearing in his theory of electromagnetism.  In 1905, Albert Einstein postulated that the speed of light c with respect to any inertial frame is a constant and is independent of the motion of the light source. He explored the consequences of that postulate by deriving the theory of relativity and in doing so showed that the parameter c had relevance outside of the context of light and electromagnetism.\nAfter centuries of increasingly precise measurements, in 1975 the speed of light was known to be 299792458 m/s (983571056 ft/s; 186282.397 mi/s) with a measurement uncertainty of 4 parts per billion. In 1983, the metre was redefined in the International System of Units (SI) as the distance travelled by light in vacuum in 1/299792458 of a second.\n\n\n== Numerical value, notation, and units ==\nThe speed of light in vacuum is usually denoted by a lowercase c, for \"constant\" or the Latin celeritas (meaning \"swiftness, celerity\"). In 1856, Wilhelm Eduard Weber and Rudolf Kohlrausch had used c for a different constant later shown to equal \u221a2 times the speed of light in vacuum. Historically, the symbol V was used as an alternative symbol for  the speed of light, introduced by James Clerk Maxwell in 1865. In 1894, Paul Drude redefined c with its modern meaning.  Einstein used V in his original German-language papers on special relativity in 1905, but in 1907 he switched to c, which by then had become the standard symbol for the speed of light.Sometimes c is used for the speed of waves in any material medium, and c0 for the speed of light in vacuum. This subscripted notation, which is endorsed in official SI literature, has the same form as other related constants: namely, \u03bc0 for the vacuum permeability or magnetic constant, \u03b50 for the vacuum permittivity or electric constant, and Z0 for the impedance of free space. This article uses c exclusively for the speed of light in vacuum.\nSince 1983, the metre has been defined in the International System of Units (SI) as the distance light travels in vacuum in \u200b1\u2044299792458 of a second. This definition fixes the speed of light in vacuum at exactly 299,792,458 m/s.\nAs a dimensional physical constant, the numerical value of c is different for different unit systems.\nIn branches of physics in which c appears often, such as in relativity, it is common to use systems of natural units of measurement or the geometrized unit system where c = 1. Using these units, c does not appear explicitly because multiplication or division by 1 does not affect the result.\n\n\n== Fundamental role in physics ==\n\nThe speed at which light waves propagate in vacuum is independent both of the motion of the wave source and of the inertial frame of reference of the observer. This invariance of the speed of light was postulated by Einstein in 1905, after being motivated by Maxwell's theory of electromagnetism and the lack of evidence for the luminiferous aether; it has since been consistently confirmed by many experiments.  It is only possible to verify experimentally that the two-way speed of light (for example, from a source to a mirror and back again) is frame-independent, because it is impossible to measure the one-way speed of light (for example, from a source to a distant detector) without some convention as to how clocks at the source and at the detector should be synchronized. However, by adopting Einstein synchronization for the clocks, the one-way speed of light becomes equal to the two-way speed of light by definition. The special theory of relativity explores the consequences of this invariance of c with the assumption that the laws of physics are the same in all inertial frames of reference. One consequence is that c is the speed at which all massless particles and waves, including light, must travel in vacuum.\n\nSpecial relativity has many counterintuitive and experimentally verified implications. These include the equivalence of mass and energy (E = mc2), length contraction (moving objects shorten), and time dilation (moving clocks run more slowly). The factor \u03b3 by which lengths contract and times dilate is known as the Lorentz factor and is given by \u03b3 = (1 \u2212 v2/c2)\u22121/2, where v is the speed of the object. The difference of \u03b3 from 1 is negligible for speeds much slower than c, such as most everyday speeds\u2014in which case special relativity is closely approximated by Galilean relativity\u2014but it increases at relativistic speeds and diverges to infinity as v approaches c. For example, a time dilation factor of \u03b3 = 2 occurs at a relative velocity of 86.6% of the speed of light (v = .866c). Similarly, a time dilation factor of \u03b3 = 10 occurs at v = 99.5% c.\nThe results of special relativity can be summarized by treating space and time as a unified structure known as spacetime (with c relating the units of space and time), and requiring that physical theories satisfy a special symmetry called Lorentz invariance, whose mathematical formulation contains the parameter c. Lorentz invariance is an almost universal assumption for modern physical theories, such as quantum electrodynamics, quantum chromodynamics, the Standard Model of particle physics, and general relativity. As such, the parameter c is ubiquitous in modern physics, appearing in many contexts that are unrelated to light. For example, general relativity predicts that c is also the speed of gravity and of gravitational waves. In non-inertial frames of reference (gravitationally curved spacetime or accelerated reference frames), the local speed of light is constant and equal to c, but the speed of light along a trajectory of finite length can differ from c, depending on how distances and times are defined.It is generally assumed that fundamental constants such as c have the same value throughout spacetime, meaning that they do not depend on location and do not vary with time. However, it has been suggested in various theories that the speed of light may have changed over time. No conclusive evidence for such changes has been found, but they remain the subject of ongoing research.It also is generally assumed that the speed of light is isotropic, meaning that it has the same value regardless of the direction in which it is measured. Observations of the emissions from nuclear energy levels as a function of the orientation of the emitting nuclei in a magnetic field (see Hughes\u2013Drever experiment), and of rotating optical resonators (see Resonator experiments) have put stringent limits on the possible two-way anisotropy.\n\n\n=== Upper limit on speeds ===\nAccording to special relativity, the energy of an object with rest mass m and speed v is given by \u03b3mc2, where \u03b3 is the Lorentz factor defined above. When v is zero, \u03b3 is equal to one, giving rise to the famous E = mc2 formula for mass\u2013energy equivalence. The \u03b3 factor approaches infinity as v approaches c, and it would take an infinite amount of energy to accelerate an object with mass to the speed of light. The speed of light is the upper limit for the speeds of objects with positive rest mass, and individual photons cannot travel faster than the speed of light. This is experimentally established in many tests of relativistic energy and momentum.\n\nMore generally, it is normally impossible for information or energy to travel faster than c. One argument for this follows from the counter-intuitive implication of special relativity known as the relativity of simultaneity. If the spatial distance between two events A and B is greater than the time interval between them multiplied by c then there are frames of reference in which A precedes B, others in which B precedes A, and others in which they are simultaneous. As a result, if something were travelling faster than c relative to an inertial frame of reference, it would be travelling backwards in time relative to another frame, and causality would be violated. In such a frame of reference, an \"effect\" could be observed before its \"cause\". Such a violation of causality has never been recorded, and would lead to paradoxes such as the tachyonic antitelephone.\n\n\n== Faster-than-light observations and experiments ==\n\nThere are situations in which it may seem that matter, energy, or information travels at speeds greater than c, but they do not. For example, as is discussed in the propagation of light in a medium section below, many wave velocities can exceed c. For example, the phase velocity of X-rays through most glasses can routinely exceed c, but phase velocity does not determine the velocity at which waves convey information.If a laser beam is swept quickly across a distant object, the spot of light can move faster than c, although the initial movement of the spot is delayed because of the time it takes light to get to the distant object at the speed c. However, the only physical entities that are moving are the laser and its emitted light, which travels at the speed c from the laser to the various positions of the spot. Similarly, a shadow projected onto a distant object can be made to move faster than c, after a delay in time. In neither case does any matter, energy, or information travel faster than light.The rate of change in the distance between two objects in a frame of reference with respect to which both are moving (their closing speed) may have a value in excess of c. However, this does not represent the speed of any single object as measured in a single inertial frame.Certain quantum effects appear to be transmitted instantaneously and therefore faster than c, as in the EPR paradox. An example involves the quantum states of two particles that can be entangled. Until either of the particles is observed, they exist in a superposition of two quantum states. If the particles are separated and one particle's quantum state is observed, the other particle's quantum state is determined instantaneously (i.e., faster than light could travel from one particle to the other). However, it is impossible to control which quantum state the first particle will take on when it is observed, so information cannot be transmitted in this manner.Another quantum effect that predicts the occurrence of faster-than-light speeds is called the Hartman effect: under certain conditions the time needed for a virtual particle to tunnel through a barrier is constant, regardless of the thickness of the barrier. This could result in a virtual particle crossing a large gap faster-than-light. However, no information can be sent using this effect.So-called superluminal motion is seen in certain astronomical objects, such as the relativistic jets of radio galaxies and quasars. However, these jets are not moving at speeds in excess of the speed of light: the apparent superluminal motion is a projection effect caused by objects moving near the speed of light and approaching Earth at a small angle to the line of sight: since the light which was emitted when the jet was farther away took longer to reach the Earth, the time between two successive observations corresponds to a longer time between the instants at which the light rays were emitted.In models of the expanding universe, the farther galaxies are from each other, the faster they drift apart. This receding is not due to motion through space, but rather to the expansion of space itself. For example, galaxies far away from Earth appear to be moving away from the Earth with a speed proportional to their distances. Beyond a boundary called the Hubble sphere, the rate at which their distance from Earth increases becomes greater than the speed of light.\n\n\n== Propagation of light ==\nIn classical physics, light is described as a type of electromagnetic wave. The classical behaviour of the electromagnetic field is described by Maxwell's equations, which predict that the speed c with which electromagnetic waves (such as light) propagate through the vacuum is related to the distributed capacitance and inductance of the vacuum, otherwise respectively known as the electric constant \u03b50 and the magnetic constant \u03bc0, by the equation\n\n  \n    \n      \n        c\n        =\n        \n          \n            1\n            \n              \n                \u03b5\n                \n                  0\n                \n              \n              \n                \u03bc\n                \n                  0\n                \n              \n            \n          \n        \n         \n        .\n      \n    \n    {\\displaystyle c={\\frac {1}{\\sqrt {\\varepsilon _{0}\\mu _{0}}}}\\ .}\n  In modern quantum physics, the electromagnetic field is described by the theory of quantum electrodynamics (QED). In this theory, light is described by the fundamental excitations (or quanta) of the electromagnetic field, called photons. In QED, photons are massless particles and thus, according to special relativity, they travel at the speed of light in vacuum.\nExtensions of QED in which the photon has a mass have been considered. In such a theory, its speed would depend on its frequency, and the invariant speed c of special relativity would then be the upper limit of the speed of light in vacuum. No variation of the speed of light with frequency has been observed in rigorous testing, putting stringent limits on the mass of the photon. The limit obtained depends on the model used: if the massive photon is described by Proca theory, the experimental upper bound for its mass is about 10\u221257 grams; if photon mass is generated by a Higgs mechanism, the experimental upper limit is less sharp, m \u2264 10\u221214 eV/c2  (roughly 2 \u00d7 10\u221247 g).\nAnother reason for the speed of light to vary with its frequency would be the failure of special relativity to apply to arbitrarily small scales, as predicted by some proposed theories of quantum gravity. In 2009, the observation of the spectrum of gamma-ray burst GRB 090510 did not find any difference in the speeds of photons of different energies, confirming that Lorentz invariance is verified at least down to the scale of the Planck length (lP = \u221a\u0127G/c3 \u2248 1.6163\u00d710\u221235 m) divided by 1.2.\n\n\n=== In a medium ===\n\nIn a medium, light usually does not propagate at a speed equal to c; further, different types of light wave will travel at different speeds. The speed at which the individual crests and troughs of a plane wave (a wave filling the whole space, with only one frequency) propagate is called the phase velocity vp. An actual physical signal with a finite extent (a pulse of light) travels at a different speed. The largest part of the pulse travels at the group velocity vg, and its earliest part travels at the front velocity vf.\n\nThe phase velocity is important in determining how a light wave travels through a material or from one material to another. It is often represented in terms of a refractive index. The refractive index of a material is defined as the ratio of c to the phase velocity vp in the material: larger indices of refraction indicate lower speeds. The refractive index of a material may depend on the light's frequency, intensity, polarization, or direction of propagation; in many cases, though, it can be treated as a material-dependent constant. The refractive index of air is approximately 1.0003. Denser media, such as water, glass, and diamond, have refractive indexes of around 1.3, 1.5 and 2.4, respectively, for visible light. In exotic materials like Bose\u2013Einstein condensates near absolute zero, the effective speed of light may be only a few metres per second. However, this represents absorption and re-radiation delay between atoms, as do all slower-than-c speeds in material substances. As an extreme example of light \"slowing\" in matter, two independent teams of physicists claimed to bring light to a \"complete standstill\" by passing it through a Bose\u2013Einstein condensate of the element rubidium, one team at Harvard University and the Rowland Institute for Science in Cambridge, Mass., and the other at the Harvard\u2013Smithsonian Center for Astrophysics, also in Cambridge. However, the popular description of light being \"stopped\" in these experiments refers only to light being stored in the excited states of atoms, then re-emitted at an arbitrarily later time, as stimulated by a second laser pulse. During the time it had \"stopped,\" it had ceased to be light. This type of behaviour is generally microscopically true of all transparent media which \"slow\" the speed of light.In transparent materials, the refractive index generally is greater than 1, meaning that the phase velocity is less than c. In other materials, it is possible for the refractive index to become smaller than 1 for some frequencies; in some exotic materials it is even possible for the index of refraction to become negative. The requirement that causality is not violated implies that the real and imaginary parts of the dielectric constant of any material, corresponding respectively to the index of refraction and to the attenuation coefficient, are linked by the Kramers\u2013Kronig relations. In practical terms, this means that in a material with refractive index less than 1, the absorption of the wave is so quick that no signal can be sent faster than c.\nA pulse with different group and phase velocities (which occurs if the phase velocity is not the same for all the frequencies of the pulse) smears out over time, a process known as dispersion. Certain materials have an exceptionally low (or even zero) group velocity for light waves, a phenomenon called slow light, which has been confirmed in various experiments.\nThe opposite, group velocities exceeding c, has also been shown in experiment. It should even be possible for the group velocity to become infinite or negative, with pulses travelling instantaneously or backwards in time.\nNone of these options, however, allow information to be transmitted faster than c. It is impossible to transmit information with a light pulse any faster than the speed of the earliest part of the pulse (the front velocity). It can be shown that this is (under certain assumptions) always equal to c. \nIt is possible for a particle to travel through a medium faster than the phase velocity of light in that medium (but still slower than c). When a charged particle does that in a dielectric material, the electromagnetic equivalent of a shock wave, known as Cherenkov radiation, is emitted.\n\n\n== Practical effects of finiteness ==\nThe speed of light is of relevance to communications: the one-way and  round-trip delay time are greater than zero. This applies from small to astronomical scales. On the other hand, some techniques depend on the finite speed of light, for example in distance measurements.\n\n\n=== Small scales ===\nIn supercomputers, the speed of light imposes a limit on how quickly data can be sent between processors. If a processor operates at 1 gigahertz, a signal can only travel a maximum of about 30 centimetres (1 ft) in a single cycle. Processors must therefore be placed close to each other to minimize communication latencies; this can cause difficulty with cooling. If clock frequencies continue to increase, the speed of light will eventually become a limiting factor for the internal design of single chips.\n\n\n=== Large distances on Earth ===\nGiven that the equatorial circumference of the Earth is about 40075 km and that c is about 300000 km/s, the theoretical shortest time for a piece of information to travel half the globe along the surface is about 67 milliseconds. When light is travelling around the globe in an optical fibre, the actual transit time is longer, in part because the speed of light is slower by about 35% in an optical fibre, depending on its refractive index n. Furthermore, straight lines rarely occur in global communications situations, and delays are created when the signal passes through an electronic switch or signal regenerator.\n\n\n=== Spaceflights and astronomy ===\n\nSimilarly, communications between the Earth and spacecraft are not instantaneous. There is a brief delay from the source to the receiver, which becomes more noticeable as distances increase. This delay was significant for communications between ground control and Apollo 8 when it became the first manned spacecraft to orbit the Moon: for every question, the ground control station had to wait at least three seconds for the answer to arrive. The communications delay between Earth and Mars can vary between five and twenty minutes depending upon the relative positions of the two planets. As a consequence of this, if a robot on the surface of Mars were to encounter a problem, its human controllers would not be aware of it until at least five minutes later, and possibly up to twenty minutes later; it would then take a further five to twenty minutes for instructions to travel from Earth to Mars.\nNASA must wait several hours for information from a probe orbiting Jupiter, and if it needs to correct a navigation error, the fix will not arrive at the spacecraft for an equal amount of time, creating a risk of the correction not arriving in time.\nReceiving light and other signals from distant astronomical sources can even take much longer. For example, it has taken 13 billion (13\u00d7109) years for light to travel to Earth from the faraway galaxies viewed in the Hubble Ultra Deep Field images. Those photographs, taken today, capture images of the galaxies as they appeared 13 billion years ago, when the universe was less than a billion years old. The fact that more distant objects appear to be younger, due to the finite speed of light, allows astronomers to infer the evolution of stars, of galaxies, and of the universe itself.\nAstronomical distances are sometimes expressed in light-years, especially in popular science publications and media. A light-year is the distance light travels in one year, around 9461 billion kilometres, 5879 billion miles, or 0.3066 parsecs. In round figures, a light year is nearly 10 trillion kilometres or nearly 6 trillion miles. Proxima Centauri, the closest star to Earth after the Sun, is around 4.2 light-years away.\n\n\n=== Distance measurement ===\n\nRadar systems measure the distance to a target by the time it takes a radio-wave pulse to return to the radar antenna after being reflected by the target: the distance to the target is half the round-trip transit time multiplied by the speed of light. A Global Positioning System (GPS) receiver measures its distance to GPS satellites based on how long it takes for a radio signal to arrive from each satellite, and from these distances calculates the receiver's position. Because light travels about 300000 kilometres (186000 mi) in one second, these measurements of small fractions of a second must be very precise. The Lunar Laser Ranging Experiment, radar astronomy and the Deep Space Network determine distances to the Moon, planets and spacecraft, respectively, by measuring round-trip transit times.\n\n\n=== High-frequency trading ===\nThe speed of light has become important in high-frequency trading, where traders seek to gain minute advantages by delivering their trades to exchanges fractions of a second ahead of other traders. For example, traders have been switching to microwave communications between trading hubs, because of the advantage which microwaves travelling at near to the speed of light in air, have over fibre optic signals which travel 30\u201340% slower at the speed of light through glass.\n\n\n== Measurement ==\nThere are different ways to determine the value of c. One way is to measure the actual speed at which light waves propagate, which can be done in various astronomical and earth-based setups. However, it is also possible to determine c from other physical laws where it appears, for example, by determining the values of the electromagnetic constants \u03b50 and \u03bc0 and using their relation to c. Historically, the most accurate results have been obtained by separately determining the frequency and wavelength of a light beam, with their product equalling c.\nIn 1983 the metre was defined as \"the length of the path travelled by light in vacuum during a time interval of \u200b1\u2044299792458 of a second\", fixing the value of the speed of light at 299792458 m/s by definition, as described below. Consequently, accurate measurements of the speed of light yield an accurate realization of the metre rather than an accurate value of c.\n\n\n=== Astronomical measurements ===\n\nOuter space is a convenient setting for measuring the speed of light because of its large scale and nearly perfect vacuum. Typically, one measures the time needed for light to traverse some reference distance in the solar system, such as the radius of the Earth's orbit. Historically, such measurements could be made fairly accurately, compared to how accurately the length of the reference distance is known in Earth-based units. It is customary to express the results in astronomical units (AU) per day.\nOle Christensen R\u00f8mer used an astronomical measurement to make the first quantitative estimate of the speed of light. When measured from Earth, the periods of moons orbiting a distant planet are shorter when the Earth is approaching the planet than when the Earth is receding from it. The distance travelled by light from the planet (or its moon) to Earth is shorter when the Earth is at the point in its orbit that is closest to its planet than when the Earth is at the farthest point in its orbit, the difference in distance being the diameter of the Earth's orbit around the Sun. The observed change in the moon's orbital period is caused by the difference in the time it takes light to traverse the shorter or longer distance. R\u00f8mer observed this effect for Jupiter's innermost moon Io and deduced that light takes 22 minutes to cross the diameter of the Earth's orbit.\n\nAnother method is to use the aberration of light, discovered and explained by James Bradley in the 18th century. This effect results from the vector addition of the velocity of light arriving from a distant source (such as a star) and the velocity of its observer (see diagram on the right). A moving observer thus sees the light coming from a slightly different direction and consequently sees the source at a position shifted from its original position. Since the direction of the Earth's velocity changes continuously as the Earth orbits the Sun, this effect causes the apparent position of stars to move around. From the angular difference in the position of stars (maximally 20.5 arcseconds) it is possible to express the speed of light in terms of the Earth's velocity around the Sun, which with the known length of a year can be converted to the time needed to travel from the Sun to the Earth. In 1729, Bradley used this method to derive that light travelled 10,210 times faster than the Earth in its orbit (the modern figure is 10,066 times faster) or, equivalently, that it would take light 8 minutes 12 seconds to travel from the Sun to the Earth.\n\n\n==== Astronomical unit ====\nAn astronomical unit (AU) is approximately the average distance between the Earth and Sun. It was redefined in 2012 as exactly 149597870700 m. Previously the AU was not based on the International System of Units but in terms of the gravitational force exerted by the Sun in the framework of classical mechanics. The current definition uses the recommended value in metres for the previous definition of the astronomical unit, which was determined by measurement. This redefinition is analogous to that of the metre, and likewise has the effect of fixing the speed of light to an exact value in astronomical units per second (via the exact speed of light in metres per second).\nPreviously, the inverse of c expressed in seconds per astronomical unit was measured by comparing the time for radio signals to reach different spacecraft in the Solar System, with their position calculated from the gravitational effects of the Sun and various planets. By combining many such measurements, a best fit value for the light time per unit distance could be obtained. For example, in 2009, the best estimate, as approved by the International Astronomical Union (IAU), was:\nlight time for unit distance: tau = 499.004783836(10) s\nc = 0.00200398880410(4) AU/s = 173.144632674(3) AU/day.The relative uncertainty in these measurements is 0.02 parts per billion (2\u00d710\u221211), equivalent to the uncertainty in Earth-based measurements of length by interferometry. Since the metre is defined to be the length travelled by light in a certain time interval, the measurement of the light time in terms of the previous definition of the astronomical unit can also be interpreted as measuring the length of an AU (old definition) in metres.\n\n\n=== Time of flight techniques ===\n\nA method of measuring the speed of light is to measure the time needed for light to travel to a mirror at a known distance and back. This is the working principle behind the Fizeau\u2013Foucault apparatus developed by Hippolyte Fizeau and L\u00e9on Foucault.\nThe setup as used by Fizeau consists of a beam of light directed at a mirror 8 kilometres (5 mi) away. On the way from the source to the mirror, the beam passes through a rotating cogwheel. At a certain rate of rotation, the beam passes through one gap on the way out and another on the way back, but at slightly higher or lower rates, the beam strikes a tooth and does not pass through the wheel. Knowing the distance between the wheel and the mirror, the number of teeth on the wheel, and the rate of rotation, the speed of light can be calculated.The method of Foucault replaces the cogwheel by a rotating mirror. Because the mirror keeps rotating while the light travels to the distant mirror and back, the light is reflected from the rotating mirror at a different angle on its way out than it is on its way back. From this difference in angle, the known speed of rotation and the distance to the distant mirror the speed of light may be calculated.\nNowadays, using oscilloscopes with time resolutions of less than one nanosecond, the speed of light can be directly measured by timing the delay of a light pulse from a laser or an LED reflected from a mirror. This method is less precise (with errors of the order of 1%) than other modern techniques, but it is sometimes used as a laboratory experiment in college physics classes.\n\n\n=== Electromagnetic constants ===\nAn option for deriving c that does not directly depend on a measurement of the propagation of electromagnetic waves is to use the relation between c and the vacuum permittivity \u03b50 and vacuum permeability \u03bc0 established by Maxwell's theory: c2 = 1/(\u03b50\u03bc0). The vacuum permittivity may be determined by measuring the capacitance and dimensions of a capacitor, whereas the value of the vacuum permeability is fixed at exactly 4\u03c0\u00d710\u22127 H\u22c5m\u22121 through the definition of the ampere. Rosa and Dorsey used this method in 1907 to find a value of 299710\u00b122 km/s.\n\n\n=== Cavity resonance ===\n\nAnother way to measure the speed of light is to independently measure the frequency f and wavelength \u03bb of an electromagnetic wave in vacuum. The value of c can then be found by using the relation c = f\u03bb. One option is to measure the resonance frequency of a cavity resonator. If the dimensions of the resonance cavity are also known, these can be used to determine the wavelength of the wave. In 1946, Louis Essen and A.C. Gordon-Smith established the frequency for a variety of normal modes of microwaves of a microwave cavity of precisely known dimensions. The dimensions were established to an accuracy of about \u00b10.8 \u03bcm using gauges calibrated by interferometry. As the wavelength of the modes was known from the geometry of the cavity and from electromagnetic theory, knowledge of the associated frequencies enabled a calculation of the speed of light.The Essen\u2013Gordon-Smith result, 299792\u00b19 km/s, was substantially more precise than those found by optical techniques. By 1950, repeated measurements by Essen established a result of 299792.5\u00b13.0 km/s.A household demonstration of this technique is possible, using a microwave oven and food such as marshmallows or margarine: if the turntable is removed so that the food does not move, it will cook the fastest at the antinodes (the points at which the wave amplitude is the greatest), where it will begin to melt. The distance between two such spots is half the wavelength of the microwaves; by measuring this distance and multiplying the wavelength by the microwave frequency (usually displayed on the back of the oven, typically 2450 MHz), the value of c can be calculated, \"often with less than 5% error\".\n\n\n=== Interferometry ===\n\nInterferometry is another method to find the wavelength of electromagnetic radiation for determining the speed of light. A coherent beam of light (e.g. from a laser), with a known frequency (f), is split to follow two paths and then recombined. By adjusting the path length while observing the interference pattern and carefully measuring the change in path length, the wavelength of the light (\u03bb) can be determined. The speed of light is then calculated using the equation c = \u03bbf.\nBefore the advent of laser technology, coherent radio sources were used for interferometry measurements of the speed of light. However interferometric determination of wavelength becomes less precise with wavelength and the experiments were thus limited in precision by the long wavelength (~0.4 cm (0.16 in)) of the radiowaves. The precision can be improved by using light with a shorter wavelength, but then it becomes difficult to directly measure the frequency of the light. One way around this problem is to start with a low frequency signal of which the frequency can be precisely measured, and from this signal progressively synthesize higher frequency signals whose frequency can then be linked to the original signal. A laser can then be locked to the frequency, and its wavelength can be determined using interferometry. This technique was due to a group at the National Bureau of Standards (NBS) (which later became NIST). They used it in 1972 to measure the speed of light in vacuum with a  fractional uncertainty of 3.5\u00d710\u22129.\n\n\n== History ==\nUntil the early modern period, it was not known whether light travelled instantaneously or at a very fast finite speed. The first extant recorded examination of this subject was in ancient Greece. The ancient Greeks, Muslim scholars, and classical European scientists long debated this until R\u00f8mer provided the first calculation of the speed of light. Einstein's Theory of Special Relativity concluded that the speed of light is constant regardless of one's frame of reference. Since then, scientists have provided increasingly accurate measurements.\n\n\n=== Early history ===\nEmpedocles (c. 490\u2013430 BC) was the first to propose a theory of light and claimed that light has a finite speed. He maintained that light was something in motion, and therefore must take some time to travel. Aristotle argued, to the contrary, that \"light is due to the presence of something, but it is not a movement\". Euclid and Ptolemy advanced Empedocles' emission theory of vision, where light is emitted from the eye, thus enabling sight. Based on that theory, Heron of Alexandria argued that the speed of light must be infinite because distant objects such as stars appear immediately upon opening the eyes.\nEarly Islamic philosophers initially agreed with the Aristotelian view that light had no speed of travel. In 1021, Alhazen (Ibn al-Haytham) published the Book of Optics, in which he presented a series of arguments dismissing the emission theory of vision in favour of the now accepted intromission theory, in which light moves from an object into the eye. This led Alhazen to propose that light must have a finite speed, and that the speed of light is variable, decreasing in denser bodies. He argued that light is substantial matter, the propagation of which requires time, even if this is hidden from our senses. Also in the 11th century, Ab\u016b Rayh\u0101n al-B\u012br\u016bn\u012b agreed that light has a finite speed, and observed that the speed of light is much faster than the speed of sound.In the 13th century, Roger Bacon argued that the speed of light in air was not infinite, using philosophical arguments backed by the writing of Alhazen and Aristotle. In the 1270s, Witelo considered the possibility of light travelling at infinite speed in vacuum, but slowing down in denser bodies.In the early 17th century, Johannes Kepler believed that the speed of light was infinite, since empty space presents no obstacle to it. Ren\u00e9 Descartes argued that if the speed of light were to be finite, the Sun, Earth, and Moon would be noticeably out of alignment during a lunar eclipse. Since such misalignment had not been observed, Descartes concluded the speed of light was infinite. Descartes speculated that if the speed of light were found to be finite, his whole system of philosophy might be demolished. In  Descartes' derivation of Snell's law, he assumed that even though the speed of light was instantaneous, the denser the medium, the faster was light's speed. Pierre de Fermat derived Snell's law using the opposing assumption, the denser the medium the slower light traveled. Fermat also argued in support of  a finite speed of light.\n\n\n=== First measurement attempts ===\nIn 1629, Isaac Beeckman proposed an experiment in which a person observes the flash of a cannon reflecting off a mirror about one mile (1.6 km) away. In 1638, Galileo Galilei proposed an experiment, with an apparent claim to having performed it some years earlier, to measure the speed of light by observing the delay between uncovering a lantern and its perception some distance away. He was unable to distinguish whether light travel was instantaneous or not, but concluded that if it were not, it must nevertheless be extraordinarily rapid. In 1667, the Accademia del Cimento of Florence reported that it had performed Galileo's experiment, with the lanterns separated by about one mile, but no delay was observed. The actual delay in this experiment would have been about 11 microseconds.\n\nThe first quantitative estimate of the speed of light was made in 1676 by R\u00f8mer (see R\u00f8mer's determination of the speed of light). From the observation that the periods of Jupiter's innermost moon Io appeared to be shorter when the Earth was approaching Jupiter than when receding from it, he concluded that light travels at a finite speed, and estimated that it takes light 22 minutes to cross the diameter of Earth's orbit. Christiaan Huygens combined this estimate with an estimate for the diameter of the Earth's orbit to obtain an estimate of speed of light of 220000 km/s, 26% lower than the actual value.In his 1704 book Opticks, Isaac Newton reported R\u00f8mer's calculations of the finite speed of light and gave a value of \"seven or eight minutes\" for the time taken for light to travel from the Sun to the Earth (the modern value is 8 minutes 19 seconds). Newton queried whether R\u00f8mer's eclipse shadows were coloured; hearing that they were not, he concluded the different colours travelled at the same speed. In 1729, James Bradley discovered stellar aberration. From this effect he determined that light must travel 10,210 times faster than the Earth in its orbit (the modern figure is 10,066 times faster) or, equivalently, that it would take light 8 minutes 12 seconds to travel from the Sun to the Earth.\n\n\n=== Connections with electromagnetism ===\n\nIn the 19th century Hippolyte Fizeau developed a method to determine the speed of light based on time-of-flight measurements on Earth and reported a value of 315000 km/s. His method was improved upon by L\u00e9on Foucault who obtained a value of 298000 km/s in 1862. In the year 1856, Wilhelm Eduard Weber and Rudolf Kohlrausch measured the ratio of the electromagnetic and electrostatic units of charge, 1/\u221a\u03b50\u03bc0, by discharging a Leyden jar, and found that its numerical value was very close to the speed of light as measured directly by Fizeau. The following year Gustav Kirchhoff calculated that an electric signal in a resistanceless wire travels along the wire at this speed. In the early 1860s, Maxwell showed that, according to the theory of electromagnetism he was working on, electromagnetic waves propagate in empty space at a speed equal to the above Weber/Kohlrausch ratio, and drawing attention to the numerical proximity of this value to the speed of light as measured by Fizeau, he proposed that light is in fact an electromagnetic wave.\n\n\n=== \"Luminiferous aether\" ===\n\nIt was thought at the time that empty space was filled with a background medium called the luminiferous aether in which the electromagnetic field existed. Some physicists thought that this aether acted as a preferred frame of reference for the propagation of light and therefore it should be possible to measure the motion of the Earth with respect to this medium, by measuring the isotropy of the speed of light. Beginning in the 1880s several experiments were performed to try to detect this motion, the most famous of which is the experiment performed by Albert A. Michelson and Edward W. Morley in 1887. The detected motion was always less than the observational error. Modern experiments indicate that the two-way speed of light is isotropic (the same in every direction) to within 6 nanometres per second.\nBecause of this experiment Hendrik Lorentz proposed that the motion of the apparatus through the aether may cause the apparatus to contract along its length in the direction of motion, and he further assumed, that the time variable for moving systems must also be changed accordingly (\"local time\"), which led to the formulation of the Lorentz transformation. Based on Lorentz's aether theory, Henri Poincar\u00e9 (1900) showed that this local time (to first order in v/c) is indicated by clocks moving in the aether, which are synchronized under the assumption of constant light speed. In 1904, he speculated that the speed of light could be a limiting velocity in dynamics, provided that the assumptions of Lorentz's theory are all confirmed. In 1905, Poincar\u00e9 brought Lorentz's aether theory into full observational agreement with the principle of relativity.\n\n\n=== Special relativity ===\nIn 1905 Einstein postulated from the outset that the speed of light in vacuum, measured by a non-accelerating observer, is independent of the motion of the source or observer. Using this and the principle of relativity as a basis he derived the special theory of relativity, in which the speed of light in vacuum c featured as a fundamental constant, also appearing in contexts unrelated to light. This made the concept of the stationary aether (to which Lorentz and Poincar\u00e9 still adhered) useless and revolutionized the concepts of space and time.\n\n\n=== Increased accuracy of c and redefinition of the metre and second ===\n\nIn the second half of the 20th century much progress was made in increasing the accuracy of measurements of the speed of light, first by cavity resonance techniques and later by laser interferometer techniques. These were aided by new, more precise, definitions of the metre and second. In 1950, Louis Essen determined the speed as 299792.5\u00b11 km/s, using cavity resonance. This value was adopted by the 12th General Assembly of the Radio-Scientific Union in 1957. In 1960, the metre was redefined in terms of the wavelength of a particular spectral line of krypton-86, and, in 1967, the second was redefined in terms of the hyperfine transition frequency of the ground state of caesium-133.\nIn 1972, using the laser interferometer method and the new definitions, a group at the US National Bureau of Standards in Boulder, Colorado determined the speed of light in vacuum to be c = 299792456.2\u00b11.1 m/s. This was 100 times less uncertain than the previously accepted value. The remaining uncertainty was mainly related to the definition of the metre. As similar experiments found comparable results for c, the 15th General Conference on Weights and Measures in 1975 recommended using the value 299792458 m/s for the speed of light.\n\n\n=== Defining the speed of light as an explicit constant ===\nIn 1983 the 17th CGPM found that wavelengths from frequency measurements and a given value for the speed of light are more reproducible than the previous standard. They kept the 1967 definition of second, so the caesium hyperfine frequency would now determine both the second and the metre. To do this, they redefined the metre as: \"The metre is the length of the path travelled by light in vacuum during a time interval of 1/299792458 of a second.\" As a result of this definition, the value of the speed of light in vacuum is exactly 299792458 m/s and has become a defined constant in the SI system of units. Improved experimental techniques that prior to 1983 would have measured the speed of light, no longer affect the known value of the speed of light in SI units, but instead allow a more precise realization of the metre by more accurately measuring the wavelength of Krypton-86 and other light sources.In 2011, the CGPM stated its intention to redefine all seven SI base units using what it calls \"the explicit-constant formulation\", where each \"unit is defined indirectly by specifying explicitly an exact value for a well-recognized fundamental constant\", as was done for the speed of light. It proposed a new, but completely equivalent, wording of the metre's definition: \"The metre, symbol m, is the unit of length; its magnitude is set by fixing the numerical value of the speed of light in vacuum to be equal to exactly 299792458 when it is expressed in the SI unit m s\u22121.\" This is one of the proposed changes to be incorporated in the next revision of the SI also termed the New SI.\n\n\n== See also ==\nLight-second\nSpeed of electricity\nSpeed of gravity\nSpeed of sound\nVelocity factor\nWarp factor (fictional)\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n=== Historical references ===\n\n\n=== Modern references ===\n\n\n== External links ==\n\"Test Light Speed in Mile Long Vacuum Tube.\" Popular Science Monthly, September 1930, p. 17\u201318.\nDefinition of the metre (International Bureau of Weights and Measures, BIPM)\nSpeed of light in vacuum (National Institute of Standards and Technology, NIST)\nData Gallery: Michelson Speed of Light (Univariate Location Estimation) (download data gathered by Albert A. Michelson)\nSubluminal (Java applet demonstrating group velocity information limits)\nDe Mora Luminis at MathPages\nLight discussion on adding velocities\nSpeed of Light (University of Colorado Department of Physics)\nc: Speed of Light (Sixty Symbols, University of Nottingham Department of Physics [video])\nUsenet Physics FAQ\nSpeed of light illustration (Speed of light as Live-Counter)\nThe Speed of Light, BBC Radio 4 discussion with John Barrow, Iwan Morus & Jocelyn Bell Burnell (In Our Time, 30 Nov. 2006)",
        "unit": "speed of light",
        "url": "https://en.wikipedia.org/wiki/Speed_of_light"
    },
    {
        "_id": "Viscosity",
        "clean": "Viscosity",
        "text": "The viscosity of a fluid is the measure of its resistance to gradual deformation by shear stress or tensile stress. For liquids, it corresponds to the informal concept of \"thickness\": for example, honey has a higher viscosity than water.Viscosity is the property of a fluid which opposes the relative motion between two surfaces of the fluid that are moving at different velocities. In simple terms, viscosity means friction between the molecules of fluid. When the fluid is forced through a tube, the particles which compose the fluid generally move more quickly near the tube's axis and more slowly near its walls; therefore some stress (such as a pressure difference between the two ends of the tube) is needed to overcome the friction between particle layers to keep the fluid moving. For a given velocity pattern, the stress required is proportional to the fluid's viscosity.\nA fluid that has no resistance to shear stress is known as an ideal or inviscid fluid. Zero viscosity is observed only at very low temperatures in superfluids. Otherwise, all fluids have positive viscosity and are technically said to be viscous or viscid. A fluid with a relatively high viscosity, such as pitch, may appear to be a solid.\n\n\n== Etymology ==\nThe word \"viscosity\" is derived from the Latin \"viscum\", meaning mistletoe and also a viscous glue made from mistletoe berries.\n\n\n== Definition ==\n\n\n=== Simple definition ===\n\nThe viscosity of a fluid expresses its resistance to shearing flows, in which adjacent fluid layers are in relative motion. A simple example of such a shearing flow is a planar Couette flow, where a fluid is trapped between two infinitely large plates, one fixed and one in parallel motion at constant speed \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n   (see illustration to the right). Although viscosity applies to general flows, it is easy to define and visualize in a Couette flow.\nIf the speed of the top plate is low enough, then in steady state the fluid particles move parallel to it, and their speed varies from \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n   at the bottom to u at the top. Each layer of fluid moves faster than the one just below it, and friction between them gives rise to a force resisting their relative motion. In particular, the fluid applies on the top plate a force in the direction opposite to its motion, and an equal but opposite force on the bottom plate. An external force is therefore required in order to keep the top plate moving at constant speed.\nIn many fluids, the flow velocity is observed to vary linearly from zero at the bottom to \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n   at the top. Moreover, the magnitude F of the force acting on the top plate is found to be proportional to the speed u and the area A of each plate, and inversely proportional to their separation y: \n\n  \n    \n      \n        F\n        =\n        \u03bc\n        A\n        \n          \n            u\n            y\n          \n        \n        .\n      \n    \n    {\\displaystyle F=\\mu A{\\frac {u}{y}}.}\n  The proportionality factor \u03bc is the viscosity of the fluid, with units of \n  \n    \n      \n        \n          Pa\n        \n        \u22c5\n        \n          s\n        \n      \n    \n    {\\displaystyle {\\text{Pa}}\\cdot {\\text{s}}}\n   (pascal-second). The ratio u/y is called the rate of shear deformation or shear velocity, and is the derivative of the fluid speed in the direction perpendicular to the plates (see illustrations to the right). If the velocity does not vary linearly with y, then the appropriate generalization is\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \u2202\n              u\n            \n            \n              \u2202\n              y\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\partial u}{\\partial y}},}\n  where \u03c4 = F/A, and \u2202u/\u2202y is the local shear velocity. This expression is referred to as Newton's law of viscosity. In shearing flows with planar symmetry, it is what defines \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  . It is a special case of the general definition of viscosity (see below), which can be expressed in coordinate-free form.\nUse of the Greek letter mu (\u03bc) for the viscosity is common among mechanical and chemical engineers, as well as physicists. However, the Greek letter eta (\u03b7) is also used by chemists, physicists, and the IUPAC. The viscosity \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is sometimes also referred to as the shear viscosity. However, at least one author discourages the use of this terminology, noting that \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   can be appear in nonshearing flows in addition to shearing flows.\n\n\n=== General definition ===\n\nIn general, the stresses within a flow can be attributed partly to the deformation of the material from some rest state (elastic stress), and partly to the rate of change of the deformation over time (viscous stress). In a fluid, by definition, the elastic stress includes only the hydrostatic pressure. In very general terms, the fluid's viscosity is the relation between the strain rate and the viscous stress. In the Newtonian fluid model the relationship is by definition a linear map, described by a viscosity tensor that, when multiplied by the strain rate tensor (which is the gradient of the flow's velocity), gives the viscous stress tensor. In Cartesian coordinates, this gives\n\n  \n    \n      \n        \n          \u03c4\n          \n            i\n            j\n          \n        \n        =\n        \n          \u2211\n          \n            k\n          \n        \n        \n          \u2211\n          \n            l\n          \n        \n        \n          \u03bc\n          \n            i\n            j\n            k\n            l\n          \n        \n        \n          \n            \n              \u2202\n              \n                v\n                \n                  k\n                \n              \n            \n            \n              \u2202\n              \n                r\n                \n                  l\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau _{ij}=\\sum _{k}\\sum _{l}\\mu _{ijkl}{\\frac {\\partial v_{k}}{\\partial r_{l}}}.}\n  Since the indices in the above expression can vary from 1 to 3, there are 81 \"viscosity coefficients\" \n  \n    \n      \n        \n          \u03bc\n          \n            i\n            j\n            k\n            l\n          \n        \n      \n    \n    {\\displaystyle \\mu _{ijkl}}\n   in total. However, due to spatial symmetries these coefficients are not all independent. For instance, for isotropic Newtonian fluids, the 81 coefficients can be reduced to 2 independent parameters. The most usual decomposition yields the standard (scalar) viscosity \u03bc and the bulk viscosity \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n  :\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \u03bc\n        \n          [\n          \n            \u2207\n            \n              v\n            \n            +\n            (\n            \u2207\n            \n              v\n            \n            \n              )\n              \n                \u2020\n              \n            \n          \n          ]\n        \n        \u2212\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03bc\n            \u2212\n            \u03ba\n          \n          )\n        \n        (\n        \u2207\n        \u22c5\n        \n          v\n        \n        )\n        \n          \u03b4\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {\\tau } =\\mu \\left[\\nabla \\mathbf {v} +(\\nabla \\mathbf {v} )^{\\dagger }\\right]-\\left({\\frac {2}{3}}\\mu -\\kappa \\right)(\\nabla \\cdot \\mathbf {v} )\\mathbf {\\delta } ,}\n  where \n  \n    \n      \n        \n          \u03b4\n        \n      \n    \n    {\\displaystyle \\mathbf {\\delta } }\n   is the unit tensor, and the dagger \n  \n    \n      \n        \u2020\n      \n    \n    {\\displaystyle \\dagger }\n   denotes the transpose. This equation can be thought of as a generalized form of Newton's law of viscosity. \nThe bulk viscosity expresses a type of internal friction that resists the shearless compression or expansion of a fluid. Knowledge of \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   is frequently not necessary in fluid dynamics problems. For example, incompressible liquids satisfy \n  \n    \n      \n        \u2207\n        \u22c5\n        \n          v\n        \n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\cdot \\mathbf {v} =0}\n   and so the term containing \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   is absent. Moreover, \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   is often assumed to be negligible for gases since it is \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n   in a monoatomic ideal gas. One situation in which \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   can be important is the calculation of energy loss in sound and shock waves, described by Stokes' law of sound attenuation, since these phenomena involve rapid expansions and compressions. \n\n\n=== Dynamic and kinematic viscosity ===\nIn fluid dynamics, it is common to work in terms of the kinematic viscosity (also called \"momentum diffusivity\"), defined as the ratio of the viscosity \u03bc to the density of the fluid \u03c1. It is usually denoted by the Greek letter nu (\u03bd) and has units \n  \n    \n      \n        \n          (\n          l\n          e\n          n\n          g\n          t\n          h\n          \n            )\n            \n              2\n            \n          \n          \n            /\n          \n          t\n          i\n          m\n          e\n        \n      \n    \n    {\\displaystyle \\mathrm {(length)^{2}/time} }\n  :\n\n  \n    \n      \n        \u03bd\n        =\n        \n          \n            \u03bc\n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle \\nu ={\\frac {\\mu }{\\rho }}}\n  .Consistent with this nomenclature, the viscosity \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is frequently called the dynamic viscosity. \n\n\n== Newtonian and non-Newtonian fluids ==\n\nNewton's law of viscosity is a constitutive equation (like Hooke's law, Fick's law, and Ohm's law): it is not a fundamental law of nature but an approximation that holds in some materials and fails in others.\nA fluid that behaves according to Newton's law, with a viscosity \u03bc that is independent of the stress, is said to be Newtonian. Gases, water, and many common liquids can be considered Newtonian in ordinary conditions and contexts. There are many non-Newtonian fluids that significantly deviate from that law in some way or other. For example:\n\nShear-thickening liquids, whose viscosity increases with the rate of shear strain.\nShear-thinning liquids, whose viscosity decreases with the rate of shear strain.\nThixotropic liquids, that become less viscous over time when shaken, agitated, or otherwise stressed.\nRheopectic (dilatant) liquids, that become more viscous over time when shaken, agitated, or otherwise stressed.\nBingham plastics that behave as a solid at low stresses but flow as a viscous fluid at high stresses.Shear-thinning liquids are very commonly, but misleadingly, described as thixotropic.\nEven for a Newtonian fluid, the viscosity usually depends on its composition and temperature. For gases and other compressible fluids, it depends on temperature and varies very slowly with pressure.\nThe viscosity of some fluids may depend on other factors. A magnetorheological fluid, for example, becomes thicker when subjected to a magnetic field, possibly to the point of behaving like a solid.\n\n\n== In solids ==\nThe viscous forces that arise during fluid flow must not be confused with the elastic forces that arise in a solid in response to shear, compression or extension stresses. While in the latter the stress is proportional to the amount of shear deformation, in a fluid it is proportional to the rate of deformation over time. (For this reason, Maxwell used the term fugitive elasticity for fluid viscosity.)\nHowever, many liquids (including water) will briefly react like elastic solids when subjected to sudden stress. Conversely, many \"solids\" (even granite) will flow like liquids, albeit very slowly, even under arbitrarily small stress. Such materials are therefore best described as possessing both elasticity (reaction to deformation) and viscosity (reaction to rate of deformation); that is, being viscoelastic.\nIndeed, some authors have claimed that amorphous solids, such as glass and many polymers, are actually liquids with a very high viscosity (greater than 1012 Pa\u00b7s).\n However, other authors dispute this hypothesis, claiming instead that there is some threshold for the stress, below which most solids will not flow at all, and that alleged instances of glass flow in window panes of old buildings are due to the crude manufacturing process of older eras rather than to the viscosity of glass.Viscoelastic solids may exhibit both shear viscosity and bulk viscosity. The extensional viscosity is a linear combination of the shear and bulk viscosities that describes the reaction of a solid elastic material to elongation. It is widely used for characterizing polymers.\nIn geology, earth materials that exhibit viscous deformation at least three orders of magnitude greater than their elastic deformation are sometimes called rheids.\n\n\n== Measurement ==\n\nViscosity is measured with various types of viscometers and rheometers. A rheometer is used for those fluids that cannot be defined by a single value of viscosity and therefore require more parameters to be set and measured than is the case for a viscometer. Close temperature control of the fluid is essential to acquire accurate measurements, particularly in materials like lubricants, whose viscosity can double with a change of only 5 \u00b0C.\nFor some fluids, the viscosity is constant over a wide range of shear rates (Newtonian fluids). The fluids without a constant viscosity (non-Newtonian fluids) cannot be described by a single number. Non-Newtonian fluids exhibit a variety of different correlations between shear stress and shear rate.\nOne of the most common instruments for measuring kinematic viscosity is the glass capillary viscometer.\nIn coating industries, viscosity may be measured with a cup in which the efflux time is measured. There are several sorts of cup \u2013 such as the Zahn cup and the Ford viscosity cup \u2013 with the usage of each type varying mainly according to the industry. The efflux time can also be converted to kinematic viscosities (centistokes, cSt) through the conversion equations.Also used in coatings, a Stormer viscometer uses load-based rotation in order to determine viscosity. The viscosity is reported in Krebs units (KU), which are unique to Stormer viscometers.\nVibrating viscometers can also be used to measure viscosity. Resonant, or vibrational viscometers work by creating shear waves within the liquid. In this method, the sensor is submerged in the fluid and is made to resonate at a specific frequency. As the surface of the sensor shears through the liquid, energy is lost due to its viscosity. This dissipated energy is then measured and converted into a viscosity reading. A higher viscosity causes a greater loss of energy.Extensional viscosity can be measured with various rheometers that apply extensional stress.\nVolume viscosity can be measured with an acoustic rheometer.\nApparent viscosity is a calculation derived from tests performed on drilling fluid used in oil or gas well development. These calculations and tests help engineers develop and maintain the properties of the drilling fluid to the specifications required.\n\n\n== Units ==\n\n\n=== Dynamic viscosity, \u03bc ===\nThe SI unit of dynamic viscosity is Pa\u00b7s or kg\u00b7m\u22121\u00b7s\u22121.\nBoth the physical unit of dynamic viscosity in SI units, the poiseuille (Pl), and cgs units, the poise (P), are named after Jean L\u00e9onard Marie Poiseuille. The poiseuille, which is rarely used, is equivalent to the pascal second (Pa\u00b7s), or (N\u00b7s)/m2, or kg/(m\u00b7s). If a fluid is placed between two plates with distance one meter, and one plate is pushed sideways with a shear stress of one pascal, and it moves at x meters per second, then it has viscosity of 1/x pascal seconds. For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s, while a typical motor oil could have a viscosity of about 250 mPa\u00b7s. The units used in practice are either Pa\u00b7s and its submultiples or the cgs poise referred to below, and its submultiples.\nThe cgs physical unit for dynamic viscosity, the poise (P), is also named after Jean Poiseuille. It is more commonly expressed, particularly in ASTM standards, as centipoise (cP) since the latter is equal to the SI multiple millipascal seconds (mPa\u00b7s). For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s = 1.002 cP.\n\n1 Pl = 1 Pa\u00b7s\n1 P = 1 dPa\u00b7s = 0.1 Pa\u00b7s = 0.1 kg\u00b7m\u22121\u00b7s\u22121\n1 cP = 1 mPa\u00b7s = 0.001 Pa\u00b7s = 0.001 N\u00b7s\u00b7m\u22122 = 0.001 kg\u00b7m\u22121\u00b7s\u22121.\n\n\n=== Kinematic viscosity, \u03bd ===\nThe SI unit of kinematic viscosity is m2/s.\nThe cgs physical unit for kinematic viscosity is the stokes (St), named after Sir George Gabriel Stokes. It is sometimes expressed in terms of centistokes (cSt). In U.S. usage, stoke is sometimes used as the singular form.\n\n1 St = 1 cm2\u00b7s\u22121 = 10\u22124 m2\u00b7s\u22121.\n1 cSt = 1 mm2\u00b7s\u22121 = 10\u22126 m2\u00b7s\u22121.Water at 20 \u00b0C has a kinematic viscosity of about 10\u22126 m2\u00b7s\u22121 or 1 cSt.\nThe kinematic viscosity is sometimes referred to as diffusivity of momentum, because it is analogous to diffusivity of heat and diffusivity of mass. It is therefore used in dimensionless numbers which compare the ratio of the diffusivities.\n\n\n=== Fluidity ===\nThe reciprocal of viscosity is fluidity, usually symbolized by \u03c6 = 1/\u03bc or F = 1/\u03bc, depending on the convention used, measured in reciprocal poise (P\u22121, or cm\u00b7s\u00b7g\u22121), sometimes called the rhe. Fluidity is seldom used in engineering practice.\nThe concept of fluidity can be used to determine the viscosity of an ideal solution. For two components A and B, the fluidity when A and B are mixed is\n\n  \n    \n      \n        F\n        \u2248\n        \n          \u03c7\n          \n            \n              A\n            \n          \n        \n        \n          F\n          \n            \n              A\n            \n          \n        \n        +\n        \n          \u03c7\n          \n            \n              B\n            \n          \n        \n        \n          F\n          \n            \n              B\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle F\\approx \\chi _{\\mathrm {A} }F_{\\mathrm {A} }+\\chi _{\\mathrm {B} }F_{\\mathrm {B} },}\n  which is only slightly simpler than the equivalent equation in terms of viscosity:\n\n  \n    \n      \n        \u03bc\n        \u2248\n        \n          \n            1\n            \n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          A\n                        \n                      \n                    \n                  \n                \n              \n              +\n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          B\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu \\approx {\\frac {1}{{\\dfrac {\\chi _{\\mathrm {A} }}{\\mu _{\\mathrm {A} }}}+{\\dfrac {\\chi _{\\mathrm {B} }}{\\mu _{\\mathrm {B} }}}}},}\n  where \u03c7A and \u03c7B are the mole fractions of components A and B respectively, and \u03bcA and \u03bcB are the components' pure viscosities.\n\n\n=== Non-standard units ===\nThe reyn is a British unit of dynamic viscosity.\nViscosity index is a measure for the change of viscosity with temperature. It is used in the automotive industry to characterise lubricating oil.\nAt one time the petroleum industry relied on measuring kinematic viscosity by means of the Saybolt viscometer, and expressing kinematic viscosity in units of Saybolt universal seconds (SUS). Other abbreviations such as SSU (Saybolt seconds universal) or SUV (Saybolt universal viscosity) are sometimes used. Kinematic viscosity in centistokes can be converted from SUS according to the arithmetic and the reference table provided in ASTM D 2161.\n\n\n== Molecular origins ==\n\nIn general, the viscosity of a system depends in detail on how the molecules constituting the system interact. There are no simple but correct expressions for the viscosity of a fluid. The simplest exact expressions are the Green\u2013Kubo relations for the linear shear viscosity or the transient time correlation function expressions derived by Evans and Morriss in 1985. Although these expressions are each exact, calculating the viscosity of a dense fluid using these relations currently requires the use of molecular dynamics computer simulations. On the other hand, much more progress can be made for a dilute gas. Even elementary assumptions about how gas molecules move and interact lead to a basic understanding of the molecular origins of viscosity. More sophisticated treatments can be constructed by systematically coarse-graining the equations of motion of the gas molecules. An example of such a treatment is Chapman\u2013Enskog theory, which derives expressions for the viscosity of a dilute gas from the Boltzmann equation.Momentum transport in gases is generally mediated by discrete molecular collisions, and in liquids by attractive forces which bind molecules close together. Because of this, the dynamic viscosities of liquids are typically several orders of magnitude higher than dynamic viscosities of gases.\n\n\n=== Gases ===\n\nViscosity in gases arises principally from the molecular diffusion that transports momentum between layers of flow. An elementary calculation for a dilute gas at temperature \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   and density \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   gives\n\n  \n    \n      \n        \u03bc\n        =\n        \u03b1\n        \u03c1\n        \u03bb\n        \n          \n            \n              \n                2\n                \n                  k\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                m\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\alpha \\rho \\lambda {\\sqrt {\\frac {2k_{B}T}{\\pi m}}},}\n  where \n  \n    \n      \n        \n          k\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle k_{B}}\n   is the Boltzmann constant, \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   the molecular mass, and \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   a numerical constant on the order of \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  . The quantity \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n  , the mean free path, measures the average distance a molecule travels between collisions. Even without a priori knowledge of \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  , this expression has interesting implications. In particular, since \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is typically inversely proportional to density and increases with temperature, \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   itself should increase with temperature and be independent of density. In fact, both of these predictions persist in more sophisticated treatments, and accurately describe experimental observations. Note that this behavior runs counter to common intuition regarding liquids, for which viscosity typically decreases with temperature.\nFor rigid elastic spheres of diameter \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  , \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   can be computed, giving\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            \u03b1\n            \n              \u03c0\n              \n                3\n                \n                  /\n                \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                k\n                \n                  B\n                \n              \n              m\n              T\n            \n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mu ={\\frac {\\alpha }{\\pi ^{3/2}}}{\\frac {\\sqrt {k_{B}mT}}{\\sigma ^{2}}}.}\n  In this case \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is independent of temperature, so \n  \n    \n      \n        \u03bc\n        \u221d\n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu \\propto T^{1/2}}\n  . For more complicated molecular models, however, \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   depends on temperature in a non-trivial way, and simple kinetic arguments as used here are inadequate. More fundamentally, the notion of a mean free path becomes imprecise for particles that interact over a finite range, which limits the usefulness of the concept for describing real-world gases.\n\n\n==== Chapman\u2013Enskog theory ====\n\nA technique developed by Sydney Chapman and David Enskog in the early 1900s allows a more refined calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  . It is based on the Boltzmann equation, which provides a systematic statistical description of a dilute gas in terms of intermolecular interactions. As such, their technique allows accurate calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   for more realistic molecular models, such as those incorporating intermolecular attraction rather than just hard-core repulsion.\nIt turns out that a more realistic modeling of interactions is essential for accurate prediction of the temperature dependence of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  , which experiments show increases more rapidly than the \n  \n    \n      \n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle T^{1/2}}\n   trend predicted for rigid elastic spheres. Indeed, the Chapman\u2013Enskog analysis shows that the predicted temperature dependence can be tuned by varying the parameters in various molecular models. A simple example is the Sutherland model, which describes rigid elastic spheres with weak mutual attraction. In such a case, the attractive force can be treated perturbatively, which leads to a particularly simple expression for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  :\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            5\n            \n              16\n              \n                \u03c3\n                \n                  2\n                \n              \n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    k\n                    \n                      B\n                    \n                  \n                  m\n                  T\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            1\n            \n              /\n            \n            2\n          \n        \n        \n          \n            (\n            \n              1\n              +\n              \n                \n                  S\n                  T\n                \n              \n            \n            )\n          \n          \n            \u2212\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu ={\\frac {5}{16\\sigma ^{2}}}\\left({\\frac {k_{B}mT}{\\pi }}\\right)^{1/2}\\left(1+{\\frac {S}{T}}\\right)^{-1},}\n  where \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is independent of temperature, being determined only by the parameters of the intermolecular attraction. To connect with experiment, it is convenient to rewrite as\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            (\n            \n              \n                T\n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            )\n          \n          \n            3\n            \n              /\n            \n            2\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              S\n            \n            \n              T\n              +\n              S\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\mu _{0}\\left({\\frac {T}{T_{0}}}\\right)^{3/2}{\\frac {T_{0}+S}{T+S}},}\n  where \n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   is the viscosity at temperature \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  . If \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is known from experiments at \n  \n    \n      \n        T\n        =\n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T=T_{0}}\n   and at least one other temperature, then \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   can be calculated. It turns out that expressions for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   obtained in this way are accurate for a number of gases over a sizable range of temperatures. On the other hand, Chapman and Cowling argue that this success does not imply that molecules actually interact according to the Sutherland model. Rather, they interpret the prediction for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   as a simple interpolation which is valid for some gases over fixed ranges of temperature, but otherwise does not provide a picture of intermolecular interactions which is fundamentally correct and general. Slightly more sophisticated models, such as the Lennard\u2013Jones potential, may provide a better picture, but only at the cost of a more opaque dependence on temperature. In some systems the assumption of spherical symmetry must be abandoned as well, as is the case for vapors with highly polar molecules like H2O.\n\n\n=== Liquids ===\n\nIn contrast with gases, there is no simple yet accurate picture for the molecular origins of viscosity in liquids. \nAt the simplest level of description, the relative motion of adjacent layers in a liquid is opposed primarily by attractive molecular forces\nacting across the layer boundary. In this picture, one (correctly) expects viscosity to decrease with temperature. This is because\nincreasing temperature increases the random thermal motion of the molecules, which makes it easier for them to overcome their attractive interactions.Building on this visualization, a simple theory can be constructed in analogy with the discrete structure of a solid: groups of molecules in a liquid \nare visualized as forming \"cages\" which surround and enclose single molecules. These cages can be occupied or unoccupied, and\nstronger molecular attraction corresponds to stronger cages.\nDue to random thermal motion, a molecule \"hops\" between cages at a rate which varies inversely with the strength of molecular attractions. In equilibrium these \"hops\" are not biased in any direction.\nOn the other hand, in order for two adjacent layers to move relative to each other, the \"hops\" must be biased in the direction\nof the relative motion. The force required to sustain this directed motion can be estimated for a given shear rate, leading to\n\nwhere \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is the Avogadro constant, \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is the Planck constant, \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the volume of a mole of liquid, and \n  \n    \n      \n        \n          T\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle T_{b}}\n   is the normal boiling point. This result has the same form as the widespread and accurate empirical relation \n\nwhere \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   are constants fit from data. One the other hand, several authors express caution with respect to this model.\nErrors as large as 30% can be encountered using equation (1), compared with fitting equation (2) to experimental data. More fundamentally, the physical assumptions underlying equation (1) have been extensively criticized. It has also been argued that the exponential dependence in equation (1) does not necessarily describe experimental observations more accurately than simpler, non-exponential expressions.In light of these shortcomings, the development of a less ad-hoc model is a matter of practical interest.\nForegoing simplicity in favor of precision, it is possible to write rigorous expressions for viscosity starting from the fundamental equations of motion for molecules. A classic example \nof this approach is Irving-Kirkwood theory. On the other hand, such expressions\nare given as averages over multiparticle correlation functions and are therefore difficult to apply in practice. \nIn general, empirically derived expressions (based on existing viscosity measurements) appear to be the only consistently reliable means of calculating viscosity in liquids.\n\n\n== Selected substances ==\n\n\n=== Air ===\n\nThe viscosity of air depends mostly on the temperature. At 15 \u00b0C, the viscosity of air is 1.81\u00d710\u22125 kg/(m\u00b7s), 18.1 \u03bcPa\u00b7s or 1.81\u00d710\u22125 Pa\u00b7s. The kinematic viscosity at 15 \u00b0C is 1.48\u00d710\u22125 m2/s or 14.8 cSt. At 25 \u00b0C, the viscosity is 18.6 \u03bcPa\u00b7s and the kinematic viscosity 15.7 cSt.\n\n\n=== Water ===\n\nThe dynamic viscosity of water is 8.90\u00d710\u22124 Pa\u00b7s or 8.90\u00d710\u22123 dyn\u00b7s/cm2 or 0.890 cP at about 25 \u00b0C.\nAs a function of temperature T (in kelvins): \u03bc = A \u00d7 10B/(T \u2212 C), where A = 2.414\u00d710\u22125 Pa\u00b7s, B = 247.8 K, and C = 140 K.The dynamic viscosity of liquid water at different temperatures up to the normal boiling point is listed below.\n\n\n=== Other substances ===\n\nSome dynamic viscosities of Newtonian fluids are listed below:\n\n\n== Blends of liquids ==\nThe viscosity of the blend of two or more liquids can be estimated using the Refutas equation. The calculation is carried out in three steps.\nThe first step is to calculate the viscosity blending number (VBN) (also called the viscosity blending index) of each component of the blend:\n\n  \n    \n      \n        \n          V\n          B\n          N\n        \n        =\n        14.534\n        \u00d7\n        ln\n        \u2061\n        \n          \n            (\n          \n        \n        ln\n        \u2061\n        (\n        \u03bd\n        +\n        0.8\n        )\n        \n          \n            )\n          \n        \n        +\n        10.975\n        \n      \n    \n    {\\displaystyle \\mathrm {VBN} =14.534\\times \\ln {\\big (}\\ln(\\nu +0.8){\\big )}+10.975\\,}\n     (1)where \u03bd is the kinematic viscosity in centistokes (cSt). It is important that the kinematic viscosity of each component of the blend be obtained at the same temperature.\nThe next step is to calculate the VBN of the blend, using this equation:\n\n  \n    \n      \n        \n          V\n          B\n          \n            N\n            \n              B\n              l\n              e\n              n\n              d\n            \n          \n        \n        =\n        \n          (\n          \n            \n              x\n              \n                \n                  A\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  A\n                \n              \n            \n          \n          )\n        \n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  B\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  B\n                \n              \n            \n          \n          )\n        \n        +\n        \u22ef\n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  N\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  N\n                \n              \n            \n          \n          )\n        \n        \n      \n    \n    {\\displaystyle \\mathrm {VBN_{Blend}} =\\left(x_{\\mathrm {A} }\\times \\mathrm {VBN_{A}} \\right)+\\left(x_{\\mathrm {B} }\\times \\mathrm {VBN_{B}} \\right)+\\cdots +\\left(x_{\\mathrm {N} }\\times \\mathrm {VBN_{N}} \\right)\\,}\n     (2)where xX is the mass fraction of each component of the blend.\nOnce the viscosity blending number of a blend has been calculated using equation (2), the final step is to determine the kinematic viscosity of the blend by solving equation (1) for \u03bd:\n\n  \n    \n      \n        \u03bd\n        =\n        exp\n        \u2061\n        \n          (\n          \n            exp\n            \u2061\n            \n              (\n              \n                \n                  \n                    \n                      V\n                      B\n                      \n                        N\n                        \n                          B\n                          l\n                          e\n                          n\n                          d\n                        \n                      \n                    \n                    \u2212\n                    10.975\n                  \n                  14.534\n                \n              \n              )\n            \n          \n          )\n        \n        \u2212\n        0.8\n        ,\n      \n    \n    {\\displaystyle \\nu =\\exp \\left(\\exp \\left({\\frac {\\mathrm {VBN_{Blend}} -10.975}{14.534}}\\right)\\right)-0.8,}\n     (3)where VBNBlend is the viscosity blending number of the blend.\nalternatively use the more accurate Lederer-Roegiers equation [1]\n\n  \n    \n      \n        ln\n        \u2061\n        \n          \u03b7\n          \n            1\n            ,\n            2\n          \n        \n        =\n        \n          \n            \n              \n                x\n                \n                  1\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  1\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n        +\n        \n          \n            \n              \u03b2\n              \n                x\n                \n                  2\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  2\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n      \n    \n    {\\displaystyle \\ln \\eta _{1,2}={\\frac {x_{1}\\ln \\eta _{1}}{x_{1}+x_{2}\\beta }}+{\\frac {\\beta x_{2}\\ln \\eta _{2}}{x_{1}+x_{2}\\beta }}}\n  \n\n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   is based on the difference in intermolecular cohesion energies between the liquids\n\n  \n    \n      \n        \u03b7\n      \n    \n    {\\displaystyle \\eta }\n  =dynamic viscosity\n\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  =mole fraction of particle species \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\n\n== Slurry ==\n\nThe term slurry describes mixtures of a liquid and solid particles that retain some fluidity. The viscosity of slurry can be described as relative to the viscosity of the liquid phase:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n        =\n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        \n          \u03bc\n          \n            \n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {s} }=\\mu _{\\mathrm {r} }\\mu _{\\mathrm {l} },}\n  where \u03bcs and \u03bcl are respectively the dynamic viscosity of the slurry and liquid (Pa\u00b7s), and \u03bcr is the relative viscosity (dimensionless).\nDepending on the size and concentration of the solid particles, several models exist that describe the relative viscosity as a function of volume fraction \u03c6 of solid particles.\nIn the case of extremely low concentrations of fine particles, Einstein's equation may be used:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi }\n  In the case of higher concentrations, a modified equation was proposed by Guth and Simha, which takes into account interaction between the solid particles:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        14.1\n        \n          \u03c6\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +14.1\\varphi ^{2}}\n  Further modification of this equation was proposed by Thomas from the fitting of empirical data:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        10.05\n        \n          \u03c6\n          \n            2\n          \n        \n        +\n        A\n        \n          e\n          \n            B\n            \u03c6\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +10.05\\varphi ^{2}+Ae^{B\\varphi },}\n  where A = 0.00273 and B = 16.6.\nIn the case of high shear stress (above 1 kPa), another empirical equation was proposed by Kitano et al. for polymer melts:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            (\n            \n              1\n              \u2212\n              \n                \n                  \u03c6\n                  A\n                \n              \n            \n            )\n          \n          \n            \u2212\n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=\\left(1-{\\frac {\\varphi }{A}}\\right)^{-2},}\n  where A = 0.68 for smooth spherical particles.\n\n\n== Nanofluids ==\n\nNanofluid is a novel class of fluid, which is developed by dispersing nano-sized particles in base fluid.Einstein model\nEinstein derived the applicable first theoretical formula for the estimation of viscosity values of composites or mixtures in 1906. This model developed while assuming linear viscous fluid including suspensions of rigid and spherical particles. Einstein\u2019s model is valid for very low volume fraction \n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n  .\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing )}\n  \nBrinkman model\nBrinkman modified Einstein\u2019s model for used with average particle volume fraction up to 4%\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        \n          \n            1\n            \n               \n              (\n              1\n              \u2212\n              \u2205\n              \n                )\n                \n                  2.5\n                \n              \n            \n          \n        \n        \n          \n            )\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \u2205\n        +\n        4.375\n        \n          \u2205\n          \n            2\n          \n        \n        +\n        O\n        (\n        \n          \u2205\n          \n            3\n          \n        \n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}{\\frac {1}{\\ (1-\\varnothing )^{2.5}}}{\\Biggr )}=\\mu _{bf}{\\Big (}1+2.5\\varnothing +4.375\\varnothing ^{2}+O(\\varnothing ^{3}){\\Big )}}\n  \nBatchelor model\nBatchelor reformed Einstein's theoretical model by presenting Brownian motion effect.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        +\n        6.5\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing +6.5{\\varnothing }^{2})}\n  \nWang et al. model\nWang et al. found a model to predict viscosity of nanofluid as follows.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        7.3\n        \u2205\n        +\n        123\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+7.3\\varnothing +123{\\varnothing }^{2})}\n  \nMasoumi et al. model\nMasoumi et al. suggested a new viscosity correlation by considering Brownian motion of nanoparticle in nanofluid.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              C\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta C}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                18\n                \n                  K\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                \n                  \u03c1\n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle V_{B}={\\sqrt {\\frac {18K_{B}T}{\\pi \\rho _{p}{d_{p}}^{3}}}}}\n  \n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                \u03c0\n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n              \n                6\n                \u2205\n              \n            \n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\sqrt[{3}]{\\frac {\\pi {d_{p}}^{3}}{6\\varnothing }}}}\n  \n\n  \n    \n      \n        C\n        =\n        {\n        \n          (\n          \u2212\n          1.133\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          2.771\n          )\n          \u2205\n          +\n          (\n          0.09\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          0.393\n          )\n        \n        }\n        \u00d7\n        \n          10\n          \n            \u2212\n            6\n          \n        \n      \n    \n    {\\displaystyle C=\\{{(-1.133d_{p}-2.771)\\varnothing +(0.09d_{p}-0.393)}\\}\\times 10^{-6}}\n  \nUdawattha et al. model\nUdawattha et al. modified the Masoumi et al. model. The developed model valid for suspension containing micro-size particles.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \n          \u2205\n          \n            e\n          \n        \n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              [\n              T\n              \u00d7\n              \n                10\n                \n                  \u2212\n                  10\n                \n              \n              \u00d7\n              \n                \u2205\n                \n                  \u2212\n                  0.002\n                  T\n                  \u2212\n                  0.284\n                \n              \n              ]\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+2.5\\varnothing _{e}+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta [T\\times 10^{-10}\\times \\varnothing ^{-0.002T-0.284}]}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          \u2205\n          \n            e\n          \n        \n        =\n        \u2205\n        \n          \n            \n              \n                (\n              \n            \n            1\n            +\n            \n              \n                h\n                r\n              \n            \n            \n              \n                )\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\varnothing _{e}=\\varnothing {{\\Biggl (}1+{\\frac {h}{r}}{\\Biggr )}}^{3}}\n  \nwhere\n\n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the viscosity of the sample, in [Pa\u00b7s]\n\n  \n    \n      \n        n\n        f\n      \n    \n    {\\displaystyle nf}\n   is nanofluid\n\n  \n    \n      \n        b\n        f\n      \n    \n    {\\displaystyle bf}\n   is basefluid\n\n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   is particle\n\n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n   is volume fraction\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is density of the sample, in [kg\u00b7m\u22123]\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is distance between two particles\n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle V_{B}}\n   is Brownian motion of particle\n\n  \n    \n      \n        \n          K\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle K_{B}}\n   is the Boltzmann constant\n\n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   is Temperature of the sample, in [K]\n\n  \n    \n      \n        \n          d\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle d_{p}}\n   is diameter of a particle\n\n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is nanolayer thickness (1 nm)\n\n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is radius of a particle\n\n\n== Amorphous materials ==\n\nViscous flow in amorphous materials (e.g. in glasses and melts) is a thermally activated process:\n\n  \n    \n      \n        \u03bc\n        =\n        A\n        \n          e\n          \n            \n              Q\n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =Ae^{\\frac {Q}{RT}},}\n  where Q is activation energy, T is temperature, R is the molar gas constant and A is approximately a constant.\nThe viscous flow in amorphous materials is characterized by a deviation from the Arrhenius-type behavior: Q changes from a high value QH at low temperatures (in the glassy state) to a low value QL at high temperatures (in the liquid state). Depending on this change, amorphous materials are classified as either\n\nstrong when: QH \u2212 QL < QL or\nfragile when: QH \u2212 QL \u2265 QL.The fragility of amorphous materials is numerically characterized by Doremus' fragility ratio:\n\n  \n    \n      \n        \n          R\n          \n            \n              D\n            \n          \n        \n        =\n        \n          \n            \n              Q\n              \n                \n                  H\n                \n              \n            \n            \n              Q\n              \n                \n                  L\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R_{\\mathrm {D} }={\\frac {Q_{\\mathrm {H} }}{Q_{\\mathrm {L} }}}}\n  and strong materials have RD < 2 whereas fragile materials have RD \u2265 2.\n\nThe viscosity of amorphous materials is quite exactly described by a two-exponential equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            1\n          \n        \n        T\n        \n          (\n          \n            1\n            +\n            \n              A\n              \n                2\n              \n            \n            \n              e\n              \n                \n                  B\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        \n          (\n          \n            1\n            +\n            C\n            \n              e\n              \n                \n                  D\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{1}T\\left(1+A_{2}e^{\\frac {B}{RT}}\\right)\\left(1+Ce^{\\frac {D}{RT}}\\right),}\n  with constants A1, A2, B, C and D related to thermodynamic parameters of joining bonds of an amorphous material.\nNot very far from the glass transition temperature, Tg, this equation can be approximated by a Vogel\u2013Fulcher\u2013Tammann (VFT) equation.\nIf the temperature is significantly lower than the glass transition temperature, T \u226a Tg, then the two-exponential equation simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              L\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    H\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {L} }Te^{\\frac {Q_{\\mathrm {H} }}{RT}}}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              H\n            \n          \n        \n        =\n        \n          H\n          \n            \n              d\n            \n          \n        \n        +\n        \n          H\n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle Q_{\\mathrm {H} }=H_{\\mathrm {d} }+H_{\\mathrm {m} },}\n  where Hd is the enthalpy of formation of broken bonds (termed configurons) and Hm is the enthalpy of their motion.\nWhen the temperature is less than the glass transition temperature, T < Tg, the activation energy of viscosity is high because the amorphous materials are in the glassy state and most of their joining bonds are intact.\nIf the temperature is much higher than the glass transition temperature, T \u226b Tg, the two-exponential equation also simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              H\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    L\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {H} }Te^{\\frac {Q_{\\mathrm {L} }}{RT}},}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              L\n            \n          \n        \n        =\n        \n          H\n          \n            \n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Q_{\\mathrm {L} }=H_{\\mathrm {m} }.}\n  When the temperature is higher than the glass transition temperature, T > Tg, the activation energy of viscosity is low because amorphous materials are melted and have most of their joining bonds broken, which facilitates flow.\n\n\n== Eddy viscosity ==\nIn the study of turbulence in fluids, a common practical strategy for calculation is to ignore the small-scale vortices (or eddies) in the motion and to calculate a large-scale motion with an eddy viscosity that characterizes the transport and dissipation of energy in the smaller-scale flow (see large eddy simulation). Values of eddy viscosity used in modeling ocean circulation may be from 5\u00d7104 to 1\u00d7106 Pa\u00b7s depending upon the resolution of the numerical grid.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nHatschek, Emil (1928). The Viscosity of Liquids. New York: Van Nostrand. OCLC 53438464.\nMassey, B. S.; Ward-Smith, A. J. (2011). Mechanics of Fluids (9th ed.). London & New York: Spon Press. ISBN 978-0-415-60259-4. OCLC 690084654.\n\n\n== External links ==\nFluid properties - high accuracy calculation of viscosity for frequently encountered pure liquids and gases\nGas viscosity calculator as function of temperature\nAir viscosity calculator as function of temperature and pressure\nFluid Characteristics Chart - a table of viscosities and vapor pressures for various fluids\nGas Dynamics Toolbox - calculate coefficient of viscosity for mixtures of gases\nGlass Viscosity Measurement - viscosity measurement, viscosity units and fixpoints, glass viscosity calculation\nKinematic Viscosity - conversion between kinematic and dynamic viscosity\nPhysical Characteristics of Water - a table of water viscosity as a function of temperature\nVogel\u2013Tammann\u2013Fulcher Equation Parameters\nCalculation of temperature-dependent dynamic viscosities for some common components\n\"Test Procedures for Testing Highway and Nonroad Engines and Omnibus Technical Amendments\" - United States Environmental Protection Agency\nArtificial viscosity\nViscosity of Air, Dynamic and Kinematic, Engineers Edge",
        "unit": "fluidity",
        "url": "https://en.wikipedia.org/wiki/Viscosity"
    },
    {
        "_id": "Linear_density",
        "clean": "Linear density",
        "text": "Linear density is the measure of a quantity of any characteristic value per unit of length.  Linear mass density (titer in textile engineering, the amount of mass per unit length) and linear charge density (the amount of electric charge per unit length) are two common examples used in science and engineering.\nThe term linear density is most often used when describing the characteristics of one-dimensional objects, although linear density can also be used to describe the density of a three-dimensional quantity along one particular dimension.  Just as density is most often used to mean mass density, the term linear density likewise often refers to linear mass density.  However, this is only one example of a linear density, as any quantity can be measured in terms of its value along one dimension.\nConsider a long, thin rod of mass \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   and length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  .  To calculate the average linear mass density, \n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{m}}\n  , of this one dimensional object, we can simply divide the total mass, \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  , by the total length, \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  :\n\n  \n    \n      \n        m\n        =\n        \n          \n            M\n            L\n          \n        \n      \n    \n    {\\displaystyle m={\\frac {M}{L}}}\n  If we describe the rod as having a varying mass (one that varies as a function of position along the length of the rod, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  ), we can write:\n\n  \n    \n      \n        m\n        =\n        m\n        (\n        l\n        )\n      \n    \n    {\\displaystyle m=m(l)}\n  Each infinitesimal unit of mass, \n  \n    \n      \n        d\n        m\n      \n    \n    {\\displaystyle dm}\n  , is equal to the product of its linear mass density, \n  \n    \n      \n        \n          \u03bb\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{m}}\n  , and the infinitesimal unit of length, \n  \n    \n      \n        d\n        l\n      \n    \n    {\\displaystyle dl}\n  :\n\n  \n    \n      \n        d\n        m\n        =\n        \n          \u03bb\n          \n            m\n          \n        \n        d\n        l\n      \n    \n    {\\displaystyle dm=\\lambda _{m}dl}\n  The linear mass density can then be understood as the derivative of the mass function with respect to the one dimension of the rod (the position along its length \n  \n    \n      \n        m\n        =\n        \n          \n            \n              d\n              m\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle m={\\frac {dm}{dl}}}\n  )\nThe SI unit of linear mass density is the kilogram per meter (kg/m).\nLinear density of fibers and yarns can be measured by many methods. The simplest one is to measure a length of material and weigh it. However, this requires a large sample and masks the variability of linear density along the thread, and is difficult to apply if the fibers are crimped or otherwise cannot lay flat relaxed. If the density of the material is known, the fibers are measured individually and have a simple shape, a more accurate method is direct imaging of the fiber with SEM to measure the diameter and calculation of the linear density. Finally, linear density is directly measured with a vibroscope. The sample is tensioned between two hard points, mechanical vibration is induced and the fundamental frequency is measured.\n\n\n== Linear charge density ==\nConsider a long, thin wire of charge \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   and length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  .  To calculate the average linear charge density, \n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{q}}\n  , of this one dimensional object, we can simply divide the total charge, \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  , by the total length, \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  :\n\n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            q\n          \n        \n        =\n        \n          \n            Q\n            L\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{q}={\\frac {Q}{L}}}\n  If we describe the wire as having a varying charge (one that varies as a function of position along the length of the rod, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  ), we can write:\n\n  \n    \n      \n        q\n        =\n        q\n        (\n        l\n        )\n      \n    \n    {\\displaystyle q=q(l)}\n  Each infinitesimal unit of charge, \n  \n    \n      \n        d\n        q\n      \n    \n    {\\displaystyle dq}\n  , is equal to the product of its linear charge density, \n  \n    \n      \n        \n          \u03bb\n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{q}}\n  , and the infinitesimal unit of length, \n  \n    \n      \n        d\n        l\n      \n    \n    {\\displaystyle dl}\n  :\n\n  \n    \n      \n        d\n        q\n        =\n        \n          \u03bb\n          \n            q\n          \n        \n        d\n        l\n      \n    \n    {\\displaystyle dq=\\lambda _{q}dl}\n  The linear charge density can then be understood as the derivative of the charge function with respect to the one dimension of the wire (the position along its length, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  )\n\n  \n    \n      \n        \n          \u03bb\n          \n            q\n          \n        \n        =\n        \n          \n            \n              d\n              q\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle \\lambda _{q}={\\frac {dq}{dl}}}\n  Notice that these steps were the exact same ones we took before to find :\n  \n    \n      \n        \n          \n            \n              d\n              m\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {dm}{dl}}}\n  \nThe SI unit of linear charge density is the coulomb per meter (C/m).\n\n\n== Other applications ==\nIn drawing or printing, the term linear density also refers to how densely or heavily a line is drawn.\n\n\n== Units ==\n\nCommon units include:\n\nkilogram per meter\nounce (mass) per foot\nounce (mass) per inch\npound (mass) per yard: used in the North American railway industry for the linear density of rails\npound (mass) per foot\npound (mass) per inch\ntex, a unit of measure for the linear density of fibers, defined as the mass in grams per 1,000 meters\ndenier, a unit of measure for the linear density of fibers, defined as the mass in grams per 9,000 meters\ndecitex (dtex), the SI unit for the linear density of fibers, defined as the mass in grams per 10,000 meters\n\n\n== See also ==\nDensity\nColumnar density\nPaper density\n\n\n== References ==",
        "unit": "linear current density",
        "url": "https://en.wikipedia.org/wiki/Linear_density"
    },
    {
        "_id": "Megabyte",
        "clean": "Megabyte",
        "text": "The megabyte is a multiple of the unit byte for digital information. Its recommended unit symbol is MB.  The unit prefix mega is a multiplier of 1000000 (106) in the International System of Units (SI). Therefore, one megabyte is one million bytes of information. This definition has been incorporated into the International System of Quantities.\nHowever, in the computer and information technology fields, several other definitions are used that arose for historical reasons of convenience. A common usage has been to designate one megabyte as 1048576bytes (220 B), a measurement that conveniently expresses the binary multiples inherent in digital computer memory architectures. However, most standards bodies have deprecated this usage in favor of a set of binary prefixes, in which this quantity is designated by the unit mebibyte (MiB). Less common is a convention that used the megabyte to mean 1000\u00d71024 (1024000) bytes.\n\n\n== Definitions ==\nThe megabyte is commonly used to measure either 10002 bytes or 10242 bytes. The interpretation of using base 1024 originated as a compromise technical jargon for the byte multiples that needed to be expressed by the powers of 2 but lacked a convenient name. As 1024 (210) approximates 1000 (103), roughly corresponding to the SI prefix kilo-, it was a convenient term to denote the binary multiple.  In 1998 the International Electrotechnical Commission (IEC) proposed standards for binary prefixes requiring the use of megabyte to strictly denote 10002 bytes and mebibyte to denote 10242 bytes.  By the end of 2009, the IEC Standard had been adopted by the IEEE, EU, ISO and NIST. Nevertheless, the term megabyte continues to be widely used with different meanings:\n\nBase 10\n1 MB = 1000000 bytes (= 10002 B = 106 B) is the definition recommended by the International System of Units (SI) and the International Electrotechnical Commission IEC. This definition is used in networking contexts and most storage media, particularly hard drives, flash-based storage, and DVDs, and is also consistent with the other uses of the SI prefix in computing, such as CPU clock speeds or measures of performance. The Mac OS X 10.6 file manager is a notable example of this usage in software. Since Snow Leopard, file sizes are reported in decimal units.In this convention, one thousand megabytes (1000 MB) is equal to one gigabyte (1 GB), where 1 GB is one billion bytes.\n\nBase 2\n1 MB = 1048576 bytes (= 10242 B = 220 B) is the definition used by Microsoft Windows in reference to computer memory, such as RAM. This definition is synonymous with the unambiguous binary prefix mebibyte.In this convention, one thousand and twenty-four megabytes (1024 MB) is equal to one gigabyte (1 GB), where 1 GB is 10243 bytes.\n\nMixed\n1 MB = 1024000 bytes (= 1000\u00d71024 B) is the definition used to describe the formatted capacity of the 1.44 MB 3.5-inch HD floppy disk, which actually has a capacity of 1474560bytes.Semiconductor memory doubles in size for each address lane added to an integrated circuit package, which favors counts that are powers of two. The capacity of a disk drive is the product of the sector size, number of sectors per track, number of tracks per side, and the number of disk platters in the drive. Changes in any of these factors would not usually double the size. Sector sizes were set as powers of two (most common 512 bytes or 4096 bytes) for convenience in processing. It was a natural extension to give the capacity of a disk drive in multiples of the sector size, giving a mix of decimal and binary multiples when expressing total disk capacity.\n\n\n== Examples of use ==\n\nDepending on compression methods and file format, a megabyte of data can roughly be:\n\na 1 megapixel bitmap image with 256 colors (8 bits/pixel color depth) stored without any compression.\na 4 megapixel JPEG image with normal compression.\napproximately 1 minute of 128 kbit/s MP3 compressed music.\n6 seconds of uncompressed CD audio.\na typical English book volume in plain text format (500 pages \u00d7 2000 characters per page).The human genome consists of DNA representing 800 MB of data. The parts that differentiate one person from another can be compressed to 4 MB.\n\n\n== See also ==\nTimeline of binary prefixes\nGigabyte \u00a7 Consumer confusion\n\n\n== References ==\n\n\n== External links ==\nHistorical Notes About The Cost Of Hard Drive Storage Space\nthe megabyte (established definition in Networking and Storage industries; from whatis.com)\nInternational Electrotechnical Commission definitions\nIEC prefixes and symbols for binary multiples",
        "unit": "megabyte",
        "url": "https://en.wikipedia.org/wiki/Megabyte"
    },
    {
        "_id": "Torque",
        "clean": "Torque",
        "text": "Torque, moment, or moment of force is rotational force. Just as a linear force is a push or a pull, a torque can be thought of as a twist to an object. In three dimensions, the torque is a pseudovector; for point particles, it is given by the cross product of the position vector (distance vector) and the force vector.\nThe symbol for torque is typically \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n  , the lowercase Greek letter tau. When it is called moment of force, it is commonly denoted by M.\nThe magnitude of torque of a rigid body depends on three quantities: the force applied, the lever arm vector connecting the origin to the point of force application, and the angle between the force and lever arm vectors. In symbols:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} \\,\\!}\n  \n  \n    \n      \n        \u03c4\n        =\n        \u2016\n        \n          r\n        \n        \u2016\n        \n        \u2016\n        \n          F\n        \n        \u2016\n        sin\n        \u2061\n        \u03b8\n        \n        \n      \n    \n    {\\displaystyle \\tau =\\|\\mathbf {r} \\|\\,\\|\\mathbf {F} \\|\\sin \\theta \\,\\!}\n  where\n\n  \n    \n      \n        \n          \u03c4\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}}\n   is the torque vector and \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n   is the magnitude of the torque,\nr is the position vector (a vector from the origin of the coordinate system defined to the point where the force is applied)\nF is the force vector,\n\u00d7 denotes the cross product, which is defined as magnitudes of the respective vectors times sin \u03b8.\n\u03b8 is the angle between the force vector and the lever arm vector.The SI unit for torque is N\u22c5m. For more on the units of torque, see Units.\n\n\n== Defining terminology ==\n\nTorque is referred to using different vocabulary depending on geographical location and field of study. This article refers to the definition used in US physics in its usage of the word torque. In the UK and in US mechanical engineering, torque is referred to as moment of force, usually shortened to moment. In US physics and UK physics terminology these terms are interchangeable, unlike in US mechanical engineering, where the term torque is used for the closely related \"resultant moment of a couple\".Torque is defined mathematically as the rate of change of angular momentum of an object. The definition of torque states that one or both of the angular velocity or the moment of inertia of an object are changing. Moment is the general term used for the tendency of one or more applied forces to rotate an object about an axis, but not necessarily to change the angular momentum of the object (the concept which is called torque in physics). For example, a rotational force applied to a shaft causing acceleration, such as a drill bit accelerating from rest, results in a moment called a torque. By contrast, a lateral force on a beam produces a moment (called a bending moment), but since the angular momentum of the beam is not changing, this bending moment is not called a torque. Similarly with any force couple on an object that has no change to its angular momentum, such moment is also not called a torque.\nThis article follows the US physics terminology by calling all moments by the term torque, whether or not they cause the angular momentum of an object to change.\n\n\n== History ==\nThe concept of torque, also called moment or couple, originated with the studies of Archimedes on levers. The term torque was apparently introduced into English scientific literature by James Thomson, the brother of Lord Kelvin, in 1884.\n\n\n== Definition and relation to angular momentum ==\n\nA force applied at a right angle to a lever multiplied by its distance from the lever's fulcrum (the length of the lever arm) is its torque. A force of three newtons applied two metres from the fulcrum, for example, exerts the same torque as a force of one newton applied six metres from the fulcrum. The direction of the torque can be determined by using the right hand grip rule: if the fingers of the right hand are curled from the direction of the lever arm to the direction of the force, then the thumb points in the direction of the torque.More generally, the torque on a particle (which has the position r in some reference frame) can be defined as the cross product:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} ,}\n  where r is the particle's position vector relative to the fulcrum, and F is the force acting on the particle. The magnitude \u03c4 of the torque is given by\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        F\n        sin\n        \u2061\n        \u03b8\n        ,\n        \n      \n    \n    {\\displaystyle \\tau =rF\\sin \\theta ,\\!}\n  where r is the distance from the axis of rotation to the particle, F is the magnitude of the force applied, and \u03b8 is the angle between the position and force vectors. Alternatively,\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        \n          F\n          \n            \u22a5\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =rF_{\\perp },}\n  where F\u22a5 is the amount of force directed perpendicularly to the position of the particle. Any force directed parallel to the particle's position vector does not produce a torque.It follows from the properties of the cross product that the torque vector is perpendicular to both the position and force vectors. The torque vector points along the axis of the rotation that the force vector (starting from rest) would initiate. The resulting torque vector direction is determined by the right-hand rule.The unbalanced torque on a body along axis of rotation determines the rate of change of the body's angular momentum,\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}}\n  where L is the angular momentum vector and t is time. If multiple torques are acting on the body, it is instead the net torque which determines the rate of change of the angular momentum:\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n        +\n        \u22ef\n        +\n        \n          \n            \u03c4\n          \n          \n            n\n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{1}+\\cdots +{\\boldsymbol {\\tau }}_{n}={\\boldsymbol {\\tau }}_{\\mathrm {net} }={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}.}\n  For the motion of a point particle,\n\n  \n    \n      \n        \n          L\n        \n        =\n        I\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {L} =I{\\boldsymbol {\\omega }},}\n  where I is the moment of inertia and \u03c9 is the angular velocity. It follows that\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              (\n              I\n              \n                \u03c9\n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        I\n        \n          \n            \n              \n                d\n              \n              \n                \u03c9\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        +\n        \n          \n            \n              \n                d\n              \n              I\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        \n          \n            \n              \n                d\n              \n              (\n              m\n              \n                r\n                \n                  2\n                \n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        2\n        r\n        \n          p\n          \n            \n              |\n            \n            \n              |\n            \n          \n        \n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{\\mathrm {net} }={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} (I{\\boldsymbol {\\omega }})}{\\mathrm {d} t}}=I{\\frac {\\mathrm {d} {\\boldsymbol {\\omega }}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} I}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+{\\frac {\\mathrm {d} (mr^{2})}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+2rp_{||}{\\boldsymbol {\\omega }},}\n  where \u03b1 is the angular acceleration of the particle, and p|| is the radial component of its linear momentum. This equation is the rotational analogue of Newton's Second Law for point particles, and is valid for any type of trajectory. Note that although force and acceleration are always parallel and directly proportional, the torque \u03c4 need not be parallel or directly proportional to the angular acceleration \u03b1. This arises from the fact that although mass is always conserved, the moment of inertia in general is not.\n\n\n=== Proof of the equivalence of definitions ===\nThe definition of angular momentum for a single particle is:\n\n  \n    \n      \n        \n          L\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          p\n        \n      \n    \n    {\\displaystyle \\mathbf {L} =\\mathbf {r} \\times {\\boldsymbol {p}}}\n  where \"\u00d7\" indicates the vector cross product, p is the particle's linear momentum, and r is the displacement vector from the origin (the origin is assumed to be a fixed location anywhere in space). The time-derivative of this is:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          \n            \n              \n                d\n              \n              \n                p\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        +\n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \u00d7\n        \n          p\n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times {\\frac {\\mathrm {d} {\\boldsymbol {p}}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}}\\times {\\boldsymbol {p}}.}\n  This result can easily be proven by splitting the vectors into components and applying the product rule. Now using the definition of force \n  \n    \n      \n        \n          F\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                p\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} ={\\frac {\\mathrm {d} {\\boldsymbol {p}}}{\\mathrm {d} t}}}\n   (whether or not mass is constant) and the definition of velocity \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          v\n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}}=\\mathbf {v} }\n  \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          p\n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times \\mathbf {F} +\\mathbf {v} \\times {\\boldsymbol {p}}.}\n  The cross product of momentum \n  \n    \n      \n        \n          p\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {p}}}\n   with its associated velocity \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   is zero because velocity and momentum are parallel, so the second term vanishes.\nBy definition, torque \u03c4 = r \u00d7 F. Therefore, torque on a particle is equal to the\nfirst derivative of its angular momentum with respect to time.\nIf multiple forces are applied, Newton's second law instead reads Fnet = ma, and it follows that\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times \\mathbf {F} _{\\mathrm {net} }={\\boldsymbol {\\tau }}_{\\mathrm {net} }.}\n  This is a general proof.\n\n\n== Units ==\nTorque has dimension force times distance, symbolically L2MT\u22122. Official SI literature suggests using the unit newton metre (N\u22c5m) or the unit joule per radian. The unit newton metre is properly denoted N\u22c5m or N m. This avoids ambiguity with mN, millinewtons.\nThe SI unit for energy or work is the joule. It is dimensionally equivalent to a force of one newton acting over a distance of one metre, but it is not used for torque. Energy and torque are entirely different concepts, so the practice of using different unit names (i.e., reserving newton metres for torque and using only joules for energy) helps avoid mistakes and misunderstandings. The dimensional equivalence of these units is not simply a coincidence: a torque of 1 N\u22c5m applied through a full revolution will require an energy of exactly 2\u03c0 joules. Mathematically,\n\n  \n    \n      \n        E\n        =\n        \u03c4\n        \u03b8\n         \n      \n    \n    {\\displaystyle E=\\tau \\theta \\ }\n  where E is the energy, \u03c4 is magnitude of the torque, and \u03b8 is the angle moved (in radians). This equation motivates the alternate unit name joules per radian.In Imperial units, \"pound-force-feet\" (lbf\u22c5ft), \"foot-pounds-force\", \"inch-pounds-force\", \"ounce-force-inches\" (ozf\u22c5in) are used, and other non-SI units of torque includes \"metre-kilograms-force\". For all these units, the word \"force\" is often left out. For example, abbreviating \"pound-force-foot\" to simply \"pound-foot\" (in this case, it would be implicit that the \"pound\" is pound-force and not pound-mass). This is an example of the confusion caused by the use of English units that may be avoided with SI units because of the careful distinction in SI between force (in newtons) and mass (in kilograms).\nTorque is sometimes listed with units that do not make dimensional sense, such as the gram-centimeter. In this case, \"gram\" should be understood as the force given by the weight of 1 gram on the surface of the Earth (i.e. 0.00980665 N). The surface of the Earth has a standard gravitational field strength of 9.80665 N/kg.\n\n\n== Special cases and other facts ==\n\n\n=== Moment arm formula ===\n\nA very useful special case, often given as the definition of torque in fields other than physics, is as follows:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          moment arm\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{moment arm}})({\\text{force}}).}\n  The construction of the \"moment arm\" is shown in the figure to the right, along with the vectors r and F mentioned above. The problem with this definition is that it does not give the direction of the torque but only the magnitude, and hence it is difficult to use in three-dimensional cases. If the force is perpendicular to the displacement vector r, the moment arm will be equal to the distance to the centre, and torque will be a maximum for the given force. The equation for the magnitude of a torque, arising from a perpendicular force:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          distance to centre\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{distance to centre}})({\\text{force}}).}\n  For example, if a person places a force of 10 N at the terminal end of a wrench that is 0.5 m long (or a force of 10 N exactly 0.5 m from the twist point of a wrench of any length), the torque will be 5 N.m \u2013 assuming that the person moves the wrench by applying force in the plane of movement and perpendicular to the wrench.\n\n\n=== Static equilibrium ===\nFor an object to be in static equilibrium, not only must the sum of the forces be zero, but also the sum of the torques (moments) about any point. For a two-dimensional situation with horizontal and vertical forces, the sum of the forces requirement is two equations: \u03a3H = 0 and \u03a3V = 0, and the torque a third equation: \u03a3\u03c4 = 0. That is, to solve statically determinate equilibrium problems in two-dimensions, three equations are used.\n\n\n=== Net force versus torque ===\nWhen the net force on the system is zero, the torque measured from any point in space is the same. For example, the torque on a current-carrying loop in a uniform magnetic field is the same regardless of your point of reference. If the net force \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle \\mathbf {F} }\n   is not zero, and \n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{1}}\n   is the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{1}}\n  , then the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{2}}\n   is \u2026\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n        +\n        (\n        \n          \n            r\n          \n          \n            1\n          \n        \n        \u2212\n        \n          \n            r\n          \n          \n            2\n          \n        \n        )\n        \u00d7\n        \n          F\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{2}={\\boldsymbol {\\tau }}_{1}+(\\mathbf {r} _{1}-\\mathbf {r} _{2})\\times \\mathbf {F} }\n  \n\n\n== Machine torque ==\n\nTorque is part of the basic specification of an engine: the power output of an engine is expressed as its torque multiplied by its rotational speed of the axis. Internal-combustion engines produce useful torque only over a limited range of rotational speeds (typically from around 1,000\u20136,000 rpm for a small car). The varying torque output over that range can be  measured with a dynamometer, and shown as a torque curve.\nSteam engines and electric motors tend to produce maximum torque close to zero rpm, with the torque diminishing as rotational speed rises (due to increasing friction and other constraints). Reciprocating steam engines and electric motors can start heavy loads from zero RPM without a clutch.\n\n\n== Relationship between torque, power, and energy ==\nIf a force is allowed to act through a distance, it is doing mechanical work. Similarly, if torque is allowed to act through a rotational distance, it is doing work. Mathematically, for rotation about a fixed axis through the center of mass,\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n         \n        \n          d\n        \n        \u03b8\n        ,\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\ \\mathrm {d} \\theta ,}\n  where W is work, \u03c4 is torque, and \u03b81 and \u03b82 represent (respectively) the initial and final angular positions of the body.\n\n\n=== Proof ===\nThe work done by a variable force acting over a finite linear displacement \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is given by integrating the force with respect to an elemental linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}}\n  \n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {F}}\\cdot \\mathrm {d} {\\vec {s}}}\n  However, the infinitesimal linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}}\n   is related to a corresponding angular displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {\\theta }}}\n   and the radius vector \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   as \n\n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n        =\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}=\\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n  Substitution in the above expression for work gives\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n  The expression \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n   is a scalar triple product given by \n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n            \n            \n              \n                \n                  r\n                  \u2192\n                \n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle \\left[{\\vec {F}}\\,\\mathrm {d} {\\vec {\\theta }}\\,{\\vec {r}}\\right]}\n  . An alternate expression for the same scalar triple product is\n\n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n            \n            \n              \n                \n                  r\n                  \u2192\n                \n              \n            \n          \n          ]\n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\left[{\\vec {F}}\\,\\mathrm {d} {\\vec {\\theta }}\\,{\\vec {r}}\\right]={\\vec {r}}\\times {\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  But as per the definition of torque,\n\n  \n    \n      \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {\\tau }}={\\vec {r}}\\times {\\vec {F}}}\n  Corresponding substitution in the expression of work gives,\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  Since the parameter of integration has been changed from linear displacement to angular displacement, the limits of the integration also change correspondingly, giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}{\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  If the torque and the angular displacement are in the same direction, then the scalar product reduces to a product of magnitudes; i.e., \n  \n    \n      \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        =\n        \n          |\n          \n            \n              \n                \u03c4\n                \u2192\n              \n            \n          \n          |\n        \n        \n          |\n          \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n          \n          |\n        \n        cos\n        \u2061\n        0\n        =\n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle {\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}=\\left|{\\vec {\\tau }}\\right|\\left|\\,\\mathrm {d} {\\vec {\\theta }}\\right|\\cos 0=\\tau \\,\\mathrm {d} \\theta }\n   giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\,\\mathrm {d} \\theta }\n  It follows from the work-energy theorem that W also represents the change in the rotational kinetic energy Er of the body, given by\n\n  \n    \n      \n        \n          E\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        I\n        \n          \u03c9\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle E_{\\mathrm {r} }={\\tfrac {1}{2}}I\\omega ^{2},}\n  where I is the moment of inertia of the body and \u03c9 is its angular speed.Power is the work per unit time, given by\n\n  \n    \n      \n        P\n        =\n        \n          \u03c4\n        \n        \u22c5\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle P={\\boldsymbol {\\tau }}\\cdot {\\boldsymbol {\\omega }},}\n  where P is power, \u03c4 is torque, \u03c9 is the angular velocity, and \u22c5 represents the scalar product.\nAlgebraically, the equation may be rearranged to compute torque for a given angular speed and power output. Note that the power injected by the torque depends only on the instantaneous angular speed \u2013 not on whether the angular speed increases, decreases, or remains constant while the torque is being applied (this is equivalent to the linear case where the power injected by a force depends only on the instantaneous speed \u2013 not on the resulting acceleration, if any).\nIn practice, this relationship can be observed in bicycles: Bicycles are typically composed of two road wheels, front and rear gears (referred to as sprockets) meshing with a circular chain, and a derailleur mechanism if the bicycle's transmission system allows multiple gear ratios to be used (i.e. multi-speed bicycle), all of which attached to the frame. A cyclist, the person who rides the bicycle, provides the input power by turning pedals, thereby cranking the front sprocket (commonly referred to as chainring). The input power provided by the cyclist is equal to the product of cadence (i.e. the number of pedal revolutions per minute) and the torque on spindle of the bicycle's crankset. The bicycle's drivetrain transmits the input power to the road wheel, which in turn conveys the received power to the road as the output power of the bicycle. Depending on the gear ratio of the bicycle, a (torque, rpm)input pair is converted to a (torque, rpm)output pair. By using a larger rear gear, or by switching to a lower gear in multi-speed bicycles, angular speed of the road wheels is decreased while the torque is increased, product of which (i.e. power) does not change.\nConsistent units must be used. For metric SI units, power is watts, torque is newton metres and angular speed is radians per second (not rpm and not revolutions per second).\nAlso, the unit newton metre is dimensionally equivalent to the joule, which is the unit of energy. However, in the case of torque, the unit is assigned to a vector, whereas for energy, it is assigned to a scalar.\n\n\n=== Conversion to other units ===\nA conversion factor may be necessary when using different units of power or torque.  For example, if rotational speed (revolutions per time) is used in place of angular speed (radians per time), we multiply by a factor of 2\u03c0 radians per revolution. In the following formulas, P is power, \u03c4 is torque, and \u03bd (Greek letter nu) is rotational speed.\n\n  \n    \n      \n        P\n        =\n        \u03c4\n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \u03bd\n      \n    \n    {\\displaystyle P=\\tau \\cdot 2\\pi \\cdot \\nu }\n  Showing units:\n\n  \n    \n      \n        P\n        (\n        \n          \n            W\n          \n        \n        )\n        =\n        \u03c4\n        \n          \n            (\n            N\n            \u22c5\n            m\n            )\n          \n        \n        \u22c5\n        2\n        \u03c0\n        \n          \n            (\n            r\n            a\n            d\n            \n              /\n            \n            r\n            e\n            v\n            )\n          \n        \n        \u22c5\n        \u03bd\n        \n          \n            (\n            r\n            e\n            v\n            \n              /\n            \n            s\n            e\n            c\n            )\n          \n        \n      \n    \n    {\\displaystyle P({\\rm {W}})=\\tau {\\rm {(N\\cdot m)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu {\\rm {(rev/sec)}}}\n  Dividing by 60 seconds per minute gives us the following.\n\n  \n    \n      \n        P\n        (\n        \n          \n            W\n          \n        \n        )\n        =\n        \n          \n            \n              \u03c4\n              \n                \n                  (\n                  N\n                  \u22c5\n                  m\n                  )\n                \n              \n              \u22c5\n              2\n              \u03c0\n              \n                \n                  (\n                  r\n                  a\n                  d\n                  \n                    /\n                  \n                  r\n                  e\n                  v\n                  )\n                \n              \n              \u22c5\n              \u03bd\n              \n                \n                  (\n                  r\n                  p\n                  m\n                  )\n                \n              \n            \n            60\n          \n        \n      \n    \n    {\\displaystyle P({\\rm {W}})={\\frac {\\tau {\\rm {(N\\cdot m)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu {\\rm {(rpm)}}}{60}}}\n  where rotational speed is in revolutions per minute (rpm).\nSome people (e.g., American automotive engineers) use horsepower (imperial mechanical) for power, foot-pounds (lbf\u22c5ft) for torque and rpm for rotational speed. This results in the formula changing to:\n\n  \n    \n      \n        P\n        (\n        \n          \n            h\n            p\n          \n        \n        )\n        =\n        \n          \n            \n              \u03c4\n              \n                \n                  (\n                  l\n                  b\n                  f\n                  \u22c5\n                  f\n                  t\n                  )\n                \n              \n              \u22c5\n              2\n              \u03c0\n              \n                \n                  (\n                  r\n                  a\n                  d\n                  \n                    /\n                  \n                  r\n                  e\n                  v\n                  )\n                \n              \n              \u22c5\n              \u03bd\n              (\n              \n                \n                  r\n                  p\n                  m\n                \n              \n              )\n            \n            \n              33\n              ,\n              000\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle P({\\rm {hp}})={\\frac {\\tau {\\rm {(lbf\\cdot ft)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu ({\\rm {rpm}})}{33,000}}.}\n  The constant below (in foot pounds per minute) changes with the definition of the horsepower; for example, using metric horsepower, it becomes approximately 32,550.\nUse of other units (e.g., BTU per hour for power) would require a different custom conversion factor.\n\n\n=== Derivation ===\nFor a rotating object, the linear distance covered at the circumference of rotation is the product of the radius with the angle covered.  That is:  linear distance = radius \u00d7 angular distance.   And by definition, linear distance = linear speed \u00d7 time = radius \u00d7 angular speed \u00d7 time.\nBy the definition of torque: torque = radius \u00d7 force. We can rearrange this to determine force = torque \u00f7 radius. These two values can be substituted into the definition of power:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        force\n                      \n                      \u22c5\n                      \n                        linear distance\n                      \n                    \n                    time\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        (\n                        \n                          \n                            \n                              torque\n                              r\n                            \n                          \n                        \n                        )\n                      \n                      \u22c5\n                      (\n                      r\n                      \u22c5\n                      \n                        angular speed\n                      \n                      \u22c5\n                      t\n                      )\n                    \n                    t\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                \n                  angular speed\n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\frac {{\\text{force}}\\cdot {\\text{linear distance}}}{\\text{time}}}\\\\[6pt]&={\\frac {\\left({\\dfrac {\\text{torque}}{r}}\\right)\\cdot (r\\cdot {\\text{angular speed}}\\cdot t)}{t}}\\\\[6pt]&={\\text{torque}}\\cdot {\\text{angular speed}}.\\end{aligned}}}\n  The radius r and time t have dropped out of the equation.  However, angular speed must be in radians, by the assumed direct relationship between linear speed and angular speed at the beginning of the derivation.  If the rotational speed is measured in revolutions per unit of time, the linear speed and distance are increased proportionately by 2\u03c0 in the above derivation to give:\n\n  \n    \n      \n        \n          power\n        \n        =\n        \n          torque\n        \n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \n          rotational speed\n        \n        .\n        \n      \n    \n    {\\displaystyle {\\text{power}}={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}.\\,}\n  If torque is in newton metres and rotational speed in revolutions per second, the above equation gives power in newton metres per second or watts.  If Imperial units are used, and if torque is in pounds-force feet and rotational speed in revolutions per minute, the above equation gives power in foot pounds-force per minute.  The horsepower form of the equation is then derived by applying the conversion factor 33,000 ft\u22c5lbf/min per horsepower:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                2\n                \u03c0\n                \u22c5\n                \n                  rotational speed\n                \n                \u22c5\n                \n                  \n                    \n                      \n                        ft\n                      \n                      \u22c5\n                      \n                        lbf\n                      \n                    \n                    min\n                  \n                \n                \u22c5\n                \n                  \n                    horsepower\n                    \n                      33\n                      ,\n                      000\n                      \u22c5\n                      \n                        \n                          \n                            \n                              ft\n                            \n                            \u22c5\n                            \n                              lbf\n                            \n                          \n                          min\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2248\n                \n                  \n                    \n                      \n                        torque\n                      \n                      \u22c5\n                      \n                        RPM\n                      \n                    \n                    \n                      5\n                      ,\n                      252\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}\\cdot {\\frac {{\\text{ft}}\\cdot {\\text{lbf}}}{\\text{min}}}\\cdot {\\frac {\\text{horsepower}}{33,000\\cdot {\\frac {{\\text{ft}}\\cdot {\\text{lbf}}}{\\text{min}}}}}\\\\[6pt]&\\approx {\\frac {{\\text{torque}}\\cdot {\\text{RPM}}}{5,252}}\\end{aligned}}}\n  because \n  \n    \n      \n        5252.113122\n        \u2248\n        \n          \n            \n              33\n              ,\n              000\n            \n            \n              2\n              \u03c0\n            \n          \n        \n        .\n        \n      \n    \n    {\\displaystyle 5252.113122\\approx {\\frac {33,000}{2\\pi }}.\\,}\n  \n\n\n== Principle of moments ==\nThe Principle of Moments, also known as Varignon's theorem (not to be confused with the geometrical theorem of the same name) states that the sum of torques due to several forces applied to a single point is equal to the torque due to the sum (resultant) of the forces. Mathematically, this follows from:\n\n  \n    \n      \n        (\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            1\n          \n        \n        )\n        +\n        (\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            2\n          \n        \n        )\n        +\n        \u22ef\n        =\n        \n          r\n        \n        \u00d7\n        (\n        \n          \n            F\n          \n          \n            1\n          \n        \n        +\n        \n          \n            F\n          \n          \n            2\n          \n        \n        +\n        \u22ef\n        )\n        .\n      \n    \n    {\\displaystyle (\\mathbf {r} \\times \\mathbf {F} _{1})+(\\mathbf {r} \\times \\mathbf {F} _{2})+\\cdots =\\mathbf {r} \\times (\\mathbf {F} _{1}+\\mathbf {F} _{2}+\\cdots ).}\n  \n\n\n== Torque multiplier ==\n\nTorque can be multiplied via three methods:  by locating the fulcrum such that the length of a lever is increased; by using a longer lever; or by the use of a speed reducing gearset or gear box.  Such a mechanism multiplies torque, as rotation rate is reduced.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\"Horsepower and Torque\" An article showing how power, torque, and gearing affect a vehicle's performance.\n\"Torque vs. Horsepower: Yet Another Argument\" An automotive perspective\nTorque and Angular Momentum in Circular Motion  on Project PHYSNET.\nAn interactive simulation of torque\nTorque Unit Converter\nA feel for torque An order-of-magnitude interactive.",
        "unit": "torque",
        "url": "https://en.wikipedia.org/wiki/Torque"
    },
    {
        "_id": "Frequency",
        "clean": "Frequency",
        "text": "Frequency is the number of occurrences of a repeating event per unit of time. It is also referred to as temporal frequency, which emphasizes the contrast to spatial frequency and angular frequency. The period is the duration of time of one cycle in a repeating event, so the period is the reciprocal of the frequency.  For example, if a newborn baby's heart beats at a frequency of 120 times a minute, its period\u2014the time interval between beats\u2014is half a second (that is, 60 seconds divided by 120 beats).  Frequency is an important parameter used in science and engineering to specify the rate of oscillatory and vibratory phenomena, such as mechanical vibrations, audio signals (sound), radio waves, and light.\n\n\n== Definitions ==\n\nFor cyclical processes, such as rotation, oscillations, or waves, frequency is defined as a number of cycles per unit time. In physics and engineering disciplines, such as optics, acoustics, and radio, frequency is usually denoted by a Latin letter f or by the Greek letter \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   or \u03bd (nu) (see e.g. Planck's formula).\nThe relation between the frequency and the period \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   of a repeating event or oscillation is given by\n\n  \n    \n      \n        f\n        =\n        \n          \n            1\n            T\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {1}{T}}.}\n  \n\n\n== Units ==\nThe SI derived unit of frequency is the hertz (Hz), named after the German physicist Heinrich Hertz. One hertz means that an event repeats once per second. A previous name for this unit was cycles per second (cps). The SI unit for period is the second.\nA traditional unit of measure used with rotating mechanical devices is revolutions per minute, abbreviated r/min or rpm. 60 rpm equals one hertz.\n\n\n== Period versus frequency ==\nAs a matter of convenience, longer and slower waves, such as ocean surface waves, tend to be described by wave period rather than frequency. Short and fast waves, like audio and radio, are usually described by their frequency instead of period. These commonly used conversions are listed below:\n\n\n== Related types of frequency ==\n\nAngular frequency, usually denoted by the Greek letter \u03c9 (omega), is defined as the rate of change of angular displacement, \u03b8, (during rotation), or the rate of change of the phase of a sinusoidal waveform (notably in oscillations and waves), or as the rate of change of the argument to the sine function:\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        sin\n        \u2061\n        \n          (\n          \n            \u03b8\n            (\n            t\n            )\n          \n          )\n        \n        =\n        sin\n        \u2061\n        (\n        \u03c9\n        t\n        )\n        =\n        sin\n        \u2061\n        (\n        2\n        \n          \u03c0\n        \n        f\n        t\n        )\n      \n    \n    {\\displaystyle y(t)=\\sin \\left(\\theta (t)\\right)=\\sin(\\omega t)=\\sin(2\\mathrm {\\pi } ft)}\n  \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b8\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u03c9\n        =\n        2\n        \n          \u03c0\n        \n        f\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\theta }{\\mathrm {d} t}}=\\omega =2\\mathrm {\\pi } f}\n  Angular frequency is commonly measured in radians per second (rad/s) but, for discrete-time signals, can also be expressed as radians per sampling interval, which is a dimensionless quantity.  Angular frequency (in radians) is larger than regular frequency (in Hz) by a factor of 2\u03c0.Spatial frequency is analogous to temporal frequency, but the time axis is replaced by one or more spatial displacement axes. E.g.:\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        sin\n        \u2061\n        \n          (\n          \n            \u03b8\n            (\n            t\n            ,\n            x\n            )\n          \n          )\n        \n        =\n        sin\n        \u2061\n        (\n        \u03c9\n        t\n        +\n        k\n        x\n        )\n      \n    \n    {\\displaystyle y(t)=\\sin \\left(\\theta (t,x)\\right)=\\sin(\\omega t+kx)}\n  \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b8\n            \n            \n              \n                d\n              \n              x\n            \n          \n        \n        =\n        k\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\theta }{\\mathrm {d} x}}=k}\n  Wavenumber, k, is the spatial frequency analogue of angular temporal frequency and is measured in radians per meter. In the case of more than one spatial dimension, wavenumber is a vector quantity.\n\n\n== In wave propagation ==\n\nFor periodic waves in nondispersive media (that is, media in which the wave speed is independent of frequency), frequency has an inverse relationship to the wavelength, \u03bb (lambda). Even in dispersive media, the frequency f of a sinusoidal wave is equal to the phase velocity v of the wave divided by the wavelength \u03bb of the wave:\n\n  \n    \n      \n        f\n        =\n        \n          \n            v\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {v}{\\lambda }}.}\n  In the special case of electromagnetic waves moving through a vacuum, then v = c, where c is the speed of light in a vacuum, and this expression becomes:\n\n  \n    \n      \n        f\n        =\n        \n          \n            c\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {c}{\\lambda }}.}\n  When waves from a monochrome source travel from one medium to another, their frequency remains the same\u2014only their wavelength and speed change.\n\n\n== Measurement ==\n\nMeasurement of frequency can done in the following ways,\n\n\n=== Counting ===\nCalculating the frequency of a repeating event is accomplished by counting the number of times that event occurs within a specific time period, then dividing the count by the length of the time period. For example, if 71 events occur within 15 seconds the frequency is:\n\n  \n    \n      \n        f\n        =\n        \n          \n            71\n            \n              15\n              \n              \n                s\n              \n            \n          \n        \n        \u2248\n        4.73\n        \n        \n          Hz\n        \n      \n    \n    {\\displaystyle f={\\frac {71}{15\\,{\\text{s}}}}\\approx 4.73\\,{\\text{Hz}}}\n  If the number of counts is not very large, it is more accurate to measure the time interval for a predetermined number of occurrences, rather than the number of occurrences within a specified time.  The latter method introduces a random error into the count of between zero and one count, so on average half a count. This is called gating error and causes an average error in the calculated frequency of \n  \n    \n      \n        \u0394\n        f\n        =\n        \n          \n            1\n            \n              2\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\Delta f={\\frac {1}{2T_{m}}}}\n  , or a fractional error of \n  \n    \n      \n        \n          \n            \n              \u0394\n              f\n            \n            f\n          \n        \n        =\n        \n          \n            1\n            \n              2\n              f\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\Delta f}{f}}={\\frac {1}{2fT_{m}}}}\n   where \n  \n    \n      \n        \n          T\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle T_{m}}\n   is the timing interval and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is the measured frequency. This error decreases with frequency, so it is generally a problem at low frequencies where the number of counts N is small.\n\n\n=== Stroboscope ===\nAn older method of measuring the frequency of rotating or vibrating objects is to use a stroboscope. This is an intense repetitively flashing light (strobe light) whose frequency can be adjusted with a calibrated timing circuit. The strobe light is pointed at the rotating object and the frequency adjusted up and down. When the frequency of the strobe equals the frequency of the rotating or vibrating object, the object completes one cycle of oscillation and returns to its original position between the flashes of light, so when illuminated by the strobe the object appears stationary. Then the frequency can be read from the calibrated readout on the stroboscope. A downside of this method is that an object rotating at an integral multiple of the strobing frequency will also appear stationary.\n\n\n=== Frequency counter ===\n\nHigher frequencies are usually measured with a frequency counter. This is an electronic instrument which measures the frequency of an applied repetitive electronic signal and displays the result in hertz on a digital display. It uses digital logic to count the number of cycles during a time interval established by a precision quartz time base. Cyclic processes that are not electrical in nature, such as the rotation rate of a shaft, mechanical vibrations, or sound waves, can be converted to a repetitive electronic signal by transducers and the signal applied to a frequency counter. Frequency counters can currently cover the range up to about 100 GHz. This represents the limit of direct counting methods; frequencies above this must be measured by indirect methods.\n\n\n=== Heterodyne methods ===\nAbove the range of frequency counters, frequencies of electromagnetic signals are often measured indirectly by means of heterodyning (frequency conversion). A reference signal of a known frequency near the unknown frequency is mixed with the unknown frequency in a nonlinear mixing device such as a diode. This creates a heterodyne or \"beat\" signal at the difference between the two frequencies.  If the two signals are close together in frequency the heterodyne is low enough to be measured by a frequency counter. This process only measures the difference between the unknown frequency and the reference frequency. To reach higher frequencies, several stages of heterodyning can be used. Current research is extending this method to infrared and light frequencies (optical heterodyne detection).\n\n\n== Examples ==\n\n\n=== Light ===\n\nVisible light is an electromagnetic wave, consisting of oscillating electric and magnetic fields traveling through space. The frequency of the wave determines its color: 4\u00d71014 Hz is red light, 8\u00d71014 Hz is violet light, and between these (in the range 4-8\u00d71014 Hz) are all the other colors of the visible spectrum. An electromagnetic wave can have a frequency less than 4\u00d71014 Hz, but it will be invisible to the human eye; such waves are called infrared (IR) radiation. At even lower frequency, the wave is called a microwave, and at still lower frequencies it is called a radio wave. Likewise, an electromagnetic wave can have a frequency higher than 8\u00d71014 Hz, but it will be invisible to the human eye; such waves are called ultraviolet (UV) radiation. Even higher-frequency waves are called X-rays, and higher still are gamma rays.\nAll of these waves, from the lowest-frequency radio waves to the highest-frequency gamma rays, are fundamentally the same, and they are all called electromagnetic radiation. They all travel through a vacuum at the same speed (the speed of light), giving them wavelengths inversely proportional to their frequencies.\n\n  \n    \n      \n        \n          c\n          =\n          f\n          \u03bb\n        \n      \n    \n    {\\displaystyle \\displaystyle c=f\\lambda }\n  where c is the speed of light (c in a vacuum, or less in other media), f is the frequency and \u03bb is the wavelength.\nIn dispersive media, such as glass, the speed depends somewhat on frequency, so the wavelength is not quite inversely proportional to frequency.\n\n\n=== Sound ===\n\nSound propagates as mechanical vibration waves of pressure and displacement, in air or other substances.. In general, frequency components of a sound determine its \"color\", its timbre. When speaking about the frequency (in singular) of a sound, it means the property that most determines pitch.The frequencies an ear can hear are limited to a specific range of frequencies.  The audible frequency range for humans is typically given as being between about 20 Hz and 20,000 Hz (20 kHz), though the high frequency limit usually reduces with age. Other species have different hearing ranges. For example, some dog breeds can perceive vibrations up to 60,000 Hz.In many media, such as air, the speed of sound is approximately independent of frequency, so the wavelength of the sound waves (distance between repetitions) is approximately inversely proportional to frequency.\n\n\n=== Line current ===\n\nIn Europe, Africa, Australia, Southern South America, most of Asia, and Russia, the frequency of the alternating current in household electrical outlets is 50 Hz (close to the tone G), whereas in North America and Northern South America, the frequency of the alternating current in household electrical outlets is 60 Hz (between the tones B\u266d and B; that is, a minor third above the European frequency). The frequency of the 'hum' in an audio recording can show where the recording was made, in countries using a European, or an American, grid frequency.\n\n\n== See also ==\n\n\n== Notes and references ==\n\n\n== Further reading ==\nGiancoli, D.C. (1988). Physics for Scientists and Engineers (2nd ed.). Prentice Hall. ISBN 0-13-669201-X.\n\n\n== External links ==\nConversion: frequency to wavelength and back\nConversion: period, cycle duration, periodic time to frequency\nKeyboard frequencies = naming of notes - The English and American system versus the German system\nTeaching resource for 14-16yrs on sound including frequency\nA simple tutorial on how to build a frequency meter\nFrequency - diracdelta.co.uk \u2013 JavaScript calculation.\nA frequency generator with sound, useful for hearing tests",
        "unit": "frequency",
        "url": "https://en.wikipedia.org/wiki/Frequency"
    },
    {
        "_id": "Lumber",
        "clean": "Lumber",
        "text": "Lumber (American English; used only in North America) or timber (used in the rest of the English speaking world) is a type of wood that has been processed into beams and planks, a stage in the process of wood production. Lumber is mainly used for structural purposes but has many other uses as well.\nThere are two main types of lumber. It may be supplied either rough-sawn, or surfaced on one or more of its faces. Besides pulpwood, rough lumber is the raw material for furniture-making and other items requiring additional cutting and shaping. It is available in many species, usually hardwoods; but it is also readily available in softwoods, such as white pine and red pine, because of their low cost.Finished lumber is supplied in standard sizes, mostly for the construction industry \u2013 primarily softwood, from coniferous species, including pine, fir and spruce (collectively spruce-pine-fir), cedar, and hemlock, but also some hardwood, for high-grade flooring. It is more commonly made from softwood than hardwoods, and 80% of lumber comes from softwood.\n\n\n== Terminology ==\nIn the United States milled boards of wood are referred to as lumber. However, in Britain and other Commonwealth nations, the term timber is instead used to describe sawn wood products, like floor boards.\nIn the United States and Canada, generally timber describes standing or felled trees. Specifically in Canada, lumber describes cut and surfaced wood.In the United Kingdom, the word lumber is rarely used in relation to wood and has several other meanings, including unused or unwanted items. Referring to wood, Timber is almost universally used instead.\n\n\n=== Remanufactured lumber ===\n\nRemanufactured lumber is the result of secondary or tertiary processing/cutting of previously milled lumber. Specifically, it is lumber cut for industrial or wood-packaging use. Lumber is cut by ripsaw or resaw to create dimensions that are not usually processed by a primary sawmill.\nResawing is the splitting of 1-inch through 12-inch hardwood or softwood lumber into two or more thinner pieces of full-length boards. For example, splitting a ten-foot 2\u00d74 into two ten-foot 1\u00d74s is considered resawing.\n\n\n=== Plastic lumber ===\n\nStructural lumber may also be produced from recycled plastic and new plastic stock. Its introduction has been strongly opposed by the forestry industry. Blending fiberglass in plastic lumber enhances its strength, durability, and fire resistance. Plastic fiberglass structural lumber can have a \"class 1 flame spread rating of 25 or less, when tested in accordance with ASTM standard E 84,\" which means it burns slower than almost all treated wood lumber.\n\n\n== Conversion of wood logs ==\nLogs are converted into timber by being sawn, hewn, or split. Sawing with a rip saw is the most common method, because sawing allows logs of lower quality, with irregular grain and large knots, to be used and is more economical. There are various types of sawing:\n\nPlain sawn (flat sawn, through and through, bastard sawn) \u2013 A log sawn through without adjusting the position of the log and the grain runs across the width of the boards.\nQuarter sawn and rift sawn \u2013 These terms have been confused in history but generally mean lumber sawn so the annual rings are reasonably perpendicular to the sides (not edges) of the lumber.\nBoxed heart \u2013 The pith remains within the piece with some allowance for exposure.\nHeart center \u2013 the center core of a log.\nFree of heart center (FOHC) \u2013 A side-cut timber without any pith.\nFree of knots (FOK) \u2013 No knots are present.\n\n\n== Dimensional lumber ==\n\nDimensional lumber is lumber that is cut to standardized width and depth, specified in inches. Carpenters extensively use dimensional lumber in framing wooden buildings. Common sizes include 2\u00d74 (pictured) (also two-by-four and other variants, such as four-by-two in Australia, New Zealand, and the UK), 2\u00d76, and 4\u00d74. The length of a board is usually specified separately from the width and depth. It is thus possible to find 2\u00d74s that are four, eight, and twelve feet in length. In Canada and the United States, the standard lengths of lumber are 6, 8, 10, 12, 14, 16, 18, 20, 22 and 24 feet (1.83, 2.44, 3.05, 3.66, 4.27, 4.88, 5.49, 6.10, 6.71 and 7.32 meters).  For wall framing, \"stud\" or \"precut\" sizes are available, and are commonly used. For an eight-, nine-, or ten-foot ceiling height, studs are available in 92 5\u20448 inches (235 cm), 104 5\u20448 inches (266 cm), and 116 5\u20448 inches (296 cm). The term \"stud\" is used inconsistently to specify length; where the exact length matters, one must specify the length explicitly.\n\n\n=== Historical Chinese construction ===\nUnder the prescription of the Method of Construction (\u71df\u9020\u6cd5\u5f0f) issued by the Southern Song government in the early 12th century, timbers were standardized to eight cross-sectional dimensions.  Regardless of the actual dimensions of the timber, the ratio between width and height was maintained at 1:1.5.  Units are in Song Dynasty inches (3.12 cm).\n\nTimber smaller than the 8th class were called \"unclassed\" (\u7b49\u5916).  The width of a timber is referred to as one \"timber\" (\u6750), and the dimensions of other structural components were quoted in multiples of \"timber\"; thus, as the width of the actual timber varied, the dimensions of other components were easily calculated, without resorting to specific figures for each scale.  The dimensions of timbers in similar application show a gradual diminution from the Sui Dyansty (580~618) to the modern era; a 1st class timber during the Sui was reconstructed as 15\u00d710 (Sui Dynasty inches, or 2.94 cm).\n\n\n=== North American softwoods ===\nThe length of a unit of dimensional lumber is limited by the height and girth of the tree it is milled from.  In general the maximum length is 24 ft (7.32 m). Engineered wood products, manufactured by binding the strands, particles, fibers, or veneers of wood, together with adhesives, to form composite materials, offer more flexibility and greater structural strength than typical wood building materials.Pre-cut studs save a framer much time, because they are pre-cut by the manufacturer for use in 8-, 9-, and 10-ft (2.44, 2.74 and 3.05 m) ceiling applications, which means the manufacturer has removed a few inches or centimetres of the piece to allow for the sill plate and the double top plate with no additional sizing necessary.\nIn the Americas, two-bys (2\u00d74s, 2\u00d76s, 2\u00d78s, 2\u00d710s, and 2\u00d712s), named for traditional board thickness in inches, along with the 4\u00d74 (89 mm \u00d7 89 mm), are common lumber sizes used in modern construction. They are the basic building blocks for such common structures as balloon-frame or platform-frame housing. Dimensional lumber made from softwood is typically used for construction, while hardwood boards are more commonly used for making cabinets or furniture.\nLumber's nominal dimensions are larger than the actual standard dimensions of finished lumber.  Historically, the nominal dimensions were the size of the green (not dried), rough (unfinished) boards that eventually became smaller finished lumber through drying and planing (to smooth the wood).  Today, the standards specify the final finished dimensions and the mill cuts the logs to whatever size it needs to achieve those final dimensions.  Typically, that rough cut is smaller than the nominal dimensions because modern technology makes it possible and it uses the logs more efficiently.  For example, a \"2\u00d74\" board historically started out as a green, rough board actually 2 by 4 inches (51 mm \u00d7 102 mm).  After drying and planing, it would be smaller, by a nonstandard amount.  Today, a \"2\u00d74\" board starts out as something smaller than 2 inches by 4 inches and not specified by standards, and after drying and planing is reliably 1 1\u20442 by 3 1\u20442 inches (38 mm \u00d7 89 mm).\n\nEarly standards called for green rough lumber to be of full nominal dimension when dry. However, the dimensions have diminished over time.  In 1910, a typical finished 1-inch (25 mm) board was 13\u204416 in (21 mm).  In 1928, that was reduced by 4%, and yet again by 4% in 1956.  In 1961, at a meeting in Scottsdale, Arizona, the Committee on Grade Simplification and Standardization agreed to what is now the current U.S. standard: in part, the dressed size of a 1-inch (nominal) board was fixed at \u200b3\u20444 inch; while the dressed size of 2 inch (nominal) lumber was reduced from \u200b1 5\u20448 inch to the current \u200b1 1\u20442 inch.Dimensional lumber is available in green, unfinished state, and for that kind of lumber, the nominal dimensions are the actual dimensions.\n\n\n=== Grades and standards ===\n\nIndividual pieces of lumber exhibit a wide range in quality and appearance with respect to knots, slope of grain, shakes and other natural characteristics. Therefore, they vary considerably in strength, utility, and value.\nThe move to set national standards for lumber in the United States began with publication of the American Lumber Standard in 1924, which set specifications for lumber dimensions, grade, and moisture content; it also developed  inspection and accreditation programs.  These standards have changed over the years to meet the changing needs of manufacturers and distributors, with the goal of keeping lumber competitive with other construction products. Current standards are set by the American Lumber Standard Committee, appointed by the U.S. Secretary of Commerce.Design values for most species and grades of visually graded structural products are determined in accordance with ASTM standards, which consider the effect of strength reducing characteristics, load duration, safety and other influencing factors. The applicable standards are based on results of tests conducted in cooperation with the USDA Forest Products Laboratory. Design Values for Wood Construction, which is a supplement to the ANSI/AF&PA National Design Specification\u00ae for Wood Construction, provides these lumber design values, which are recognized by the model building codes.Canada has grading rules that maintain a standard among mills manufacturing similar woods to assure customers of uniform quality. Grades standardize the quality of lumber at different levels and are based on moisture content, size, and manufacture at the time of grading, shipping, and unloading by the buyer. The National Lumber Grades Authority (NLGA) is responsible for writing, interpreting and maintaining Canadian lumber grading rules and standards. The Canadian Lumber Standards Accreditation Board (CLSAB) monitors the quality of Canada's lumber grading and identification system.\nAttempts to maintain lumber quality over time have been challenged by historical changes in the timber resources of the United States \u2013 from the slow-growing virgin forests common over a century ago to the fast-growing plantations now common in today's commercial forests.  Resulting declines in lumber quality have been of concern to both the lumber industry and consumers and have caused increased use of alternative construction products.Machine stress-rated and machine-evaluated lumber is readily available for end-uses where high strength is critical, such as trusses, rafters, laminating stock, I-beams and web joints. Machine grading measures a characteristic such as stiffness or density that correlates with the structural properties of interest, such as bending strength. The result is a more precise understanding of the strength of each piece of lumber than is possible with visually graded lumber, which allows designers to use full-design strength and avoid overbuilding.In Europe, strength grading of rectangular sawn timber (both softwood and hardwood) is done according to EN-14081  and commonly sorted into classes defined by EN-338. For softwoods the common classes are (in increasing strength) C16, C18, C24 and C30.  There are also classes specifically for hardwoods and those in most common use (in increasing strength) are D24, D30, D40, D50, D60 and D70. For these classes, the number refers to the required 5th percentile bending strength in Newtons per square millimetre. There are other strength classes, including T-classes based on tension intended for use in glulam.\n\nC14, used for scaffolding and formwork\nC16 and C24, general construction\nC30, prefab roof trusses and where design requires somewhat stronger joists than C24 can offer. TR26 is also a common trussed rafter strength class in long standing use in the UK.\nC40, usually seen in glulamGrading rules for African and South American sawn timber have been developed by ATIBT according to the rules of the Sciages Aviv\u00e9s Tropicaux Africains (SATA) and is based on clear cuttings \u2013 established by the percentage of the clear surface.\n\n\n=== North American hardwoods ===\nIn North America, market practices for dimensional lumber made from hardwoods varies significantly from the regularized standardized 'dimension lumber' sizes used for sales and specification of softwoods \u2013 hardwood boards are often sold totally rough cut, or machine planed only on the two (broader) face sides. When Hardwood Boards are also supplied with planed faces, it is usually both by random widths of a specified thickness (normally matching milling of softwood dimensional lumbers) and somewhat random lengths. But besides those older (traditional and normal) situations, in recent years some product lines have been widened to also market boards in standard stock sizes; these usually retail in big-box stores and using only a relatively small set of specified lengths; in all cases hardwoods are sold to the consumer by the board-foot (144 cubic inches or 2,360 cubic centimetres), whereas that measure is not used for softwoods at the retailer (to the cognizance of the buyer).\nAlso in North America, hardwood lumber is commonly sold in a \"quarter\" system, when referring to thickness; 4/4 (four quarter) refers to a 1-inch-thick (25 mm) board, 8/4 (eight quarter) is a 2-inch-thick (51 mm) board, etc. This \"quarter\" system is rarely used for softwood lumber; although softwood decking is sometimes sold as 5/4, even though it is actually one-inch thick (from milling 1/8th inch off each side in a motorized planing step of production).\nThe \"quarter\" system of reference is a traditional (cultural) North American lumber industry nomenclature used specifically to indicate the thickness of rough sawn hardwood lumber.\nThe following paragraph is exactly backwards from North American cultural practices where finished retail and rough lumber share the same terminology, as is discussed in the paragraph after about 'architects, designers, and builders':\nIn rough sawn lumber it immediately clarifies that the lumber is not yet milled, avoiding confusion with milled dimension lumber which is measured as actual thickness after machining. Examples \u2013 3/4\", 19mm, or 1x.\nIn recent years architects, designers, and builders have begun to use the \"quarter\" system in specifications as a vogue of insider knowledge, though the materials being specified are finished lumber, thus conflating  the separate systems and causing confusion.\nHardwoods cut for furniture are cut in the fall and winter, after the sap has stopped running in the trees. If hardwoods are cut in the spring or summer the sap ruins the natural color of the timber and decreases the value of the timber for furniture.\n\n\n=== Engineered lumber ===\n\nEngineered lumber is lumber created by a manufacturer and designed for a certain structural purpose. The main categories of engineered lumber are:\nLaminated veneer lumber (LVL) \u2013 LVL comes in \u200b1 3\u20444 inch thicknesses with depths such as \u200b9 1\u20442, \u200b11 7\u20448, 14, 16, 18, and 24 inches, and are often doubled or tripled up. They function as beams to provide support over large spans, such as removed support walls and garage door openings, places where dimensional lumber is insufficient, and also in areas where a heavy load is bearing from a floor, wall or roof above on a somewhat short span where dimensional lumber is  impractical. This type of lumber is compromised if it is altered by holes or notches anywhere within the span or at the ends, but nails can be driven into it wherever necessary to anchor the beam or to add hangers for I-joists or dimensional lumber joists that terminate at an LVL beam.\nWooden I-joists \u2013 sometimes called \"TJI\", \"Trus Joists\" or \"BCI\", all of which are brands of wooden I-joists, they are used for floor joists on upper floors and also in first floor conventional foundation construction on piers as opposed to slab floor construction. They are engineered for long spans and are doubled up in places where a wall will be aligned over them, and sometimes tripled where heavy roof-loaded support walls are placed above them. They consist of a top and bottom chord or flange made from dimensional lumber with a webbing in-between made from oriented strand board (OSB) (or, latterly, steel mesh forms which allow passage of services without cutting). The webbing can be removed up to certain sizes or shapes according to the manufacturer's or engineer's specifications, but for small holes, wooden I-joists come with \"knockouts\", which are perforated, pre-cut areas where holes can be made easily, typically without engineering approval. When large holes are needed, they can typically be made in the webbing only and only in the center third of the span; the top and bottom chords lose their integrity if cut. Sizes and shapes of the hole, and typically the placing of a hole itself, must be approved by an engineer prior to the cutting of the hole and in many areas, a sheet showing the calculations made by the engineer must be provided to the building inspection authorities before the hole will be approved. Some I-joists are made with W-style webbing like a truss to eliminate cutting and to allow ductwork to pass through.\nFinger-jointed lumber \u2013 solid dimensional lumber lengths typically are limited to lengths of 22 to 24 feet, but can be made longer by the technique of \"finger-jointing\" by using small solid pieces, usually 18 to 24 inches long, and joining them together using finger joints and glue to produce lengths that can be up to 36 feet long in 2\u00d76 size. Finger-jointing also is predominant in precut wall studs. It is also an affordable alternative for non-structural hardwood that will be painted (staining would leave the finger-joints visible). Care is taken during construction to avoid nailing directly into a glued joint as stud breakage can occur.\nGlulam beams \u2013 created from 2\u00d74 or 2\u00d76 stock by gluing the faces together to create beams such as 4\u00d712 or 6\u00d716. As such, a beam acts as one larger piece of lumber \u2013 thus eliminating the need to harvest larger, older trees for the same size beam.\nManufactured trusses \u2013 trusses are used in home construction as a pre-fabricated replacement for roof rafters and ceiling joists (stick-framing). It is seen as an easier installation and a better solution for supporting roofs than the use of dimensional lumber's struts and purlins as bracing. In the southern U.S. and elsewhere, stick-framing with dimensional lumber roof support is still predominant. The main drawbacks of trusses are reduced attic space, time required for engineering and ordering, and a cost higher than the dimensional lumber needed if the same project were conventionally framed. The advantages are significantly reduced labor costs (installation is faster than conventional framing), consistency, and overall schedule savings.\n\n\n=== Various pieces and cuts ===\n\nSquare and rectangular forms: Plank, slat, batten, board, lath, strapping (typically \u200b3\u20444 in \u00d7 \u200b1 1\u20442 in), cant (A partially sawn log such as sawn on two sides or squared to a large size and later resawn into lumber. A flitch is a type of cant with wane on one or both sides). Various pieces are also known by their uses such as post, beam, (girt), stud, rafter, joist, sill plate, wall plate.\nRod forms: pole, (dowel), stick (staff, baton)\n\n\n=== Timber piles ===\nIn the United States, pilings are mainly cut from southern yellow pines and Douglas firs. Treated pilings are available in Chromated copper arsenate retentions of 0.60, 0.80 and 2.50 pounds per cubic foot (9.6, 12.8 and 40.0 kg/m3) if treatment is required.\n\n\n== Defects in lumber ==\nDefects occurring in lumber are grouped into the following four divisions:\n\n\n=== Conversion ===\nDuring the process of converting timber to commercial form the following defects may occur:\n\nChip mark: this defect is indicated by the marks or signs placed by chips on the finished surface of timber\nDiagonal grain: improper sawing of timber\nTorn grain: when a small depression is made on the finished surface due to falling of some tool\nWane: presence of original rounded surface in the finished product\n\n\n=== Defects due to fungi and animals ===\nFungi attack timber when these conditions are all present:\n\nThe timber moisture content is above 25% on a dry-weight basis\nThe environment is sufficiently warm\nOxygen (O2) is presentWood with less than 25% moisture (dry weight basis) can remain free of decay for centuries. Similarly, wood submerged in water may not be attacked by fungi if the amount of oxygen is inadequate.\nFungi timber defects:\n\nBlue stain\nBrown rot\nDry rot\nHeart rot\nSap stain\nWet rot\nWhite rotFollowing are the insects and molluscs which are usually responsible for the decay of timber:\n\nWoodboring beetles\nMarine borers (Barnea similis)\nTeredos (Teredo navalis)\nTermites\nCarpenter ants\nCarpenter bees\n\n\n=== Natural forces ===\n\nThere are two main natural forces responsible for causing defects in timber: abnormal growth and rupture of tissues. Rupture of tissue includes cracks or splits in the wood called \"shakes\". \"Ring shake\", \"wind shake\", or \"ring failure\" is when the wood grain separates around the growth rings either while standing or during felling. Shakes may reduce the strength of a timber and the appearance thus reduce lumber grade and may capture moisture, promoting decay. Eastern hemlock is known for having ring shake. A \"check\" is a crack on the surface of the wood caused by the outside of a timber shrinking as it seasons. Checks may extend to the pith and follow the grain. Like shakes, checks can hold water promoting rot. A \"split\" goes all the way through a timber. Checks and splits occur more frequently at the ends of lumber because of the more rapid drying in these locations.\n\n\n=== Seasoning ===\nThe seasoning of lumber is typically either kiln- or air-dried. Defects due to seasoning are the main cause of splits, bowing and honeycombing.\n\n\n== Durability and service life ==\nUnder proper conditions, wood provides excellent, lasting performance. However, it also faces several potential threats to service life, including fungal activity and insect damage \u2013 which can be avoided in numerous ways. Section 2304.11 of the International Building Code  addresses protection against decay and termites. This section provides requirements for non-residential construction applications, such as wood used above ground (e.g., for framing, decks, stairs, etc.), as well as other applications.\nThere are four recommended methods to protect wood-frame structures against durability hazards and thus provide maximum service life for the building. All require proper design and construction:\n\nControlling moisture using design techniques to avoid decay\nProviding effective control of termites and other insects\nUsing durable materials such as pressure treated or naturally durable species of wood where appropriate\nProviding quality assurance during design and construction and throughout the building\u2019s service life using appropriate maintenance practices\n\n\n=== Moisture control ===\nWood is a hygroscopic material, which means it naturally absorbs and releases water to balance its internal moisture content with the surrounding environment. The moisture content of wood is measured by the weight of water as a percentage of the oven-dry weight of the wood fiber. The key to controlling decay is controlling moisture. Once decay fungi are established, the minimum moisture content for decay to propagate is 22 to 24 percent, so building experts recommend 19 percent as the maximum safe moisture content for untreated wood in service. Water by itself does not harm the wood, but rather, wood with consistently high moisture content enables fungal organisms to grow.\nThe primary objective when addressing moisture loads is to keep water from entering the building envelope in the first place, and to balance the moisture content within the building itself. Moisture control by means of accepted design and construction details is a simple and practical method of protecting a wood-frame building against decay. For applications with a high risk of staying wet, designers specify durable materials such as naturally decay-resistant species or wood that has been treated with preservatives. Cladding, shingles, sill plates and exposed timbers or glulam beams are examples of potential applications for treated wood.\n\n\n=== Controlling termites and other insects ===\nFor buildings in termite zones, basic protection practices addressed in current building codes include (but are not limited to) the following:\n\u2022 Grading the building site away from the foundation to provide proper drainage\n\u2022 Covering exposed ground in any crawl spaces with 6-mil polyethylene film and maintaining at least 12 to 18 inches (300 to 460 mm) of clearance between the ground and the bottom of framing members above (12 inches to beams or girders, 18 inches to joists or plank flooring members)\n\u2022 Supporting post columns by concrete piers so that there is at least 6 inches (150 mm) of clear space between the wood and exposed earth\n\u2022 Installing wood framing and sheathing in exterior walls at least eight inches above exposed earth; locating siding at least six inches from the finished grade\n\u2022 Where appropriate, ventilating crawl spaces according to local building codes\n\u2022 Removing building material scraps from the job site before backfilling.\n\u2022 If allowed by local regulation, treating the soil around the foundation with an approved termiticide to provide protection against subterranean termites\n\n\n=== Preservatives ===\n\nTo avoid decay and termite infestation, untreated wood is separated from the ground and other sources of moisture. These separations are required by many building codes and are considered necessary to maintain wood elements in permanent structures at a safe moisture content for decay protection. When it is not possible to separate wood from the sources of moisture, designers often rely on preservative-treated wood.Wood can be treated with a preservative that improves service life under severe conditions without altering its basic characteristics. It can also be pressure-impregnated with fire-retardant chemicals that improve its performance in a fire. One of the early treatments to \"fireproof lumber\", which retard fires, was developed in 1936 by the Protexol Corporation, in which lumber is heavily treated with salt.\nWood does not deteriorate simply because it gets wet. When wood breaks down, it is because an organism is eating it. Preservatives work by making the food source inedible to these organisms. Properly preservative-treated wood can have 5 to 10 times the service life of untreated wood. Preserved wood is used most often for railroad ties, utility poles, marine piles, decks, fences and other outdoor applications. Various treatment methods and types of chemicals are available, depending on the attributes required in the particular application and the level of protection needed.There are two basic methods of treating: with and without pressure. Non-pressure methods are the application of preservative by brushing, spraying or dipping the piece to be treated. Deeper, more thorough penetration is achieved by driving the preservative into the wood cells with pressure. Various combinations of pressure and vacuum are used to force adequate levels of chemical into the wood. Pressure-treating preservatives consist of chemicals carried in a solvent.\nChromated copper arsenate, once the most commonly used wood preservative in North America began being phased out of most residential applications in 2004. Replacing it are amine copper quat and copper azole.\nAll wood preservatives used in the United States and Canada are registered and regularly re-examined for safety by the U.S. Environmental Protection Agency and Health Canada's Pest Management and Regulatory Agency, respectively.\n\n\n== Ancient construction works ==\nTimber was used as a dominant building material in most of the ancient temples of Kerala and coastal Karnataka of India.\n\n\n== Timber framing ==\n\nTimber framing is a style of construction which uses heavier framing elements than modern stick framing, which uses dimensional lumber. The timbers originally were tree boles squared with a broadaxe or adze and joined together with joinery without nails. Modern timber framing has been growing in popularity in the United States since the 1970s.\n\n\n== Environmental effects of lumber ==\nGreen building minimizes the impact or \"environmental footprint\" of a building. Wood is a major building material that is renewable and replenishable in a continuous cycle. Studies show manufacturing wood uses less energy and results in less air and water pollution than steel and concrete. However, demand for lumber is blamed for deforestation.\n\n\n=== Residual wood ===\nThe conversion from coal to biomass power is a growing trend in the United States.The United Kingdom, Uzbekistan, Kazakhstan, Australia, Fiji, Madagascar, Mongolia, Russia, Denmark, Switzerland and Swaziland governments all support an increased role for energy derived from biomass, which are organic materials available on a renewable basis and include residues and/or byproducts of the logging, sawmilling and papermaking processes. In particular, they view it as a way to lower greenhouse gas emissions by reducing consumption of oil and gas while supporting the growth of forestry, agriculture and rural economies. Studies by the U.S. government have found the country\u2019s combined forest and agriculture land resources have the power to sustainably supply more than one-third of its current petroleum consumption.Biomass is already an important source of energy for the North American forest products industry. It is common for companies to have cogeneration facilities, also known as combined heat and power, which convert some of the biomass that results from wood and paper manufacturing to electrical and thermal energy in the form of steam. The electricity is used to, among other things, dry lumber and supply heat to the dryers used in paper-making.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nSathre, R; O'Conner, J (2010). A Synthesis of Research on Wood Products and Greenhouse Gas Impacts (PDF) (2 ed.). FPInnovations. ISBN 978-0-86488-546-3. Archived from the original (PDF) on 2012-03-21.\n\n\n== External links ==\nNational Hardwood Lumber Association (Rules for Grading Hardwood Lumber \u2013 Inspector Training School)\nTimber Development Association of NSW \u2013 Australia\nTDA: Timber Decking Association \u2013 UK\nTRADA: Timber Research And Development Association\nThe Forest Products Laboratory. U.S. main wood products research lab. Madison, WI (E)\nWCTE, World Conference on Timber Engineering\u3000June 20\u201324, 2010, Riva del Garda, Trentino, Italy\nForest Products data in Canada since 1990",
        "unit": "volume (lumber)",
        "url": "https://en.wikipedia.org/wiki/Lumber"
    },
    {
        "_id": "Base_pair",
        "clean": "Base pair",
        "text": "A base pair (bp) is a unit consisting of two nucleobases bound to each other by hydrogen bonds.  They form the building blocks of the DNA double helix and contribute to the folded structure of both DNA and RNA. Dictated by specific hydrogen bonding patterns, Watson-Crick base pairs (guanine-cytosine and adenine-thymine) allow the DNA helix to maintain a regular helical structure that is subtly dependent on its nucleotide sequence. The complementary nature of this based-paired structure provides a redundant copy of the genetic information encoded within each strand of DNA. The regular structure and data redundancy provided by the DNA double helix make DNA well suited to the storage of genetic information, while base-pairing between DNA and incoming nucleotides provides the mechanism through which DNA polymerase replicates DNA and RNA polymerase transcribes DNA into RNA. Many DNA-binding proteins can recognize specific base pairing patterns that identify particular regulatory regions of genes.\nIntramolecular base pairs can occur within single-stranded nucleic acids. This is particularly important in RNA molecules (e.g., transfer RNA), where Watson-Crick base pairs (guanine-cytosine and adenine-uracil) permit the formation of short double-stranded helices, and a wide variety of non-Watson-Crick interactions (e.g., G-U or A-A) allow RNAs to fold into a vast range of specific three-dimensional structures. In addition, base-pairing between transfer RNA (tRNA) and messenger RNA (mRNA) forms the basis for the molecular recognition events that result in the nucleotide sequence of mRNA becoming translated into the amino acid sequence of proteins via the genetic code.\nThe size of an individual gene or an organism's entire genome is often measured in base pairs because DNA is usually double-stranded. Hence, the number of total base pairs is equal to the number of nucleotides in one of the strands (with the exception of non-coding single-stranded regions of telomeres). The haploid human genome (23 chromosomes) is estimated to be about 3.2 billion bases long and to contain 20,000\u201325,000 distinct protein-coding genes. A kilobase (kb) is a unit of measurement in molecular biology equal to 1000 base pairs of DNA or RNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 \u00d7 1037 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).\n\n\n== Hydrogen bonding and stability ==\n\nHydrogen bonding is the chemical interaction that underlies the base-pairing rules described above. Appropriate geometrical correspondence of hydrogen bond donors and acceptors allows only the \"right\" pairs to form stably. DNA with high GC-content is more stable than DNA with low GC-content. But, contrary to popular belief, the hydrogen bonds do not stabilize the DNA significantly; stabilization is mainly due to stacking interactions.The larger nucleobases, adenine and guanine, are members of a class of double-ringed chemical structures called purines; the smaller nucleobases, cytosine and thymine (and uracil), are members of a class of single-ringed chemical structures called pyrimidines. Purines are complementary only with pyrimidines: pyrimidine-pyrimidine pairings are energetically unfavorable because the molecules are too far apart for hydrogen bonding to be established; purine-purine pairings are energetically unfavorable because the molecules are too close, leading to overlap repulsion. Purine-pyrimidine base pairing of AT or GC or UA (in RNA) results in proper duplex structure. The only other purine-pyrimidine pairings would be AC and GT and UG (in RNA); these pairings are mismatches because the patterns of hydrogen donors and acceptors do not correspond. The GU pairing, with two hydrogen bonds, does occur fairly often in RNA (see wobble base pair).\nPaired DNA and RNA molecules are comparatively stable at room temperature, but the two nucleotide strands will separate above a melting point that is determined by the length of the molecules, the extent of mispairing (if any), and the GC content. Higher GC content results in higher melting temperatures; it is, therefore, unsurprising that the genomes of extremophile organisms such as Thermus thermophilus are particularly GC-rich. On the converse, regions of a genome that need to separate frequently \u2014 for example, the promoter regions for often-transcribed genes \u2014 are comparatively GC-poor (for example, see TATA box). GC content and melting temperature must also be taken into account when designing  primers for PCR reactions.\n\n\n=== Examples ===\nThe following DNA sequences illustrate pair double-stranded patterns. By convention, the top strand is written from the 5' end to the 3' end; thus, the bottom strand is written 3' to 5'.\n\nA base-paired DNA sequence:\nATCGATTGAGCTCTAGCG\nTAGCTAACTCGAGATCGCThe corresponding RNA sequence, in which uracil is substituted for thymine where uracil takes its place in the RNA strand:\nAUCGAUUGAGCUCUAGCG\nUAGCUAACUCGAGAUCGC\n\n\n== Base analogs and intercalators ==\n\nChemical analogs of nucleotides can take the place of proper nucleotides and establish non-canonical base-pairing, leading to errors (mostly point mutations) in DNA replication and DNA transcription. This is due to their isosteric chemistry. One common mutagenic base analog is 5-bromouracil, which resembles thymine but can base-pair to guanine in its enol form.\nOther chemicals, known as DNA intercalators, fit into the gap between adjacent bases on a single strand and induce frameshift mutations by \"masquerading\" as a base, causing the DNA replication machinery to skip or insert additional nucleotides at the intercalated site. Most intercalators are large polyaromatic compounds and are known or suspected carcinogens. Examples include ethidium bromide and acridine.\n\n\n== Unnatural base pair (UBP) ==\n\nAn unnatural base pair (UBP) is a designed subunit (or nucleobase) of DNA which is created in a laboratory and does not occur in nature.  DNA sequences have been described which use newly created nucleobases to form a third base pair, in addition to the two base pairs found in nature, A-T (adenine \u2013 thymine) and G-C (guanine \u2013 cytosine).  A few research groups have been searching for a third base pair for DNA, including teams led by Steven A. Benner, Philippe Marliere, Floyd Romesberg and Ichiro Hirao. Some new base pairs have been reported.In 1989 Steven Benner (then working at the Swiss Federal Institute of Technology in Zurich) and his team led with modified forms of cytosine and guanine into DNA molecules in vitro. The nucleotides, which encoded RNA and proteins, were successfully replicated in vitro. Since then, Benner's team has been trying to engineer cells that can make foreign bases from scratch, obviating the need for a feedstock.In 2002, Ichiro Hirao\u2019s group in Japan developed an unnatural base pair between 2-amino-8-(2-thienyl)purine (s) and pyridine-2-one (y) that functions in transcription and translation, for the site-specific incorporation of non-standard amino acids into proteins. In 2006, they created 7-(2-thienyl)imidazo[4,5-b]pyridine (Ds) and pyrrole-2-carbaldehyde (Pa) as a third base pair for replication and transcription. Afterward, Ds and 4-[3-(6-aminohexanamido)-1-propynyl]-2-nitropyrrole (Px) was discovered as a high fidelity pair in PCR amplification. In 2013, they applied the Ds-Px pair to DNA aptamer generation by in vitro selection (SELEX) and demonstrated the genetic alphabet expansion significantly augment DNA aptamer affinities to target proteins.In 2012, a group of American scientists led by Floyd Romesberg, a chemical biologist at the Scripps Research Institute in San Diego, California, published that his team designed an unnatural base pair (UBP).  The two new artificial nucleotides or Unnatural Base Pair (UBP) were named d5SICS and dNaM. More technically, these artificial nucleotides bearing hydrophobic nucleobases, feature two fused aromatic rings that form a (d5SICS\u2013dNaM) complex or base pair in DNA. His team designed a variety of in vitro or \"test tube\" templates containing the unnatural base pair and they confirmed that it was efficiently replicated with high fidelity in virtually all sequence contexts using the modern standard in vitro techniques, namely PCR amplification of DNA and PCR-based applications. Their results show that for PCR and PCR-based applications, the d5SICS\u2013dNaM unnatural base pair is functionally equivalent to a natural base pair, and when combined with the other two natural base pairs used by all organisms, A\u2013T and G\u2013C, they provide a fully functional and expanded six-letter \"genetic alphabet\".In 2014 the same team from the Scripps Research Institute reported that they synthesized a stretch of circular DNA known as a plasmid containing natural T-A and C-G base pairs along with the best-performing UBP Romesberg's laboratory had designed and inserted it into cells of the common bacterium E. coli that successfully replicated the unnatural base pairs through multiple generations. The transfection did not hamper the growth of the E. coli cells and showed no sign of losing its unnatural base pairs to its natural DNA repair mechanisms. This is the first known example of a living organism passing along an expanded genetic code to subsequent generations. Romesberg said he and his colleagues created 300 variants to refine the design of nucleotides that would be stable enough and would be replicated as easily as the natural ones when the cells divide.  This was in part achieved by the addition of a supportive algal gene that expresses a nucleotide triphosphate transporter which efficiently imports the triphosphates of both d5SICSTP and dNaMTP into E. coli bacteria. Then, the natural bacterial replication pathways use them to accurately replicate a plasmid containing d5SICS\u2013dNaM. Other researchers were surprised that the bacteria replicated these human-made DNA subunits.The successful incorporation of a third base pair is a significant breakthrough toward the goal of greatly expanding the number of amino acids which can be encoded by DNA, from the existing 20 amino acids to a theoretically possible 172, thereby expanding the potential for living organisms to produce novel proteins. The artificial strings of DNA do not encode for anything yet, but scientists speculate they could be designed to manufacture new proteins which could have industrial or pharmaceutical uses. Experts said the synthetic DNA incorporating the unnatural base pair raises the possibility of life forms based on a different DNA code.\n\n\n== Length measurements ==\nThe following abbreviations are commonly used to describe the length of a D/RNA molecule:\n\nbp  = base pair(s)\u2014one bp corresponds to approximately 3.4 \u00c5 (340 pm)  of length along the strand, and to roughly 618 or 643 daltons for DNA and RNA respectively.\nkb (= kbp) = kilo base pairs = 1,000 bp\nMb (= Mbp) = mega base pairs = 1,000,000 bp\nGb = giga base pairs = 1,000,000,000 bp.For single-stranded DNA/RNA, units of nucleotides are used\u2014abbreviated nt (or knt, Mnt, Gnt)\u2014as they are not paired.\nTo distinguish between units of computer storage and bases, kbp, Mbp, Gbp, etc. may be used for base pairs.\nThe centimorgan is also often used to imply distance along a chromosome, but the number of base pairs it corresponds to varies widely. In the Human genome, the centimorgan is about 1 million base pairs.\n\n\n== See also ==\nList of Y-DNA single-nucleotide polymorphisms\nNon-canonical base pairing\n\n\n== References ==\n\n\n== Further reading ==\nWatson JD; Baker TA; Bell SP; Gann A; Levine M; Losick R (2004). Molecular Biology of the Gene (5th ed.). Pearson Benjamin Cummings: CSHL Press. (See esp. ch. 6 and 9)\nAstrid Sigel; Helmut Sigel; Roland K. O. Sigel, eds. (2012). Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. Springer. doi:10.1007/978-94-007-2172-2. ISBN 978-9-4007-2171-5.\nClever, Guido H.; Shionoya, Mitsuhiko (2012). \"Chapter 10. Alternative DNA Base-Pairing through Metal Coordination\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 269\u2013294. doi:10.1007/978-94-007-2172-2_10. ISBN 978-94-007-2171-5. PMID 22210343.\nMegger, Dominik A.; Megger, Nicole; Mueller, Jens (2012). \"Chapter 11. Metal-Mediated Base Pairs in Nucleic Acids with Purine and Pyrimidine-Derived Neucleosides\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 295\u2013317. doi:10.1007/978-94-007-2172-2_11. ISBN 978-94-007-2171-5. PMID 22210344.\n\n\n== External links ==\nDAN\u2014webserver version of the EMBOSS tool for calculating melting temperatures",
        "unit": "kilo base pair",
        "url": "https://en.wikipedia.org/wiki/Base_pair"
    },
    {
        "_id": "Inch",
        "clean": "Inch",
        "text": "The inch (abbreviation: in or \u2033) is a unit of length in the (British) imperial and United States customary systems of measurement. It is equal to \u200b1\u204436 yard or \u200b1\u204412 of a foot. Derived from the Roman uncia (\"twelfth\"),the word inch is also sometimes used to translate similar units in other measurement systems, usually understood as deriving from the width of the human thumb. Standards for the exact length of an inch have varied in the past, but since the adoption of the international yard during the 1950s and 1960s it has been based on the metric system and defined as exactly 2.54 cm.\n\n\n== Name ==\nThe English word \"inch\" (Old English: ynce) was an early borrowing from Latin uncia (\"one-twelfth; Roman inch; Roman ounce\") not present in other Germanic languages. The vowel change from Latin /u/ to Old English /y/ (which became Modern English /\u026a/) is known as umlaut. The consonant change from the Latin /k/ (spelled c) to English /t\u0283/ is palatalisation. Both were features of Old English phonology; see Phonological history of Old English \u00a7 Palatalization and Germanic umlaut \u00a7 I-mutation in Old English for more information.\n\"Inch\" is cognate with \"ounce\" (Old English: ynse), whose separate pronunciation and spelling reflect its reborrowing in Middle English from Anglo-Norman unce and ounce.In many other European languages, the word for \"inch\" is the same as or derived from the word for \"thumb\", as a man's thumb is about an inch wide (and this was even sometimes used to define the inch). Examples include Afrikaans: duim; Catalan: polzada (\"inch\") and polze (\"thumb\"); Czech: palec; Danish and Norwegian: tomme (\"inch\") tommel (\"thumb\"); Dutch: duim; French: pouce; Hungarian: h\u00fcvelyk; Italian: pollice; Portuguese: polegada (\"inch\") and polegar (\"thumb\"); Slovak: palec; Spanish: pulgada (\"inch\") and pulgar (\"thumb\"); and Swedish: tum (\"inch\") and tumme (\"thumb\").\n\n\n== Usage ==\nThe inch is a commonly used customary unit of length in the United States, Canada, and the United Kingdom. It is also used in Japan for electronic parts, especially display screens. In most of continental Europe, the inch is also used informally as a measure for display screens. For the United Kingdom, guidance on public sector use states that, since 1 October 1995, without time limit, the inch (along with the foot) is to be used as a primary unit for road signs and related measurements of distance (with the possible exception of clearance heights and widths) and may continue to be used as a secondary or supplementary indication following a metric measurement for other purposes.The international standard symbol for inch is in (see ISO 31-1, Annex A) but traditionally the inch is denoted by a double prime, which is often approximated by double quotes, and the foot by a prime, which is often approximated by an apostrophe. For example, three feet two inches can be written as 3\u2032 2\u2033. (This is akin to how the first and second \"cuts\" of the hour and degree are likewise indicated by prime and double prime symbols.) Subdivisions of an inch are typically written using dyadic fractions with odd number numerators; for example, two and three eighths of an inch would be written as 2 3/8\u2033 and not as 2.375\u2033 nor as 2 6/16\u2033.\n\n\n=== Equivalences ===\n1 international inch is equal to:\n\n10,000 tenths\n1,000 thou or mil\n100 points or gries\n72 PostScript points\n10, 12, 16, or 40 lines\n6 computer picas\n3 barleycorns\n2.54 centimetres exactly (1 centimetre \u2248 0.3937008 inches.)\n0.999998 US Survey inches\n1/3 or 0.333 palms\n1/4 or 0.25 hands\n1/12 or 0.08333 feet\n1/36 or 0.02777 yards\n\n\n== History ==\n\nThe earliest known reference to the inch in England is from the Laws of \u00c6thelberht dating to the early 7th century, surviving in a single manuscript, the Textus Roffensis from 1120. Paragraph LXVII sets out the fine for wounds of various depths: one inch, one shilling, two inches, two shillings, etc.An Anglo-Saxon unit of length was the barleycorn. After 1066, 1 inch was equal to 3 barleycorns, which continued to be its legal definition for several centuries, with the barleycorn being the base unit. One of the earliest such definitions is that of 1324, where the legal definition of the inch was set out in a statute of Edward II of England, defining it as \"three grains of barley, dry and round, placed end to end, lengthwise\".Similar definitions are recorded in both English and Welsh medieval law tracts. One, dating from the first half of the 10th century, is contained in the Laws of Hywel Dda which superseded those of Dyfnwal, an even earlier definition of the inch in Wales. Both definitions, as recorded in Ancient Laws and Institutes of Wales (vol i., pp. 184, 187, 189), are that \"three lengths of a barleycorn is the inch\".King David I of Scotland in his Assize of Weights and Measures (c. 1150) is said to have defined the Scottish inch as the width of an average man's thumb at the base of the nail, even including the requirement to calculate the average of a small, a medium, and a large man's measures. However, the oldest surviving manuscripts date from the early 14th century and appear to have been altered with the inclusion of newer material.In 1814, Charles Butler, a mathematics teacher at Cheam School, recorded the old legal definition of the inch to be \"three grains of sound ripe barley being taken out the middle of the ear, well dried, and laid end to end in a row\", and placed the barleycorn, not the inch, as the base unit of the English Long Measure system, from which all other units were derived. John Bouvier similarly recorded in his 1843 law dictionary that the barleycorn was the fundamental measure. Butler observed, however, that \"[a]s the length of the barley-corn cannot be fixed, so the inch according to this method will be uncertain\", noting that a standard inch measure was now (by his time) kept in the Exchequer chamber, Guildhall, and that was the legal definition of the inch. This was a point also made by George Long in his 1842 Penny Cyclop\u00e6dia, observing that standard measures had since surpassed the barleycorn definition of the inch, and that to recover the inch measure from its original definition, in the event that the standard measure were destroyed, would involve the measurement of large numbers of barleycorns and taking their average lengths. He noted that this process would not perfectly recover the standard, since it might introduce errors of anywhere between one hundredth and one tenth of an inch in the definition of a yard.Before the adoption of the international yard and pound, various definitions were in use. In the United Kingdom and most countries of the British Commonwealth, the inch was defined in terms of the Imperial Standard Yard. The United States adopted the conversion factor 1 metre = 39.37 inches by an act in 1866. In 1893, Mendenhall ordered the physical realization of the inch to be based on the international prototype metres numbers 21 and 27, which had been received from the CGPM, together with the previously adopted conversion factor.In 1930, the British Standards Institution adopted an inch of exactly 25.4 mm. The American Standards Association followed suit in 1933. By 1935, industry in 16 countries had adopted the \"industrial inch\" as it came to be known.In 1946, the Commonwealth Science Congress recommended a yard of exactly 0.9144 metres for adoption throughout the British Commonwealth. This was adopted by Canada in 1951, the United States on 1 July 1959, Australia in 1961, effective 1 January 1964, and the United Kingdom in 1963, effective on 1 January 1964. The new standards gave an inch of exactly 25.4 mm, 1.7 millionths of an inch longer than the old imperial inch and 2 millionths of an inch shorter than the old US inch.\n\n\n== Related units ==\n\n\n=== US Survey inches ===\nThe United States retains the 1/39.37-metre definition for survey purposes, producing a 2 millionth part difference between standard and US survey inches. This is approximately 1/8 inch per mile. In fact, 12.7 kilometres is exactly 500,000 standard inches and exactly 499,999 survey inches. This difference is significant when doing calculations in State Plane Coordinate Systems with coordinate values in the hundreds of thousands or millions of feet.\n\n\n=== Continental inches ===\n\nBefore the adoption of the metric system, several European countries had customary units whose name translates into \"inch\". The French pouce measured 2.70 cm, at least when applied to describe the calibre of artillery pieces. The Amsterdam foot (voet) consisted of 11 Amsterdam inches (duim). The Amsterdam foot is about 8% shorter than an English foot.\n\n\n=== Scottish inch ===\nThe now obsolete Scottish inch (Scottish Gaelic: \u00f2irleach), 1/12 of a Scottish foot, was about 1.0016 imperial inches (about 2.5441 cm). It was used in the popular expression Gie 'im an inch, an he'll tak an ell, in English \"Give him an inch and he'll take an ell\", first published as \"For when I gave you an inch, you tooke an ell\" by John Heywood in 1546. (The ell, equal to 37 inches (about 94 cm), was in use in England until 1685.) Modern versions of the saying include \"Give him an inch and he'll take a mile\" and \"Give him and inch and he'll take a yard\".\n\n\n== See also ==\nEnglish units\nSquare inch, Cubic inch, and Metric inch\nInternational yard and pound\nAnthropic units\n\"Roman inch\" (uncia) and \"French inch\" (pouce)\nPyramid inch\nDigit and Line\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Citations ===\n\n\n=== Bibliography ===\nAttenborough, F. L. (1922), The Laws of the Earliest English Kings (Llanerch Press Facsimile Reprint 2000 ed.), Cambridge: Cambridge University Press, ISBN 978-1-86143-101-1, retrieved 11 July 2018\nCollins Encyclopedia of Scotland\nWeights and Measures, by D. Richard Torrance, SAFHS, Edinburgh, 1996, ISBN 1-874722-09-9 (NB book focusses on Scottish weights and measures exclusively)\nThis article incorporates text from \"Dwelly's [Scottish] Gaelic Dictionary\" (1911).\nScottish National Dictionary and Dictionary of the Older Scottish Tongue",
        "unit": "inch",
        "url": "https://en.wikipedia.org/wiki/Inch"
    },
    {
        "_id": "Pascal_(unit)",
        "clean": "Pascal (unit)",
        "text": "The pascal (symbol: Pa) is the SI derived unit of pressure used to quantify internal pressure, stress, Young's modulus and ultimate tensile strength. It is defined as one newton per square metre. It is named after the French polymath Blaise Pascal.\nCommon multiple units of the pascal are the hectopascal (1 hPa = 100 Pa) which is equal to one millibar, and the kilopascal (1 kPa = 1000 Pa) which is equal to one centibar.\nThe unit of measurement called standard atmosphere (atm) is defined as 101325 Pa. Meteorological reports typically state atmospheric pressure in millibars.\n\n\n== Etymology ==\nThe unit is named after Blaise Pascal, noted for his contributions to hydrodynamics and hydrostatics, and experiments with a barometer. The name pascal was adopted for the SI unit newton per square metre (N/m2) by the 14th General Conference on Weights and Measures in 1971.\n\n\n== Definition ==\nThe pascal can be expressed using SI derived units, or alternatively solely SI base units, as:\n\n  \n    \n      \n        \n          \n            1\n             \n            P\n            a\n            =\n            1\n             \n            \n              \n                N\n                \n                  m\n                  \n                    2\n                  \n                \n              \n            \n            =\n            1\n             \n            \n              \n                \n                  k\n                  g\n                \n                \n                  m\n                  \u22c5\n                  \n                    s\n                    \n                      2\n                    \n                  \n                \n              \n            \n            =\n            1\n             \n            \n              \n                J\n                \n                  m\n                  \n                    3\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\rm {1~Pa=1~{\\frac {N}{m^{2}}}=1~{\\frac {kg}{m\\cdot s^{2}}}=1~{\\frac {J}{m^{3}}}}}}\n  where N is the newton, m is the metre, kg is the kilogram, s is the second, and J is the joule.One pascal is the pressure exerted by a force of magnitude one newton perpendicularly upon an area of one square metre.\n\n\n== Standard units ==\nThe unit of measurement called an atmosphere or a standard atmosphere (atm) is 101325 Pa (101.325 kPa). This value is often used as a reference pressure and specified as such in some national and international standards, such as the International Organization for Standardization's ISO 2787 (pneumatic tools and compressors), ISO 2533 (aerospace) and ISO 5024 (petroleum). In contrast, International Union of Pure and Applied Chemistry (IUPAC) recommends the use of 100 kPa as a standard pressure when reporting the properties of substances.Unicode has dedicated code-points U+33A9 \u33a9 Square Pa and U+33AA \u33aa Square kPa in the CJK Compatibility block, but these exist only for backward-compatibility with some older ideographic character-sets and are therefore deprecated.\n\n\n== Uses ==\nThe pascal (Pa) or kilopascal (kPa) as a unit of pressure measurement is widely used throughout the world and has largely replaced the pounds per square inch (psi) unit, except in some countries that still use the imperial measurement system or the US customary system, including the United States.\nGeophysicists use the gigapascal (GPa) in measuring or calculating tectonic stresses and pressures within the Earth.\nMedical elastography measures tissue stiffness non-invasively with ultrasound or magnetic resonance imaging, and often displays the Young's modulus or shear modulus of tissue in kilopascals.\nIn materials science and engineering, the pascal measures the stiffness, tensile strength and compressive strength of materials. In engineering use, because the pascal represents a very small quantity, the megapascal (MPa) is the preferred unit for these uses.\n\nThe pascal is also equivalent to the SI unit of energy density, J/m3. This applies not only to the thermodynamics of pressurised gases, but also to the energy density of electric, magnetic, and gravitational fields.\nIn measurements of sound pressure or loudness of sound, one pascal is equal to 94 decibels SPL.  The quietest sound a human can hear, known as the threshold of hearing, is 0 dB SPL, or 20 \u00b5Pa.\nThe airtightness of buildings is measured at 50 Pa.\n\n\n=== Hectopascal and millibar units ===\n\nThe units of atmospheric pressure commonly used in meteorology were formerly the bar, which was close to the average air pressure on Earth, and the millibar. Since the introduction of SI units, meteorologists generally measure pressures in hectopascals (hPa) unit, equal to 100 pascals or 1 millibar. Exceptions include Canada, which use kilopascals (kPa). In many other fields of science, the SI is preferred, which means Pa with a prefix (in multiples of 1000) is preferred.Many countries also use the millibars. In practically all other fields, the kilopascal (1000 pascals) is used instead.\n\n\n== See also ==\nCentimetre of water\nMetric prefix\nOrders of magnitude (pressure)\nPascal's law\n\n\n== References ==\n\n\n== External links ==",
        "unit": "pascal",
        "url": "https://en.wikipedia.org/wiki/Pascal_(unit)"
    },
    {
        "_id": "Energy",
        "clean": "Energy",
        "text": "In physics, energy is the quantitative property that must be transferred to an object in order to perform work on, or to heat, the object.  Energy is a conserved quantity; the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The SI unit of energy is the joule, which is the energy transferred to an object by the work of moving it a distance of 1 metre against a force of 1 newton.\nCommon forms of energy include the kinetic energy of a moving object, the potential energy stored by an object's position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object's temperature.\nMass and energy are closely related. Due to mass\u2013energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. For example, after heating an object, its increase in energy could be measured as a small increase in mass, with a sensitive enough scale.\nLiving organisms require available energy to stay alive, such as the energy humans get from food.  Human civilization requires energy to function, which it gets from  energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth's climate and ecosystem are driven by the radiant energy Earth receives from the sun and the geothermal energy contained within the earth.\n\n\n== Forms ==\n\nThe total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object -- or the composite motion of the components of an object - and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may stored in the field itself.\nWhile these two categories are sufficient to describe all forms of energy, it is often convenient to refer to particular combinations of potential and kinetic energy as its own form. For example, macroscopic mechanical energy is the sum of translational and rotational kinetic and potential energy in a system neglects the kinetic energy due to temperature, and nuclear energy which combines utilize potentials from the nuclear force and the weak force), among others.\n\n\n== History ==\n\nThe word energy derives from the Ancient Greek: \u1f10\u03bd\u03ad\u03c1\u03b3\u03b5\u03b9\u03b1, translit. energeia, lit. 'activity, operation', which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.\nIn the late 17th century, Gottfried Leibniz proposed the idea of the Latin: vis viva, or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total vis viva was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the random motion of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from vis viva only by a factor of two.\nIn 1807, Thomas Young was possibly the first to use the term \"energy\" instead of vis viva, in its modern sense. Gustave-Gaspard Coriolis described \"kinetic energy\" in 1829 in its modern sense, and in 1853, William Rankine coined the term \"potential energy\". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.\nThese developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jo\u017eef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.\n\n\n== Units of measure ==\n\nIn 1843, James Prescott Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the \"Joule apparatus\": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.\nIn the International System of Units (SI), the unit of energy is the joule, named after James Prescott Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British Thermal Units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.\nThe SI unit of energy rate (energy per unit time) is the watt, which is a joule per second.  Thus, one joule is one watt-second, and 3600 joules equal one watt-hour.  The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.\n\n\n== Scientific use ==\n\n\n=== Classical mechanics ===\n\nIn classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.\nWork, a function of energy, is force times distance.\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            C\n          \n        \n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          s\n        \n      \n    \n    {\\displaystyle W=\\int _{C}\\mathbf {F} \\cdot \\mathrm {d} \\mathbf {s} }\n  This says that the work (\n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  ) is equal to the line integral of the force F along a path C; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.\nThe total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.Another energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy minus the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).\nNoether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.\n\n\n=== Chemistry ===\nIn the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants. A reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at given temperature T) is related to the activation energy E, by the Boltzmann's population factor e\u2212E/kT \u2013 that is the probability of molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation.The activation energy necessary for a chemical reaction can be in the form of thermal energy.\n\n\n=== Biology ===\n\nIn biology, energy is an attribute of all biological systems from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or an organelle of a biological organism. Energy is thus often said to be stored by cells in the structures of molecules of substances such as carbohydrates (including sugars), lipids, and proteins, which release energy when reacted with oxygen in respiration. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, assuming an average human energy expenditure of 12,500 kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 \u00f7 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a \"feel\" for the use of a given amount of energy.Sunlight's radiant energy is also captured by plants as chemical potential energy in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into the high-energy compounds carbohydrates, lipids, and proteins. Plants also release oxygen during photosynthesis, which is utilized by living organisms as an electron acceptor, to release the energy of carbohydrates, lipids, and proteins. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark, in a forest fire, or it may be made available more slowly for animal or human metabolism, when these molecules are ingested, and catabolism is triggered by enzyme action.\nAny living organism relies on an external source of energy\u2014radiant energy from the Sun in the case of green plants, chemical energy in some form in the case of animals\u2014to be able to grow and reproduce. The daily 1500\u20132000 Calories (6\u20138 MJ) recommended for a human adult are taken as a combination of oxygen and food molecules, the latter mostly carbohydrates and fats, of which glucose (C6H12O6) and stearin (C57H110O6) are convenient examples. The food molecules are oxidised to carbon dioxide and water in the mitochondria\n\n  \n    \n      \n        \n          \n            C\n            \n              6\n            \n            \n              \n            \n          \n          \n            H\n            \n              12\n            \n            \n              \n            \n          \n          \n            O\n            \n              6\n            \n            \n              \n            \n          \n          +\n          6\n          \n          \n            O\n            \n              2\n            \n            \n              \n            \n          \n          \u27f6\n          6\n          \n          \n            CO\n            \n              2\n            \n            \n              \n            \n          \n          +\n          6\n          \n          \n            H\n            \n              2\n            \n            \n              \n            \n          \n          O\n        \n      \n    \n    {\\displaystyle {\\ce {C6H12O6 + 6O2 -> 6CO2 + 6H2O}}}\n  \nC57H110O6 + 81.5O2 \u2192 57CO2 + 55H2Oand some of the energy is used to convert ADP into ATP.\n\nADP + HPO42\u2212 \u2192 ATP + H2OThe rest of the chemical energy in O2 and the carbohydrate or fat is converted into heat: the ATP is used as a sort of \"energy currency\", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:\ngain in kinetic energy of a sprinter during a 100 m race: 4 kJ\ngain in gravitational potential energy of a 150 kg weight lifted through 2 metres: 3 kJ\nDaily food intake of a normal adult: 6\u20138 MJIt would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy), and it is true that most real machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe (\"the surroundings\"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology: to take just the first step in the food chain, of the estimated 124.7 Pg/a of carbon that is fixed by photosynthesis, 64.3 Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.\n\n\n=== Earth sciences ===\nIn geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations brought about by solar energy on the atmosphere of the planet Earth.\nSunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives many weather phenomena, save those generated by volcanic events. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, give up some of their thermal energy suddenly to power a few days of violent air movement.\nIn a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may be later released to active kinetic energy in landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars created these atoms.\n\n\n=== Cosmology ===\nIn cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.\n\n\n=== Quantum mechanics ===\n\nIn quantum mechanics, energy is defined in terms of the energy operator\nas a time derivative of the wave function. The Schr\u00f6dinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schr\u00f6dinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schr\u00f6dinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: \n  \n    \n      \n        E\n        =\n        h\n        \u03bd\n      \n    \n    {\\displaystyle E=h\\nu }\n   (where \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is Planck's constant and \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.\n\n\n=== Relativity ===\nWhen calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically \u2013 using Lorentz transformations instead of Newtonian mechanics \u2013 Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n        =\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{0}=mc^{2}}\n  ,where\n\nm is the mass of the body,\nc is the speed of light in vacuum,\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle E_{0}}\n   is the rest energy.For example, consider electron\u2013positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles.  This is a reversible process \u2013 the inverse process is called pair creation \u2013 in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.\nIn general relativity, the stress\u2013energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.Energy and mass are manifestations of one and the same underlying physical property of a system.  This property is responsible for the inertia and strength of gravitational interaction of the system (\"mass manifestations\"), and is also responsible for the potential ability of the system to perform work or heating (\"energy manifestations\"), subject to the limitations of other physical laws.\nIn classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy\u2013momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of space-time (= boosts).\n\n\n== Transformation ==\n\nEnergy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery, from chemical energy to electric energy; a dam: gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator; or a heat engine, from heat to work.\nExamples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. Our Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that in itself (since it still contains the same total energy even if in different forms), but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.\nThere are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.\nEnergy transformations in the universe over time are characterized by various kinds of potential energy that has been available since the Big Bang later being \"released\" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nuclear decay, in which energy is released that was originally \"stored\" in heavy isotopes (such as uranium and thorium), by nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae, to store energy in the creation of these heavy elements before they were incorporated into the solar system and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic energy and thermal energy in a very short time. Yet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at maximum. At its lowest point the kinetic energy is at maximum and is equal to the decrease of potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.\nEnergy is also transferred from potential energy (\n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle E_{p}}\n  ) to kinetic energy (\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n  ) and then back to potential energy constantly. This is referred to as conservation of energy. In this closed system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:\n\nThe equation can then be simplified further since \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        =\n        m\n        g\n        h\n      \n    \n    {\\displaystyle E_{p}=mgh}\n   (mass times acceleration due to gravity times the height) and \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{k}={\\frac {1}{2}}mv^{2}}\n   (half mass times velocity squared). Then the total amount of energy can be found by adding \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        +\n        \n          E\n          \n            k\n          \n        \n        =\n        \n          E\n          \n            t\n            o\n            t\n            a\n            l\n          \n        \n      \n    \n    {\\displaystyle E_{p}+E_{k}=E_{total}}\n  .\n\n\n=== Conservation of energy and mass in transformation ===\nEnergy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass-energy equivalence. The formula E = mc\u00b2, derived by Albert Einstein (1905) quantifies the relationship between rest-mass and rest-energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J. J. Thomson (1881), Henri Poincar\u00e9 (1900), Friedrich Hasen\u00f6hrl (1904) and others (see Mass-energy equivalence#History for further information).\nPart of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since \n  \n    \n      \n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle c^{2}}\n   is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1 kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~\n  \n    \n      \n        9\n        \u00d7\n        \n          10\n          \n            16\n          \n        \n      \n    \n    {\\displaystyle 9\\times 10^{16}}\n   joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics.\n\n\n=== Reversible and non-reversible transformations ===\nThermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another, is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as heat, and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomisation in a crystal).\nAs the universe evolves in time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or other kinds of increases in disorder). This has been referred to as the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), grows less and less.\n\n\n== Conservation of energy ==\n\nThe fact that energy can be neither created nor be destroyed is called the law of conservation of energy.  In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out by work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.\nRichard Feynman said during a 1961 lecture:\nThere is a fact, or if you wish, a law, governing all natural phenomena that are known to date. There is no known exception to this law\u2014it is exact so far as we know. The law is called the conservation of energy. It states that there is a certain quantity, which we call energy, that does not change in manifold changes which nature undergoes. That is a most abstract idea, because it is a mathematical principle; it says that there is a numerical quantity which does not change when something happens. It is not a description of a mechanism, or anything concrete; it is just a strange fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same.\n\nMost kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.This law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle - it is impossible to define the exact amount of energy during any definite time interval. The uncertainty principle should not be confused with energy conservation - rather it provides mathematical limits to which energy can in principle be defined and measured.\nEach of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appears as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.\nIn quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by\n\n  \n    \n      \n        \u0394\n        E\n        \u0394\n        t\n        \u2265\n        \n          \n            \u210f\n            2\n          \n        \n      \n    \n    {\\displaystyle \\Delta E\\Delta t\\geq {\\frac {\\hbar }{2}}}\n  which is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since H and t are not dynamically conjugate variables, neither in classical nor in quantum mechanics).\nIn particle physics, this inequality permits a qualitative understanding of virtual particles which carry momentum, exchange by which and with real particles, is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons (which are simply lowest quantum mechanical energy state of photons) are also responsible for electrostatic interaction between electric charges (which results in Coulomb law), for spontaneous radiative decay of exited atomic and nuclear states, for the Casimir force, for van der Waals bond forces and some other observable phenomena.\n\n\n== Energy transfer ==\n\n\n=== Closed systems ===\nEnergy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, and the conductive transfer of thermal energy.\nEnergy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:\n\nwhere \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is the amount of energy transferred, \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n    represents the work done on the system, and \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   represents the heat flow into the system. As a simplification, the heat term, \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  , is sometimes ignored, especially when the thermal efficiency of the transfer is high.\n\nThis simplified equation is the one used to define the joule, for example.\n\n\n=== Open systems ===\nBeyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (both of these process are illustrated by fueling an auto, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  , one may write\n\n\n== Thermodynamics ==\n\n\n=== Internal energy ===\nInternal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.\n\n\n=== First law of thermodynamics ===\nThe first law of thermodynamics asserts that energy (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a gain in energy signified by a positive quantity) is given as\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        T\n        \n          d\n        \n        S\n        \u2212\n        P\n        \n          d\n        \n        V\n        \n      \n    \n    {\\displaystyle \\mathrm {d} E=T\\mathrm {d} S-P\\mathrm {d} V\\,}\n  ,where the first term on the right is the heat transferred into the system, expressed in terms of temperature T and entropy S (in which entropy increases and the change dS is positive when the system is heated), and the last term on the right hand side is identified as work done on the system, where pressure is P and volume V (the negative sign results since compression of the system requires work to be done on it and so the volume change, dV, is negative when work is done on the system).\nThis equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and pV-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a closed system is expressed in a general form by\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        \u03b4\n        Q\n        +\n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\mathrm {d} E=\\delta Q+\\delta W}\n  where \n  \n    \n      \n        \u03b4\n        Q\n      \n    \n    {\\displaystyle \\delta Q}\n   is the heat supplied to the system and \n  \n    \n      \n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\delta W}\n   is the work applied to the system.\n\n\n=== Equipartition of energy ===\nThe energy of a mechanical harmonic oscillator (a mass on a spring) is alternatively kinetic and potential. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over the whole cycle, or over many cycles, net energy is thus equally split between kinetic and potential. This is called equipartition principle; total energy of a system with many degrees of freedom is equally split among all available degrees of freedom.\nThis principle is vitally important to understanding the behaviour of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between \"new\" and \"old\" degrees. This mathematical result is called the second law of thermodynamics. The second law of thermodynamics is valid only for systems which are near or in equilibrium state. For non-equilibrium systems, the laws governing system\u2019s behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way to maximize its entropy production.\n\n\n== See also ==\n\nCombustion\nIndex of energy articles\nIndex of wave articles\nOrders of magnitude (energy)\nPower station\nTransfer energy\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n\nEnergy at Curlie (based on DMOZ)\nDifferences between Heat and Thermal energy - BioCab",
        "unit": "energy",
        "url": "https://en.wikipedia.org/wiki/Energy"
    },
    {
        "_id": "Roentgen_(unit)",
        "clean": "Roentgen (unit)",
        "text": "The roentgen or r\u00f6ntgen () (symbol R) is a legacy unit of measurement for the exposure of X-rays and gamma rays. It is defined as the electric charge freed by such radiation in a specified volume of air divided by the mass of that air. \nIn 1928 it was the first international measurement quantity for ionising radiation to be defined for radiation protection, and was an easily replicated method of measuring air ionization directly by using an ion chamber. It is named after the German physicist Wilhelm R\u00f6ntgen, who discovered X-rays.\nAlthough relatively easy to measure, it had the disadvantage that it was only a measure of air ionisation and not a direct measure of radiation absorption in other materials. As the science of radiation dosimetry developed, it was realised that the ionising effect, and hence damage, was linked to energy absorbed by irradiated materials, and new radiometric units for radiation protection were defined from 1953 onwards which took this into account. A new quantity Kerma was defined which can measure air ionisation, and is the modern metrological successor to the roengten, and from this the absorbed dose can be calculated using known coefficients for specific target materials. In radiation protection the absorbed dose is the energy absorption which is an indication of likely acute tissue effects occurring at high dose rates, and from low levels of absorbed dose the equivalent dose, representing the stochastic health risk, can be calculated; for which the current SI units used are the gray (Gy) and the sievert (Sv) respectively.\nThe roengten has been redefined over the years. It was last defined by the US National Institute of Standards and Technology (NIST) in 1998 as 2.58\u00d710\u22124 C/kg, with a recommendation that the definition be given in every document where the roentgen is used. One roentgen deposits  0.00877 grays (0.877 rads) of absorbed dose in dry air, or 0.0096 Gy (0.96 rad) in soft tissue. One roentgen of X-rays may deposit anywhere from 0.01 to 0.04 Gy (1.0 to 4.0 rad) in bone depending on the beam energy.  This tissue-dependent conversion from kerma to absorbed dose is called the F-factor in radiotherapy contexts. The conversion depends on the ionizing energy of a reference medium, which is ambiguous in the latest NIST definition.\n\n\n== History ==\nThe roentgen has its roots in the Villard unit defined in 1908 by the American Roentgen Ray Society as \"the quantity of radiation which liberates by ionisation one esu of electricity per cm3 of air under normal conditions of temperature and pressure.\" Using 1 esu \u2248 3.33564\u00d710\u221210 C and the air density of ~1.293 kg/m\u00b3 at 0 \u00b0C and 101 kPa, this converts to 2.58 \u00d7 10\u22124 C/kg, which is the modern value given by NIST.\n1 esu/cm3 \u00d7 3.33564 \u00d7 10\u221210 C/esu \u00d7 1,000,000 cm3/m3 \u00f7 1.293 kg/m3 = 2.58 \u00d7 10\u22124 C/kg\nThis definition was used under different names (e, R, and German unit of radiation) for the next 20 years. In the meantime, the French Roentgen was given a different definition which amounted to 0.444 German R.\n\n\n=== ICR definitions ===\nIn 1928, the International Congress of Radiology (ICR) defined the roentgen as \"the quantity of X-radiation which, when the secondary electrons are fully utilised and the wall effect of the chamber is avoided, produce in 1 cc of atmospheric air at 0 \u00b0C and 76 cm of mercury pressure such a degree of conductivity that 1 esu of charge is measured at saturation current.\"  The stated 1 cc of air would have a mass of 1.293 mg at the conditions given, so in 1937 the ICR rewrote this definition in terms of this mass of air instead of volume, temperature and pressure. The 1937 definition was also extended to gamma rays, but later capped at 3 MeV in 1950.\n\n\n=== GOST definition ===\nThe USSR all-union committee of standards (GOST) had meanwhile adopted a significantly different definition of the roentgen in 1934. GOST standard 7623 defined it as \"the physical dose of X-rays which produces charges each of one electrostatic unit in magnitude per cm3 of irradiated volume in air at 0 \u00b0C and normal atmospheric pressure when ionization is complete.\"  The distinction of physical dose from dose caused confusion, some of which may have led Cantrill and Parker report that the roentgen had become shorthand for 83 ergs per gram (0.0083 Gy) of tissue. They named this derivative quantity the roentgen equivalent physical (rep) to distinguish it from the ICR roentgen.\n\n\n=== ICRP definition ===\nThe introduction of the roentgen measurement unit, which relied upon measuring the ionisation of air, replaced earlier less accurate practices that relied on timed exposure, film exposure, or fluorescence. This led the way to setting exposure limits,and the National Council on Radiation Protection and Measurements of the United States established the first formal dose limit in 1931 as 0.1 roentgen per day. The International X-ray and Radium Protection Committee, now known as the International Commission on Radiological Protection (ICRP) soon followed with a limit of 0.2 roentgen per day in 1934. In 1950, the ICRP reduced their recommended limit to 0.3 roentgen per week for whole-body exposure.\nThe International Commission on Radiation Units and Measurements (ICRU) took over the definition of the roentgen in 1950, defining it as \"the quantity of X or \u03b3-radiation such that the associated corpuscular emission per 0.001293 gram of air produces, in air, ions carrying 1 electrostatic unit of quantity of electricity of either sign.\" The 3 MeV cap was no longer part of the definition, but the degraded usefulness of this unit at high beam energies was mentioned in the accompanying text. In the meantime, the new concept of roentgen equivalent man (rem) had been developed.\nStarting in 1957, the ICRP began to publish their recommendations in terms of rem, and the roentgen fell into disuse. The medical imaging community still has a need for ionization measurements, but they gradually converted to using C/kg as legacy equipment was replaced. The ICRU recommended redefining the roentgen to be exactly 2.58 \u00d7 10\u22124 C/kg in 1971.\n\n\n=== European Union ===\nIn 1971 the European Economic Community, in Directive 71/354/EEC, catalogued the units of measure that could be used \"for ... public health ... purposes\".  The directive included the curie, rad, rem and roentgen  as permissible units, but required that the use of the rad, rem and roentgen be reviewed before 31 December 1977. This document defined the roentgen as exactly 2.58 \u00d7 10\u22124 C/kg, as per the ICRU recommendation. Directive 80/181/EEC, published in December 1979, which replaced directive 71/354/EEC, explicitly catalogued the gray, becquerel and sievert for this purpose and required that the curie, rad, rem and roentgen be phased out by 31 December 1985.\n\n\n=== NIST definition ===\nToday the roentgen is rarely used, and the International Committee for Weights and Measures (CIPM) never accepted the use of the roentgen. From 1977 to 1998, the US NIST's translations of the SI brochure stated that the CIPM temporarily accepted the use of the roentgen (and other radiology units) with SI units since 1969. However, the only related CIPM decision shown in the appendix are with regards to the curie in 1964. The NIST brochures defined the roentgen as 2.58 \u00d7 10\u22124 C/kg, to be employed with exposures of x or \u03b3 radiation, but did not state the medium to be ionized. The CIPM's current SI brochure excludes the roentgen from the tables of non-SI units accepted for use with the SI. The US NIST clarified in 1998 that it was providing its own interpretations of the SI system, whereby it accepted the roentgen for use in the US with the SI, while recognizing that the CIPM did not. By then, the limitation to x and \u03b3 radiation had been dropped. NIST recommends defining the roentgen in every document where this unit is used. The continued use of the roentgen is strongly discouraged by the NIST.\n\n\n== Development of replacement radiometric quantities ==\n\nWhilst a convenient quantity to measure with an air ion chamber, the rontgen had the disadvantage that it was not a direct measure of either the intensity of X-rays or their absorption, but rather was a measurement of the ionising effect of X-rays in a specific circumstance; which was dry air at 0 \u00b0C and 1 standard atmosphere of pressure.Because of this the rontgen had a variable relationship to the amount of energy absorbed dose per unit mass in the target material, as different materials have different absorption characteristics. As the science of radiation dosimetry developed, this was seen as a serious shortcoming.\nIn 1940, Louis Harold Gray, who had been studying the effect of neutron damage on human tissue, together with William Valentine Mayneord and the radiobiologist John Read, published a paper in which a unit of measure, dubbed the \"gram roentgen\" (symbol: gr) defined as \"that amount of neutron radiation which produces an increment in energy in unit volume of tissue equal to the increment of energy produced in unit volume of water by one roentgen of radiation\" was proposed. This unit was found to be equivalent to 88 ergs in air. In 1953 the ICRU recommended the rad, equal to 100 erg/g, as the new unit of measure of absorbed radiation. The rad was expressed in coherent cgs units.In the late 1950s the General Conference on Weights and Measures (CGPM) invited the ICRU to join other scientific bodies to work with the International Committee for Weights and Measures (CIPM) in the development of a system of units that could be used consistently over many disciplines. This body, initially known as the \"Commission for the System of Units\", renamed in 1964 as the \"Consultative Committee for Units\" (CCU), was responsible for overseeing the development of the International System of Units (SI). At the same time it was becoming increasingly obvious that the definition of the roentgen was unsound, and in 1962 it was redefined.\nThe CCU decided to define the SI unit of absorbed radiation in terms of energy per unit mass, which in MKS units was J/kg. This was confirmed in 1975 by the 15th CGPM, and the unit was named the \"gray\" in honour of Louis Harold Gray, who had died in 1965. The gray was equal to 100 rad. The definition of the roentgen had had the attraction of being relatively simple to define for photons in air, but the gray is independent of the primary ionizing radiation type, and can be used for both kerma and absorbed dose in a wide range of matter.When measuring absorbed dose in a human due to external exposure, the SI unit the gray, or the related non-SI rad are used. From these can be developed the dose equivalents to consider biological effects from differing radiation types and target materials. These are equivalent dose, and effective dose for which the SI unit sievert or the non-SI  rem are used.\n\n\n== Radiation-related quantities ==\nThe following table shows radiation quantities in SI and non-SI units:\n\n\n== See also ==\nWilhelm Conrad R\u00f6ntgen\nRad (unit)\u2014c.g.s. unit of absorbed dose\nGray (unit)\u2014SI unit of absorbed dose\nRoentgen equivalent man, or rem, a unit of radiation dose equivalent\nSievert\u2014The sievert (symbol: Sv) is the SI derived unit of dose equivalent.\nOrders of magnitude (radiation)\n\n\n== References ==\n\n\n== External links ==\nNIST: Units outside the SI\nHealth Physics Society information page on radiation dose units",
        "unit": "roentgen",
        "url": "https://en.wikipedia.org/wiki/Roentgen_(unit)"
    },
    {
        "_id": "Barn_(unit)",
        "clean": "Barn (unit)",
        "text": "A barn (symbol: b) is a unit of area equal to 10\u221228 m2 (100 fm2). Originally used in nuclear physics for expressing the cross sectional area of nuclei and nuclear reactions, today it is also used in all fields of high-energy physics to express the cross sections of any scattering process, and is best understood as a measure of the probability of interaction between small particles. A barn is  approximately the cross-sectional area of a uranium nucleus. The barn is also the unit of area used in nuclear quadrupole resonance and nuclear magnetic resonance to quantify the interaction of a nucleus with an electric field gradient. While the barn is not an SI unit, the SI standards body acknowledges its existence due to its continued use in particle physics.\n\n\n== Etymology ==\nThe etymology of the unit barn is whimsical: during Manhattan Project research on the atomic bomb during World War II, American physicists at Purdue University needed a secretive unit to describe the approximate cross sectional area presented by the typical nucleus (10\u221228 m2) and decided on \"barn\". This was particularly applicable because they considered this a large target for particle accelerators that needed to have direct strikes on nuclei and the American idiom \"couldn't hit the broad side of a barn\" refers to someone whose aim is terrible. Initially they hoped the name would obscure any reference to the study of nuclear structure; eventually, the word became a standard unit in nuclear and particle physics.\n\n\n== Commonly used prefixed versions ==\nOther related units are the outhouse (1 \u03bcb, or 10\u221234 m2) and the shed (10\u221224 b (1 yb), or 10\u221252 m2), although these are rarely used in practice.\n\n\n== Conversions ==\nCalculated cross sections are often given in terms of gigaelectronvolts (GeV), via the conversion \u01272c2/GeV2 = 0.3894 mb = 38 940 am2.\nIn natural units (where \u0127 = c = 1), this simplifies to GeV\u22122 = 0.3894 mb = 38 940 am2.\n\n\n=== SI units with prefix ===\nIn SI, one can use units such as square femtometers (fm2).\n\n\n== Inverse femtobarn ==\nThe inverse femtobarn (fb\u22121) is the unit typically used to measure the number of particle collision events per femtobarn of target cross-section, and is the conventional unit for time-integrated luminosity. Thus if a detector has accumulated 100 fb\u22121 of integrated luminosity, one expects to find 100 events per femtobarn of cross-section within these data.\nConsider a particle accelerator where two streams of particles, with cross-sectional areas measured in femtobarns, are directed to collide over a period of time. The total number of collisions will be directly proportional to the luminosity of the collisions measured over this time. Therefore, the collision count can be calculated by multiplying the integrated luminosity by the sum of the cross-section for those collision processes. This count is then expressed as inverse femtobarns for the time period (e.g., 100 fb\u22121 in nine months). Inverse femtobarns are often quoted as an indication of particle collider productivity.Fermilab produced 10 fb\u22121 in the first decade of the 21st century.  Fermilab's Tevatron took about 4 years to reach 1 fb\u22121 in 2005, while two of CERN's LHC experiments, ATLAS and CMS, reached over 5 fb\u22121 of proton-proton data in 2011 alone. In April 2012 the LHC achieved the collision energy of 8 TeV with a luminosity peak of 6760 inverse microbarns per second; by May 2012 the LHC delivered 1 inverse femtobarn of data per week to each detector collaboration. A record of over 23 fb\u22121 was achieved during 2012. As of November 2016, the LHC had achieved 40  fb\u22121 over that year, significantly exceeding the stated goal of 25  fb\u22121.\n\n\n=== Usage example ===\nAs a simplified example, if a beamline runs for 8 hours (28 800 seconds) at an instantaneous luminosity of 300 \u00d7 1030 cm\u22122s\u22121 = 300 \u03bcb\u22121s\u22121, then it will gather data totaling an integrated luminosity of 8 640 000 \u03bcb\u22121 = 8.64 pb\u22121 = 0.008 64 fb\u22121 during this period. If this is multiplied by the cross-section, then a dimensionless number is obtained which would be simply the number of expected scattering events.\n\n\n== See also ==\nOrders of magnitude (area)\nList of unusual units of measurement\n\n\n== References ==\n\n\n== External links ==\nIUPAC citation for this usage of \"barn\"",
        "unit": "megabarn",
        "url": "https://en.wikipedia.org/wiki/Barn_(unit)"
    },
    {
        "_id": "Centavo",
        "clean": "Centavo",
        "text": "Centavo is a Spanish and Portuguese word, derived from the Latin centum, meaning \"one hundred\", and the suffix -avo, meaning \"portion\" or \"fraction\". Centavo means, strictly, \"one-hundredth\".\nIt is a fractional monetary unit, used to represent one hundredth of a basic monetary unit in many countries around the world, including:\n\n\n== Circulating ==\nArgentine peso\nBolivian boliviano\nBrazilian real\nCape Verdean escudo\nChilean peso (until 1984)\nColombian peso\nCuban peso\nDominican peso\nEast Timor centavo coins\nEcuadorian centavo coins\nGuatemalan quetzal\nHonduran lempira\nMexican peso\nMozambican metical\nNicaraguan c\u00f3rdoba\nPhilippine peso (In English usage; s\u00e9ntimo or c\u00e9ntimo is used in Tagalog and Spanish respectively.)\n\n\n== Obsolete ==\n\nBrazilian cruzeiro (from 1942 to 1986 and from 1990 to 1993)\nBrazilian cruzado (from 1986 to 1989)\nBrazilian cruzado novo (from 1989 to 1990)\nCosta Rican col\u00f3n (Between 1917 and 1920 only. As c\u00e9ntimo for other periods.)\nEcuadorian sucre (New centavo coins continued to circulate after the sucre was replaced by U.S. dollar in 2000.)\nSalvadoran col\u00f3n\nGuinea Bissau peso\nMozambican escudo\nPortuguese escudo (Before the euro was introduced)\nPortuguese Guinean escudo\nPortuguese Indian escudo\nPuerto Rican peso\nS\u00e3o Tom\u00e9 and Pr\u00edncipe escudo\nVenezuelan venezolano\nVenezuelan peso",
        "unit": "centavo",
        "url": "https://en.wikipedia.org/wiki/Centavo"
    },
    {
        "_id": "Viscosity",
        "clean": "Viscosity",
        "text": "The viscosity of a fluid is the measure of its resistance to gradual deformation by shear stress or tensile stress. For liquids, it corresponds to the informal concept of \"thickness\": for example, honey has a higher viscosity than water.Viscosity is the property of a fluid which opposes the relative motion between two surfaces of the fluid that are moving at different velocities. In simple terms, viscosity means friction between the molecules of fluid. When the fluid is forced through a tube, the particles which compose the fluid generally move more quickly near the tube's axis and more slowly near its walls; therefore some stress (such as a pressure difference between the two ends of the tube) is needed to overcome the friction between particle layers to keep the fluid moving. For a given velocity pattern, the stress required is proportional to the fluid's viscosity.\nA fluid that has no resistance to shear stress is known as an ideal or inviscid fluid. Zero viscosity is observed only at very low temperatures in superfluids. Otherwise, all fluids have positive viscosity and are technically said to be viscous or viscid. A fluid with a relatively high viscosity, such as pitch, may appear to be a solid.\n\n\n== Etymology ==\nThe word \"viscosity\" is derived from the Latin \"viscum\", meaning mistletoe and also a viscous glue made from mistletoe berries.\n\n\n== Definition ==\n\n\n=== Simple definition ===\n\nThe viscosity of a fluid expresses its resistance to shearing flows, in which adjacent fluid layers are in relative motion. A simple example of such a shearing flow is a planar Couette flow, where a fluid is trapped between two infinitely large plates, one fixed and one in parallel motion at constant speed \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n   (see illustration to the right). Although viscosity applies to general flows, it is easy to define and visualize in a Couette flow.\nIf the speed of the top plate is low enough, then in steady state the fluid particles move parallel to it, and their speed varies from \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n   at the bottom to u at the top. Each layer of fluid moves faster than the one just below it, and friction between them gives rise to a force resisting their relative motion. In particular, the fluid applies on the top plate a force in the direction opposite to its motion, and an equal but opposite force on the bottom plate. An external force is therefore required in order to keep the top plate moving at constant speed.\nIn many fluids, the flow velocity is observed to vary linearly from zero at the bottom to \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n   at the top. Moreover, the magnitude F of the force acting on the top plate is found to be proportional to the speed u and the area A of each plate, and inversely proportional to their separation y: \n\n  \n    \n      \n        F\n        =\n        \u03bc\n        A\n        \n          \n            u\n            y\n          \n        \n        .\n      \n    \n    {\\displaystyle F=\\mu A{\\frac {u}{y}}.}\n  The proportionality factor \u03bc is the viscosity of the fluid, with units of \n  \n    \n      \n        \n          Pa\n        \n        \u22c5\n        \n          s\n        \n      \n    \n    {\\displaystyle {\\text{Pa}}\\cdot {\\text{s}}}\n   (pascal-second). The ratio u/y is called the rate of shear deformation or shear velocity, and is the derivative of the fluid speed in the direction perpendicular to the plates (see illustrations to the right). If the velocity does not vary linearly with y, then the appropriate generalization is\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \u2202\n              u\n            \n            \n              \u2202\n              y\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\partial u}{\\partial y}},}\n  where \u03c4 = F/A, and \u2202u/\u2202y is the local shear velocity. This expression is referred to as Newton's law of viscosity. In shearing flows with planar symmetry, it is what defines \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  . It is a special case of the general definition of viscosity (see below), which can be expressed in coordinate-free form.\nUse of the Greek letter mu (\u03bc) for the viscosity is common among mechanical and chemical engineers, as well as physicists. However, the Greek letter eta (\u03b7) is also used by chemists, physicists, and the IUPAC. The viscosity \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is sometimes also referred to as the shear viscosity. However, at least one author discourages the use of this terminology, noting that \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   can be appear in nonshearing flows in addition to shearing flows.\n\n\n=== General definition ===\n\nIn general, the stresses within a flow can be attributed partly to the deformation of the material from some rest state (elastic stress), and partly to the rate of change of the deformation over time (viscous stress). In a fluid, by definition, the elastic stress includes only the hydrostatic pressure. In very general terms, the fluid's viscosity is the relation between the strain rate and the viscous stress. In the Newtonian fluid model the relationship is by definition a linear map, described by a viscosity tensor that, when multiplied by the strain rate tensor (which is the gradient of the flow's velocity), gives the viscous stress tensor. In Cartesian coordinates, this gives\n\n  \n    \n      \n        \n          \u03c4\n          \n            i\n            j\n          \n        \n        =\n        \n          \u2211\n          \n            k\n          \n        \n        \n          \u2211\n          \n            l\n          \n        \n        \n          \u03bc\n          \n            i\n            j\n            k\n            l\n          \n        \n        \n          \n            \n              \u2202\n              \n                v\n                \n                  k\n                \n              \n            \n            \n              \u2202\n              \n                r\n                \n                  l\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau _{ij}=\\sum _{k}\\sum _{l}\\mu _{ijkl}{\\frac {\\partial v_{k}}{\\partial r_{l}}}.}\n  Since the indices in the above expression can vary from 1 to 3, there are 81 \"viscosity coefficients\" \n  \n    \n      \n        \n          \u03bc\n          \n            i\n            j\n            k\n            l\n          \n        \n      \n    \n    {\\displaystyle \\mu _{ijkl}}\n   in total. However, due to spatial symmetries these coefficients are not all independent. For instance, for isotropic Newtonian fluids, the 81 coefficients can be reduced to 2 independent parameters. The most usual decomposition yields the standard (scalar) viscosity \u03bc and the bulk viscosity \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n  :\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \u03bc\n        \n          [\n          \n            \u2207\n            \n              v\n            \n            +\n            (\n            \u2207\n            \n              v\n            \n            \n              )\n              \n                \u2020\n              \n            \n          \n          ]\n        \n        \u2212\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03bc\n            \u2212\n            \u03ba\n          \n          )\n        \n        (\n        \u2207\n        \u22c5\n        \n          v\n        \n        )\n        \n          \u03b4\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {\\tau } =\\mu \\left[\\nabla \\mathbf {v} +(\\nabla \\mathbf {v} )^{\\dagger }\\right]-\\left({\\frac {2}{3}}\\mu -\\kappa \\right)(\\nabla \\cdot \\mathbf {v} )\\mathbf {\\delta } ,}\n  where \n  \n    \n      \n        \n          \u03b4\n        \n      \n    \n    {\\displaystyle \\mathbf {\\delta } }\n   is the unit tensor, and the dagger \n  \n    \n      \n        \u2020\n      \n    \n    {\\displaystyle \\dagger }\n   denotes the transpose. This equation can be thought of as a generalized form of Newton's law of viscosity. \nThe bulk viscosity expresses a type of internal friction that resists the shearless compression or expansion of a fluid. Knowledge of \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   is frequently not necessary in fluid dynamics problems. For example, incompressible liquids satisfy \n  \n    \n      \n        \u2207\n        \u22c5\n        \n          v\n        \n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\cdot \\mathbf {v} =0}\n   and so the term containing \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   is absent. Moreover, \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   is often assumed to be negligible for gases since it is \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n   in a monoatomic ideal gas. One situation in which \n  \n    \n      \n        \u03ba\n      \n    \n    {\\displaystyle \\kappa }\n   can be important is the calculation of energy loss in sound and shock waves, described by Stokes' law of sound attenuation, since these phenomena involve rapid expansions and compressions. \n\n\n=== Dynamic and kinematic viscosity ===\nIn fluid dynamics, it is common to work in terms of the kinematic viscosity (also called \"momentum diffusivity\"), defined as the ratio of the viscosity \u03bc to the density of the fluid \u03c1. It is usually denoted by the Greek letter nu (\u03bd) and has units \n  \n    \n      \n        \n          (\n          l\n          e\n          n\n          g\n          t\n          h\n          \n            )\n            \n              2\n            \n          \n          \n            /\n          \n          t\n          i\n          m\n          e\n        \n      \n    \n    {\\displaystyle \\mathrm {(length)^{2}/time} }\n  :\n\n  \n    \n      \n        \u03bd\n        =\n        \n          \n            \u03bc\n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle \\nu ={\\frac {\\mu }{\\rho }}}\n  .Consistent with this nomenclature, the viscosity \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is frequently called the dynamic viscosity. \n\n\n== Newtonian and non-Newtonian fluids ==\n\nNewton's law of viscosity is a constitutive equation (like Hooke's law, Fick's law, and Ohm's law): it is not a fundamental law of nature but an approximation that holds in some materials and fails in others.\nA fluid that behaves according to Newton's law, with a viscosity \u03bc that is independent of the stress, is said to be Newtonian. Gases, water, and many common liquids can be considered Newtonian in ordinary conditions and contexts. There are many non-Newtonian fluids that significantly deviate from that law in some way or other. For example:\n\nShear-thickening liquids, whose viscosity increases with the rate of shear strain.\nShear-thinning liquids, whose viscosity decreases with the rate of shear strain.\nThixotropic liquids, that become less viscous over time when shaken, agitated, or otherwise stressed.\nRheopectic (dilatant) liquids, that become more viscous over time when shaken, agitated, or otherwise stressed.\nBingham plastics that behave as a solid at low stresses but flow as a viscous fluid at high stresses.Shear-thinning liquids are very commonly, but misleadingly, described as thixotropic.\nEven for a Newtonian fluid, the viscosity usually depends on its composition and temperature. For gases and other compressible fluids, it depends on temperature and varies very slowly with pressure.\nThe viscosity of some fluids may depend on other factors. A magnetorheological fluid, for example, becomes thicker when subjected to a magnetic field, possibly to the point of behaving like a solid.\n\n\n== In solids ==\nThe viscous forces that arise during fluid flow must not be confused with the elastic forces that arise in a solid in response to shear, compression or extension stresses. While in the latter the stress is proportional to the amount of shear deformation, in a fluid it is proportional to the rate of deformation over time. (For this reason, Maxwell used the term fugitive elasticity for fluid viscosity.)\nHowever, many liquids (including water) will briefly react like elastic solids when subjected to sudden stress. Conversely, many \"solids\" (even granite) will flow like liquids, albeit very slowly, even under arbitrarily small stress. Such materials are therefore best described as possessing both elasticity (reaction to deformation) and viscosity (reaction to rate of deformation); that is, being viscoelastic.\nIndeed, some authors have claimed that amorphous solids, such as glass and many polymers, are actually liquids with a very high viscosity (greater than 1012 Pa\u00b7s).\n However, other authors dispute this hypothesis, claiming instead that there is some threshold for the stress, below which most solids will not flow at all, and that alleged instances of glass flow in window panes of old buildings are due to the crude manufacturing process of older eras rather than to the viscosity of glass.Viscoelastic solids may exhibit both shear viscosity and bulk viscosity. The extensional viscosity is a linear combination of the shear and bulk viscosities that describes the reaction of a solid elastic material to elongation. It is widely used for characterizing polymers.\nIn geology, earth materials that exhibit viscous deformation at least three orders of magnitude greater than their elastic deformation are sometimes called rheids.\n\n\n== Measurement ==\n\nViscosity is measured with various types of viscometers and rheometers. A rheometer is used for those fluids that cannot be defined by a single value of viscosity and therefore require more parameters to be set and measured than is the case for a viscometer. Close temperature control of the fluid is essential to acquire accurate measurements, particularly in materials like lubricants, whose viscosity can double with a change of only 5 \u00b0C.\nFor some fluids, the viscosity is constant over a wide range of shear rates (Newtonian fluids). The fluids without a constant viscosity (non-Newtonian fluids) cannot be described by a single number. Non-Newtonian fluids exhibit a variety of different correlations between shear stress and shear rate.\nOne of the most common instruments for measuring kinematic viscosity is the glass capillary viscometer.\nIn coating industries, viscosity may be measured with a cup in which the efflux time is measured. There are several sorts of cup \u2013 such as the Zahn cup and the Ford viscosity cup \u2013 with the usage of each type varying mainly according to the industry. The efflux time can also be converted to kinematic viscosities (centistokes, cSt) through the conversion equations.Also used in coatings, a Stormer viscometer uses load-based rotation in order to determine viscosity. The viscosity is reported in Krebs units (KU), which are unique to Stormer viscometers.\nVibrating viscometers can also be used to measure viscosity. Resonant, or vibrational viscometers work by creating shear waves within the liquid. In this method, the sensor is submerged in the fluid and is made to resonate at a specific frequency. As the surface of the sensor shears through the liquid, energy is lost due to its viscosity. This dissipated energy is then measured and converted into a viscosity reading. A higher viscosity causes a greater loss of energy.Extensional viscosity can be measured with various rheometers that apply extensional stress.\nVolume viscosity can be measured with an acoustic rheometer.\nApparent viscosity is a calculation derived from tests performed on drilling fluid used in oil or gas well development. These calculations and tests help engineers develop and maintain the properties of the drilling fluid to the specifications required.\n\n\n== Units ==\n\n\n=== Dynamic viscosity, \u03bc ===\nThe SI unit of dynamic viscosity is Pa\u00b7s or kg\u00b7m\u22121\u00b7s\u22121.\nBoth the physical unit of dynamic viscosity in SI units, the poiseuille (Pl), and cgs units, the poise (P), are named after Jean L\u00e9onard Marie Poiseuille. The poiseuille, which is rarely used, is equivalent to the pascal second (Pa\u00b7s), or (N\u00b7s)/m2, or kg/(m\u00b7s). If a fluid is placed between two plates with distance one meter, and one plate is pushed sideways with a shear stress of one pascal, and it moves at x meters per second, then it has viscosity of 1/x pascal seconds. For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s, while a typical motor oil could have a viscosity of about 250 mPa\u00b7s. The units used in practice are either Pa\u00b7s and its submultiples or the cgs poise referred to below, and its submultiples.\nThe cgs physical unit for dynamic viscosity, the poise (P), is also named after Jean Poiseuille. It is more commonly expressed, particularly in ASTM standards, as centipoise (cP) since the latter is equal to the SI multiple millipascal seconds (mPa\u00b7s). For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s = 1.002 cP.\n\n1 Pl = 1 Pa\u00b7s\n1 P = 1 dPa\u00b7s = 0.1 Pa\u00b7s = 0.1 kg\u00b7m\u22121\u00b7s\u22121\n1 cP = 1 mPa\u00b7s = 0.001 Pa\u00b7s = 0.001 N\u00b7s\u00b7m\u22122 = 0.001 kg\u00b7m\u22121\u00b7s\u22121.\n\n\n=== Kinematic viscosity, \u03bd ===\nThe SI unit of kinematic viscosity is m2/s.\nThe cgs physical unit for kinematic viscosity is the stokes (St), named after Sir George Gabriel Stokes. It is sometimes expressed in terms of centistokes (cSt). In U.S. usage, stoke is sometimes used as the singular form.\n\n1 St = 1 cm2\u00b7s\u22121 = 10\u22124 m2\u00b7s\u22121.\n1 cSt = 1 mm2\u00b7s\u22121 = 10\u22126 m2\u00b7s\u22121.Water at 20 \u00b0C has a kinematic viscosity of about 10\u22126 m2\u00b7s\u22121 or 1 cSt.\nThe kinematic viscosity is sometimes referred to as diffusivity of momentum, because it is analogous to diffusivity of heat and diffusivity of mass. It is therefore used in dimensionless numbers which compare the ratio of the diffusivities.\n\n\n=== Fluidity ===\nThe reciprocal of viscosity is fluidity, usually symbolized by \u03c6 = 1/\u03bc or F = 1/\u03bc, depending on the convention used, measured in reciprocal poise (P\u22121, or cm\u00b7s\u00b7g\u22121), sometimes called the rhe. Fluidity is seldom used in engineering practice.\nThe concept of fluidity can be used to determine the viscosity of an ideal solution. For two components A and B, the fluidity when A and B are mixed is\n\n  \n    \n      \n        F\n        \u2248\n        \n          \u03c7\n          \n            \n              A\n            \n          \n        \n        \n          F\n          \n            \n              A\n            \n          \n        \n        +\n        \n          \u03c7\n          \n            \n              B\n            \n          \n        \n        \n          F\n          \n            \n              B\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle F\\approx \\chi _{\\mathrm {A} }F_{\\mathrm {A} }+\\chi _{\\mathrm {B} }F_{\\mathrm {B} },}\n  which is only slightly simpler than the equivalent equation in terms of viscosity:\n\n  \n    \n      \n        \u03bc\n        \u2248\n        \n          \n            1\n            \n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          A\n                        \n                      \n                    \n                  \n                \n              \n              +\n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          B\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu \\approx {\\frac {1}{{\\dfrac {\\chi _{\\mathrm {A} }}{\\mu _{\\mathrm {A} }}}+{\\dfrac {\\chi _{\\mathrm {B} }}{\\mu _{\\mathrm {B} }}}}},}\n  where \u03c7A and \u03c7B are the mole fractions of components A and B respectively, and \u03bcA and \u03bcB are the components' pure viscosities.\n\n\n=== Non-standard units ===\nThe reyn is a British unit of dynamic viscosity.\nViscosity index is a measure for the change of viscosity with temperature. It is used in the automotive industry to characterise lubricating oil.\nAt one time the petroleum industry relied on measuring kinematic viscosity by means of the Saybolt viscometer, and expressing kinematic viscosity in units of Saybolt universal seconds (SUS). Other abbreviations such as SSU (Saybolt seconds universal) or SUV (Saybolt universal viscosity) are sometimes used. Kinematic viscosity in centistokes can be converted from SUS according to the arithmetic and the reference table provided in ASTM D 2161.\n\n\n== Molecular origins ==\n\nIn general, the viscosity of a system depends in detail on how the molecules constituting the system interact. There are no simple but correct expressions for the viscosity of a fluid. The simplest exact expressions are the Green\u2013Kubo relations for the linear shear viscosity or the transient time correlation function expressions derived by Evans and Morriss in 1985. Although these expressions are each exact, calculating the viscosity of a dense fluid using these relations currently requires the use of molecular dynamics computer simulations. On the other hand, much more progress can be made for a dilute gas. Even elementary assumptions about how gas molecules move and interact lead to a basic understanding of the molecular origins of viscosity. More sophisticated treatments can be constructed by systematically coarse-graining the equations of motion of the gas molecules. An example of such a treatment is Chapman\u2013Enskog theory, which derives expressions for the viscosity of a dilute gas from the Boltzmann equation.Momentum transport in gases is generally mediated by discrete molecular collisions, and in liquids by attractive forces which bind molecules close together. Because of this, the dynamic viscosities of liquids are typically several orders of magnitude higher than dynamic viscosities of gases.\n\n\n=== Gases ===\n\nViscosity in gases arises principally from the molecular diffusion that transports momentum between layers of flow. An elementary calculation for a dilute gas at temperature \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   and density \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   gives\n\n  \n    \n      \n        \u03bc\n        =\n        \u03b1\n        \u03c1\n        \u03bb\n        \n          \n            \n              \n                2\n                \n                  k\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                m\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\alpha \\rho \\lambda {\\sqrt {\\frac {2k_{B}T}{\\pi m}}},}\n  where \n  \n    \n      \n        \n          k\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle k_{B}}\n   is the Boltzmann constant, \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   the molecular mass, and \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   a numerical constant on the order of \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  . The quantity \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n  , the mean free path, measures the average distance a molecule travels between collisions. Even without a priori knowledge of \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  , this expression has interesting implications. In particular, since \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is typically inversely proportional to density and increases with temperature, \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   itself should increase with temperature and be independent of density. In fact, both of these predictions persist in more sophisticated treatments, and accurately describe experimental observations. Note that this behavior runs counter to common intuition regarding liquids, for which viscosity typically decreases with temperature.\nFor rigid elastic spheres of diameter \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  , \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   can be computed, giving\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            \u03b1\n            \n              \u03c0\n              \n                3\n                \n                  /\n                \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                k\n                \n                  B\n                \n              \n              m\n              T\n            \n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mu ={\\frac {\\alpha }{\\pi ^{3/2}}}{\\frac {\\sqrt {k_{B}mT}}{\\sigma ^{2}}}.}\n  In this case \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is independent of temperature, so \n  \n    \n      \n        \u03bc\n        \u221d\n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu \\propto T^{1/2}}\n  . For more complicated molecular models, however, \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   depends on temperature in a non-trivial way, and simple kinetic arguments as used here are inadequate. More fundamentally, the notion of a mean free path becomes imprecise for particles that interact over a finite range, which limits the usefulness of the concept for describing real-world gases.\n\n\n==== Chapman\u2013Enskog theory ====\n\nA technique developed by Sydney Chapman and David Enskog in the early 1900s allows a more refined calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  . It is based on the Boltzmann equation, which provides a systematic statistical description of a dilute gas in terms of intermolecular interactions. As such, their technique allows accurate calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   for more realistic molecular models, such as those incorporating intermolecular attraction rather than just hard-core repulsion.\nIt turns out that a more realistic modeling of interactions is essential for accurate prediction of the temperature dependence of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  , which experiments show increases more rapidly than the \n  \n    \n      \n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle T^{1/2}}\n   trend predicted for rigid elastic spheres. Indeed, the Chapman\u2013Enskog analysis shows that the predicted temperature dependence can be tuned by varying the parameters in various molecular models. A simple example is the Sutherland model, which describes rigid elastic spheres with weak mutual attraction. In such a case, the attractive force can be treated perturbatively, which leads to a particularly simple expression for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  :\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            5\n            \n              16\n              \n                \u03c3\n                \n                  2\n                \n              \n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    k\n                    \n                      B\n                    \n                  \n                  m\n                  T\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            1\n            \n              /\n            \n            2\n          \n        \n        \n          \n            (\n            \n              1\n              +\n              \n                \n                  S\n                  T\n                \n              \n            \n            )\n          \n          \n            \u2212\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu ={\\frac {5}{16\\sigma ^{2}}}\\left({\\frac {k_{B}mT}{\\pi }}\\right)^{1/2}\\left(1+{\\frac {S}{T}}\\right)^{-1},}\n  where \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is independent of temperature, being determined only by the parameters of the intermolecular attraction. To connect with experiment, it is convenient to rewrite as\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            (\n            \n              \n                T\n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            )\n          \n          \n            3\n            \n              /\n            \n            2\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              S\n            \n            \n              T\n              +\n              S\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\mu _{0}\\left({\\frac {T}{T_{0}}}\\right)^{3/2}{\\frac {T_{0}+S}{T+S}},}\n  where \n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   is the viscosity at temperature \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  . If \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is known from experiments at \n  \n    \n      \n        T\n        =\n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T=T_{0}}\n   and at least one other temperature, then \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   can be calculated. It turns out that expressions for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   obtained in this way are accurate for a number of gases over a sizable range of temperatures. On the other hand, Chapman and Cowling argue that this success does not imply that molecules actually interact according to the Sutherland model. Rather, they interpret the prediction for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   as a simple interpolation which is valid for some gases over fixed ranges of temperature, but otherwise does not provide a picture of intermolecular interactions which is fundamentally correct and general. Slightly more sophisticated models, such as the Lennard\u2013Jones potential, may provide a better picture, but only at the cost of a more opaque dependence on temperature. In some systems the assumption of spherical symmetry must be abandoned as well, as is the case for vapors with highly polar molecules like H2O.\n\n\n=== Liquids ===\n\nIn contrast with gases, there is no simple yet accurate picture for the molecular origins of viscosity in liquids. \nAt the simplest level of description, the relative motion of adjacent layers in a liquid is opposed primarily by attractive molecular forces\nacting across the layer boundary. In this picture, one (correctly) expects viscosity to decrease with temperature. This is because\nincreasing temperature increases the random thermal motion of the molecules, which makes it easier for them to overcome their attractive interactions.Building on this visualization, a simple theory can be constructed in analogy with the discrete structure of a solid: groups of molecules in a liquid \nare visualized as forming \"cages\" which surround and enclose single molecules. These cages can be occupied or unoccupied, and\nstronger molecular attraction corresponds to stronger cages.\nDue to random thermal motion, a molecule \"hops\" between cages at a rate which varies inversely with the strength of molecular attractions. In equilibrium these \"hops\" are not biased in any direction.\nOn the other hand, in order for two adjacent layers to move relative to each other, the \"hops\" must be biased in the direction\nof the relative motion. The force required to sustain this directed motion can be estimated for a given shear rate, leading to\n\nwhere \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is the Avogadro constant, \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is the Planck constant, \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the volume of a mole of liquid, and \n  \n    \n      \n        \n          T\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle T_{b}}\n   is the normal boiling point. This result has the same form as the widespread and accurate empirical relation \n\nwhere \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   are constants fit from data. One the other hand, several authors express caution with respect to this model.\nErrors as large as 30% can be encountered using equation (1), compared with fitting equation (2) to experimental data. More fundamentally, the physical assumptions underlying equation (1) have been extensively criticized. It has also been argued that the exponential dependence in equation (1) does not necessarily describe experimental observations more accurately than simpler, non-exponential expressions.In light of these shortcomings, the development of a less ad-hoc model is a matter of practical interest.\nForegoing simplicity in favor of precision, it is possible to write rigorous expressions for viscosity starting from the fundamental equations of motion for molecules. A classic example \nof this approach is Irving-Kirkwood theory. On the other hand, such expressions\nare given as averages over multiparticle correlation functions and are therefore difficult to apply in practice. \nIn general, empirically derived expressions (based on existing viscosity measurements) appear to be the only consistently reliable means of calculating viscosity in liquids.\n\n\n== Selected substances ==\n\n\n=== Air ===\n\nThe viscosity of air depends mostly on the temperature. At 15 \u00b0C, the viscosity of air is 1.81\u00d710\u22125 kg/(m\u00b7s), 18.1 \u03bcPa\u00b7s or 1.81\u00d710\u22125 Pa\u00b7s. The kinematic viscosity at 15 \u00b0C is 1.48\u00d710\u22125 m2/s or 14.8 cSt. At 25 \u00b0C, the viscosity is 18.6 \u03bcPa\u00b7s and the kinematic viscosity 15.7 cSt.\n\n\n=== Water ===\n\nThe dynamic viscosity of water is 8.90\u00d710\u22124 Pa\u00b7s or 8.90\u00d710\u22123 dyn\u00b7s/cm2 or 0.890 cP at about 25 \u00b0C.\nAs a function of temperature T (in kelvins): \u03bc = A \u00d7 10B/(T \u2212 C), where A = 2.414\u00d710\u22125 Pa\u00b7s, B = 247.8 K, and C = 140 K.The dynamic viscosity of liquid water at different temperatures up to the normal boiling point is listed below.\n\n\n=== Other substances ===\n\nSome dynamic viscosities of Newtonian fluids are listed below:\n\n\n== Blends of liquids ==\nThe viscosity of the blend of two or more liquids can be estimated using the Refutas equation. The calculation is carried out in three steps.\nThe first step is to calculate the viscosity blending number (VBN) (also called the viscosity blending index) of each component of the blend:\n\n  \n    \n      \n        \n          V\n          B\n          N\n        \n        =\n        14.534\n        \u00d7\n        ln\n        \u2061\n        \n          \n            (\n          \n        \n        ln\n        \u2061\n        (\n        \u03bd\n        +\n        0.8\n        )\n        \n          \n            )\n          \n        \n        +\n        10.975\n        \n      \n    \n    {\\displaystyle \\mathrm {VBN} =14.534\\times \\ln {\\big (}\\ln(\\nu +0.8){\\big )}+10.975\\,}\n     (1)where \u03bd is the kinematic viscosity in centistokes (cSt). It is important that the kinematic viscosity of each component of the blend be obtained at the same temperature.\nThe next step is to calculate the VBN of the blend, using this equation:\n\n  \n    \n      \n        \n          V\n          B\n          \n            N\n            \n              B\n              l\n              e\n              n\n              d\n            \n          \n        \n        =\n        \n          (\n          \n            \n              x\n              \n                \n                  A\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  A\n                \n              \n            \n          \n          )\n        \n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  B\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  B\n                \n              \n            \n          \n          )\n        \n        +\n        \u22ef\n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  N\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  N\n                \n              \n            \n          \n          )\n        \n        \n      \n    \n    {\\displaystyle \\mathrm {VBN_{Blend}} =\\left(x_{\\mathrm {A} }\\times \\mathrm {VBN_{A}} \\right)+\\left(x_{\\mathrm {B} }\\times \\mathrm {VBN_{B}} \\right)+\\cdots +\\left(x_{\\mathrm {N} }\\times \\mathrm {VBN_{N}} \\right)\\,}\n     (2)where xX is the mass fraction of each component of the blend.\nOnce the viscosity blending number of a blend has been calculated using equation (2), the final step is to determine the kinematic viscosity of the blend by solving equation (1) for \u03bd:\n\n  \n    \n      \n        \u03bd\n        =\n        exp\n        \u2061\n        \n          (\n          \n            exp\n            \u2061\n            \n              (\n              \n                \n                  \n                    \n                      V\n                      B\n                      \n                        N\n                        \n                          B\n                          l\n                          e\n                          n\n                          d\n                        \n                      \n                    \n                    \u2212\n                    10.975\n                  \n                  14.534\n                \n              \n              )\n            \n          \n          )\n        \n        \u2212\n        0.8\n        ,\n      \n    \n    {\\displaystyle \\nu =\\exp \\left(\\exp \\left({\\frac {\\mathrm {VBN_{Blend}} -10.975}{14.534}}\\right)\\right)-0.8,}\n     (3)where VBNBlend is the viscosity blending number of the blend.\nalternatively use the more accurate Lederer-Roegiers equation [1]\n\n  \n    \n      \n        ln\n        \u2061\n        \n          \u03b7\n          \n            1\n            ,\n            2\n          \n        \n        =\n        \n          \n            \n              \n                x\n                \n                  1\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  1\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n        +\n        \n          \n            \n              \u03b2\n              \n                x\n                \n                  2\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  2\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n      \n    \n    {\\displaystyle \\ln \\eta _{1,2}={\\frac {x_{1}\\ln \\eta _{1}}{x_{1}+x_{2}\\beta }}+{\\frac {\\beta x_{2}\\ln \\eta _{2}}{x_{1}+x_{2}\\beta }}}\n  \n\n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   is based on the difference in intermolecular cohesion energies between the liquids\n\n  \n    \n      \n        \u03b7\n      \n    \n    {\\displaystyle \\eta }\n  =dynamic viscosity\n\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  =mole fraction of particle species \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\n\n== Slurry ==\n\nThe term slurry describes mixtures of a liquid and solid particles that retain some fluidity. The viscosity of slurry can be described as relative to the viscosity of the liquid phase:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n        =\n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        \n          \u03bc\n          \n            \n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {s} }=\\mu _{\\mathrm {r} }\\mu _{\\mathrm {l} },}\n  where \u03bcs and \u03bcl are respectively the dynamic viscosity of the slurry and liquid (Pa\u00b7s), and \u03bcr is the relative viscosity (dimensionless).\nDepending on the size and concentration of the solid particles, several models exist that describe the relative viscosity as a function of volume fraction \u03c6 of solid particles.\nIn the case of extremely low concentrations of fine particles, Einstein's equation may be used:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi }\n  In the case of higher concentrations, a modified equation was proposed by Guth and Simha, which takes into account interaction between the solid particles:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        14.1\n        \n          \u03c6\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +14.1\\varphi ^{2}}\n  Further modification of this equation was proposed by Thomas from the fitting of empirical data:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        10.05\n        \n          \u03c6\n          \n            2\n          \n        \n        +\n        A\n        \n          e\n          \n            B\n            \u03c6\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +10.05\\varphi ^{2}+Ae^{B\\varphi },}\n  where A = 0.00273 and B = 16.6.\nIn the case of high shear stress (above 1 kPa), another empirical equation was proposed by Kitano et al. for polymer melts:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            (\n            \n              1\n              \u2212\n              \n                \n                  \u03c6\n                  A\n                \n              \n            \n            )\n          \n          \n            \u2212\n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=\\left(1-{\\frac {\\varphi }{A}}\\right)^{-2},}\n  where A = 0.68 for smooth spherical particles.\n\n\n== Nanofluids ==\n\nNanofluid is a novel class of fluid, which is developed by dispersing nano-sized particles in base fluid.Einstein model\nEinstein derived the applicable first theoretical formula for the estimation of viscosity values of composites or mixtures in 1906. This model developed while assuming linear viscous fluid including suspensions of rigid and spherical particles. Einstein\u2019s model is valid for very low volume fraction \n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n  .\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing )}\n  \nBrinkman model\nBrinkman modified Einstein\u2019s model for used with average particle volume fraction up to 4%\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        \n          \n            1\n            \n               \n              (\n              1\n              \u2212\n              \u2205\n              \n                )\n                \n                  2.5\n                \n              \n            \n          \n        \n        \n          \n            )\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \u2205\n        +\n        4.375\n        \n          \u2205\n          \n            2\n          \n        \n        +\n        O\n        (\n        \n          \u2205\n          \n            3\n          \n        \n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}{\\frac {1}{\\ (1-\\varnothing )^{2.5}}}{\\Biggr )}=\\mu _{bf}{\\Big (}1+2.5\\varnothing +4.375\\varnothing ^{2}+O(\\varnothing ^{3}){\\Big )}}\n  \nBatchelor model\nBatchelor reformed Einstein's theoretical model by presenting Brownian motion effect.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        +\n        6.5\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing +6.5{\\varnothing }^{2})}\n  \nWang et al. model\nWang et al. found a model to predict viscosity of nanofluid as follows.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        7.3\n        \u2205\n        +\n        123\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+7.3\\varnothing +123{\\varnothing }^{2})}\n  \nMasoumi et al. model\nMasoumi et al. suggested a new viscosity correlation by considering Brownian motion of nanoparticle in nanofluid.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              C\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta C}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                18\n                \n                  K\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                \n                  \u03c1\n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle V_{B}={\\sqrt {\\frac {18K_{B}T}{\\pi \\rho _{p}{d_{p}}^{3}}}}}\n  \n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                \u03c0\n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n              \n                6\n                \u2205\n              \n            \n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\sqrt[{3}]{\\frac {\\pi {d_{p}}^{3}}{6\\varnothing }}}}\n  \n\n  \n    \n      \n        C\n        =\n        {\n        \n          (\n          \u2212\n          1.133\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          2.771\n          )\n          \u2205\n          +\n          (\n          0.09\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          0.393\n          )\n        \n        }\n        \u00d7\n        \n          10\n          \n            \u2212\n            6\n          \n        \n      \n    \n    {\\displaystyle C=\\{{(-1.133d_{p}-2.771)\\varnothing +(0.09d_{p}-0.393)}\\}\\times 10^{-6}}\n  \nUdawattha et al. model\nUdawattha et al. modified the Masoumi et al. model. The developed model valid for suspension containing micro-size particles.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \n          \u2205\n          \n            e\n          \n        \n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              [\n              T\n              \u00d7\n              \n                10\n                \n                  \u2212\n                  10\n                \n              \n              \u00d7\n              \n                \u2205\n                \n                  \u2212\n                  0.002\n                  T\n                  \u2212\n                  0.284\n                \n              \n              ]\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+2.5\\varnothing _{e}+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta [T\\times 10^{-10}\\times \\varnothing ^{-0.002T-0.284}]}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          \u2205\n          \n            e\n          \n        \n        =\n        \u2205\n        \n          \n            \n              \n                (\n              \n            \n            1\n            +\n            \n              \n                h\n                r\n              \n            \n            \n              \n                )\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\varnothing _{e}=\\varnothing {{\\Biggl (}1+{\\frac {h}{r}}{\\Biggr )}}^{3}}\n  \nwhere\n\n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the viscosity of the sample, in [Pa\u00b7s]\n\n  \n    \n      \n        n\n        f\n      \n    \n    {\\displaystyle nf}\n   is nanofluid\n\n  \n    \n      \n        b\n        f\n      \n    \n    {\\displaystyle bf}\n   is basefluid\n\n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   is particle\n\n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n   is volume fraction\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is density of the sample, in [kg\u00b7m\u22123]\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is distance between two particles\n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle V_{B}}\n   is Brownian motion of particle\n\n  \n    \n      \n        \n          K\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle K_{B}}\n   is the Boltzmann constant\n\n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   is Temperature of the sample, in [K]\n\n  \n    \n      \n        \n          d\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle d_{p}}\n   is diameter of a particle\n\n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is nanolayer thickness (1 nm)\n\n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is radius of a particle\n\n\n== Amorphous materials ==\n\nViscous flow in amorphous materials (e.g. in glasses and melts) is a thermally activated process:\n\n  \n    \n      \n        \u03bc\n        =\n        A\n        \n          e\n          \n            \n              Q\n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =Ae^{\\frac {Q}{RT}},}\n  where Q is activation energy, T is temperature, R is the molar gas constant and A is approximately a constant.\nThe viscous flow in amorphous materials is characterized by a deviation from the Arrhenius-type behavior: Q changes from a high value QH at low temperatures (in the glassy state) to a low value QL at high temperatures (in the liquid state). Depending on this change, amorphous materials are classified as either\n\nstrong when: QH \u2212 QL < QL or\nfragile when: QH \u2212 QL \u2265 QL.The fragility of amorphous materials is numerically characterized by Doremus' fragility ratio:\n\n  \n    \n      \n        \n          R\n          \n            \n              D\n            \n          \n        \n        =\n        \n          \n            \n              Q\n              \n                \n                  H\n                \n              \n            \n            \n              Q\n              \n                \n                  L\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R_{\\mathrm {D} }={\\frac {Q_{\\mathrm {H} }}{Q_{\\mathrm {L} }}}}\n  and strong materials have RD < 2 whereas fragile materials have RD \u2265 2.\n\nThe viscosity of amorphous materials is quite exactly described by a two-exponential equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            1\n          \n        \n        T\n        \n          (\n          \n            1\n            +\n            \n              A\n              \n                2\n              \n            \n            \n              e\n              \n                \n                  B\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        \n          (\n          \n            1\n            +\n            C\n            \n              e\n              \n                \n                  D\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{1}T\\left(1+A_{2}e^{\\frac {B}{RT}}\\right)\\left(1+Ce^{\\frac {D}{RT}}\\right),}\n  with constants A1, A2, B, C and D related to thermodynamic parameters of joining bonds of an amorphous material.\nNot very far from the glass transition temperature, Tg, this equation can be approximated by a Vogel\u2013Fulcher\u2013Tammann (VFT) equation.\nIf the temperature is significantly lower than the glass transition temperature, T \u226a Tg, then the two-exponential equation simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              L\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    H\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {L} }Te^{\\frac {Q_{\\mathrm {H} }}{RT}}}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              H\n            \n          \n        \n        =\n        \n          H\n          \n            \n              d\n            \n          \n        \n        +\n        \n          H\n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle Q_{\\mathrm {H} }=H_{\\mathrm {d} }+H_{\\mathrm {m} },}\n  where Hd is the enthalpy of formation of broken bonds (termed configurons) and Hm is the enthalpy of their motion.\nWhen the temperature is less than the glass transition temperature, T < Tg, the activation energy of viscosity is high because the amorphous materials are in the glassy state and most of their joining bonds are intact.\nIf the temperature is much higher than the glass transition temperature, T \u226b Tg, the two-exponential equation also simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              H\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    L\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {H} }Te^{\\frac {Q_{\\mathrm {L} }}{RT}},}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              L\n            \n          \n        \n        =\n        \n          H\n          \n            \n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Q_{\\mathrm {L} }=H_{\\mathrm {m} }.}\n  When the temperature is higher than the glass transition temperature, T > Tg, the activation energy of viscosity is low because amorphous materials are melted and have most of their joining bonds broken, which facilitates flow.\n\n\n== Eddy viscosity ==\nIn the study of turbulence in fluids, a common practical strategy for calculation is to ignore the small-scale vortices (or eddies) in the motion and to calculate a large-scale motion with an eddy viscosity that characterizes the transport and dissipation of energy in the smaller-scale flow (see large eddy simulation). Values of eddy viscosity used in modeling ocean circulation may be from 5\u00d7104 to 1\u00d7106 Pa\u00b7s depending upon the resolution of the numerical grid.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nHatschek, Emil (1928). The Viscosity of Liquids. New York: Van Nostrand. OCLC 53438464.\nMassey, B. S.; Ward-Smith, A. J. (2011). Mechanics of Fluids (9th ed.). London & New York: Spon Press. ISBN 978-0-415-60259-4. OCLC 690084654.\n\n\n== External links ==\nFluid properties - high accuracy calculation of viscosity for frequently encountered pure liquids and gases\nGas viscosity calculator as function of temperature\nAir viscosity calculator as function of temperature and pressure\nFluid Characteristics Chart - a table of viscosities and vapor pressures for various fluids\nGas Dynamics Toolbox - calculate coefficient of viscosity for mixtures of gases\nGlass Viscosity Measurement - viscosity measurement, viscosity units and fixpoints, glass viscosity calculation\nKinematic Viscosity - conversion between kinematic and dynamic viscosity\nPhysical Characteristics of Water - a table of water viscosity as a function of temperature\nVogel\u2013Tammann\u2013Fulcher Equation Parameters\nCalculation of temperature-dependent dynamic viscosities for some common components\n\"Test Procedures for Testing Highway and Nonroad Engines and Omnibus Technical Amendments\" - United States Environmental Protection Agency\nArtificial viscosity\nViscosity of Air, Dynamic and Kinematic, Engineers Edge",
        "unit": "kinematic viscosity",
        "url": "https://en.wikipedia.org/wiki/Viscosity"
    },
    {
        "_id": "Foot_(unit)",
        "clean": "Foot (unit)",
        "text": "The foot (pl. feet; abbreviation: ft; symbol: \u2032, the prime symbol) is a unit of length in the imperial and US customary systems of measurement. Since 1959, both units have been defined by international agreement as equivalent to 0.3048 meters exactly. In both systems, the foot comprises 12 inches and three feet compose a yard.\nHistorically the \"foot\" was a part of many local systems of units, including the Greek, Roman, Chinese, French, and English systems. It varied in length from country to country, from city to city, and sometimes from trade to trade. Its length was usually between 250 mm and 335 mm and was generally, but not always, subdivided into 12 inches or 16 digits.\nThe United States is the only industrialized nation that uses the international foot and the survey foot (a customary unit of length) in preference to the meter in its commercial, engineering, and standards activities. The foot is legally recognized in the United Kingdom; road signs must use imperial units (however distances on road signs are always marked in miles or yards, not feet), while its usage is widespread among the British public as a measurement of height. The foot is recognized as an alternative expression of length in Canada officially defined as a unit derived from the meter although both the U.K. and Canada have partially metricated their units of measurement. The measurement of altitude in international aviation is one of the few areas where the foot is used outside the English-speaking world.\nThe length of the international foot corresponds to a human foot with shoe size of 13 (UK), 14 (US male), 15.5 (US female) or 46 (EU sizing).\n\n\n== Historical origin ==\n\nHistorically the human body has been used to provide the basis for units of length. The foot of a white male is typically about 15.3% of his height, giving a person of 160 centimetres (5 ft 3 in) a foot of 245 millimetres (9.6 in) and one of 180 centimetres (5 ft 11 in) a foot of 275 millimetres (10.8 in).\nArcheologists believe that the Egyptians, Ancient Indians and Mesopotamians preferred the cubit while the Romans and the Greeks preferred the foot. Under the Harappan linear measures, Indus cities during the Bronze Age used a foot of 13.2 inches (340 mm) and a cubit of 20.8 inches (530 mm). The Egyptian equivalent of the foot\u2014a measure of four palms or 16 digits\u2014was known as the djeser and has been reconstructed as about 30 cm (12 in).\nThe Greek foot (\u03c0\u03bf\u03cd\u03c2, pous) had a length of \u200b1\u2044600 of a stadion, one stadion being about 181.2 m, therefore a foot being at the time about 302 mm. Its exact size varied from city to city and could range as much as between 270 mm and 350 mm, but lengths used for temple construction appear to have been about 295 mm to 325 mm, the former being close to the size of the Roman foot.\nThe standard Roman foot (pes) was normally about 295.7 mm (97% of today's measurement), but in the provinces, the pes Drusianus (foot of Nero Claudius Drusus) was used, with a length of about 334 mm. (In reality, this foot predated Drusus.)Originally both the Greeks and the Romans subdivided the foot into 16 digits, but in later years, the Romans also subdivided the foot into 12 unciae (from which both the English words \"inch\" and \"ounce\" are derived).\nAfter the fall of the Roman Empire, some Roman traditions were continued but others fell into disuse. In AD 790 Charlemagne attempted to reform the units of measure in his domains. His units of length were based on the toise and in particular the toise de l'\u00c9critoire, the distance between the fingertips of the outstretched arms of a man. The toise has 6 pieds (feet) each of 326.6 mm (12.86 in).\nHe was unsuccessful in introducing a standard unit of length throughout his realm: an analysis of the measurements of Charlieu Abbey shows that during the 9th century the Roman foot of 296.1 mm was used; when it was rebuilt in the 10th century, a foot of about 320 mm was used. At the same time, monastic buildings used the Carolingian foot of 340 mm.The procedure for verification of the foot as described in the 16th century by Jacob Koebel in his book Geometrei. Von k\u00fcnstlichem Feldmessen und absehen is:\nStand at the door of a church on a Sunday and bid 16 men to stop, tall ones and small ones, as they happen to pass out when the service is finished; then make them put their left feet one behind the other, and the length thus obtained shall be a right and lawful rood to measure and survey the land with, and the 16th part of it shall be the right and lawful foot.\n\n\n=== England ===\n\nThe measures of Iron Age Britain are uncertain and proposed reconstructions such as the Megalithic Yard are controversial. Later Welsh legend credited Dyfnwal Moelmud with the establishment of their units, including a foot of 9 inches. The Belgic or North German foot of 335 mm (13.2 inches) was introduced to England either by the Belgic Celts during their invasions prior to the Romans or by the Anglo-Saxons in the 5th and 6th century.\nRoman units were introduced following their invasion in AD 43. The Roman foot had been previously standardized by Agrippa at around 296 mm or 11.65 inches. Following the Roman withdrawal and Saxon invasions, the Roman foot continued to be used in the construction crafts while the Belgic foot was used for land measurement. Both the Welsh and Belgic feet seem to have been based on multiples of the barleycorn, but by as early as 950 the English kings seem to have (ineffectually) ordered measures to be based upon an iron yardstick at Winchester and then London. Henry I was said to have ordered a new standard to be based upon his own arm and, by the c.\u20091300 Act concerning the Composition of Yards and Perches traditionally credited to Edward I or II, the statute foot was a different measure exactly \u200b10\u204411 of the old foot. The barleycorn, inch, ell, and yard were likewise shrunk, while rods and furlongs remained the same. The ambiguity over the state of the mile was resolved by the 1593 Act against Converting of Great Houses into Several Tenements and for Restraint of Inmates and Inclosures in and near about the City of London and Westminster, which codified the statute mile as comprising 5,280 feet. The differences among the various physical standard yards around the world, revealed by increasingly powerful microscopes, eventually led to the 1959 adoption of the international foot defined in terms of the meter.\n\n\n== Definition ==\n\n\n=== International foot ===\nThe international yard and pound agreement of July 1959 defined the length of the international yard in the United States and countries of the Commonwealth of Nations as exactly 0.9144 meters. Consequently, the international foot is defined to be equal to exactly 0.3048 meters. This was 2 ppm shorter than the previous U.S. definition and 1.7 ppm longer than the previous British definition.The international standard symbol for a foot is \"ft\" (see ISO 31-1, Annex A). In some cases, the foot is denoted by a prime, which is often marked by an apostrophe, and the inch by a double prime; for example, 2 feet 4 inches is sometimes denoted as 2\u2032\u22124\u2033, 2\u2032 4\u2033 or 2\u20324\u2033.  (See 'minute' for another case where prime and double prime symbols are used to denote first and second cuts in refining measurement.)\n\n\n=== Pre-1959 ===\nIn the United States, the foot was defined as 12 inches, with the inch being defined by the Mendenhall Order of 1893 by 39.37 inches = 1 m. In Imperial units, the foot was defined as \u200b1\u20443 yard, with the yard being realized as a physical standard (separate from the standard meter).\nThe yard standards of the different Commonwealth countries were periodically compared with one another. The value of the United Kingdom primary standard of the yard was determined in terms of the meter by the National Physical Laboratory in 1964 as 0.9143969 m, implying a pre-1959 foot in the UK of approximately 0.304798966667 m.\n\n\n=== Survey foot ===\nWhen the international foot was defined in 1959, a great deal of survey data was already available based on the former definitions, especially in the United States and in India. The small difference between the survey and the international foot would not be detectable on a survey of a small parcel, but becomes significant for mapping, or when the state plane coordinate system (SPCS) is used in the US, because the origin of the system may be hundreds of thousands of feet (hundreds of miles) from the point of interest. Hence the previous definitions continued to be used for surveying in the United States and India for many years, and are denoted survey feet to distinguish them from the international foot. The United Kingdom was unaffected by this problem, as the retriangulation of Great Britain (1936\u201362) had been done in meters.\n\n\n==== US survey foot ====\nThe United States survey foot is defined as exactly \u200b1200\u20443937 meters, approximately 0.304800609601 m. \nOut of the 50 states, 24 have legislated that surveying measures should be based on the U.S. survey foot, eight have legislated that they be made on the basis of the international foot, and 18 have not specified the conversion factor from metric units.In 1986 the National Geodetic Survey (NGS) released the North American Datum of 1983, which underlies the state plane coordinate systems and is entirely defined in meters. An NGS policy from 1991 has this to say about the units used with the new datum to define the SPCS 83:\n\nIn preparation for the adjustment of the North American Datum of 1983, 31 states enacted legislation for the State Plane Coordinate System of 1983 (SPCS 83). All states defined SPCS 83 with metric parameters. Within the legislation, the U.S. Survey Foot was specified in 11 states and the International Foot was specified in 6 states. In all other states the meter is the only referenced unit of measure in the SPCS 83 legislation. The remaining 19 states do not yet have any legislation concerning SPCS 83.\nSince then, 42 states have abandoned the non-metric versions of SPCS 83: seven states continue to keep location data in survey feet as well as in meters, while one state keeps data in international feet as well as in meters. State legislation is also important for determining the conversion factor to be used for everyday land surveying and real estate transactions, although the difference (2 ppm) is of no practical significance given the precision of normal surveying measurements over short distances (usually much less than a mile).\n\n\n==== Indian survey foot ====\nThe Indian survey foot is defined as exactly 0.3047996 m, presumably derived from a measurement of the previous Indian standard of the yard. The current National Topographic Database of the Survey of India is based on the metric WGS-84 datum, which is also used by the Global Positioning System.\n\n\n== Historical use ==\n\n\n=== Metric foot ===\nAn ISO 2848 measure of 3 basic modules (30 cm) is called a \"metric foot\", but there were earlier distinct definitions of a metric foot during metrication in France and Germany.\n\n\n==== France ====\nIn 1799 the meter became the official unit of length in France. This was not fully enforced, and in 1812 Napoleon introduced the system of mesures usuelles which restored the traditional French measurements in the retail trade, but redefined them in terms of metric units. The foot, or pied m\u00e9trique, was defined as one third of a meter. This unit continued in use until 1837.\n\n\n==== Germany ====\nIn southwestern Germany in 1806, the Confederation of the Rhine was founded and three different reformed feet were defined, all of which were based on the metric system:\nIn Hesse, the Fu\u00df (foot) was redefined as 25 cm.\nIn Baden, the Fu\u00df was redefined as 30 cm.\nIn the Palatinate, the Fu\u00df was redefined as being \u200b33 1\u20443 cm (as in France).\n\n\n=== Other obsolete feet ===\nPrior to the introduction of the metric system, many European cities and countries used the foot, but it varied considerably in length: the voet in Ieper, Belgium, was 273.8 millimetres (10.78 in) while the piede in Venice was 347.73 millimetres (13.690 in). Lists of conversion factors between the various units of measure were given in many European reference works including:\n\nTrait\u00e9, Paris \u2013 1769\nPalaiseau \u2013 Bordeaux: 1816 \nde Gelder, Amsterdam and The Hague \u2013 1824\nHorace, Brussels \u2013 1840\nNoback & Noback (2 volumes), Leipzig \u2013 1851\nBruhns, Leipzig \u2013 1881Many of these standards were peculiar to a particular city, especially in Germany (which, before German Unification in 1871, consisted of many kingdoms, principalities, free cities and so on). In many cases the length of the unit was not uniquely fixed: for example, the English foot was stated as 11 pouces 2.6 lignes (French inches and lines) by Picard, 11 pouces 3.11 lignes by Maskelyne and 11 pouces 3 lignes by D'Alembert.Most of the various feet in this list ceased to be used when the countries adopted the metric system. The Netherlands and modern Belgium adopted the metric system in 1817, having used the mesures usuelles under Napoleon and the newly formed German Empire adopted the metric system in 1871.The palm (typically 200 mm to 280 mm) was used in many Mediterranean cities instead of the foot. Horace Doursther, whose reference was published in Belgium which had the smallest foot measurements, grouped both units together, while J.F.G. Palaiseau devoted three chapters to units of length: one for linear measures (palms and feet), one for cloth measures (ells) and one for distances traveled (miles and leagues). In the table below, arbitrary cut-off points of 270 mm and 350 mm have been chosen.\n\n(In Belgium, the words pied (French) and voet (Dutch) would have been used interchangeably.)\nNotes\n\n\n== See also ==\nAnthropic units\nEnglish units\nMermin's foot\nMetric foot\nHistory of measurement\nImperial units\nInternational System of Units\nPous\nSystems of measurement\nUnited States customary units\nUnits of measurement\nKorean units of measurement\n\n\n== Notes ==\n\n\n== References ==",
        "unit": "foot",
        "url": "https://en.wikipedia.org/wiki/Foot_(unit)"
    },
    {
        "_id": "Dime_(United_States_coin)",
        "clean": "Dime (United States coin)",
        "text": "The dime, in U.S. usage, is a ten-cent coin, one tenth of a United States dollar, labeled formally as \"one dime\". The denomination was first authorized by the Coinage Act of 1792. The dime is the smallest in diameter and is the thinnest of all U.S. coins currently minted for circulation, being .705 inches (17.91 mm) in diameter and .053 inches (1.35 mm) in thickness. The obverse of the coin depicts the profile of President Franklin D. Roosevelt and the reverse boasts an olive branch, a torch, and an oak branch, from left to right respectively. As of 2011, the dime coin cost 5.65 cents to produce.The word dime comes from the French word d\u00eeme, meaning \"tithe\" or \"tenth part\", from the Latin decima [pars]. In the past prices have occasionally been quoted on signage and other materials in terms of dimes, abbreviated as \"d\" or a lowercase \"d\" with a slash through it (\u20ab) as with the cent and mill signs.\n\n\n== History ==\nThe Coinage Act of 1792 established the dime (spelled \"disme\" in the legislation), cent, and mill. as subdivisions of the dollar equal to \u200b1\u204410, \u200b1\u2044100 and \u200b1\u20441000 dollar respectively.\nThe first known proposal for a decimal-based coinage system in the United States was made in 1783 by Thomas Jefferson, Benjamin Franklin, Alexander Hamilton, and David Rittenhouse. Hamilton, the nation's first Secretary of the Treasury, recommended the issuance of six such coins in 1791, in a report to Congress. Among the six was a silver coin, \"which shall be, in weight and value, one tenth part of a silver unit or dollar\".\nFrom 1796 to 1837, dimes were composed of 89.24% silver and 10.76% copper, the value of which required the coins to be physically very small to prevent their intrinsic value being worth more than face value. Thus dimes are made small and thin. The silver percentage was increased to 90.0% with the introduction of the Seated Liberty dime; the use of a richer alloy was offset by reducing the diameter from 18.8 millimeters (0.740 inch) to its current figure of 17.9 millimeters (0.705 inch).With the passage of the Coinage Act of 1965, the dime's silver content was removed. Dimes from 1965 to the present are composed of outer layers of 75% copper and 25% nickel, bonded to a pure copper core. Starting in 1992, the U.S. Mint began issuing Silver Proof Sets annually, which contain dimes composed of the pre-1965 standard of 90% silver and 10% copper. These sets are intended solely for collectors, and are not meant for general circulation.\n\n\n== Design history ==\nSince its introduction in 1796, the dime has been issued in six different major types, excluding the 1792 \"disme\". The name for each type (except for the Barber dime) indicates the design on the coin's obverse.\n\nDraped Bust 1796\u20131807\nCapped Bust 1809\u20131837\nSeated Liberty 1837\u20131891\nBarber 1892\u20131916\nWinged Liberty Head (Mercury) 1916\u20131945\nRoosevelt 1946\u2013present\n\n\n=== \"Disme\" (1792) ===\n\nThe Coinage Act of 1792, passed on April 2, 1792, authorized the mintage of a \"disme\", one-tenth the silver weight and value of a dollar. The composition of the disme was set at 89.24% silver and 10.76% copper. In 1792, a limited number of dismes were minted but never circulated. Some of these were struck in copper, indicating that the 1792 dismes were in fact pattern coins. The first dimes minted for circulation did not appear until 1796, due to a lack of demand for the coin and production problems at the United States Mint.\n\n\n=== Draped Bust (1796\u20131807) ===\n\nThe first dime to be circulated was the Draped Bust dime, in 1796. It featured the same obverse and reverse as all other circulating coins of the time, the so-called Draped Bust/Small Eagle design. This design was the work of then-Chief Engraver Robert Scot. The portrait of Liberty on the obverse was based on a Gilbert Stuart drawing of prominent Philadelphia socialite Ann Willing Bingham, wife of noted American statesman William Bingham. The reverse design is of a small bald eagle surrounded by palm and olive branches, and perched on a cloud. Since the Coinage Act of 1792 required only that the cent and half cent display their denomination, Draped Bust dimes were minted with no indication of their value.All 1796 dimes have 15 stars on the obverse, representing the number of U.S. states then in the Union. The first 1797 dimes were minted with 16 stars, reflecting Tennessee's admission as the 16th state. Realizing that the practice of adding one star per state could quickly clutter the coin's design, U.S. Mint Director Elias Boudinot ordered a design alteration, to feature just 13 stars (for the original Thirteen Colonies). Therefore, 1797 dimes can be found with either 13 or 16 stars.Also designed by Robert Scot, the Heraldic Eagle reverse design made its debut in 1798. The obverse continued from the previous series, but the eagle on the reverse was changed from the widely criticized \"scrawny\" hatchling to a scaled-down version of the Great Seal of the United States. The Draped Bust/Heraldic Eagles series continued through 1807 (although no dimes dated 1799 or 1806 were minted). Both Draped Bust designs were composed of 89.24% silver and 10.76% copper. In all, there are 31 varieties of Draped Bust dimes.\n\n\n=== Capped Bust (1809\u20131837) ===\n\nThe Draped Bust design was succeeded by the Capped Bust, designed by Mint Assistant Engraver John Reich. Both the obverse and reverse were changed extensively. The new reverse featured a bald eagle grasping three arrows (symbolizing strength) and an olive branch (symbolizing peace). Covering the eagle's breast is a U.S. shield with six horizontal lines and 13 vertical stripes. Also on the reverse is the lettering \"10C,\" making it the only dime minted with the value given in cents (subsequent issues are inscribed with the words \"ONE DIME\"). The lack of numeric value markings on subsequent dime coins causes some confusion amongst foreign visitors, who may be unaware of the value of the coin. Also, the Capped Bust dime was the first dime to have its value written on the coin. Previous designs of the dime had no indication of its value, the way people determined its value was by its sizeCapped Bust dimes minted through 1828 are known as the Large type. This is partially because they were struck without a restraining collar, which gave them a broader appearance. In 1828, Chief Engraver William Kneass introduced the close collar method of coining (which automated the process of placing reeds on a coin's edge). In addition to standardizing the diameter of coins, the new method allowed the Mint to produce thicker coins. To maintain a standard weight and alloy, the diameter of most coins was reduced. In particular, the dime was reduced in diameter from 18.8 to 18.5 millimeters. This new Capped Bust dime, which began production in 1828, is known as the Small type. There are 123 varieties known of Capped Bust Dimes.\n\n\n=== Seated Liberty (1837\u20131891) ===\n\nChristian Gobrecht completed the design of the Seated Liberty dime, whose obverse was used with every circulating silver U.S. coin of the period. Mint Director Robert Maskell Patterson requested a new coin design, to be reminiscent of the Britannia image found on coinage of the United Kingdom. Chief Engraver William Kneass drew the original sketches, but suffered a stroke and was too ill to finish them or to oversee preparation of the dies. The task then fell to Gobrecht, who was promoted to Second Engraver.The obverse features an image of Liberty sitting on a rock, wearing a dress and holding a staff with a liberty cap on top. Her right hand is balancing a shield with the inscription \"LIBERTY.\" The reverse featured the inscription \"ONE DIME,\" surrounded by a wreath. All Seated Liberty dimes contain 90% silver and 10% copper, and are 17.9 millimeters (0.705 inch) in diameter. This size and metal composition would continue until 1965, when silver was permanently removed from circulating dimes.There were several minor varieties during the Seated Liberty's run. The initial design (1837) had no stars on the obverse and, further, the dates were minted in a Large Date and Small Date variety. These two types can be distinguished by noting the \"3\" and the \"7\" in the date. In the Large Date variety, the \"3\" has a pointed serif at top, and the horizontal element of the \"7\" is straight. In the Small Date variety, the \"3\" has a rounded serif, and there is small a knob, or bulge, in the \"7\" horizontal element. Only the Philadelphia Mint made both varieties. The Small Date is slightly rarer. The New Orleans Mint also made the Seated Liberty Dime in this year, but only in the Small Date variety.Thirteen stars (symbolizing the 13 original colonies) were added to the perimeter of the obverse in 1838. These were replaced with the legend \"United States of America,\" which was moved from the reverse in mid-1860. At the same time, the laurel wreath on the reverse was changed to a wreath of corn, wheat, maple, and oak leaves and expanded nearly to the rim of the coin. This reverse design continued through the end of the series in 1891 and was changed only slightly in 1892, when the Barber dime debuted. Another variety is the 1838\u201340 dime minted with no drapery underneath the left elbow of Liberty.\n\nArrows at the date in 1853 and 1873 indicated changes made in the coin's mass (from 2.67 grams to 2.49 grams in 1853, then to 2.50 grams in 1873). The first change was made in response to rising silver prices, while the latter alteration was brought about by the Mint Act of 1873 which, in an attempt to make U.S. coinage the currency of the world, added a small amount of mass to the dime, quarter, and half-dollar to bring their weights in line with fractions of the French 5-franc piece. The change also ensured the quarter dollar (which is valued 2.5 times the dime) weighed 2.5 times the dime (6.25g), and the half dollar (twice the value of the quarter dollar) weighed twice what the quarter dollar weighed (12.5g). In this way, a specific weight of these coins, no matter the mixture of denominations, would always be worth the same. This relation in weight and value continued in the cupronickel coins from 1965 on.\nThis produced the greatest rarities in the Seated Dime Series, the 1873 & 1874 Carson City Dimes, with arrows and the unique 1873 Carson City Dime without arrows.\n\n\n=== Barber (1892\u20131916) ===\n\nThe Barber dime is named for its designer, Charles E. Barber, who was Chief Engraver of the U.S. Mint from 1879 to 1917. The design was shared with the quarter and half-dollar of the same period. Extensive internal politics surrounded the awarding of the design job, which had initially been opened to the public. A four-member committee (which included Barber), appointed by then-Mint Director James Kimball, accorded only two of more than 300 submissions an honorable mention. Kimball's successor, Edward O. Leech, decided to dispense with the committees and public design competitions and simply instructed Barber to develop a new design. It has been speculated that this is what Barber had wanted all along.The Barber dime, as with all previous dimes, featured an image of Liberty on the obverse. She is wearing a Phrygian cap, a laurel wreath with a ribbon, and a headband with the inscription \"LIBERTY\". This inscription is one of the key elements used in determining the condition of Barber dimes. Liberty's portrait was inspired by two sources\u2014French coins and medals of the period, as well as ancient Greek and Roman sculpture. The obverse also contains the long-used 13 stars (for the 13 colonies) design element. The reverse contained a wreath and inscription almost identical to the one used on the final design of the Seated Liberty dime. Dimes were produced at all four of the mints that operated during the period. While circulated coins of the entire series are readily available to collectors there is one outstanding rarity, the 1894-S Barber Dime. Twenty-four were minted, with 9 currently known.\n\n\n=== Winged Liberty Head (\"Mercury\") (1916\u20131945) ===\n\nAlthough most commonly referred to as the \"Mercury\" dime, the Winged Liberty Head does not depict the Roman messenger god. The obverse figure is a depiction of the mythological goddess Liberty wearing a Phrygian cap, a classic Western symbol of liberty and freedom, with its wings intended to symbolize freedom of thought. Designed by noted sculptor Adolph A. Weinman, the Winged Liberty Head dime is considered by many to be one of the most beautiful U.S. coin designs ever produced. The composition (90% silver, 10% copper) and diameter (17.9 millimeters) of the \"Mercury\" dime was unchanged from the Barber dime.\nWeinman (who had studied under Augustus Saint-Gaudens) won a 1915 competition against two other artists for the design job, and is thought to have modeled his version of Liberty on Elsie Kachel Stevens, wife of noted poet Wallace Stevens. The reverse design, a fasces juxtaposed with an olive branch, was intended to symbolize America's readiness for war, combined with its desire for peace. Although the fasces was later officially adopted by Benito Mussolini and his National Fascist Party, the symbol was also common in American iconography and has generally avoided any stigma associated with its usage in wartime Italy.The 1916-D issue of only 264,000 coins is highly sought after, due largely to the fact that the overwhelming majority of the dimes struck at the Denver Mint in 1916 carried the pre-existing Barber design. Thus, the 1916-D is worth up to thousands of dollars if it is in relatively fine condition. A considerable number of common 1916 Philadelphia mint dimes have been altered with a \"D\" added, so buyers should be careful to purchase only from reputable dealers or to accept only sealed and graded coins. Be aware that any dimes that bear the date \"1922\" are counterfeit. Having possession of a counterfeit coin is illegal and can lead to its forfeiture.Many coins in the \"Mercury\" series exhibit striking defects, most notably the fact that the line separating the two horizontal bands in the center of the fasces is often missing, in whole or in part; the 1945 issue of the Philadelphia Mint hardly ever appears with this line complete from left to right, and as a result, such coins (designated as \"FSB\" for \"full split bands\") are worth more than usual for uncirculated specimens. A valuable variety is an overdate, where 1942 was stamped over a 1941 die at the Philadelphia mint. A less obvious, but still quite valuable, example from the same year is from the Denver mint.\n\n\n=== Franklin D. Roosevelt (1946\u2013present) ===\n\nSoon after the death of President Franklin D. Roosevelt in 1945, legislation was introduced by Virginia Congressman Ralph H. Daughton that called for the replacement of the Mercury dime with one bearing Roosevelt's image. The dime was chosen to honor Roosevelt partly due to his efforts in the founding of the National Foundation for Infantile Paralysis (later renamed the March of Dimes), which originally raised money for polio research and to aid victims of the disease and their families.Due to the limited amount of time available to design the new coin, the Roosevelt dime was the first regular-issue U.S. coin designed by a Mint employee in more than 40 years. Chief Engraver John R. Sinnock was chosen, as he had already designed a Mint presidential medal of Roosevelt. Sinnock's first design, submitted on October 12, 1945, was rejected, but a subsequent one was accepted on January 6, 1946. The dime was released to the public on January 30, 1946, which would have been Roosevelt's 64th birthday. Sinnock's design placed his initials (\"JS\") at the base of Roosevelt's neck, on the coin's obverse. His reverse design elements of a torch, olive branch, and oak branch symbolized, respectively, liberty, peace, and strength.Controversy immediately ensued, as strong anti-Communist sentiment in the United States led to the circulation of rumors that the \"JS\" engraved on the coin was the initials of Joseph Stalin, placed there by a Soviet agent in the mint. The Mint quickly issued a statement denying this, confirming that the initials were indeed Sinnock's. The same rumor arose after the release of the Sinnock designed Franklin half dollar in April 1948.\n\nAnother controversy surrounding Sinnock's design involves his image of Roosevelt. Soon after the coin's release, it was claimed that Sinnock borrowed his design of Roosevelt from a bas relief created by African American sculptor Selma Burke, unveiled at the Recorder of Deeds Building in Washington, D.C. in September 1945. Sinnock denied this and stated that he simply utilized his earlier design on the Roosevelt medal.With the passage of the Coinage Act of 1965, the composition of the dime changed from 90% silver and 10% copper to a clad \"sandwich\" of pure copper inner layer between two outer layers of cupronickel (75% copper, 25% nickel) alloy giving a total composition of 91.67% Cu and 8.33% Ni. This composition was selected because it gave similar mass (now 2.268 grams instead of 2.5 grams) and electrical properties (important in vending machines)\u2014and most importantly, because it contained no precious metal.\nSince 1946 the Roosevelt dime has been minted every year. Through 1955, all three mints, Philadelphia, Denver, and San Francisco produced circulating coinage; production at San Francisco ended in 1955, resuming in 1968 with proof coinage only. Through 1964 \"D\" and \"S\" mintmarks can be found to the left of the torch. From 1968, the mintmarks have appeared above the date. None were used in 1965\u201367, and Philadelphia did not show a mintmark until 1980 (in 1982, an error left the \"P\" off a small number of dimes, which are now valuable). To commemorate the 50th anniversary of the design, the 1996 mint sets included a \"W\" mintmarked dime made at the West Point Mint. A total of 1,457,000 dimes were issued in the sets, making it the lowest mintage Roosevelt dime up to that time. Since then, the \"P\" mint mark 2015 reverse proof dime and \"W\" mint mark 2015 proof dime, minted at Philadelphia and West Point for inclusion in the March of Dimes collector set, have the lowest mintages with 75,000 pieces struck for each.\n\n\n== See also ==\n1792 half disme\nDime store, also known as a \"Five and dime\"\nDime novel, later known as dime store novel\nMarch of Dimes\n\"Stop on a dime\"\nUnited States Mint coin production\n\n\n== References ==\n\n\n== External links ==\nOfficial specifications for all U.S. legal tender coins",
        "unit": "dime",
        "url": "https://en.wikipedia.org/wiki/Dime_(United_States_coin)"
    },
    {
        "_id": "South_African_rand",
        "clean": "South African rand",
        "text": "The rand (sign: R; code: ZAR) is the currency of South Africa. The Rand is subdivided into 100 cents (sign: \"c\"). The ISO 4217 code is ZAR, from Dutch Zuid-Afrikaanse Rand (South African Rand). The Rand is legal tender in the Common Monetary Area between South Africa, Swaziland, Lesotho, and Namibia, although the last three countries do have their own currencies pegged at par with rand.\nBefore 1976, the rand was legal tender in Botswana.\n\n\n== Etymology ==\nThe Rand takes its name from the WitwatersRand (\"white waters' ridge\" in English), the ridge upon which Johannesburg is built and where most of South Africa's gold deposits were found.\n\n\n== History ==\nThe Rand was introduced in the-then Union of South Africa on 14 February 1961, three months before the Republic of South Africa was established. A Decimal Coinage Commission had been set up in 1956 to consider a move away from the denominations of pounds, shillings, and pence, submitting its recommendation on 8 August 1958. It replaced the South African pound as legal tender, at the rate of 2 Rand to 1 pound, or 10 shillings to the Rand. The government introduced a mascot, Decimal Dan, \"the Rand-cent man\" (known in Afrikaans as Daan Desimaal). This was accompanied by a radio jingle, to inform the public about the new currency.\n\n\n=== Brief exchange rate history ===\n\n\n==== 1971\u20132000 ====\n\nOne Rand was worth US$1.40 from the time of its inception in 1961 until late-1971. Its value thereafter fluctuated as various exchange rate dispensations were implemented by the South African authorities. By the early-1980s, high inflation and mounting political pressure combined with sanctions placed against the country due to international opposition to the apartheid system started to erode its value. The currency broke above parity with the dollar for the first time in March 1982, and continued to trade between R 1 and R 1.30 to the dollar until June 1984, when depreciation of the currency gained momentum. By February 1985, it was trading over R 2 per dollar, and in July that year, all foreign exchange trading was suspended for three days to try to stop the depreciation.\nBy the time that State President P. W. Botha made his Rubicon speech on 15 August 1985, it had weakened to R 2.40 per dollar. The currency recovered somewhat between 1986\u201388, trading near the R 2 level most of the time and even breaking beneath it sporadically. The recovery was short-lived, however, and by the end of 1989, the Rand was trading at levels more than R 2.50 per dollar.\nAs it became clear in the early-1990s that the country was destined for Black majority rule and one reform after the other was announced, uncertainty about the future of the country hastened the depreciation until the level of R 3 to the dollar was breached in November 1992. A host of local and international events influenced the currency after that, most notably the 1994 presiential election which had it weaken to over R 3.60 to the dollar, the election of Tito Mboweni as the new governor of the South African Reserve Bank, and the inauguration of President Thabo Mbeki in 1999 which had it quickly slide to over R 6 to the dollar. The controversial land reform programme that was initiated in Zimbabwe, followed by the September 11, 2001 attacks, propelled it to its weakest historical level of R 13.84 to the dollar in December 2001.\n\n\n==== 2001\u20132011 ====\n\nThis sudden depreciation in 2001 led to a formal investigation, which in turn led to a dramatic recovery. By the end of 2002, the currency was trading  under R 9 to the dollar again, and by the end of 2004 was trading under R 5.70 to the dollar. The currency softened somewhat in 2005, and was trading around R 6.35 to the dollar at the end of the year. At the start of 2006, however, the currency resumed its rally, and as of 19 January 2006, was trading under R 6 to the dollar again. However, during the second and third quarters of 2006 (i.e. April through September), the Rand weakened significantly.\nIn sterling terms, it fell from around 9.5p to just over 7p, losing some 25% of its international trade-weighted value in just six months. In late-2007, the Rand rallied modestly to just over 8p, only to experience a precipitous slide during the first quarter of 2008.\nThis downward slide could be attributed to a range of factors: South Africa's worsening current account deficit, which widened to a 36\u2011year high of 7.3% of gross domestic product (GDP) in 2007; inflation at a five-year high of just under 9%; escalating global risk aversion as investors' concerns over the spreading impact of the sub-prime crisis grew; and a general flight to \"safe havens\", away from the perceived risks of emerging markets. The Rand depreciation was exacerbated by the Eskom electricity crisis, which arose from the utility being unable to meet the country's rapidly growing energy demands.\n\n\n==== 2012\u2013present ====\nA stalled mining industry in late-2012 led to new lows in early-2013. In late-January 2014, the Rand slid to R11.25 to the dollar, with analysts attributing the shift to \"word from the US Federal Reserve that it would trim back stimulus spending, which led to a massive sell-off in emerging economies.\" In 2014, South Africa experienced its worst year against the US dollar since 2009, and in March 2015, the Rand traded at its worst since 2002. At the time, Trading Economics released data that the Rand \"averaged R4.97 to the dollar between 1972 and 2015, reaching an all time high of R12.45 in December of 2001 and a record low of R0.67 in June of 1973.\" By the end of 2014, the Rand had weakened to R 15.05 per dollar, partly due to South Africa's consistent trade account deficit with the rest of the world.\nFrom 9 December 2015 to 13 December 2015, over a four-day period, the Rand dropped over 10% due to what some suspected was  President Zuma's surprise announcement that he would be replacing the then-Finance Minister Nhlanhla Nene with the little-known David van Rooyen. The rapid drop in value was stemmed when Zuma backtracked and announced that the better-known previous Minister of Finance, Pravin Gordhan, would instead be appointed to the post. Zuma's surprise sacking of Nene damaged international confidence in the Rand, with it experiencing significant exchange volatility throughout much of January 2016, reaching an all-time low of R 17.9169 to the US dollar on the 9 January 2016 before rebounding to R 16.57 later the same day.The January drop in value was also partly caused by Japanese retail investors cutting their losses in the currency to look for higher-yield investments elsewhere and due to concerns over the impact of the economic slowdown in China, South Africa's largest export partner.  By mid-January, economists were speculating that the Rand could expect to see further volatility for the rest of 2016.\nBy 29 April, it reached its highest performance over the previous five months, exchanging at a rate of 14.16 to the United States dollar.Following the United Kingdom's vote to leave the European Union (EU), the Rand dropped in value over 8% against the United States dollar on 24 June 2016, the currency's largest single-day decline since the 2008 economic crash.  This was partly due to a general global financial retreat from currencies seen as risky to the US dollar and partly due to concerns over how the UK's withdrawal from the EU would impact South Africa's economy and trade relations.In April 2017, a Reuters poll estimated that the Rand would remain relatively stable for the rest of the year, as two polls found that analysts had already factored in a possible downgrade to \"junk\" status. At the time, Moody's graded South Africa two notches above junk status. When President Jacob Zuma narrowly won a motion of no-confidence in South Africa in August 2017, the Rand continued to slide, dropping 1.7% that day. In September 2017, Goldman Sachs Group said that the debt and corruption of Eskom Holdings was the biggest risk to South Africa's economy and exchange rate of the Rand. At the time, it had no permanent CEO, and Colin Coleman of Goldman Sachs in Africa said the company was \"having discussions on solutions\" on finding credible management. In October 2017, the Rand firmed against the US dollar as it recovered from a six-month low. Reuters noted that \"South Africa is highly susceptible to global investor sentiment as the country relies on foreign money to cover it's large budget and current account deficits.\" On November 13, 2017, the Rand \"tumbled\" over a full percent when the budget chief Michael Sachs stood down from his position in Zuma's administration.\n\n\n== Coins ==\n\nCoins were introduced in 1961 in denominations of \u200b1\u20442, 1, \u200b2 1\u20442, 5, 10, 20, and 50 cents. In 1965, 2-cent coins replaced the \u200b2 1\u20442-cent coins. The \u200b1\u20442-cent coin was last struck for circulation in 1973. The 2-Rand coin was introduced in 1989, followed by 5-Rand coins in 1994. Production of the 1- and 2-cent coins was discontinued in 2002, primarily due to inflation having devalued them, but they remain legal tender.  Shops normally round the total purchase price of goods to the nearest 10 cents (in favour of the consumer).\nIn an effort to curb counterfeiting, a new 5-Rand coin was released in August 2004. Security features introduced on the coin include a bimetal design (similar to the \u20ac1 and \u20ac2 coins, the Thai 10-baht coin, the Philippine ten peso coin, the British \u00a32 coin, and the Canadian $2 coin), a specially serrated security groove along the rim and microlettering.\n\n\n== Banknotes ==\nThe first series of Rand banknotes was introduced in 1961 in denominations of 1-, 2-, 10-, and 20-Rand, with similar designs and colours to the preceding pound notes to ease the transition. They bore the image of what was believed at the time to be Jan van Riebeeck, the first V.O.C. administrator of Cape Town. It was later discovered that the image was not in fact Van Riebeeck at all, a portrait of Bartholomeus Vermuyden had been mistaken for Van Riebeeck. Like the last pound notes, they were printed in two variants, one with English written first and the other with Afrikaans written first.\nIn 1966, a second series was released with designs which moved away from the previous pound notes. Notes with denominations of 1-, 5- and 10-Rand were produced with predominantly one colour per note. A smaller 1-Rand note with the same design was introduced in 1973 and a 2-Rand note was introduced in 1974. The 20-Rand denomination from the first series was dropped. All notes bore the image of Jan van Riebeeck. The practice of having an English and an Afrikaans version of each note was continued in this series.\nThe 1978 series began with denominations of 2-, 5-, 10- and 20-Rand, with a 50-Rand introduced in 1984. This series had only one language variant for each denomination of note. Afrikaans was the first language on the 2-, 10-, and 50-Rand, while English was the first language on the 5- and 20-Rand. The 1-Rand note was replaced by a coin.\nIn the 1990s, the notes were redesigned with images of the Big Five wildlife species. 10-, 20- and 50-Rand notes were introduced in 1992 & 1993, retaining the colour scheme of the previous issue. Coins were introduced for the 2- and 5-Rand, replacing the notes of the previous series, mainly because of the severe wear and tear experienced with low-denomination notes in circulation. In 1994, 100- and 200-Rand notes were introduced.\nThe 2005 series has the same principal design, but with additional security features such as colour-shifting ink on the 50-Rand and higher and the EURion constellation. The obverses of all denominations were printed in English, while two other official languages were printed on the reverse, thus making use of all 11 official languages of South Africa.\nIn 2010, the South African Reserve Bank and commercial banks withdrew all 1994 series 200-Rand banknotes due to relatively high-quality counterfeit notes in circulation.In 2011, the South African Reserve Bank issued 100-Rand banknotes which were defective because they lacked fluorescent printing visible under UV light. In June, printing of this denomination was moved from the South African Bank Note Company to Crane Currency\u2019s Swedish division (Tumba Bruk), which reportedly produced 80 million 100-Rand notes. The South African Reserve Bank shredded 3.6 million 100-Rand banknotes printed by Crane Currency because they had the same serial numbers as a batch printed by the South African Bank Note Company. In addition, the notes printed in Sweden were not the correct colour, and they were 1 mm short.On 11 February 2012, President Jacob Zuma announced that the country would be issuing a new set of banknotes bearing Nelson Mandela's image. They were entered into circulation on 6 November 2012. These contained the same denominations of 10-, 20-, 50-, 100- and 200-Rand.\nIn 2013, the 2012 series was updated with the addition of the EURion constellation to all five denominations.On 18 July 2018, a special commemorative series of banknotes was released in commemoration of the 100th anniversary of Nelson Mandela's birth. This series includes notes of all denominations, 10-, 20-, 50-, 100- and 200-Rand. These notes will circulate alongside the existing notes. The notes depict the standard face of Nelson Mandela on the obverse, but instead of the Big Five animals on the reverse, they show a younger Mandela with different iconic scenes relating to his legacy. These scenes comprise: the rolling hills of the Eastern Cape, featuring Mandela\u2019s humble birthplace of Mvezo (10-Rand); the home of Mandela in Soweto, where he defined his political life alongside other struggle icons (20-Rand); the site where Mandela was captured near Howick, following 17 months in hiding, where a monument to him has been erected (50-Rand); the place of Mandela's 27-year imprisonment at Robben Island, showing a pile of quarried limestone (100-Rand); the statue of Mandela at the Union Buildings in remembrance of when he was inaugurated there in 1994 (200-Rand).\n\n\n=== First series ===\n\n\n=== Second series ===\n\n\n=== Third series ===\n\n\n=== Fourth series ===\n\n\n=== Fifth series ===\n\n\n=== Sixth series ===\n\n\n=== Seventh series ===\n\n\n== See also ==\nFinancial Rand\nWitwatersRand\nKrugerRand\nCoins of the South African Rand\nSouth African pound\nEconomy of South Africa\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\nSouth African Reserve Bank Currency Page\nUS Federal Reserve Bank historical exchange rate data\nSouth African Currency Page, with a short description of each note.\nSouth African Currency Page (old Rand), a short description of pre-1994 (apartheid-era) notes.",
        "unit": "south african rand",
        "url": "https://en.wikipedia.org/wiki/South_African_rand"
    },
    {
        "_id": "Penny",
        "clean": "Penny",
        "text": "A penny is a coin (pl. pennies) or a unit of currency (pl. pence) in various countries. Borrowed from the Carolingian denarius (whence its former abbreviation d.), it is usually the smallest denomination within a currency system. Presently, it is the formal name of the British penny (abbr. p) and the informal name of one American cent (abbr. \u00a2) as well as the informal Irish designation of 1 cent euro coin (abbr. c). It is the informal name of the cent unit of account in Canada, although one cent coins are no longer minted there.  The name is also used in reference to various historical currencies also derived from the Carolingian system, such as the French denier and the German pfennig. It may also be informally used to refer to any similar smallest-denomination coin, such as the euro cent or Chinese fen.\nThe Carolingian penny was originally a .940-fine silver coin weighing 1/240 pound. It was adopted by Offa of Mercia and other English kings and remained the principal currency in Europe over the next few centuries until repeated debasements necessitated the development of more valuable coins. The British penny remained a silver coin until the expense of the Napoleonic Wars prompted the use of base metals in 1797. Despite the decimalization of currencies in the United States and, later, throughout the British Commonwealth, the name remains in informal use.\nNo penny is currently formally subdivided, although farthings (\u00bc d.), halfpennies, and half cents have previously been minted and the mill (1/10\u00a2) remains in use as a unit of account in some contexts.\n\n\n== Name ==\n \nPenny is first attested in a 1394 Scots text, a variant of Old English peni, a development of numerous variations including pennig, penning, and pending. The etymology of the term \"penny\" is uncertain, although cognates are common across almost all Germanic languages and suggest a base *pan-, *pann-, or *pand- with the individualizing suffix -ing. Common suggestions include that it was originally *panding as a Low Franconian form of Old High German pfant \"pawn\" (in the sense of a pledge or debt, as in a pawnbroker putting up collateral as a pledge for repayment of loans); *panning as a form of the West Germanic word for \"frying pan\", presumably owing to its shape; and *ponding as a very early borrowing of Latin pondus (\"pound\"). Recently, it has been proposed that it may represent an early borrowing of Punic PN (Pane or Pene, \"Face\"), as the face of Carthaginian goddess Tanit was represented on nearly all Carthaginian currency. Following decimalization, the British and Irish coins were marked \"new penny\" until 1982 and 1985, respectively.\nThe regular plural pennies fell out of use in England from the 16th century, except in reference to coins considered individually. It remains common in Scottish English and is standard for all senses in American English, where, however, the informal \"penny\" is typically only used of the coins in any case, values being expressed in \"cents\". The informal name for the American cent seems to have spread from New York State.In British English, prior to decimalization, values from two to eleven pence and of twenty pence are often written and spoken as a single word, as twopence or tuppence, threepence or thruppence, &c. (Other values were usually expressed in terms of shillings and pence or written as two words, which may or may not be hyphenated.) Where a single coin represented a number of pence, it was treated as a single noun, as a sixpence or two eightpences. Thus, \"a threepence\" would be single coin of that value whereas \"three pence\" would be its value and \"three pennies\" would be three penny coins. In British English, divisions of a penny were added to such combinations without a conjunction, as sixpence-farthing, and such constructions were also treated as single nouns. Adjectival use of such coins used the ending -penny, as sixpenny.The British abbreviation d. derived from the Latin denarius. It followed the amount after a space. It has been replaced since decimalization by p, usually written without a space or period. From this abbreviation, it is common to speak of pennies and values in pence as \"p\". In North America, it is common to abbreviate cents with the currency symbol \u00a2. Elsewhere, it is usually written with a simple c.\n\n\n== History ==\n\n\n=== Antiquity ===\n\nThe medieval silver penny was modeled on similar coins in antiquity, such as the Greek drachma, the Carthaginian shekel, and the Roman denarius. Forms of these seem to have reached as far as Norway and Sweden. The use of Roman currency in Britain seems to have fallen off after the Roman withdrawal and subsequent Saxon invasions.\n\n\n=== Frankish Empire ===\n\nCharlemagne's father Pepin the Short instituted a major currency reform around AD 755, aiming to reorganise Francia's previous silver standard with a standardized .940-fine denier (Latin: denarius) weighing 1\u2044240 pound. (As the Carolingian pound seems to have been about 489.5 grams, each penny weighted about 2 grams.) Around 790, Charlemagne introduced a new .950 or .960-fine penny with a smaller diameter. Surviving specimens have an average weight of 1.70 grams, although some estimate the original ideal mass at 1.76 grams. Despite the purity and quality of these pennies, however, they were repeatedly rejected by traders throughout the Carolingian period in favor of the gold coins used elsewhere, a situation that led to repeated legislation against such refusal to accept the king's currency.\n\n\n=== England ===\n\nSome of the Anglo-Saxons kingdoms initially copied the solidus, the late Roman gold coin; at the time, however, gold was so rare and valuable that even the smallest coins had such a great value that they could only be used in very large transactions and were sometimes not available at all. Around AD 641\u2013670, there seems to have been a movement to use coins with a lower gold content. This decreased their value and may have increased the number that could be minted, but these paler coins do not seem to have solved the problem of the value and scarcity of the currency. The miscellaneous silver sceattas minted in Frisia and Anglo-Saxon England after around 680 were probably known as \"pennies\" at the time. (The misnomer is based on a probable misreading of the Anglo-Saxon legal codes.) Their purity varied and their weight fluctuated from about 0.8 to about 1.3 grams. They continued to be minted in East Anglia under Beonna and in Northumbria as late as the mid-9th century.\nThe first Carolingian-style pennies were introduced by King Offa of Mercia (r. 757\u2013796), modeled on Pepin's system. His first series was 1\u2044240 of the Saxon pound of 5400 grains (350 grams), giving a pennyweight of about 1.46 grams. His queen Cynethryth also minted these coins under her own name. Near the end of his reign, Offa minted his coins in imitation of Charlemagne's reformed pennies. Offa's coins were imitated by East Anglia, Kent, Wessex and Northumbria, as well as by two Archbishops of Canterbury. As in the Frankish Empire, all these pennies notionally composed shillings (solidi; sol) and pounds (librae; livres) but during this period neither larger unit was minted. Instead, they functioned only as notional units of account. (For instance, a \"shilling\" or \"solidus\" of grain was a measure equivalent to the amount of grain that 12 pennies could purchase.) English currency was notionally .925-fine sterling silver at the time of Henry II, but the weight and value of the silver penny steadily declined from 1300 onwards.\nIn 1257, Henry III minted a gold penny which had the nominal value of 1 shilling eightpence (i.e., 20 d.). At first, the coin proved unpopular because it was overvalued for its weight; by 1265 it was so undervalued\u2014the bullion value of its gold being worth 2 shillings (i.e., 24 d.) by then\u2014that the coins still in circulation were almost entirely melted down for the value of their gold. Only eight gold pennies are known to survive. It was not until the reign of Edward III that the florin and noble established a common gold currency in England.\n\nThe earliest halfpenny and farthing (\u00bcd.) found date to the reign of Henry III. The need for small change was also sometimes met by simply cutting a full penny into halves or quarters. In 1527, Henry VIII abolished the Tower pound of 5400 grains, replacing it with the Troy pound of 5760 grains and establishing a new pennyweight of 1.56 grams, although, confusingly, the penny coin by then weighed about 8 grains, and had never weighed as much as this 24 grains. The last silver pence for general circulation were minted during the reign of Charles II around 1660. Since then, they have only been coined for issue as Maundy money, royal alms given to the elderly on Maundy Thursday.\n\n\n=== United Kingdom ===\n\nThroughout the 18th century, the British government did not mint pennies for general circulation and the bullion value of the existing silver pennies caused them to be withdrawn from circulation. Merchants and mining companies\u2014such as Anglesey's Parys Mining Co.\u2014began to issue their own copper tokens to fill the need for small change. Finally, amid the Napoleonic Wars, the government authorized Matthew Boulton to mint copper pennies and twopences at Soho Mint in Birmingham in 1797. Typically, 1 lb. of copper produced 24 pennies. In 1860, the copper penny was replaced with a bronze one (95% copper, 4% tin, 1% zinc). Each pound of bronze was coined into 48 pennies.\n\n\n=== United States ===\n\nThe United States' cent\u2014popularly known as the \"penny\" since the early 19th century\u2014began with the unpopular copper chain cent in 1793.\n\n\n=== South Africa ===\nThe penny that was brought to the Cape Colony (in what is now South Africa) was a large coin \u2014 36 mm in diameter, 3.3 mm thick and 1 oz (28 g) \u2014 and the twopence was correspondingly larger at 41 mm in diameter, 5 mm thick and 2 oz (57 g). On them was Britannia with a trident in her hand. The English called this coin the Cartwheel penny due to its large size and raised rim, but the Capetonians referred to it as the Devil's Penny as they assumed that only the Devil used a trident. The coins were very unpopular due to their large weight and size. On 6 June 1825, Lord Charles Somerset, the governor, issued a proclamation that only British Sterling would be legal tender in the Cape (South Africa colony). The new British coins (which were introduced in England in 1816), among them being the shilling, six-pence of silver, the penny, half-penny, and quarter-penny in copper, were introduced to the Cape. Later two-shilling, four-penny, and three-penny coins were added to the coinage. The size and denomination of the 1816 British coins, with the exception of the four-penny coins, were used in South Africa until 1960.\n\n\n== Criticism ==\n\nHandling and counting penny coins entail transaction costs that may be higher than a penny. It has been claimed that, for micropayments, the mental arithmetic costs more than the penny. Changes in the price of metal commodity, combined with the continual debasement of paper currencies, causes the metal value of penny coins to exceed their face value.Australia and New Zealand adopted 5\u00a2 and 10\u00a2, respectively, as their lowest denomination, followed by Canada, which adopted 5\u00a2 as its lowest denomination in 2012. Several nations have stopped minting equivalent value coins, and efforts have been made to end the routine use of pennies in several countries, including the United States. In the UK, since 1992, one- and two-penny coins have been made from copper-plated steel (making them magnetic) instead of bronze.\n\n\n== In popular culture ==\nIn British and American culture, finding a penny is traditionally considered lucky. A proverbial expression of this is \"Find a penny, pick it up, and all the day you'll have good luck.\"\n\"A penny for your thoughts\" is an idiomatic way of asking someone what they're thinking about. It is first attested in John Heywood's 1547 Dialogue Conteinying the Nomber in Effect of All the Proverbes in the Englishe Tongue, at a time when the penny was still a sterling silver coin.\nThe possibly related American expression \"my two cents\" (standing for \"my humble opinion\") uses the low-value denomination to depreciate the speaker's thoughts for the sake of humility or irony.\nIn British English, to \"spend a penny\" means to urinate. Its etymology is literal: coin-operated public toilets commonly charged a predecimal penny, beginning with the Great Exhibition of 1851.\nAround Decimal Day, British Rail introduced the \"Superloo\", improved public toilets that charged 2p (roughly the equivalent of 6d.).\nIn 1936 U.S. shoemaker G.H. Bass & Co. introduced its \"Weejuns\" penny loafers. Other companies followed with similar products.\n\n\n== List of pennies ==\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Citations ===\n\n\n=== Bibliography ===\n\"Penny\", Encyclop\u00e6dia Britannica, 11th ed., Vol. XXI, Cambridge: Cambridge University Press, 1911, pp. 115\u2013116.\nAllen, Larry (2009), \"Carolingian Reform\", The Encyclopedia of Money, Sta. Barbara: ABC Clio, pp. 59\u201360, ISBN 978-1-59884-251-7.\nBlackburn, M.A.S.;  et al. (1986), Medieval European Coinage, Vol. 1: The Early Middle Ages (5th\u201310th centuries), Cambridge.\nBosworth;  et al., An Old English Dictionary.\nChown, John F (1994), A History of Money from AD 800, London: Routledge, ISBN 0-415-10279-0.\nCipolla, Carlo M. (1993), Before the Industrial Revolution: European Society and Economy, 1000-1700.\nFerguson, Wallace K. (1974), \"Money and Coinage of the Age of Erasmus: An Historical and Analytical Glossary with Particular Reference to France, the Low Countries, England, the Rhineland, and Italy\", The Correspondence of Erasmus: Letters 1 to 141: 1484 to 1500, Toronto: University of Toronto Press, pp. 311\u2013349, ISBN 0-8020-1981-1.\nFrassetto, Michael (2003), Encyclopedia of Barbarian Europe: Society in Transformation.\nKeary, Charles Francis (2005), A Catalogue of English Coins in the British Museum: Anglo-Saxon Series, Vol. I.\nMunro, John H. (2012), \"The Technology and Economics of Coinage Debasements in Medieval and Early Modern Europe: With Special Reference to the Low Countries and England\", Money in the Pre-Industrial World: Bullion, Debasements, and Coin Substitutes, Pickering & Chatto, republished 2016 by Routledge, pp. 30 ff, ISBN 978-1-84893-230-2.\nScott, Martin (1964), Medieval Europe, New York: Dorset Press, ISBN 0-88029-115-X.\nIslam and the Carolingian Penny, National Bank of Belgium Museum, November 2006.\nSelgin, George A. (2008), Good Money: Birmingham Button Makers, the Royal Mint, and the Beginnings of Modern Coinage, 1775-1821, University of Michigan Press, ISBN 0-472-11631-2.\nSuchodolski, Stanislaw (1983), \"On the Rejection of Good Coin in Carolingian Europe\", Studies in Numismatic Method: Presented to Philip Grierson, Cambridge: Cambridge University Press, pp. 147\u2013152, ISBN 0-521-22503-5.\n\n\n== External links ==\nCopper Penny Importance \u2013 Blog post & video covering the importance of retaining copper pennies.\nThe MegaPenny Project \u2013 A visualisation of what exponential numbers of pennies would look like.\nSilver Pennies \u2013 Pictures of English silver pennies from Anglo-Saxon times to the present.\nCopper Pennies \u2013 Pictures of English copper pennies from 1797 to 1860.\nUS Lincoln Penny on the Planet Mars \u2013 Curiosity Rover (September 10, 2012).\n \"Penny\". Collier's New Encyclopedia. 1921.\n \"Penny\". New International Encyclopedia. 1905.",
        "unit": "penny",
        "url": "https://en.wikipedia.org/wiki/Penny"
    },
    {
        "_id": "Cent_(currency)",
        "clean": "Cent (currency)",
        "text": "In many national currencies, the cent, commonly represented by the cent sign (a minuscule letter \"c\" crossed by a diagonal stroke or a vertical line: \u00a2; or a simple \"c\") is a monetary unit that equals \u200b1\u2044100 of the basic monetary unit. Etymologically, the word cent derives from the Latin word \"centum\" meaning hundred. Cent also refers to a coin worth one cent.\nIn the United States, the 1\u00a2 coin is generally known by the nickname penny, alluding to the British coin and unit of that name.\nIn the European Union, coins designs are chosen nationally, while the reverse and the currency as a whole is managed by the European Central Bank (ECB).\nIn Canada, the 1\u00a2 coin is no longer produced since 2012.\n\n\n== Symbol ==\n\nA cent is commonly represented by the cent sign, a minuscule letter \"c\" crossed by a diagonal stroke or a vertical line: \u00a2; or a simple \"c\", depending on the currency (see below). Cent amounts from 1 cent to 99 cents can be represented as one or two digits followed by the appropriate abbreviation (2\u00a2, 5\u00a2, 75\u00a2, 99\u00a2), or as a subdivision of the base unit ($0.99).\nBack in the days of typewriters, the cent sign appeared as the shift of the 6 key. The cent sign has not survived the changeover from typewriters to computer keyboards (replaced positionally by the caret). There are alternative ways, however, to create the character (offset 162) in most common code pages, including Unicode and Windows-1252:\n\nOn DOS- or Windows-based computers, hold Alt while typing 0162 or 155 on the numeric keypad. If there is no numeric keypad, as on many laptops, type A2 in Windows Wordpad followed by Alt+X and copy/paste the resulting \u00a2 into the target document.  For the US International keyboard: <Right Alt> <Shift> c (Windows).\nOn Macintosh systems, hold \u2325 Option and press 4 on the number row.\nOn Unix/Linux systems with a compose key, Compose+|+C and Compose+/+C are typical sequences.The cent sign has Unicode code point:\n\nU+00A2 \u00a2 cent sign (HTML &#162; \u00b7  &cent;),\nU+FFE0 \uffe0 fullwidth cent sign (HTML &#65504;).When written in English, the cent sign (\u00a2 or c) follows the amount (with no space between), in contrast with a larger currency symbol, which is placed before the amount. For example, 2\u00a2 and $0.02, or 2c and \u20ac0.02.\nThe Ghanaian cedi's symbol is \u20b5.\n\n\n== Usage ==\nExamples of currencies around the world featuring centesimal (\u200b1\u2044100) units called cent, or related words from the same root such as c\u00e9ntimo, cent\u00e9simo, centavo or sen, are:\n\nArgentine peso (as centavo)\nAruban florin\nAustralian dollar\nBarbadian dollar\nBahamian dollar\nBelize dollar\nBermudian dollar\nBolivian boliviano (as centavo)\nBrazilian real (as centavo)\nBrunei dollar (as sen)\nCanadian dollar\nCayman Islands dollar\nChilean peso (as centavo). Centavos officially exist and are considered in financial transactions; however, there are no current centavo-denominated coins.\nCook Islands dollar (cent, although one \"50 tene\" coin has)\nCuban peso (as centavo)\nEast Caribbean dollar\nEritrean nakfa\nEstonian kroon (as sent)\nEuro \u2013 the coins bear the text \"EURO CENT\". Greek coins have \u039b\u0395\u03a0\u03a4\u039f (\"lepto\") on the obverse of the one-cent coin and \u039b\u0395\u03a0\u03a4\u0391 (\"lepta\") on the obverse of the others. Actual usage varies depending on language.\nFijian dollar\nGuyanese dollar\nHong Kong dollar (as \"dimes\")\nIndonesian rupiah (as sen)\nJamaican dollar\nKenyan shilling\nLesotho loti (as sente)\nLiberian dollar\nMalaysian ringgit (as sen)\nMauritian rupee\nMexican peso (as centavo)\nMoroccan dirham (as santim)\nNamibian dollar\nNetherlands Antillean gulden\nNew Zealand dollar\nPanamanian balboa (as cent\u00e9simo)\nPeruvian nuevo sol (as c\u00e9ntimo)\nPhilippine peso (as centavo)\nSeychellois rupee\nSierra Leonean leone\nSingapore dollar\nSouth African rand\nSri Lankan rupee\nSurinamese dollar\nSwazi lilangeni\nNew Taiwan dollar\nTanzanian shilling\nTongan pa\u02bbanga (as seniti)\nTrinidad and Tobago dollar\nUgandan shilling (cent discontinued in 2013)\nUnited States dollar\nUruguayan peso (as cent\u00e9simo)\nZimbabwean dollarExamples of currencies featuring centesimal (\u200b1\u2044100) units not called cent\n\nBritish pound \u2013 divided into 100 pence (singular: penny) since 1971\nBulgarian lev (as stotinka, Bulgarian: \u0441\u0442\u043e\u0442\u0438\u043d\u043a\u0430 (\"hundredth\")\nChinese Yuan/Renminbi \u2013 divided into 100 f\u0113n (\u5206); in general usage, divided into 10 ji\u01ceo (\u89d2).\nCroatian kuna \u2013 divided into 100 lipa\nDanish krone \u2013 divided into 100 \u00f8re\nEstonian mark \u2013 divided into 100 penni (nominative: penn)\nIndian rupee \u2013 divided into 100 paise\nIsraeli new shekel \u2013 divided into 100 agorot\nMacao pataca \u2013 divided into 100 avos\nMacedonian denar \u2013 divided into 100 deni\nNorwegian krone \u2013 divided into 100 \u00f8re\nPakistani rupee \u2013 divided into 100 paise\nPolish z\u0142oty \u2013 divided into 100 groszy (singular: grosz)\nRomanian and Moldovan leu \u2013 divided into 100 bani\nRussian ruble \u2013 divided into 100 kopeks\nSaudi riyal;\u2013 divided into 100 halalas\nSerbian dinar \u2013 divided into 100 paras\nSwedish krona \u2013 divided into 100 \u00f6re\nSwiss franc \u2013 divided into 100 rappen (known as centime in French and centesimo in Italian)\nThai baht \u2013 divided into 100 satang\nTurkish Lira \u2013 divided into 100 kuru\u015f\nUnited Arab Emirates dirham \u2013 divided into 100 fils\nUkrainian hrywnia \u2013 divided into 100 kopijkas.Examples of currencies which do not feature centesimal (\u200b1\u2044100) units:\n\nCosta Rican col\u00f3n \u2013 no fractional denomination in circulation since the 1980s, formerly divided into 100 c\u00e9ntimos.\nCzech koruna \u2013 no fractional denomination in circulation, formerly divided into 100 hellers\nJapanese yen \u2013 no fractional denomination in circulation, formerly divided into 100 sen and 1000 rin.\nSouth Korean Won  no fractional denomination in circulation, formerly divided into 100 jeon.\nIcelandic kr\u00f3na \u2013 no fractional denomination in circulation, formerly divided into 100 eyrir.\nKuwaiti dinar \u2013 divided into 1000 fils\nOmani rial \u2013 divided into 1000 baisa\nMauritanian ouguiya \u2013 divided into 5 khoums\nMalagasy ariary \u2013 divided into 5 iraimbilanjaExamples of currencies which use the cent symbol for other purpose:\n\nCosta Rican col\u00f3n \u2013 The common symbol '\u00a2' is frequently used locally to represent '\u20a1', the proper col\u00f3n designation\nGhanaian cedi \u2013 The common symbol '\u00a2' is sometimes used to represent '\u20b5', the proper cedi designation\n\n\n== See also ==\nCent (music)\n\n\n== References ==",
        "unit": "cent",
        "url": "https://en.wikipedia.org/wiki/Cent_(currency)"
    },
    {
        "_id": "Basis_point",
        "clean": "Basis point",
        "text": "A per ten thousand sign or basis point (often denoted as bp, often pronounced as \"bip\" or \"beep\") is (a difference of) one hundredth of a percent or equivalently one ten thousandth. The related concept of a permyriad is literally one part per ten thousand. Figures are commonly quoted in basis points in finance, especially in fixed income markets.\n\n\n== Definition ==\n\n1 basis point = (a difference of) 1 permyriad or one-hundredth of one percent.\n1 bp = (a difference of) 1\u2031 or 0.01% or 0.1\u2030 or 10\u22124 or \u200b1\u204410000 or 0.0001.\n100 bp = (a difference of) 1% or 100\u2031.Basis points are used as a convenient unit of measurement in contexts where percentage differences of less than 1% are discussed. The most common example is interest rates, where differences in interest rates of less than 1% per year are usually meaningful to talk about. For example, a difference of 0.10 percentage points is equivalent to a change of 10 basis points (e.g., a 4.67% rate increases by 10 basis points to 4.77%). In other words, an increase of 100 basis points means a rise by 1 percentage point.\nLike percentage points, basis points avoid the ambiguity between relative and absolute discussions about interest rates by dealing only with the absolute change in numeric value of a rate. For example,  if a report says there has been a \"1% increase\" from a 10% interest rate, this could refer to an increase either from 10% to 10.1% (relative, 1% of 10%), or from 10% to 11% (absolute, 1% plus 10%).  However, if the report says there has been a \"100 basis point increase\" from a 10% interest rate, then the interest rate of 10% has increased by 1.00% (the absolute change) to an 11% rate.\nIt is common practice in the financial industry to use basis points to denote a rate change in a financial instrument, or the difference (spread) between two interest rates, including the yields of fixed-income securities.\nSince certain loans and bonds may commonly be quoted in relation to some index or underlying security, they will often be quoted as a spread over (or under) the index. For example, a loan that bears interest of 0.50% per annum above the London Interbank Offered Rate (LIBOR) is said to be 50 basis points over LIBOR, which is commonly expressed as \"L+50bps\" or simply \"L+50\".\nThe term \"basis point\" has its origins in trading the \"basis\" or the spread between two interest rates.  Since the basis is usually small, these are quoted multiplied up by 10,000, and hence a \"full point\" movement in the \"basis\" is a basis point.  Contrast with pips in FX forward markets.\nExpense ratios of investment funds are often quoted in basis points.\n\n\n== Permyriad ==\nA related concept is one part per ten thousand, \u200b1\u204410,000. The same unit is also (rarely) called a permyriad, literally meaning \"for (every) myriad (ten thousand)\".  If used interchangeably, the permyriad is potentially confusing because an increase of one basis point to a 10 basis point value is generally understood to mean an increase to 11 basis points; not an increase of one part in ten thousand, meaning an increase to 10.001 basis points. This is akin to the difference between percentage and percentage point. A permyriad is written with U+2031 \u2031 PER TEN THOUSAND SIGN (HTML &#8241;) which looks like a percent sign (%) with three zeroes to the right of the slash. (It can be regarded as a stylized form of the four zeros in the denominator of \"\u200b1\u204410,000\", although it originates as a natural extension of the percent (%) and permille (\u2030) signs).\n\n\n== See also ==\nPercentage point\nPercent (%) 1 part in 100\nPermille (\u2030) 1 part in 1000\nParts-per notation\nPercentage in point (pip)\nTick size\n\n\n== References ==",
        "unit": "basis point",
        "url": "https://en.wikipedia.org/wiki/Basis_point"
    },
    {
        "_id": "Minute_and_second_of_arc",
        "clean": "Minute and second of arc",
        "text": "A minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to 1/60 of one degree. Since one degree is 1/360 of a turn (or complete rotation), one minute of arc is 1/21600 of a turn. A minute of arc is \u03c0/10800 of a radian. A second of arc, arcsecond (arcsec), or arc second is 1/60 of an arcminute, 1/3600 of a degree, 1/1296000 of a turn, and \u03c0/648000 (about 1/206265) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying, and marksmanship.\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (\u03bcas), for instance, are commonly used in astronomy.\nThe number of square arcminutes in a complete sphere is \n  \n    \n      \n        4\n        \u03c0\n        \n          \n            (\n            \n              \n                \n                  10\n                  \n                  800\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \n              466\n              \n              560\n              \n              000\n            \n            \u03c0\n          \n        \n        \u2248\n      \n    \n    {\\displaystyle 4\\pi \\left({\\frac {10\\,800}{\\pi }}\\right)^{2}={\\frac {466\\,560\\,000}{\\pi }}\\approx }\n   148510660 square arcminutes (the surface area of a unit sphere in square units divided by the solid angle area subtended by a square arcminute, also in square units - so that the final result is a dimensionless number).\n\n\n== Symbols and abbreviations ==\nThe standard symbol for marking the arcminute is the prime (\u2032) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1\u2032. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (\n  \n    \n      \n        \n          \n            \n              \n                \n                \u2032\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {'}}}\n  ).\nThe standard symbol for the arcsecond is the double prime (\u2033) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1\u2033. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42\u00b0 25.32\u2032 or 42\u00b0 25.322\u2032. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\n\n== Common examples ==\nThe full moon's average apparent size is about 31 arcminutes (or 0.52\u00b0).\nAn arcminute is approximately the resolution of the human eye.\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of 4 kilometres (about 2.5 mi). An arcsecond is also the angle subtended by\n\nan object of diameter 725.27 km at a distance of one astronomical unit,\nan object of diameter 45866916 km at one light-year,\nan object of diameter one astronomical unit (149597871 km) at a distance of one parsec.A milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\nA nanoarcsecond is about the size of a penny on Neptune's moon Triton as observed from Earth.\nAlso notable examples of size in arcseconds are:\n\nHubble Space Telescope has calculational resolution of 0.05 arcseconds and actual resolution of almost 0.1 arcseconds, which is close to the diffraction limit.\ncrescent Venus measures between 60.2 and 66 seconds of arc.\n\n\n== Uses ==\n\n\n=== Astronomy ===\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (\u03b2) and longitude (\u03bb); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (\u03b4), are all measured in degrees, arcminutes and arcseconds. The principal exception is right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\u2033 and 60\u2033), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arc second, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\nThe ESA astrometric space probe Gaia, launched in 2013, can approximate star positions to 7 microarcseconds (\u00b5as).Apart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.Space telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble Space Telescope can reach an angular size of stars down to about 0.1\u2033. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\n\n=== Cartography ===\nMinutes (\u2032) and seconds (\u2033) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or \u22481.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use  base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places (1/1000 of a degree) have about 1/4 the precision of degrees-minutes-seconds (1/3600 of a degree) and specify locations within about 120 meters or 400 feet.\n\n\n=== Property cadastral surveying ===\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, North 65\u00b0 39\u2032 18\u2033 West 85.69 feet would describe a line running from the starting point 85.69 feet in a direction 65\u00b0 39\u2032 18\u2033 (or 65.655\u00b0) away from north toward the west.\n\n\n=== Firearms ===\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA is subtended by a sphere with a diameter of 1.047 inches at 100 yards (2.908 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, at 500 yards, 1 MOA is subtended by a sphere with a diameter of 5.235 inches, and at 1000 yards 1 MOA is subtended by a sphere with a diameter of 10.47 inches. \nSince many modern telescopic sights are adjustable in half (1/2), quarter (1/4), or eighth (1/8) MOA increments, also known as clicks, zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that click in fractions of MOA. This makes zeroing and adjustments much easier:\n\nTo adjust a \u200b1\u20442 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 \u00d7 2 = 6 clicks down and 1.5 x 2 = 3 clicks right\nTo adjust a \u200b1\u20444 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 4 = 12 clicks down and 1.5 \u00d7 4 = 6 clicks right\nTo adjust a \u200b1\u20448 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 8 = 24 clicks down and 1.5 \u00d7 8 = 12 clicks rightAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is 1/10 mil (which approximates \u200b1\u20443 MOA).\n\nTo adjust a 1/10 mil scope 0.9 mil down and 0.4 mil right, the scope needs to be adjusted 9 clicks down and 4 clicks right (which equals approximately 3 and 1.5 MOA respectively).One thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\nThe physical group size equivalent to m minutes of arc can be calculated as follows: group size = tan(m/60) \u00d7 distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan(1/60) \u2248 1.047 inches. In metric units 1 MOA at 100 meters \u2248 2.908 centimeters.\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a 1 MOA rifle should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\nRifle manufacturers and gun magazines often refer to this capability as sub-MOA, meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.The Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 \u00d7 \u03c0 \u00d7 1000, regardless the target range. Therefore, 1 MOA \u2248 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 mrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system.  A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\nIn the table below conversions from mil to metric values are exact (e.g. 0.1 mil equals exactly 1 cm at 100 meters), while conversions of minutes of arc to both metric and imperial values are approximate.\n\n(Values in bold face are exact. All mil fractions are given in tenths, which is more convenient for practical use.)\n\n1\u2032 at 100 yards equals 22619/ 21600 = 1.04717593 in \u2248 1.047 inches\n1\u2032 \u2248 0.291 mil (or 2.91 cm at 100 m, approximately  3 cm at 100 m)\n1 mil \u2248 3.44\u2032, so 1/10 mil \u2248 1/3\u2032\n0.1 mil equals exactly 1 cm at 100 m, or approximately 0.36 inches at 100 yards\n\n\n=== Human vision ===\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\n\n=== Materials ===\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (\u03c9-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n=== Manufacturing ===\nSome measurement devices make use of arcminutes and arcseconds to measure angles when the object being measured is too small for direct visual inspection. For instance, a toolmaker's optical comparator will often include an option to measure in \"minutes and seconds\".\n\n\n== See also ==\nDegree (angle) \u00a7 Subdivisions\nSexagesimal \u00a7 Modern usage\nSquare minute\nSquare second\nMilliradian\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nMOA / mils By Robert Simeone",
        "unit": "second of arc",
        "url": "https://en.wikipedia.org/wiki/Minute_and_second_of_arc"
    },
    {
        "_id": "Chinese_yuan",
        "clean": "Chinese yuan",
        "text": "The renminbi (Ab.: RMB; simplified Chinese: \u4eba\u6c11\u5e01; traditional Chinese: \u4eba\u6c11\u5e63; pinyin:  r\u00e9nm\u00ednb\u00ec; literally: \"people's currency\"; sign: \u5143; code: CNY) is the official currency of the People's Republic of China. The yuan (Chinese: \u5143; pinyin: yu\u00e1n) is the basic unit of the renminbi, but is also used to refer to the Chinese currency generally, especially in international contexts where \"Chinese yuan\" is widely used to refer to the renminbi. The distinction between the terms renminbi and yuan is similar to that between sterling and pound, which respectively refer to the British currency and its primary unit. One yuan is subdivided into 10 jiao (Chinese: \u89d2; pinyin: ji\u01ceo), and a jiao in turn is subdivided into 10 fen (Chinese: \u5206; pinyin: f\u0113n). The renminbi is issued by the People's Bank of China, the monetary authority of China.Until 2005, the value of the renminbi was pegged to the US dollar. As China pursued its transition from central planning to a market economy, and increased its participation in foreign trade, the renminbi was devalued to increase the competitiveness of Chinese industry. It has previously been claimed that the renminbi's official exchange rate was undervalued by as much as 37.5% against its purchasing power parity. More recently, however, appreciation actions by the Chinese government, as well as quantitative easing measures taken by the American Federal Reserve and other major central banks, have caused the renminbi to be within as little as 8% of its equilibrium value by the second half of 2012. Since 2006, the renminbi exchange rate has been allowed to float in a narrow margin around a fixed base rate determined with reference to a basket of world currencies. The Chinese government has announced that it will gradually increase the flexibility of the exchange rate. As a result of the rapid internationalization of the renminbi, it became the world's 8th most traded currency in 2013, and 5th by 2015.On 1 October 2016, the RMB became the first emerging market currency to be included in the IMF's special drawing rights basket, the basket of currencies used by the IMF (reserve currency).\n\n\n== Terminology ==\nThe ISO code for renminbi (which may also be used for the yuan) is CNY (an abbreviation for \"Chinese yuan\"), or also CNH when traded in off-shore markets such as Hong Kong. The currency is often abbreviated RMB, or indicated by the yuan sign \u00a5. The latter may be written CN\u00a5 to distinguish it from other currencies with the same symbol (such as the Japanese yen).  In Chinese texts the currency may also be indicated with the Chinese character for the yuan, \u5706 (or \u5143 informally). The renminbi is legal tender in mainland China, but not in Hong Kong or Macau. However, Renminbi is widely accepted in Hong Kong and Macau, and are easily exchanged in the two territories, with banks in Hong Kong allowing people to maintain accounts in RMB and withdraw RMB banknotes from ATM terminals.\n\n\n== History ==\n\nA variety of currencies circulated in China during the Republic of China (ROC) era, most of which were denominated in the unit yu\u00e1n (Mandarin pronunciation in IPA: [\u0265\u00e6\u030cn\u02e7\u02e5]). Each was distinguished by a currency name, such as the fabi (\"legal tender\"), the \"gold yuan\", and the \"silver yuan\".\nThe renminbi was introduced by the People's Bank of China in December 1948, about a year before the establishment of the People's Republic of China. It was issued only in paper money form at first, and replaced the various currencies circulating in the areas controlled by the Communists. One of the first tasks of the new government was to end the hyperinflation that had plagued China in the final years of the Kuomintang (KMT) era. That achieved, a revaluation occurred in 1955 at the rate of 1 new yuan = 10,000 old yuan.\nAs the Communist Party of China took control of ever larger territories in the latter part of the Chinese Civil War, its People's Bank of China began in 1948 to issue a unified currency for use in Communist-controlled territories. Also denominated in yuan, this currency was identified by different names, including \"People's Bank of China banknotes\" (simplified Chinese: \u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u949e\u7968; traditional Chinese: \u4e2d\u570b\u4eba\u6c11\u9280\u884c\u9214\u7968; from November 1948), \"New Currency\" (simplified Chinese: \u65b0\u5e01; traditional Chinese: \u65b0\u5e63; from December 1948), \"People's Bank of China notes\" (simplified Chinese: \u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u5238; traditional Chinese: \u4e2d\u570b\u4eba\u6c11\u9280\u884c\u5238; from January 1949), \"People's Notes\" (\u4eba\u6c11\u5238, as an abbreviation of the last name), and finally \"People's Currency\", or \"renminbi\", from June 1949.\n\n\n=== Era of the planned economy ===\n\nFrom 1949 until the late 1970s, the state fixed China's exchange rate at a highly overvalued level as part of the country's import-substitution strategy. During this time frame, the focus of the state's central planning was to accelerate industrial development and reduce China's dependence on imported manufactured goods. The overvaluation allowed the government to provide imported machinery and equipment to priority industries at a relatively lower domestic currency cost than otherwise would have been possible.\n\n\n=== Transition to an equilibrium exchange rate ===\nChina's transition by the mid-1990s to a system in which the value of its currency was determined by supply and demand in a foreign exchange market was a gradual process spanning 15 years that involved changes in the official exchange rate, the use of a dual exchange rate system, and the introduction and gradual expansion of markets for foreign exchange.\nThe most important move to a market-oriented exchange rate was an easing of controls on trade and other current account transactions, as occurred in several very early steps. In 1979 the State Council approved a system allowing exporters and their provincial and local government owners to retain a share of their foreign exchange earnings, referred to as foreign exchange quotas. At the same time, the government introduced measures to allow retention of part of the foreign exchange earnings from non-trade sources, such as overseas remittances, port fees paid by foreign vessels, and tourism.\nAs early as October 1980, exporting firms that retained foreign exchange above their own import needs were allowed to sell the excess through the state agency responsible for the management of China's exchange controls and its foreign exchange reserves, the State Administration of Exchange Control. Beginning in the mid-1980s, the government sanctioned foreign exchange markets, known as swap centers eventually in most large cities.\nThe government also gradually allowed market force to take the dominant role by introducing an \"internal settlement rate\" of RMB 2.8 to 1 US dollar which was a devaluation of almost 100 percent.\n\n\n=== Evolution of exchange policy since 1994 ===\nIn November 1993 the Third Plenum of the Fourteenth CPC Central Committee approved a comprehensive reform strategy in which foreign exchange management reforms were highlighted as a key element for a market-oriented economy. A floating exchange rate regime and convertibility for RMB were seen as the ultimate goal of the reform. Conditional convertibility under current account was achieved by allowing firms to surrender their foreign exchange earning from current account transactions and purchase foreign exchange as needed. Restrictions on Foreign Direct Investment (FDI) was also loosened and capital inflows to China surged.\n\n\n=== Convertibility ===\nDuring the era of the command economy, the value of the renminbi  was set to unrealistic values in exchange with western currency and severe currency exchange rules were put in place. With the opening of the Chinese economy in 1978, a dual-track currency system was instituted, with renminbi usable only domestically, and with foreign visitors to China forced to use foreign exchange certificates. The unrealistic levels at which exchange rates were pegged led to a strong black market in currency transactions.\nIn the late 1980s and early 1990s, China worked to make the RMB more convertible. Through the use of swap centres, the exchange rate was brought to realistic levels and the dual track currency system was abolished.\nAs of 2013, the renminbi is convertible on current accounts but not capital accounts. The ultimate goal has been to make the RMB fully convertible. However, partly in response to the Asian financial crisis in 1998, China has been concerned that the Chinese financial system would not be able to handle the potential rapid cross-border movements of hot money, and as a result, as of 2012, the currency trades within a narrow band specified by the Chinese central government.\nFollowing the Internationalization of the renminbi, on 30 November 2015, the IMF voted to designate the renminbi as one of several main world currencies, thus including it in the basket of special drawing rights. The RMB became the first emerging market currency to be included in the IMF\u2019s SDR basket on 1 October 2016. The other main world currencies are the United States dollar, euro, British pound, and Japanese yen.\n\n\n== Issuance ==\nAs of 2016, renminbi banknotes are available in denominations from \u00a50.1, \u00a50.2, \u00a50.5 (1, 2, and 5 jiao), \u00a51, \u00a52, \u00a55, \u00a510, \u00a520, \u00a550 and \u00a5100 yuan. These denominations have been available since 1955, except for the 50 and 100 yuan notes (added in 1980) and 20 yuan notes (added in or after 1999). Coins are available in denominations from 1 fen to 1 yuan (\u00a50.01\u20131). Thus some denominations exist in both coins and banknotes. On rare occasions larger yuan coin denominations such as \u00a55 have been issued to commemorate events but use of these outside of collecting has never been widespread.\nThe denomination of each banknote is printed in Chinese. The numbers themselves are printed in financial Chinese numeral characters, as well as Arabic numerals. The denomination and the words \"People's Bank of China\" are also printed in Mongolian, Tibetan, Uyghur and Zhuang on the back of each banknote, in addition to the boldface Hanyu Pinyin \"Zhongguo Renmin Yinhang\" (without tones). The right front of the note has a tactile representation of the denomination in Chinese Braille starting from the fourth series. See corresponding section for detailed information.\nThe fen and jiao denominations have become increasingly unnecessary as prices have increased. Coins under \u00a50.1 are used infrequently. Chinese retailers tend to avoid decimal values (such as \u00a59.99), opting instead for integer values of yuan (such as \u00a59 or \u00a510).\n\n\n=== Coins ===\nIn 1953, aluminium 1-, 2-, and 5-fen coins began being struck for circulation, and were first introduced in 1955. These depict the national emblem on the obverse (front) and the name and denomination framed by wheat stocks on the reverse (back). In 1980, brass 1-, 2-, and 5-jiao and cupro-nickel 1-yuan coins were added, although the 1 and 2 jiao were only produced until 1981, with the last 5 jiao and 1 yuan issued in 1985. All jiao coins depicted similar designs to the fen coins while the yuan depicted the Great Wall of China. In 1991, a new coinage was introduced, consisting of an aluminium 1 jiao, brass 5 jiao and nickel-clad-steel 1 yuan. These were smaller than the previous jiao and yuan coins and depicted flowers on the obverse and the national emblem on the reverse. Issuance of the aluminum 1- and 2-fen coins ceased in 1991, with that of the 5 fen halting in 1994. The small coins were still made for annual uncirculated mint sets in limited quantities, and from the beginning of 2005 the 1-fen coin got a new lease on life by being issued again every year since then up to present. New designs of the 1 and 5 jiao and 1 yuan were again introduced in between 1999 and 2002, with the 1 jiao being significantly reduced in size. In 2005, the metallic composition of the 1 jiao was changed from aluminum to more durable nickel-plated steel. The frequency of usage of coins varies between different parts of China, with coins typically being more popular in urban areas, and small notes being more popular in rural areas. Older fen and large jiao coins are uncommonly still seen in circulation but are still valid in exchange.\n\n\n=== Banknotes ===\n\nAs of 2018, there have been five series of renminbi banknotes issued by the People's Republic of China:\n\nThe first series of renminbi banknotes was issued on 1 December 1948, by the newly founded People's Bank of China.  It introduced notes in denominations of 1, 5, 10, 20, 50, 100 and 1000 yuan. Notes for 200, 500, 5000 and 10,000 yuan followed in 1949, with 50,000 yuan notes added in 1950. A total of 62 different designs were issued. The notes were officially withdrawn on various dates between 1 April and 10 May 1955. The name \"first series\" was given retroactively in 1950, after work began to design a new series.These first renminbi notes were printed with the words \"People's Bank of China\", \"Republic of China\", and the denomination, written in Chinese characters by Dong Biwu.The second series of renminbi banknotes was introduced on 1 March 1955 (but dated 1953). Each note has the words \"People's Bank of China\" as well as the denomination in the Uyghur, Tibetan, Mongolian and Zhuang languages on the back, which has since appeared in each series of renminbi notes. The denominations available in banknotes were \u00a50.01, \u00a50.02, \u00a50.05, \u00a50.1, \u00a50.2, \u00a50.5, \u00a51, \u00a52, \u00a53, \u00a55 and \u00a510. Except for the three fen denominations and the 3 yuan which were withdrawn, notes in these denominations continued to circulate. Good examples of this series have gained high status with banknote collectors.\nThe third series of renminbi banknotes was introduced on 15 April 1962, though many denominations were dated 1960. New dates would be issued as stocks of older dates were gradually depleted. The sizes and design layout of the notes had changed but not the order of colors for each denomination. For the next two decades, the second and third series banknotes were used concurrently. The denominations were of \u00a50.1, \u00a50.2, \u00a50.5, \u00a51, \u00a52, \u00a55 and \u00a510. The third series was phased out during the 1990s and then was recalled completely on 1 July 2000.\nThe fourth series of renminbi banknotes was introduced between 1987 and 1997, although the banknotes were dated 1980, 1990, or 1996. They are still legal tender. Banknotes are available in denominations of \u00a50.1, \u00a50.2, \u00a50.5, \u00a51, \u00a52, \u00a55, \u00a510, \u00a550 and \u00a5100. Like previous issues, the color designation for already existing denominations remained in effect.\nThe fifth series of renminbi banknotes and coins was progressively introduced from 1999. This series also bears the years 2005 (all except \u00a51) and 2015 (\u00a5100 only). As of 2016, it includes banknotes for \u00a51, \u00a55, \u00a510, \u00a520, \u00a550 and \u00a5100. Significantly, the fifth series uses the portrait of Mao Zedong on all banknotes, in place of the various leaders and workers which had been featured previously. During this series new security features were added, the \u00a52 denomination was discontinued, and the color pattern for each note was changed.\n\n\n=== Commemorative issues of the renminbi ===\nIn 1999, a commemorative red \u00a550 note was issued in honor of the 50th anniversary of the establishment of the People's Republic of China. This note features Mao Zedong on the front and various animals on the back.\nAn orange polymer note, and so far, China's only polymer note, commemorating the new millennium was issued in 2000 with a face value of \u00a5100. This features a dragon on the obverse and the reverse features the China Millennium monument (at the Center for Cultural and Scientific Fairs).\nFor the 2008 Beijing Olympics, a green \u00a510 note was issued featuring the Bird's Nest Stadium on the front with the back showing a classical Olympic discus thrower and various other athletes.\nOn 26 November 2015, the People's Bank of China issued a blue \u00a5100 commemorative note to commemorate aerospace science and technology.\n\n\n=== Use in minority regions ===\n\nThe renminbi yuan has different names when used in minority regions. \n\nWhen used in Inner Mongolia and other Mongol autonomies, a yuan is called a tugreg (Mongolian: \u1832\u1826\u182d\u1826\u1837\u1822\u182d\u180c t\u00fcg\u00fcrig). However, when used in the republic of Mongolia, it is still named yuani (Mongolian: \u044e\u0430\u043d\u044c) to differentiate it from Mongolian t\u00f6gr\u00f6g (Mongolian: \u0442\u04e9\u0433\u0440\u04e9\u0433). One Chinese t\u00fcg\u00fcrig (tugreg) is divided into 100 m\u00f6ngg\u00fc (Mongolian: \u182e\u1825\u1829\u182d\u1826), one Chinese jiao is labeled \"10 m\u00f6ngg\u00fc\". In Mongolian, renminbi is called aradin jogos or arad-un jogos (Mongolian: \u1820\u1837\u1820\u1833\u202f\u1824\u1828 \u1835\u1823\u182d\u1823\u1830 arad-un \u01f0o\u03b3os).\nWhen used in Tibet and other Tibetan autonomies, a yuan is called a gor (Tibetan: \u0f66\u0f92\u0f7c\u0f62\u0f0b, ZYPY: Gor). One gor is divided into 10 gorsur (Tibetan: \u0f66\u0f92\u0f7c\u0f62\u0f0b\u0f5f\u0f74\u0f62\u0f0b, ZYPY: Gorsur) or 100 gar (Tibetan: \u0f66\u0f90\u0f62\u0f0b, ZYPY: gar). In Tibetan, renminbi is called mimangxogng\u00fc (Tibetan: \u0f58\u0f72\u0f0b\u0f51\u0f58\u0f44\u0f66\u0f0b\u0f64\u0f7c\u0f42\u0f0b\u0f51\u0f44\u0f74\u0f63\u0f0d, ZYPY: Mimang Xogng\u00fc) or mimang shog ngul.\nWhen used in the Uyghur autonomy region of Xinjiang, the renminbi is called Xelq puli (Uyghur: \u062e\u06d5\u0644\u0642 \u067e\u06c7\u0644\u0649\u200e)\n\n\n=== Production and minting ===\nRenminbi currency production is carried out by a state owned corporation, China Banknote Printing and Minting Corporation (CBPMC; \u4e2d\u56fd\u5370\u949e\u9020\u5e01\u603b\u516c\u53f8) headquartered in Beijing. CBPMC uses several printing, engraving and minting facilities around the country to produce banknotes and coins for subsequent distribution. Banknote printing facilities are based in Beijing, Shanghai, Chengdu, Xi'an, Shijiazhuang, and Nanchang. Mints are located in Nanjing, Shanghai, and Shenyang. Also, high grade paper for the banknotes is produced at two facilities in Baoding and Kunshan. The Baoding facility is the largest facility in the world dedicated to developing banknote material according to its website. In addition, the People's Bank of China has its own printing technology research division that researches new techniques for creating banknotes and making counterfeiting more difficult.\n\n\n=== Suggested future design ===\nOn 13 March 2006, some delegates to an advisory body at the National People's Congress proposed to include Sun Yat-sen and Deng Xiaoping on the renminbi banknotes. However, the proposal was not adopted.\n\n\n== Economics ==\n\n\n=== Value ===\n\nFor most of its early history, the RMB was pegged to the U.S. dollar at \u00a52.46 per USD (note: during the 1970s, it was revalued until it reached \u00a51.50 per USD in 1980). When China's economy gradually opened in the 1980s, the RMB was devalued in order to improve the competitiveness of Chinese exports. Thus, the official exchange rate increased from \u00a51.50 in 1980 to \u00a58.62 by 1994 (the lowest rate on record). Improving current account balance during the latter half of the 1990s enabled the Chinese government to maintain a peg of \u00a58.27 per USD from 1997 to 2005.\nThe RMB reached a record high exchange value of \u00a56.0395 to the U.S. dollar on 14 January 2014. Chinese leadership have been raising the yuan to tame inflation, a step U.S. officials have pushed for years to lower the massive trade deficit with China. Strengthening the value of the RMB also fits with the Chinese transition to a more consumer-led economic growth model.In 2015 the People's Bank of China again devalued their country's currency. As of  1 September 2015, the exchange rate for 1 USD is \u00a56.37.\n\n\n=== Depegged from the U.S. dollar ===\nOn 21 July 2005, the peg was finally lifted, which saw an immediate one-time RMB revaluation to \u00a58.11 per USD. The exchange rate against the euro stood at \u00a510.07060 yuan per euro.\nHowever the peg was reinstituted unofficially when the financial crisis hit: \"Under intense pressure from Washington, China took small steps to allow its currency to strengthen for three years starting in July 2005. But China 're-pegged' its currency to the dollar as the financial crisis intensified in July 2008.\"On 19 June 2010, the People\u2019s Bank of China released a statement simultaneously in Chinese and English indicating that they would \"proceed further with reform of the RMB exchange rate regime and increase the RMB exchange rate flexibility\". The news was greeted with praise by world leaders including Barack Obama, Nicolas Sarkozy and Stephen Harper. The PBoC maintained there would be no \"large swings\" in the currency. The RMB rose to its highest level in five years and markets worldwide surged on Monday, 21 June following China's announcement.In August 2015, Joseph Adinolfi, a reporter for MarketWatch, reported that China had re-pegged the RMB. In his article, he narrated that \"Weak trade data out of China, released over the weekend, weighed on the currencies of Australia and New Zealand on Monday. But the yuan didn\u2019t budge. Indeed, the Chinese currency, also known as the renminbi, has been remarkably steady over the past month despite the huge selloff in China\u2019s stock market and a spate of disappointing economic data. Market strategists, including Simon Derrick, chief currency strategist at BNY Mellon, and Marc Chandler, head currency strategist at Brown Brothers Harriman, said that\u2019s because China\u2019s policy makers have effectively re-pegged the yuan. \u201cWhen I look at the dollar-renminbi right now, that looks like a fixed exchange rate again. They\u2019ve re-pegged it,\u201d Chandler said.\"\n\n\n=== Managed float ===\nThe RMB has now moved to a managed floating exchange rate based on market supply and demand with reference to a basket of foreign currencies. In July 2005, the daily trading price of the U.S. dollar against the RMB in the inter-bank foreign exchange market was allowed to float within a narrow band of 0.3% around the central parity  published by the People's Bank of China; in a later announcement published on 18 May 2007, the band was extended to 0.5%. On 14 April 2012, the band was extended to 1.0%. On 17 March 2014, the band was extended to 2%.  China has stated that the basket is dominated by the United States dollar, euro, Japanese yen and South Korean won, with a smaller proportion made up of the British pound, Thai baht, Russian ruble, Australian dollar, Canadian dollar and Singapore dollar.On 10 April 2008, it traded at \u00a56.9920 per US dollar, which was the first time in more than a decade that a dollar had bought less than seven yuan, and at 11.03630 yuan per euro.\nBeginning in January 2010, Chinese and non-Chinese citizens have an annual exchange limit of a maximum of US$50,000. Exchange will only proceed if the applicant appears in person at the relevant bank, and presents their passport or Chinese ID; these deals are being centrally registered. The maximum dollar withdrawal is $10,000 per day, the maximum purchase limit of USD is $500 per day. This stringent management of the currency leads to a bottled-up demand for exchange in both directions. It is viewed as a major tool to keep the currency peg, preventing inflows of 'hot money'.\nA shift of Chinese reserves into the currencies of their other trading partners has caused these nations to shift more of their reserves into dollars, leading to no great change in the value of the renminbi against the dollar.\n\n\n=== Futures market ===\nRenminbi futures are traded at the Chicago Mercantile Exchange. The futures are cash-settled at the exchange rate published by the People's Bank of China.\n\n\n=== Purchasing power parity ===\nScholarly studies suggest that the yuan is undervalued on the basis of purchasing power parity analysis. One 2011 study suggests a 37.5% undervaluation.\nThe World Bank estimated that, by purchasing power parity, one International dollar was equivalent to approximately \u00a51.9 in 2004.\nThe International Monetary Fund estimated that, by purchasing power parity, one International dollar was equivalent to approximately \u00a53.462 in 2006, \u00a53.621 in 2007, \u00a53.798 in 2008, \u00a53.872 in 2009, \u00a53.922 in 2010, \u00a53.946 in 2011, \u00a53.952 in 2012, \u00a53.944 in 2013 and \u00a53.937 in 2014.The People\u2019s Bank of China lowered the renminbi\u2019s daily fix to the US dollar by 1.9 per cent to \u00a56.2298 on 11 August 2015. The People\u2019s Bank of China again lowered the renminbi\u2019s daily fix to the US dollar from \u00a56.620 to \u00a56.6375 after the Brexit on 27 June 2016. It had not been this low since December 2010.\n\n\n=== Internationalization ===\n\nBefore 2009, the Chinese renminbi had little to no exposure in the international markets because of strict government controls by the central Chinese government that prohibited almost all export of the currency, or use of it in international transactions. Transactions between Chinese companies and a foreign entity were generally denominated in US dollars. With Chinese companies unable to hold US dollars and foreign companies unable to hold Chinese yuan, all transactions would go through the People's Bank of China. Once the sum was paid by the foreign party in dollars, the central bank would pass the settlement in renminbi to the Chinese company at the state-controlled exchange rate.\nIn June 2009 the Chinese officials announced a pilot scheme where business and trade transactions were allowed between limited businesses in Guangdong province and Shanghai, and only counterparties in Hong Kong, Macau, and select ASEAN nations. Proving a success, the program was further extended to 20 Chinese provinces and counterparties internationally in July 2010, and in September 2011 it was announced that the remaining 11 Chinese provinces would be included.\nIn steps intended to establish the renminbi as an international reserve currency, China has agreements with Russia, Vietnam, Sri Lanka, Thailand, and Japan, allowing trade with those countries to be settled directly in renminbi instead of requiring conversion to US dollars, with Australia and South Africa to follow soon.\n\n\n=== International reserve currency ===\nCurrency restrictions regarding renminbi-denominated bank deposits and financial products were greatly liberalized in July 2010. In 2010 renminbi-denominated bonds were reported to have been purchased by Malaysia's central bank and that McDonald's had issued renminbi denominated corporate bonds through Standard Chartered Bank of Hong Kong. Such liberalization allows the yuan to look more attractive as it can be held with higher return on investment yields, whereas previously that yield was virtually none.  Nevertheless, some national banks such as Bank of Thailand (BOT) have expressed a serious concern about RMB since BOT cannot substitute the deprecated US dollars in its US$200 billion foreign exchange reserves for renminbi as much as it wishes because:\n\nThe Chinese government has not taken full responsibilities and commitments on economic affairs at global levels.\nRenminbi still has not become well-liquidated (fully convertible) yet.\nThe Chinese government still lacks deep and wide vision about how to perform fund-raising to handle international loans at global levels.To meet IMF requirements, China gave up some of its tight control over the currency.Countries that are left-leaning in the political spectrum had already begun to use the renminbi as an alternative reserve currency to the United States dollar; the Central Bank of Chile reported in 2011 to have US$91 million worth of renminbi in reserves, and the president of the Central Bank of Venezuela, Nelson Merentes, made statements in favour of the renminbi following the announcement of reserve withdrawals from Europe and the United States.\n\n\n=== Use as a currency outside mainland China ===\nThe two special administrative regions, Hong Kong and Macau, have their own respective currencies, according to the \"one country, two systems\" principle and the basic laws of the two territories.  Therefore, the Hong Kong dollar and the Macanese pataca remain the legal tenders in the two territories, and renminbi, although sometimes accepted, is not legal tender.  Banks in Hong Kong allow people to maintain accounts in RMB. Because of changes in legislation in July 2010, many banks around the world are now slowly offering individuals the chance to hold deposits in Chinese renminbi.\nThe RMB had a presence in Macau even before the 1999 return to the People's Republic of China from Portugal. Banks in Macau can issue credit cards based on the renminbi, but not loans. Renminbi-based credit cards cannot be used in Macau's casinos.The Republic of China, which governs Taiwan, believes wide usage of the renminbi would create an underground economy and undermine its sovereignty. Tourists are allowed to bring in up to \u00a520,000 when visiting Taiwan. These renminbi must be converted to the New Taiwan dollar at trial exchange sites in Matsu and Kinmen.  The Chen Shui-bian administration insisted that it would not allow full convertibility until the mainland signs a bilateral foreign exchange settlement agreement, though president Ma Ying-jeou has pledged to allow full convertibility as soon as possible.\nThe renminbi circulates in some of China's neighbors, such as Pakistan, Mongolia and northern Thailand. Cambodia welcomes the renminbi as an official currency and Laos and Myanmar allow it in border provinces such as Wa and Kokang and economic zones like Mandalay. Though unofficial, Vietnam recognizes the exchange of the renminbi to the \u0111\u1ed3ng.Since 2007, RMB-nominated bonds are issued outside mainland China; these are colloquially called \"dim sum bonds\". In April 2011, the first initial public offering denominated in renminbi occurred in Hong Kong, when the Chinese property investment trust Hui Xian raised \u00a510.48 billion ($1.6 billion) in its IPO. Beijing has allowed renminbi-denominated financial markets to develop in Hong Kong as part of the effort to internationalise the renminbi.\n\n\n=== Other markets ===\n\nSince currency flows in and out of mainland China are still restricted, RMB traded in off-shore markets, such as the Hong Kong market, can have a different value to RMB traded on the mainland. The offshore RMB market is usually denoted as CNH, but there is another RMB interbank and spot market in Taiwan for domestic trading known as CNT.\nOther RMB markets include the dollar-settled non-deliverable forward (NDF), and the trade-settlement exchange rate (CNT).Note that the two CNT mentioned above are different from each other.\n\n\n=== Current exchange rates ===\n\n\n== See also ==\nChina Banknote Printing and Minting Corporation (CBPMC)\nChinese lunar coins\nEconomy of China\nList of renminbi exchange rates\nTibetan coins and currency\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\nPhotographs of all Chinese currency and sound of pronunciation in Chinese\nStephen Mulvey, Why China's currency has two names - BBC News, 2010-06-26\nHistorical and current banknotes of the People's Republic of China (in English) (in German)\nForeign exchange certificates (FEC) of the People's Republic of China (in English) (in German)",
        "unit": "chinese yuan",
        "url": "https://en.wikipedia.org/wiki/Chinese_yuan"
    },
    {
        "_id": "Base_pair",
        "clean": "Base pair",
        "text": "A base pair (bp) is a unit consisting of two nucleobases bound to each other by hydrogen bonds.  They form the building blocks of the DNA double helix and contribute to the folded structure of both DNA and RNA. Dictated by specific hydrogen bonding patterns, Watson-Crick base pairs (guanine-cytosine and adenine-thymine) allow the DNA helix to maintain a regular helical structure that is subtly dependent on its nucleotide sequence. The complementary nature of this based-paired structure provides a redundant copy of the genetic information encoded within each strand of DNA. The regular structure and data redundancy provided by the DNA double helix make DNA well suited to the storage of genetic information, while base-pairing between DNA and incoming nucleotides provides the mechanism through which DNA polymerase replicates DNA and RNA polymerase transcribes DNA into RNA. Many DNA-binding proteins can recognize specific base pairing patterns that identify particular regulatory regions of genes.\nIntramolecular base pairs can occur within single-stranded nucleic acids. This is particularly important in RNA molecules (e.g., transfer RNA), where Watson-Crick base pairs (guanine-cytosine and adenine-uracil) permit the formation of short double-stranded helices, and a wide variety of non-Watson-Crick interactions (e.g., G-U or A-A) allow RNAs to fold into a vast range of specific three-dimensional structures. In addition, base-pairing between transfer RNA (tRNA) and messenger RNA (mRNA) forms the basis for the molecular recognition events that result in the nucleotide sequence of mRNA becoming translated into the amino acid sequence of proteins via the genetic code.\nThe size of an individual gene or an organism's entire genome is often measured in base pairs because DNA is usually double-stranded. Hence, the number of total base pairs is equal to the number of nucleotides in one of the strands (with the exception of non-coding single-stranded regions of telomeres). The haploid human genome (23 chromosomes) is estimated to be about 3.2 billion bases long and to contain 20,000\u201325,000 distinct protein-coding genes. A kilobase (kb) is a unit of measurement in molecular biology equal to 1000 base pairs of DNA or RNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 \u00d7 1037 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).\n\n\n== Hydrogen bonding and stability ==\n\nHydrogen bonding is the chemical interaction that underlies the base-pairing rules described above. Appropriate geometrical correspondence of hydrogen bond donors and acceptors allows only the \"right\" pairs to form stably. DNA with high GC-content is more stable than DNA with low GC-content. But, contrary to popular belief, the hydrogen bonds do not stabilize the DNA significantly; stabilization is mainly due to stacking interactions.The larger nucleobases, adenine and guanine, are members of a class of double-ringed chemical structures called purines; the smaller nucleobases, cytosine and thymine (and uracil), are members of a class of single-ringed chemical structures called pyrimidines. Purines are complementary only with pyrimidines: pyrimidine-pyrimidine pairings are energetically unfavorable because the molecules are too far apart for hydrogen bonding to be established; purine-purine pairings are energetically unfavorable because the molecules are too close, leading to overlap repulsion. Purine-pyrimidine base pairing of AT or GC or UA (in RNA) results in proper duplex structure. The only other purine-pyrimidine pairings would be AC and GT and UG (in RNA); these pairings are mismatches because the patterns of hydrogen donors and acceptors do not correspond. The GU pairing, with two hydrogen bonds, does occur fairly often in RNA (see wobble base pair).\nPaired DNA and RNA molecules are comparatively stable at room temperature, but the two nucleotide strands will separate above a melting point that is determined by the length of the molecules, the extent of mispairing (if any), and the GC content. Higher GC content results in higher melting temperatures; it is, therefore, unsurprising that the genomes of extremophile organisms such as Thermus thermophilus are particularly GC-rich. On the converse, regions of a genome that need to separate frequently \u2014 for example, the promoter regions for often-transcribed genes \u2014 are comparatively GC-poor (for example, see TATA box). GC content and melting temperature must also be taken into account when designing  primers for PCR reactions.\n\n\n=== Examples ===\nThe following DNA sequences illustrate pair double-stranded patterns. By convention, the top strand is written from the 5' end to the 3' end; thus, the bottom strand is written 3' to 5'.\n\nA base-paired DNA sequence:\nATCGATTGAGCTCTAGCG\nTAGCTAACTCGAGATCGCThe corresponding RNA sequence, in which uracil is substituted for thymine where uracil takes its place in the RNA strand:\nAUCGAUUGAGCUCUAGCG\nUAGCUAACUCGAGAUCGC\n\n\n== Base analogs and intercalators ==\n\nChemical analogs of nucleotides can take the place of proper nucleotides and establish non-canonical base-pairing, leading to errors (mostly point mutations) in DNA replication and DNA transcription. This is due to their isosteric chemistry. One common mutagenic base analog is 5-bromouracil, which resembles thymine but can base-pair to guanine in its enol form.\nOther chemicals, known as DNA intercalators, fit into the gap between adjacent bases on a single strand and induce frameshift mutations by \"masquerading\" as a base, causing the DNA replication machinery to skip or insert additional nucleotides at the intercalated site. Most intercalators are large polyaromatic compounds and are known or suspected carcinogens. Examples include ethidium bromide and acridine.\n\n\n== Unnatural base pair (UBP) ==\n\nAn unnatural base pair (UBP) is a designed subunit (or nucleobase) of DNA which is created in a laboratory and does not occur in nature.  DNA sequences have been described which use newly created nucleobases to form a third base pair, in addition to the two base pairs found in nature, A-T (adenine \u2013 thymine) and G-C (guanine \u2013 cytosine).  A few research groups have been searching for a third base pair for DNA, including teams led by Steven A. Benner, Philippe Marliere, Floyd Romesberg and Ichiro Hirao. Some new base pairs have been reported.In 1989 Steven Benner (then working at the Swiss Federal Institute of Technology in Zurich) and his team led with modified forms of cytosine and guanine into DNA molecules in vitro. The nucleotides, which encoded RNA and proteins, were successfully replicated in vitro. Since then, Benner's team has been trying to engineer cells that can make foreign bases from scratch, obviating the need for a feedstock.In 2002, Ichiro Hirao\u2019s group in Japan developed an unnatural base pair between 2-amino-8-(2-thienyl)purine (s) and pyridine-2-one (y) that functions in transcription and translation, for the site-specific incorporation of non-standard amino acids into proteins. In 2006, they created 7-(2-thienyl)imidazo[4,5-b]pyridine (Ds) and pyrrole-2-carbaldehyde (Pa) as a third base pair for replication and transcription. Afterward, Ds and 4-[3-(6-aminohexanamido)-1-propynyl]-2-nitropyrrole (Px) was discovered as a high fidelity pair in PCR amplification. In 2013, they applied the Ds-Px pair to DNA aptamer generation by in vitro selection (SELEX) and demonstrated the genetic alphabet expansion significantly augment DNA aptamer affinities to target proteins.In 2012, a group of American scientists led by Floyd Romesberg, a chemical biologist at the Scripps Research Institute in San Diego, California, published that his team designed an unnatural base pair (UBP).  The two new artificial nucleotides or Unnatural Base Pair (UBP) were named d5SICS and dNaM. More technically, these artificial nucleotides bearing hydrophobic nucleobases, feature two fused aromatic rings that form a (d5SICS\u2013dNaM) complex or base pair in DNA. His team designed a variety of in vitro or \"test tube\" templates containing the unnatural base pair and they confirmed that it was efficiently replicated with high fidelity in virtually all sequence contexts using the modern standard in vitro techniques, namely PCR amplification of DNA and PCR-based applications. Their results show that for PCR and PCR-based applications, the d5SICS\u2013dNaM unnatural base pair is functionally equivalent to a natural base pair, and when combined with the other two natural base pairs used by all organisms, A\u2013T and G\u2013C, they provide a fully functional and expanded six-letter \"genetic alphabet\".In 2014 the same team from the Scripps Research Institute reported that they synthesized a stretch of circular DNA known as a plasmid containing natural T-A and C-G base pairs along with the best-performing UBP Romesberg's laboratory had designed and inserted it into cells of the common bacterium E. coli that successfully replicated the unnatural base pairs through multiple generations. The transfection did not hamper the growth of the E. coli cells and showed no sign of losing its unnatural base pairs to its natural DNA repair mechanisms. This is the first known example of a living organism passing along an expanded genetic code to subsequent generations. Romesberg said he and his colleagues created 300 variants to refine the design of nucleotides that would be stable enough and would be replicated as easily as the natural ones when the cells divide.  This was in part achieved by the addition of a supportive algal gene that expresses a nucleotide triphosphate transporter which efficiently imports the triphosphates of both d5SICSTP and dNaMTP into E. coli bacteria. Then, the natural bacterial replication pathways use them to accurately replicate a plasmid containing d5SICS\u2013dNaM. Other researchers were surprised that the bacteria replicated these human-made DNA subunits.The successful incorporation of a third base pair is a significant breakthrough toward the goal of greatly expanding the number of amino acids which can be encoded by DNA, from the existing 20 amino acids to a theoretically possible 172, thereby expanding the potential for living organisms to produce novel proteins. The artificial strings of DNA do not encode for anything yet, but scientists speculate they could be designed to manufacture new proteins which could have industrial or pharmaceutical uses. Experts said the synthetic DNA incorporating the unnatural base pair raises the possibility of life forms based on a different DNA code.\n\n\n== Length measurements ==\nThe following abbreviations are commonly used to describe the length of a D/RNA molecule:\n\nbp  = base pair(s)\u2014one bp corresponds to approximately 3.4 \u00c5 (340 pm)  of length along the strand, and to roughly 618 or 643 daltons for DNA and RNA respectively.\nkb (= kbp) = kilo base pairs = 1,000 bp\nMb (= Mbp) = mega base pairs = 1,000,000 bp\nGb = giga base pairs = 1,000,000,000 bp.For single-stranded DNA/RNA, units of nucleotides are used\u2014abbreviated nt (or knt, Mnt, Gnt)\u2014as they are not paired.\nTo distinguish between units of computer storage and bases, kbp, Mbp, Gbp, etc. may be used for base pairs.\nThe centimorgan is also often used to imply distance along a chromosome, but the number of base pairs it corresponds to varies widely. In the Human genome, the centimorgan is about 1 million base pairs.\n\n\n== See also ==\nList of Y-DNA single-nucleotide polymorphisms\nNon-canonical base pairing\n\n\n== References ==\n\n\n== Further reading ==\nWatson JD; Baker TA; Bell SP; Gann A; Levine M; Losick R (2004). Molecular Biology of the Gene (5th ed.). Pearson Benjamin Cummings: CSHL Press. (See esp. ch. 6 and 9)\nAstrid Sigel; Helmut Sigel; Roland K. O. Sigel, eds. (2012). Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. Springer. doi:10.1007/978-94-007-2172-2. ISBN 978-9-4007-2171-5.\nClever, Guido H.; Shionoya, Mitsuhiko (2012). \"Chapter 10. Alternative DNA Base-Pairing through Metal Coordination\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 269\u2013294. doi:10.1007/978-94-007-2172-2_10. ISBN 978-94-007-2171-5. PMID 22210343.\nMegger, Dominik A.; Megger, Nicole; Mueller, Jens (2012). \"Chapter 11. Metal-Mediated Base Pairs in Nucleic Acids with Purine and Pyrimidine-Derived Neucleosides\". Interplay between Metal Ions and Nucleic Acids. Metal Ions in Life Sciences. 10. pp. 295\u2013317. doi:10.1007/978-94-007-2172-2_11. ISBN 978-94-007-2171-5. PMID 22210344.\n\n\n== External links ==\nDAN\u2014webserver version of the EMBOSS tool for calculating melting temperatures",
        "unit": "mega base pair",
        "url": "https://en.wikipedia.org/wiki/Base_pair"
    }
]